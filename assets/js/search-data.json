{
  
    
        "post0": {
            "title": "Iterative Mask Filling",
            "content": "- 논문 링크: https://arxiv.org/pdf/2401.01830 . - 논문 구현: https://github.com/Jaesu26/textmentations . - 핵심 아이디어 알아 보기 . &#44060;&#50836; . - 대량의 데이터는 종종 복잡한 모델을 사용하는 것보다 더 큰 영향력을 행사한다 . - 하지만 대량의 라벨링된 데이터를 얻기 위해 많은 비용이 필요하다 . - 이런 상황에서 데이터 증강은 비싼 비용 지불없이 모델의 성능 및 일반화 능력 향상을 이끌어 낼 수 있다 . - 증강된 데이터는 원본 문장의 라벨을 따르면서도 기존의 데이터 분포와는 달라야한다 . - Iterative Mask Filling은 이를 충족시키는 새로운 텍스트 증강 기법 중 하나이다 . Iterative Mask Fill . . - 문장의 맥락을 파악하기 위해 대량의 코퍼스로 학습된 마스크 언어 모델(masked language model)을 사용한다 . - iterative mask filling 알고리즘은 다음과 같다 . 1. 문장을 단어 단위로 토큰화한다 (영어의 경우 띄어쓰기 단위로 나누면 된다) . 2. 나뉜 토큰의 개수를 $N$이라고 하면 첫 번째 토큰부터 $N$번째 토큰까지 순회하며 다음을 수행한다 . 2-1. 현재 인덱스를 $i$라고 하자. $i=1$부터 시작한다 . 2-2. $i$번 째 토큰를 마스크 토큰으로 대체한다 . 2-3. $i$번 째의 마스크 토큰을 포함한 전체 토큰을 모델에 입력으로 사용하기 위해 벡터로 변환한다 . 2-4. 해당 벡터를 마스크 언어 모델에 통과시켜 마스크 토큰을 대체할 수 있는 (토큰, 마스킹 되기 전의 원래 토큰이 해당 토큰일 확률) 쌍을 얻는다 . 2-5. 확률을 기준으로 내림차순 정렬 후 상위 $k$개의 토큰 중에서 하나를 확률에 따라 가중치를 두어 무작위로 선택한다 . 2-6. 2-5에서 선택된 토큰으로 마스크 토큰을 대체한다 . 3. 토큰을 합하여 문장으로 변환한다 .",
            "url": "https://jaesu26.github.io/study-blog/paper%20review/2024/10/21/iterative-mask-filling.html",
            "relUrl": "/paper%20review/2024/10/21/iterative-mask-filling.html",
            "date": " • Oct 21, 2024"
        }
        
    
  
    
        ,"post1": {
            "title": "VIME (Value Imputation and Mask Estimation)",
            "content": "- 논문 링크: https://vanderschaar-lab.com/papers/NeurIPS2020_VIME.pdf . - 논문 구현: https://github.com/Jaesu26/vime . - 핵심 아이디어 알아 보기 . &#44060;&#50836; . - 이미지넷과 같이 라벨링된 많은 데이터를 기반으로 많은 지도 학습 모델이 발전했다 . - 하지만 현실에서 라벨링된 데이터를 많이 수집하는 것은 비싸고 때로는 불가능하다 . - 라벨링만 되지 않았을 뿐 데이터는 많이 존재하는데 이를 활용한 것이 자기 지도 학습과 준 지도 학습이다 . - 하지만 현존하는 자기 지도 학습과 준 지도 학습은 정형 데이터에 효과적이지 않다 . - 자기 지도 학습과 준 지도 학습은 라벨링 되지 않은 데이터를 어떻게 활용하느냐가 중요하다 . - 원본 데이터에 약간의 변형을 가한 후 복원한 정보를 사용해 원본과 복원된 것의 차이를 학습한다 (pretext task) . - 이미지는 회전, 색상 변환 등 변형 방식이 다양하지만 정형 데이터는 그렇지 않다 (정형 데이터에 회전 변환?) . - VIME은 mask vector estimation과 feature vector estimation이라는 새로운 pretext tasks를 제안하여 자기 지도 학습을 해결하고자 한다 . - 또한, 새로운 정형 데이터 augmentation method을 제안한다 . Self-supervised learning (VIME) . . - 새로운 2가지 pretext tasks: feature vector esitimation, mask vector estimation . - 2가지 pretext tasks는 하나의 pretext 분포 $P_{X_s, Y_s}$를 공유한다 . - 첫 번째로 mask vector 제너레이터는 $ mathbf{m} = [m_1, dots, m_d]^ top in {0, 1 }^d$를 생성한다 . - $m_j$는 마스킹할 확률이 $p_m$인 베르누이 분포에서 샘플링된 것이다 (i.e. $p_{ mathbf{m}} = prod limits_{j=1}^{d} operatorname{Bern} left(m_j|p_m right))$ . - 두 번째로 pretext 제너레이터 $g_m: mathcal{X} times {0, 1 }^d to mathcal{X}$은 라벨링되지 않은 $ mathcal{D}_u$에서 샘플링한 $ mathbf{x}$와 $ textbf{m}$을 사용해 $ mathbf{ tilde x}$를 생성한다 . - 이때 $ mathbf{ tilde x} = g_m left( mathbf{x}, mathbf{m} right) = mathbf{m} odot mathbf{ bar x} + (1- mathbf{m}) odot mathbf{x}$ . - $ mathbf{ bar x}$는 $ mathbf x$의 각 피쳐에 대해 랜덤 셔플을 적용한 행렬이다 . - 즉, 마스킹 안된 곳은 원본을 사용하고 마스킹된 곳은 랜덤 셔플한 것을 사용하겠다는 의미이다 . - 인코더 $e$는 $ mathbf{ tilde x}$를 $ mathbf z$로 재표현한 후 pretext predictive model이 $ mathbf z$로부터 원래의 $ mathbf x$를 추정한다 . - 위의 문제를 해결하기 위해 2개의 서브 태스크로 나누어 해결한다 . 1. mask vector estimation: 어떤 피쳐가 마스크 되었는지 예측한다 . - $s_m: mathcal{Z} to {0, 1 }^d$, $ mathbf z$를 입력으로 사용해 $ mathbf{ hat{m}}$을 추정한다 . 2. feature vector esimation: 마스킹된 피쳐의 원래 값을 추정한다 . - $s_r: mathcal{Z} to mathcal{X}$, $ mathbf z$를 입력으로 사용해 $ mathbf{ hat{x}}$을 추정한다 . - $e$와 $s_m, s_r$은 다음의 최적화 문제에서 함께 학습된다 . $$ min_{e,s_m,s_r} mathbb{E}_{ mathbf{x} sim P_X, mathbf{m} sim P_{ mathbf m}, mathbf{ bar x} sim g_m( mathbf{x}, mathbf{m})} left[l_m left( mathbf{m}, mathbf{ hat m} right) + alpha cdot l_r left( mathbf{x}, mathbf{ hat x} right) right]$$- 이때 $ mathbf{ hat m} = (s_m circ e)( mathbf{ tilde x}), quad mathbf{ hat x} = (s_r circ e )( mathbf{ tilde x})$ . $$l_m left( mathbf{m}, mathbf{ hat m} right) = - frac{1}{d} left[ sum limits_{j=1}^{d}m_j log left[(s_m circ e)_j( mathbf{ tilde x}) right] + (1- m_j) log left[(1- s_m circ e)_j( mathbf{ tilde x}) right] right]$$- $l_m$은 마스크 벡터 로스로 마스크 벡터의 각 차원에 대해 바이너리 크로스 엔트로피를 계산한 후 평균낸 것이다 . - $l_r$은 재구성 로스 (reconstruction loss)로 다음과 같다 . $$l_r left( mathbf x, mathbf{ hat x} right) = frac{1}{d} left[ sum limits_{j=1}^{d} left(x_j - (s_r circ e)_j( mathbf{ tilde x}) right)^2 right]$$ . - 범주형 변수의 경우 MSE loss 대신에 cross entropy loss를 사용한다 . - 이 과정에서 인코더 $e$는 $ mathbf{x}$에서 상관관계가 높은 변수들을 포착하는 법과 $ mathbf{x}$로 복구할 수 있는 잠재 공간 $ mathbf{z}$를 만드는 법을 배운다 . Semi-supervised learning (VIME) . . - 여기서는 self-supervised learning에서 학습된 인코더 $e$를 semi-supervised learning에 활용하는 법을 보인다 . - $f_e = f circ e, ; hat{y}=f_e( mathbf{x})$, predictive model $f$를 다음의 목적 함수를 최소화하는 방향으로 학습시킨다 . $$ mathcal{L}_{ text{final}} = mathcal{L}_s + beta cdot mathcal{L}_u$$ . - supervised loss $ mathcal{L}_s$는 다음과 같다 . $$ mathcal{L}_s = mathbb{E}_{( mathbf{x},y) sim P_{X,Y}} left[l_s left(y, f_e( mathbf{x}) right) right]$$ . - $l_s$는 일반적인 지도 학습에서 사용되는 손실 함수로 MSE loss나 cross entropy loss같은 것이다 . - unsupervised(consistency) loss $ mathcal{L}_u$는 원래 샘플 $ mathbf{x}$와 재구성된 $ mathbf{ tilde x}$로 정의된다 . $$ mathcal{L}_u = mathbb{E}_{ mathbf{x} sim P_X, mathbf{m} sim p_{ mathbf{m}}, mathbf{ tilde x} sim g_m( mathbf{x}, mathbf{m})} left[ left(f_e( mathbf{ tilde x}) - f_e( mathbf{x}) right)^2 right]$$ . - consistency loss는 모델 $f$가 $ mathbf{x}$에 약간의 변형을 가하더라도 기존과 동일한 $y$로 예측하도록 만든다 . - 약간의 변형이라면 원본 클래스인 $y$가 손상되지 않을 것이므로 합리적인 생각이며 이를 통해 라벨링되지 않은 데이터를 활용할 수 있게 만든다 . - consistency loss ($ mathcal{L}_u$)에 집중해보자 . - 고정된 샘플 $ mathbf{x}$에 대해 $ mathcal{L}_u$는 $p_{ mathbf{m}}$과 $g_m( mathbf{x}, mathbf{m})$에 관한 식이며 $f_e( mathbf{ tilde{x}})$의 분산으로 해석될 수 있다 . - 약간의 변형이 가해져도 동일한 클래스여야 하므로 합리적인 방식이다 . - $ mathcal{L}_u$를 $f_e( mathbf{ tilde{x}})$의 분산으로 해석한다면 $ mathcal{L}_u$의 추정량 $ hat{ mathcal{L}}_u$는 다음과 같다 . $$ hat{ mathcal{L}}_u = frac{1}{N_b K} sum limits_{i=1}^{N_b} sum limits_{k=1}^{K} left[ left(f_e( mathbf{ tilde{x}}_{i,k}) - f_e( mathbf{x}_i) right)^2 right] = frac{1}{N_b K} sum limits_{i=1}^{N_b} sum limits_{k=1}^{K} left[ left(f( mathbf{z}_{i,k}) - f( mathbf{z}_i) right)^2 right]$$- 에폭마다 배치로부터 $K$개의 증강 샘플 $ mathbf{ tilde x}_1, dots, mathbf{ tilde x}_K$이 생성된다 . - $N_b$는 배치 크기, $ mathbf{z}_i$는 $f_e( mathbf{x})$이며 $ mathbf{z}_{i,k}, ,k=1, dots,K$는 $ mathbf{ tilde x}_1, dots, mathbf{ tilde x}_K$로부터 만든 것이다 . - 훈련이 끝난 후 테스트 샘플의 아웃풋은 $ hat{y} = f_e left( mathbf{x}^t right)$와 같이 얻어진다 . &#48512;&#47197; . - 분산: $Var(X) = E left(X-E(X) right)^2$ .",
            "url": "https://jaesu26.github.io/study-blog/paper%20review/2024/10/16/vime.html",
            "relUrl": "/paper%20review/2024/10/16/vime.html",
            "date": " • Oct 16, 2024"
        }
        
    
  
    
        ,"post2": {
            "title": "파이썬 TypeVar",
            "content": "- 참고: https://docs.python.org/3.11/library/typing.html#typing.TypeVar . - 참고: https://peps.python.org/pep-0483/ . - 참고: https://peps.python.org/pep-0484/ . TypeVar &#54028;&#54756;&#52824;&#44592; . class typing.TypeVar(name, *constraints, bound=None, covariant=False, contravariant=False) . - TypeVar는 어떨 때 사용하는지, 각 파라미터가 무슨 역할을 하는지 알아보자 . &#50780; &#49324;&#50857;&#54644;? . def repeat(x: str, n: int) -&gt; list[str]: &quot;&quot;&quot;Return a list containing n references to x.&quot;&quot;&quot; return [x] * n . - 위와 같은 함수를 고려해보자 . - 입력으로 x가 들어오면 x를 n개 담은 리스트를 반환한다 (참고로 참조라 원소의 id는 동일함) . - 이 때 x의 타입은 str이길 기대한다 . - 물론 str이 아니어도 함수는 문제없이 작동하긴 한다 . - 그런데 만약 x의 타입으로 int도 가능하게 하고 싶으면 어떻게 해야 할까? . def repeat(x: str | int, n: int) -&gt; list[str | int]: &quot;&quot;&quot;Return a list containing n references to x.&quot;&quot;&quot; return [x] * n . - 위와 같이 | 또는 typing.Union[str, int]를 사용해 나타내는 걸 생각해볼 수 있다 . - 그런데 이러한 표기법엔 조금의 문제가 존재한다 . - x 타입이 str이라면 반환 타입은 당연히 list[str]여야 될 것 같지만 list[int]여도 문제 없다 (mypy같은 타입 검사기에 오류가 발생하지 않음) . - 표기법의 의미 그대로 str 또는 int이기 때문이다 . - 물론 위 함수는 동작상 반환 값의 타입이 list[x]의 타입을 따라가지만 다른 경우엔 문제가 될 수 있다 . def add(a: str | int, b: str | int) -&gt; str | int: return a + b . - 위의 add 함수를 고려하자 . - a, b, 반환 값의 타입 모두 str이거나 int이라는 첫 번째 경우의 의도와 같이 작성한 것이지만 . - 실제론 a와 b의 타입이 달라도 타입 검사기에 문제가 생기지 않는다 . - 하지만 둘의 타입이 다르면 실행 시 오류가 발생한다 . - 즉, a의 타입이 str이면 b도 str이면 좋겠고 a가 int라면 b도 int이면 좋겠다 . - 이러한 소망은 Union을 사용해선 이룰 수 없다 . - 이를 가능하게 하는 것이 TypeVar이다 . &#46308;&#50612;&#44032;&#44592;&#50640; &#50526;&#49436; . &#49436;&#48652; &#53440;&#51077;&#50640; &#45824;&#54644; &#50508;&#50500;&#48372;&#51088; . def greeting(name: str) -&gt; str: return &quot;Hello &quot; + name class MyStr(str): ... greeting(&quot;abc&quot;) # Possible greeting(MyStr(&quot;abc&quot;)) # Also possible . - 기본적으로 특정 타입의 서브 타입도 허용된다 (name은 str 타입뿐만 아니라 str의 서브 타입도 가질 수 있다) . - 그렇다면 서브 타입이란게 정확히 무엇일까? . - first_var가 first_type 타입을 가지고 second_var가 second_type 타입을 가진다고 해보자 . - first_var에 second_var를 할당해도 문제가 없을까? (즉, first_var = second_var가 문제 없이 가능한가?) . - 다음 두 조건을 만족하면 문제 없이 가능하다고 하자 . 1. second_type의 모든 값은 first_type의 값 집합에도 존재한다 . 2. first_type의 모든 함수는 second_type의 함수 집합에도 존재한다 . - 이 두 조건을 만족한다면 second_type은 first_type의 서브 타입으로 정의된다 . - 위 두 조건에 의해 아래 두 문장이 성립한다 . 1. 모든 타입은 자기 자신의 서브 타입이다 . 2. 값 집합은 서브 타입으로 대체하는 과정에서 더 작아지지만 함수 집합은 더 커진다 . - 직관적인 예시로 Dog 클래스와 Animal 클래스를 생각해보자 . - 모든 Dog는 Animal이므로 당연하게도 Dog는 Animal보다 더 많은 함수를 가지고 있다 (2번째 정의) . - 예컨대 Dog가 bark 함수를 가지고 있을 수 있는데 Animal은 bark 함수를 가지고 있지 않다 (모든 Animal이 짖을 수 있는 건 아니다) . 또 다른 예시 | . - int는 float의 서브 타입이다 (직관적으로 당연해 보인다) . - 모든 정수는 실수에 속하며 더욱 많은 연산자를 지원한다 (예컨대 비트 쉬프트 연산이 있다) . lucky_number = 3.14 # type: float lucky_number = 42 # Safe lucky_number * 2 # This works lucky_number &lt;&lt; 5 # Fails unlucky_number = 13 # type: int unlucky_number &lt;&lt; 5 # This works unlucky_number = 2.72 # Unsafe . - lucky_number는 float 타입이다 . - int는 float의 서브 타입이므로 할당 가능하다 . - 하지만 float 타입 변수에는 int 타입 변수에만 적용할 수 있는 비트 쉬프트 연산을 적용할 수 없다 . - unluck_number는 int 타입이다 . - 비트 쉬프트 연산은 당연히 작동한다 . - 하지만 float은 int의 서브 타입이 아니므로 값을 할당할 수 없다 . 또 다른 예시 2 | . def append_pi(lst: list[float]) -&gt; None: lst += [3.14] my_list = [1, 3, 5] # type: list[int] append_pi(my_list) # Naively, this should be safe... my_list[-1] &lt;&lt; 5 # ... but this fails . - int는 float의 서브 타입이지만 list[int]는 list[float]의 서브 타입이 아니다 . - list[int]가 list[float]의 서브 타입이려면 위에서 언급했던 두 조건을 만족해야 한다 . - list[float]로부터 파생될 수 있는 모든 값은 list[int]를 포함하므로 첫 번째 조건은 만족한다 . - 하지만 append_pi 함수에 list[int]를 인자로 전달하면 기존의 가능한 연산을 적용할 수 없다 . - my_list의 타입은 list[int]이므로 각 원소에 대해 비트 연산이 가능해야 한다 . - 하지만 append_pi 함수로 $ pi$를 마지막 원소에 추가하면 해당 원소에 대해 비트 연산이 불가능해진다 . - 즉, 원해 가능한 연산자를 적용하지 못해 함수 집합이 오히려 더 작아졌으므로 두 번째 조건을 만족하지 못한다 . &#44592;&#48376; &#50857;&#48277; . 첫 번째 예시 | . T = TypeVar(&quot;T&quot;) # Can be anything def repeat(x: T, n: int) -&gt; list[T]: return [x] * n def multiply(x: T, n: int) -&gt; T: return x * n . - T = TypeVar(&quot;T&quot;)와 같이 변수명과 name 인자명을 동일하게 작성해야 한다 . - 이제부터 T는 함수 내에서 임의의 타입을 의미한다 . - 만약 repeat 함수에서 x의 타입이 int라면 반환값의 타입은 list[int]이다 . - 참고로 T의 타입은 동일한 함수내에서만 일치하면 된다 . - repeat 함수에서 T의 타입으로 int를 사용했다고 multiply 함수에서도 int로만 사용해야 된다는 것은 아니다 . - 그런데 모든 타입이 가능하게 하기 보단 특정 타입만 가능하게 하고 싶을 수 있다 . - 이런 경우엔 제한하고 싶은 타입을 *constraints로 전달하면 된다 . 두 번째 예시 | . A = TypeVar(&quot;A&quot;, str, bytes) # Must be exactly str or bytes class MyStr(str): ... def concatenate(x: A, y: A) -&gt; A: return x + y def do_nothing(x: A) -&gt; A: return x res1 = concatenate(&quot;a&quot;, &quot;b&quot;) # Type of res1 is str res2 = concatenate(MyStr(&quot;a&quot;), &quot;b&quot;) # Type of res2 is str res3 = concatenate(b&quot;a&quot;, b&quot;b&quot;) # Type of res3 is bytes res4 = concatenate(&quot;a&quot;, b&quot;b&quot;) # Error, type variable &quot;A&quot; can not be object res5 = do_nothing(MyStr(&quot;ab&quot;)) reveal_type(res5) # Type of res5 is str . - A = TypeVar(&quot;A&quot;, str, bytes)라면 A의 타입으론 str 또는 bytes만 가능하다 . - 여기서 Must be exactly str or bytes란 표현이 오해를 불러올 수 있다 . - 파이썬은 기본적으로 서브 타입을 허용한다 . - 즉, A 타입을 가지는 변수에 str의 서브 타입인 MyStr을 대입해도 문제없다 . - 대신 str의 서브 타입인 MyStr을 사용하더라도 타입 검사기는 해당 변수의 타입이 MyStr이 아닌 str인 것으로 간주한다 . - res5 = do_nothing(MyStr(&quot;ab&quot;))의 경우 res5의 타입을 검사하면 MyStr여야 될 것 같지만 실제로는 str이다 . - concatenate(&quot;a&quot;, b&quot;b&quot;)는 오류를 발생시킨다 . - 왜냐하면 str과 bytes의 공통 슈퍼 타입은 object인데 TypeVar를 사용해 str과 bytes만 가능하도록 제한을 걸었기 때문이다 . - 한편, 제한하는 타입은 2개 이상부터 가능하다 (예컨대 S = TypeVar(&quot;S&quot;, str)과 같이 할 수 없다) . 세 번째 예시 | . S = TypeVar(&quot;S&quot;, bound=str) # Can be any subtype of str def print_capitalized(x: S) -&gt; S: print(x.capitalize()) return x res1 = print_capitalized(MyStr(&quot;abc&quot;)) # Type of res1 is MyStr . - 대신 bound를 사용할 수 있다 . - S = TypeVar(&quot;S&quot;, bound=str)와 같이 할당하면 S는 타입으로 str 또는 str의 sub type을 취할 수 있다 . - constraints와 달리 bound는 서브 타입을 허용한다 . - res1 = print_capitalized(MyStr(&quot;abc&quot;))에서 타입 검사기로 res1의 타입을 검사하면 str이 아닌 MyStr이다 . - 하위 타입 말고 정확히 str 타입으로 강제하는 것은 불가능하다 (이런 경우라면 런타입에서 타입이 str인지 검사하자) . 네 번째 예시 | . T = TypeVar(&quot;T&quot;) # Can be anything class UserID(int): ... def do_nothing(one_arg: T, other_arg: T) -&gt; None: pass do_nothing(1, 2) # Ok, T is int do_nothing(&quot;abc&quot;, UserID(42)) # Also Ok, T is object def do_something1(one_arg: T, other_arg: T) -&gt; None: # Error print(one_arg.jungsanghwa()) print(other_arg.letsgo()) def do_something2(one_arg: Any, other_arg: Any) -&gt; None: # OK print(one_arg.jungsanghwa()) print(other_arg.letsgo()) . - T = TypeVar(&quot;T&quot;)는 정말 모든 것이 될 수 있을 것 같지만 그렇지는 않다 . covariant, contravariant . - covariant (공변성): 타입이 상속 계층을 따라 동일한 방향으로 변경된다 . - contravariant (반공변성): 타입이 상속 계층을 따라 반대 방향으로 변경된다 . - 위 두 파라미터를 사용한 타입 변수는 단독으로는 사용 불가능하고 list와 같은 제네릭 타입에만 사용할 수 있다 . - 위 두 파라미터는 타입 변수의 파라미터가 아니라 제네릭의 파라미터이다 . - 그렇기 때문에 일반 함수에는 사용 불가능하다 . T_co = TypeVar(&quot;T_co&quot;, covariant=True) def f(x: list[T_co]) -&gt; T_co: # Error return x[0] . class Animal: def speak(self) -&gt; str: return &quot;Animal sound.&quot; class Dog(Animal): def speak(self) -&gt; str: return &quot;Woof!&quot; class Cat(Animal): def speak(self) -&gt; str: return &quot;Meow!&quot; class SuperCutyCat(Cat): def speak(self) -&gt; str: return &quot;Purr! I&#39;m super cute!&quot; . covariant . - 공변성은 상위 타입이 필요한 곳에 하위 타입을 사용할 수 있음을 의미한다 . from typing import TypeVar, Generic Animal_co = TypeVar(&quot;Animal_co&quot;, bound=Animal, covariant=True) class AnimalContainer(Generic[Animal_co]): def __init__(self, animal: Animal_co) -&gt; None: self.animal = animal def get_animal(self) -&gt; Animal_co: return self.animal . dog_container = AnimalContainer(Dog()) cat_container = AnimalContainer(Cat()) # Covariance allows assigning AnimalContainer[Dog] to AnimalContainer[Animal] animal_container: AnimalContainer[Animal] = dog_container print(animal_container.get_animal().speak()) # Output: &quot;Woof!&quot; . Woof! . - AnimalContainer[Animal]에 AnimalContainer[Dog] 또는 AnimalContainer[Cat]도 대입할 수 있다 . - AnimalContainer는 공변성을 가지므로 AnimalContainer[Dog]와 AnimalContainer[Cat]는 AnimalContainer[Animal]의 서브 타입이기 때문이다 . contravariant . - 반공변성은 상위 타입을 필요로 하는 곳에 하위 타입을 사용할 수 없다는 것을 의미한다 . - 대신, 하위 타입이 필요한 곳에 상위 타입을 사용할 수 있다. . Animal_contra = TypeVar(&quot;Animal_contra&quot;, bound=Animal, contravariant=True) class AnimalHandler(Generic[Animal_contra]): def handle(self, animal: Animal_contra) -&gt; None: print(f&quot;Handling {animal.speak()}&quot;) # Create an instance of a handler that can handle any Animal wrong_animal_handler: AnimalHandler[Cat] = AnimalHandler[SuperCutyCat]() # Error animal_handler: AnimalHandler[Cat] = AnimalHandler[Animal]() # Contravariance allows this # Handle a Cat animal_handler.handle(Dog()) # Error, Dog is not a subtype of Cat animal_handler.handle(Animal()) # Error, Animal is not a subtype of Cat animal_handler.handle(Cat()) # Output: &quot;Woof!&quot; animal_handler.handle(SuperCutyCat()) # Output: &quot;Purr! I&#39;m super cute!&quot; . Handling Woof! Handling Animal sound. Handling Meow! Handling Purr! I&#39;m super cute! . - AnimalHandler[Cat]에 AnimalHandler[Animal]도 대입할 수 있다 . - 하지만 AnimalHandler[Cat]에 AnimalHandler[SuperCutyCat]을 대입할 수는 없다 . - AnimalHandler는 반공변성을 가지므로 AnimalHandler[SuperCutyCat]은 AnimalHandler[Cat]의 서브 타입이 아니기 때문이다 . &#48512;&#47197; . - int는 float의 서브 타입일 뿐 인스턴스는 아니다 . x = 1 print(isinstance(x, float)) # False . False . - 참고로 bool은 int의 인스턴스이다 (True는 1, False는 0) . x = True print(isinstance(x, int)) # True . True . - bool은 int를 상속 받은 클래스이므로 당연하게도 int의 서브 타입이다 . - int는 float의 서브 타입이고 bool은 int의 서브 타입이므로 bool은 float의 서브 타입이다 .",
            "url": "https://jaesu26.github.io/study-blog/python/2024/08/13/TypeVar.html",
            "relUrl": "/python/2024/08/13/TypeVar.html",
            "date": " • Aug 13, 2024"
        }
        
    
  
    
        ,"post3": {
            "title": "@pytest.fixture와 @pytest.fixture()의 차이",
            "content": "- pytest.fixture: https://github.com/pytest-dev/pytest/blob/8.3.2/src/_pytest/fixtures.py#L1242 . &#46168;&#51060; &#47924;&#49832; &#52264;&#51060;&#51064;&#45936;? . @pytest.fixture | . @pytest.fixture def f(): # do something # 위의 코드는 다음과 동일함 f = pytest.fixture(f) . - 반면에 . @pytest.fixture() | . @pytest.fixture() def f(): # do something # 위의 코드는 다음과 동일함 pyfixture = pytest.fixture() f = pyfixture(f) # 또는 f = pytest.fixture()(f) . - 둘은 방식의 차이가 분명히 존재한다 . - 하지만 실제로 사용해보면 둘의 결과가 같다는 것을 알 수 있다 . - 어떻게 가능한 걸까? . - pytest에서 fixture 함수(=데코레이터 함수)는 기본적으로 2가지 형태로 오버로딩 되어있다 . def deco(func): # do something . - 참고로 데코레이터 함수의 첫 번째 인자는 당연하게도 데코레이터에 넣을 함수이다 . pytest.fixture &#54632;&#49688; . @overload def fixture( fixture_function: FixtureFunction, *, scope: _ScopeName | Callable[[str, Config], _ScopeName] = ..., params: Iterable[object] | None = ..., autouse: bool = ..., ids: Sequence[object | None] | Callable[[Any], object | None] | None = ..., name: str | None = ..., ) -&gt; FixtureFunction: ... . - 첫 번째 인자인 fixture_function은 데코레이터에 넣을 함수를 뜻한다 (그냥 func이라 해도 되는데 풀네임으로 적었다 생각하면 됨) . - 그리고 타입은 FixtureFunction이다 (이거 그냥 Callable TypeVar임) . - 그리고 리턴 타입도 FixtureFunction이다 . - 일반적인 데코레이터 함수와 동일하다 . - 그럼 이제 두 번째 형태를 보자 . @overload def fixture( fixture_function: None = ..., *, scope: _ScopeName | Callable[[str, Config], _ScopeName] = ..., params: Iterable[object] | None = ..., autouse: bool = ..., ids: Sequence[object | None] | Callable[[Any], object | None] | None = ..., name: str | None = None, ) -&gt; FixtureFunctionMarker: ... . - 첫 번째 꼴과 다름 점은 2가지가 존재한다 . 1. fixture_function의 타입이 None이다 . 2. 리턴 타입이 FixtureFunctionMarker이다 . - 참고로 FixtureFunctionMarker는 클래스이다 . - 자 이제 함수 내부를 살펴보자 (매우 간단함) . def fixture( fixture_function=None, *, scope=&quot;function&quot;, params=None, autouse=False, ids=None, name=None, ): fixture_marker = FixtureFunctionMarker( scope=scope, params=tuple(params) if params is not None else None, autouse=autouse, ids=None if ids is None else ids if callable(ids) else tuple(ids), name=name, _ispytest=True, ) # Direct decoration if fixture_function: return fixture_marker(fixture_function) return fixture_marker . - 주석과 타입은 가독성을 위해 생략했다 . - 일단 fixture_marker를 생성하고 시작한다 . - 그리고 입력으로 fixture_function이 들어온다면(None이 아니라면) fixture_marker(fixture_function)을 리턴한다 . - fixture_function이 None이면 fixture_marker를 리턴한다 . - [$ star$] 즉, 데코레이터로 @pytest.fixture를 쓰든 @pytest.fixture()를 쓰든 결국 fixture_marker(fixture_function)을 리턴한다 [$ star$] . - 여기서 끝내도 되지만 각 경우 어떤 일이 일어나는지 조금 더 자세히 알아보자 . @pytest.fixture . - @pytest.fixture인 경우 f = pytest.fixture(f)라고 했다 . - 그러면 if문에서 fixture_function이 None이 아니고 f이다 . - 그래서 fixture_marker(f)를 리턴한다 . - 여기서 궁금한건 fixture_marker는 뭐냐는 거다 . - 일단 fixture_marker는 FixtureFunctionMarker 클래스의 인스턴스다 . - fixture_marker(f)는 FixtureFunctionMarker 클래스의 __call__ 메서드를 호출한 것이다 . - 이제 궁금한건 이 클래스의 __call__ 메서드가 반환하는게 무엇이냐이다 . @final @dataclasses.dataclass(frozen=True) class FixtureFunctionMarker: def __call__(self, function: FixtureFunction) -&gt; FixtureFunction: ... . - 위는 FixtureFunctionMarker에서 __call__ 메서드 부분만 따온 것이다 . - __call__ 메서드는 FixtureFunction 타입을 반환하고 이는 아까 말했듯이 그냥 함수이다 . - 즉, @pytest.fixture인 경우 그냥 일반적인 데코레이터와 다를바가 없다 . @pytest.fixture() . pyfixture = pytest.fixture() f = pyfixture(f) . - pyfixture = pytest.fixture()를 잘보자 . - pytest.fixture()는 사실 pytest.fixture(fixture_function=None)과 같다 (함수의 default값을 생각하면 당연함) . - 함수 내부를 보면 if fixture_function 코드가 있음. 근데 여기선 fixture_function이 None이다 . - 따라서 해당 if문은 스킵된다 . - 그래서 그냥 fixture_marker만 리턴한다 . - 데코레이터가 @pytest.fixture일 땐 pytest.fixture(f) == fixture_marker(f)였다 . - 즉, pytest.fixture()(f) == fixture_marker(f)이고 pytest.fixture(f) == fixture_marker(f)이다 . - pytest.fixture()로 입력 안하고 pytest.fixture로 입력하니 자체적으로 pytest.fixture()과 동일한 기능을 하게 만들어준다 . - 따라서 @pytest.fixture()나 @pytest.fixture나 동일한 기능을 수행한다 .",
            "url": "https://jaesu26.github.io/study-blog/python/2024/08/09/pytestfixture.html",
            "relUrl": "/python/2024/08/09/pytestfixture.html",
            "date": " • Aug 9, 2024"
        }
        
    
  
    
        ,"post4": {
            "title": "파이토치는 답을 알고 있다",
            "content": "&#47785;&#54364; . 아래의 코드로 모델을 어떻게 학습시키는지 이해하는 것 | . for epoch in range(10): y_hat = model(X) loss = loss_fn(y_hat, y) optimizer.zero_grad() loss.backward() optimizer.step() . - 파이토치로 모델을 학습시킬 때 위와 같은 코드 형태를 자주 본다 . - 두루뭉실하게 알고 있던 내용을 확립시키고 싶다 . &#47784;&#45944;&#51012; &#54617;&#49845;&#49884;&#53416;&#45796;&#45716; &#44163;? . - 주어진 데이터 $(X, y)$를 잘 분석하여 $X$를 $y$로 맵핑하는 함수 $f$를 추정하는 것이다 ($y approx f(x)$인 $f$를 찾는 것) . - $X$는 설명 변수, $y$는 반응 변수이다 . - 예컨대 $(X,y)$는 (이미지, 카테고리)일 수 있고 (유저 로그, 매크로 유무)일 수도 있다 . - 중요한 건 데이터는 $(X,y)$의 형태이며 $X$를 바탕으로 $y$를 추정하고 싶다는 것이다 . - 즉, 어떤 모델이 있다고 하자 . - 모델에 인풋으로 $X$를 넣으면 $ hat{y}$이 출력될 텐데 모델이 잘 학습됐다면 $ hat{y}$이 $y$값과 비슷할 것이다 . - 위 코드에서 y_hat = model(X) 부분을 나타낸다 . &#54924;&#44480;&#47784;&#54805; &#44032;&#51221; . - 실제로 모델을 학습시키기 위해 간단한 회귀모형을 가정하자 . - model: $y_i = f(x_i) + epsilon_i = w_0 + w_1x_i + epsilon_i = 3.5 + 2x_i + epsilon_i, quad i = 1,2, cdots,n$ . - 벡터로 표현한다면 model: $ mathbf y = mathbf X mathbf W + boldsymbol{ epsilon}$ . $$ mathbf y = begin{bmatrix} y_1 y_2 vdots y_n end{bmatrix}, quad mathbf X = begin{bmatrix} 1 &amp; x_1 1 &amp; x_2 vdots &amp; vdots 1 &amp; x_n end{bmatrix}, quad mathbf W = begin{bmatrix} 3.5 2 end{bmatrix}, quad boldsymbol epsilon = begin{bmatrix} epsilon_1 epsilon_2 vdots epsilon_n end{bmatrix} $$- $ mathbf X$: $n times 2$ 행렬 . - $ mathbf y$: $n times 1$ 열벡터 . - $ mathbf W$: $2 times 1$ 열벡터 . - $ boldsymbol epsilon$: $n times 1$ 열벡터 . &#45936;&#51060;&#53552; &#49373;&#49457; . import matplotlib.pyplot as plt import torch . torch.manual_seed(26) n = 100 ones = torch.ones(n) x, _ = torch.randn(n).sort() X = torch.stack([ones, x], dim=1) W = torch.tensor([3.5, 2]) ϵ = torch.randn(n) * 0.5 y = X@W + ϵ y_without_error = X@W . plt.plot(x, y, &quot;o&quot;) plt.plot(x, y_without_error, &quot;--&quot;) . [&lt;matplotlib.lines.Line2D at 0x17f03038fa0&gt;] . . Note: epsilon을 타이핑하고 Tab을 누르면 $ epsilon$ 기호를 코드에 사용할 수 있다 . - 예시를 위해 간단한 회귀모형을 만들었다 . - 위에서는 회귀 직선을 그래프상에 주황색 점선으로 표시했다 . - 하지만 이를 표기하지 않아도 회귀 직선을 그리라고 하면 주황색 점선과 비슷한 위치에 그릴 것이다 . - 그런데 왜 파란 점들을 표현하는 회귀 직선을 주황색 점선과 비슷하게 그린걸까? . &#54924;&#44480; &#47784;&#45944; &#54617;&#49845; . - 그것은 아마 주황색 점선인 회귀 모델이 파란점들을 잘 표현한다 생각하기 때문일 것이다 . - 그런데 잘 표현한다는 것은 어떤 의미일까? . - 실제 값 $y$와 이를 추정한 $ hat{y}$가 있을 때 둘 사이의 거리가 $0$이라면 잘 표현했다 생각할 것이다 . - 만약 둘의 거리 차이가 크다면 잘 표현하지 못했다 생각할 것이다 . - 이를 반영하고자 오차 $ epsilon=y- hat{y}$를 사용하자! . - 그런데 $y=4, hat{y}=5$인 것과 $y=4, hat{y}=1$중에 후자가 오차가 더 작다 . - 하지만 둘의 거리를 생각해보면 전자가 $ hat{y}$이 $y$를 잘 표현했다고 할 수 있을 것이다 . - 부호에 상관없이 절대적인 거리가 작은 것이 더 중요하다 . - 그렇게 하기 위해 제곱을 사용하자 . - 즉, $ epsilon^2=(y- hat{y})^2$를 표현력의 척도로 생각할 수 있다 . - 그런데 $(y- hat{y})^2$ 대신 $|y- hat{y}|$를 사용해도 둘 사이의 거리를 나타내는데 충분하다 . - 절댓값을 사용하지 않고 제곱을 사용하는 이유는 미분과 같은 계산 편의성 때문이라 생각하자 . - 모델을 학습시킨다는 것은 $ mathbf W$와 비슷한 $ mathbf{ hat{W}}$을 찾는 것이고 잘 학습했는지에 대한 평가는 $(y- hat{y})^2$이 작은지로 판단한다 . - 그런데 사용할 데이터가 하나가 아닌 여럿이므로 이를 합하여 표현력의 척도를 $ sum limits_{i=1}^{n} left(y_i- hat{y}_i right)^2$로 수정하자 . - 사실, 표현력의 척도는 손실 함수라고 표현한다 (값이 작을수록 손실도 작아지니 괜찮은 표현같다) . - 손실 함수에 데이터를 입력하여 나온 스칼라는 손실이 된다 . - 위 코드에서 loss = loss_fn(y_hat, y)를 나타낸다 (loss_fn은 loss_function의 줄임말이다) . &#44536;&#47088;&#45936; $ mathbf{W}$&#47484; &#50612;&#46523;&#44172; &#52628;&#51221;&#54644;? . - 우리는 앞선 과정을 통해 모델을 평가할 수 있는 손실 함수을 만들었다 . - 그런데 모델이 잘한지 못한지를 평가하는 것으로 $ mathbf{ hat{W}}$를 $ mathbf W$에 가깝게 만들 수 있을까? . - 모델은 $ mathbf{ hat{W}}$를 가지고 있고 입력으로 $ mathbf X$가 들어오면 $ mathbf{X} mathbf{ hat{W}}$을 계산한다 . - 그러면 $ text{loss} = sum limits_{i=1}^{n} left(y_i-( hat{w}_0 + hat{w}_1x_i) right)^2= left( mathbf{y} - mathbf{X} mathbf{ hat{W}} right)^ top left( mathbf{y} - mathbf{X} mathbf{ hat{W}} right)$을 계산한다 . - loss가 작다는 것은 곧 $ mathbf{ hat{W}}$와 $ mathbf{W}$가 유사하다는 것이다 . - 그런데 사실 우리는 원래의 함수 $f$가 단순한 회귀 직선인 것을 알고 있고 $ mathbf{X}$와 $ mathbf{y}$도 가지고 있다 . - 따라서 $ epsilon^2= sum limits_{i=1}^{n}(y_i-w_0 - w_1x_i)^2$을 최소화하는 $ hat{w}_0, hat{w}_1$을 구할수 있다 . - 하지만 현실에선 $f$가 주어지지 않는다 . - $f$를 추정해야 하며 추정한 $ hat{f}$가 간단하면 위와 같이 최적화 문제를 해결할 수 있다 . - 그런데 현실에는 복잡한 문제도 많이 있는데? &gt; 이미지 카테고리 구분 . - 이론적으로 계산하는 것 외의 방법은 없을까? . &#44221;&#49324; &#54616;&#44053;&#48277; . - 손실 함수는 $f$와 다르게 이미 주어졌다 (애초에 우리가 선택함) . - $ text{loss} = sum limits_{i=1}^{n} left(y_i-(w_0 + w_1x_i) right)^2 = left( mathbf{y} - mathbf{X} mathbf{W} right)^ top left( mathbf{y} - mathbf{X} mathbf{W} right)$ . - 위의 loss를 최소화시키는 $ mathbf{W}$는 $ mathbf{ hat{W}}$으로써 원래의 참인 $ mathbf{W}$를 추정할 수 있다 . - $ mathbf{X}, mathbf{y}$는 이미 주어진 데이터이고 $ mathbf{W}$는 학습 중에 변하는 값이다 . - 즉, loss는 $ mathbf{W}$의 함수이다 &gt; $ text{loss}( mathbf{W}) = text{loss}(w_0,w_1)$ . 경사 하강법 1차원 아이디어 | . &#52628;&#44032;&#47196; &#49373;&#44033;&#54644;&#48380; &#44163; . 1. 쓸모있는 손실 함수란? . 2. 벡터 미분 .",
            "url": "https://jaesu26.github.io/study-blog/statistics/2024/08/03/%EA%B2%BD%EC%82%AC%ED%95%98%EA%B0%95%EB%B2%95%EA%B3%BC%EC%98%A4%EC%B0%A8%EC%97%AD%EC%A0%84%ED%8C%8C.html",
            "relUrl": "/statistics/2024/08/03/%EA%B2%BD%EC%82%AC%ED%95%98%EA%B0%95%EB%B2%95%EA%B3%BC%EC%98%A4%EC%B0%A8%EC%97%AD%EC%A0%84%ED%8C%8C.html",
            "date": " • Aug 3, 2024"
        }
        
    
  
    
        ,"post5": {
            "title": "뽑기를 기댓값만큼 시도해도 약 36.8%의 사람은 실패한다",
            "content": "&#49345;&#54889; &#44032;&#51221; . - 어떤 아이템 상자가 있는데 내가 원하는 아이템 A는 $10 %$ 확률로 등장한다고 해보자 . - 아이템 A를 뽑을 때까지 시도한 횟수는 기하 분포를 따른다 . - 뽑을 확률이 $0.1$이니까 10번 하면 뽑겠지(?)라고 생각할 수 있지만 현실은 그렇지 않다 . 기댓값은 10번이 맞는데... | . def f(p): return 1 - (1 - p)**(1 / p) . f(p=0.1) . 0.6513215599 . - $P( text{10번 안에 뽑음}) = 1 - P( text{10번 모두 실패})$ . - 이 값은 약 $0.65$이다 . - 즉, 아이템 뽑기를 시도한 $35 %$의 사람들은 기댓값안에 원하는 아이템 A를 뽑지 못한다 . - 애초에 모두가 기댓값안에 아이템을 뽑으면 기댓값이 그렇게 형성될 수가 없다... . &#54869;&#47456;&#50640; &#46384;&#47480; &#48320;&#54868; . 확률이 더 낮아진다면? | . - 더 희귀한 아이템 B가 있는데 B를 뽑을 확률은 $1 %$라고 한다 . - 100번 안에 아이템 B를 뽑을 확률은 몇 일까? . f(p=0.01) . 0.6339676587267709 . - $10 %$일 땐 약 $65 %$였는데 $1 %$가 되니 약 $63.4 %$가 됐다 . - $63.4 %$라고 하니 생각보다 할 만한 것 같다(?) . - 아이템 뽑기 확률이 더 낮아지면 어떻게 될까? . - 이번엔 더 희귀한 아이템 C를 고려하자 . - C는 정말 희귀해서 $0.1 %$의 확률로 등장한다 . - 1000번 시도해서 C를 뽑을 확률, 그러니까 적어도 한 개 뽑을 확률은 얼마일까? . f(p=0.001) . 0.6323045752290363 . - ?? 확률이 $1 %$일 때랑 차이가 거의 나지 않는다 . - 생각해보면 확률이 낮아져도 시도 횟수는 올라가니까 엄청난 차이가 생길 것 같지는 않다 . - 그럼 확률을 더욱 낮게 해보자 . - 그래프로 비교할 수 있으면 더 좋을 것 같다 . import matplotlib.pyplot as plt import numpy as np p = np.arange(1e-4, 1, 1e-4) fp = f(p) convergence_value = 1 - 1 / np.e plt.figure(figsize=(10, 6)) plt.plot(p, fp, color=&quot;blue&quot;, linestyle=&quot;-&quot;, label=&quot;$f(p) = 1 - (1 - p)^{1 / p}$&quot;) plt.axhline(y=convergence_value, color=&quot;r&quot;, linestyle=&quot;--&quot;, label=&quot;$1 - frac{1}{e}$&quot;) plt.xlabel(&quot;$p$&quot;) plt.ylabel(&quot;$f(p)$&quot;) plt.ylim(0.6, 1) plt.title(&quot;Graph of $f(p) = 1 - (1 - p)^{1 / p}$&quot;) plt.xlim(0.0001, 1) plt.xscale(&quot;log&quot;) plt.gca().invert_xaxis() plt.xticks([1, 0.1, 0.01, 0.001, 0.0001], [&quot;1&quot;, &quot;0.1&quot;, &quot;0.01&quot;, &quot;0.001&quot;, &quot;0.0001&quot;]) plt.minorticks_off() plt.tight_layout() plt.legend() plt.show() . . &#51652;&#49892; . - 위의 그래프를 보면 $f(p)$가 어느 한 점으로 수렴하는 것 같다 . - 우리가 고려하고 있는 상황을 복기해보자 . - 당첨 확률이 $p$인 뽑기를 $n = frac{1}{p}$번 하는 것을 고려하자 . - 이때 당첨 확률이 $p$인 뽑기를 $n$번 시도해서 1개도 못 뽑을 확률을 $P(A)$라 하고 이를 계산하자 . - $P(A)=(1-p)^{ frac{1}{p}}$이다 . - 그런데 어디서 본 것 같은 모양이다? . - 자연로그의 밑 $e= lim limits_{n to infty} left(1+ frac{1}{n} right)^n$ . - $ lim limits_{p to 0+}(1-p)^{ frac{1}{p}} = lim limits_{n to infty} left(1- frac{1}{n} right)^{n}, quad n to infty ; text{as} ; p to {0+}$ . - $ lim limits_{n to infty} left(1- frac{1}{n} right)^{n} = lim limits_{n to infty} left( frac{n-1}{n} right)^{n}$ . - $n = t+1$로 치환하면 $ lim limits_{t to infty} left( frac{t}{t+1} right)^{t+1} = lim limits_{t to infty} left( frac{t+1}{t} right)^{-(t+1)} = lim limits_{t to infty} left(1+ frac{1}{t} right)^{-t} left(1+ frac{1}{t} right)^{-1}$ . - 극한의 성질에 의해 $ lim limits_{t to infty} left(1+ frac{1}{t} right)^{-t}= left( lim limits_{t to infty} left(1+ frac{1}{t} right)^t right)^{-1}=e^{-1}, quad lim limits_{t to infty} left(1+ frac{1}{t} right)^{-1} = 1$ . - 따라서 극한의 성질에 의해 . - $ lim limits_{t to infty} left(1+ frac{1}{t} right)^{-t} left(1+ frac{1}{t} right)^{-1}= lim limits_{t to infty} left(1+ frac{1}{t} right)^{-t} times lim limits_{t to infty} left(1+ frac{1}{t} right)^{-1}= frac{1}{e}$ . - 즉, $p$가 적당히 작으면 $P(A)$를 $ frac{1}{e}$에 근사할 수 있다 . &#54876;&#50857; . - 어떤 사람이 당첨 확률이 $p=0.1$인 아이템을 35번 사용했는데도 당첨 안됐다고 해보자 . - $p=0.1$이므로 당첨되기 위해 시도하는 횟수의 기댓값은 $10$이다 . - 기댓값만큼 시도해서 안될 확률은 약 $0.368$였다 . - 아이템을 사용하는 것은 독립시행이므로 35번 시도해서 안될 확률은 $0.368^{ frac{35}{10}} approx 0.03$이다 . - 추가로 내가 다른 사람들보다 운이 얼마나 없는지도 평가할 수 있다 . - 당첨되기까지의 시도 횟수를 오름차순 정렬해보자 . - 35번 쓰고도 당첨 안된 사람은 하위 $3 %$안에 든다 . - 물론 아직 당첨된 게 아니므로 운이 더 나빠질 가능성이 남아있다 . - 참고로 이러한 접근 방법은 당첨 될 때까지 시도하는 모든 것에 가능하다 . - 즉, 확률 변수가 2개의 결과 (ex: $0$ or $1$, 당첨 or 실패)를 가지며 원하는 결과가 나올 때까지 시도하는 것에 바로 적용 가능하다 . - 이러한 확률 변수는 기하 분포를 따른다 . &#48512;&#47197; . $ lim limits_{x to a}f(x) = f left( lim limits_{x to a}x right)$ . - 함수 $f$가 $x=a$에서 연속이면 아래가 성립한다 . - $ lim limits_{x to a}f(x)=f left( lim limits_{x to a}x right)$ . - 연속 함수의 정의에 따라 $ lim limits_{x to a}f(x)=f(a)$ . - $y=x$는 당연히 연속 함수이므로 $ lim limits_{x to a}x=a$ . - 따라서 $f(a)$에 $a$ 대신 $ lim limits_{x to a}x$를 대입할 수 있다 . - 즉, $ lim limits_{x to a}f(x)=f(a)=f left( lim limits_{x to a}x right)$ . - 참고로 $x to a$는 $x$가 발산하는 경우($x to infty$ or $x to- infty$)를 포함하는 게 아니다 . $ lim limits_{x to a} {f(x)g(x) } = left { lim limits_{x to a}f(x) right } left { lim limits_{x to a}g(x) right }$ . - $ lim limits_{x to a}f(x) = alpha, , lim limits_{x to a}g(x) = beta$라고 하자 . - 그러면 $ lim limits_{x to a} {f(x)g(x) } = left { lim limits_{x to a}f(x) right } left { lim limits_{x to a}g(x) right }$이 성립한다 . - 단, 함수 $f(x)g(x), , f(x), , g(x)$가 $x=a$에서 극한값을 가져야 성립한다 . - 참고로 $ alpha, beta$는 실수이다 . - 만약 이를 어기면 $ lim limits_{x to 0+}x=0, lim limits_{x to0+} frac{1}{x}= infty$이므로 . - $ lim limits_{x to 0+} frac{x}{x} =1, , left { lim limits_{x to 0+}x right } left { lim limits_{x to0+} frac{1}{x} right }=0 cdot infty$ . - 하지만 $1 neq 0 cdot infty$이고 애초에 $ infty$은 수가 아니므로 곱셈과 같은 연산을 할 수 없다 .",
            "url": "https://jaesu26.github.io/study-blog/statistics/2024/07/31/%EB%BD%91%EA%B8%B0%ED%99%95%EB%A5%A0%EA%B8%B0%EB%8C%93%EA%B0%92.html",
            "relUrl": "/statistics/2024/07/31/%EB%BD%91%EA%B8%B0%ED%99%95%EB%A5%A0%EA%B8%B0%EB%8C%93%EA%B0%92.html",
            "date": " • Jul 31, 2024"
        }
        
    
  
    
        ,"post6": {
            "title": "수학 논리 퀴즈 2",
            "content": "- 수학 논리 퀴즈와 같은 부류의 또 다른 문제이다 . - 파이썬 풀이 부분에서 수학 논리 퀴즈에서 사용한 코드를 참고했다 . - 유명한 문제이다: https://en.wikipedia.org/wiki/Sum_and_Product_Puzzle . - 위 링크에선 $x &lt; y$인 조건이 있는데 여기선 무시했다 . &#47928;&#51228; &#49345;&#54889; . - 2 이상 100 이하의 두 수 $x, y$를 고려하자 . - A에게는 두 수의 곱을 B에게는 두 수의 합을 알려주었다 . - 아래 A와 B의 대화를 바탕으로 $x, y$를 맞혀라 . - A: 도저히 모르겠는데요 . - B: 당신이 모를 거란 것쯤은 이미 알고 있었어요 . - A: 아, 두 수가 뭔지 알겠습니다 . - B: 저도 두 수가 뭔지 알겠습니다 . &#54400;&#51060; . A: &#46020;&#51200;&#55176; &#47784;&#47476;&#44192;&#45716;&#45936;&#50836; . - 두 수의 곱을 $P$라고 하자 . - A가 정답을 모르겠다는 것은 $P=xy$를 만족하는 $(x,y)$ 쌍이 2개 이상임을 뜻한다 . B: &#45817;&#49888;&#51060; &#47784;&#47484; &#44144;&#46976; &#44163;&#52196;&#51008; &#51060;&#48120; &#50508;&#44256; &#51080;&#50632;&#50612;&#50836; . - 두 수의 합을 $S$라고 하자 . - 일단 $S$는 6 이상 198 이하이다 . - 그렇지 않다면 B는 A의 답변을 듣지 않고도 정답을 바로 맞힐 수 있다 . - $S=x+y$를 만족하는 $(x,y)$쌍을 찾아보자 . - $S$가 홀수일 때 두 수 $x,y$로 가능한 조합은 $(2, S-2), cdots, left( big lfloor frac{S}{2} big rfloor, big lfloor frac{S}{2} big rfloor + 1 right)$이고 . - $S$가 짝수일 때 두 수 $x,y$로 가능한 조합은 $(2, S-2), cdots, left( frac{S}{2}, frac{S}{2} right)$이다 . - 그런데 B는 A가 정답을 모를거라고 확신했다 . - 가능한 모든 $(x,y)$쌍에 대해 $xy$를 계산해보자 . - 만약 $xy$ 중에 두 소수의 곱이 존재한다면 B는 A가 정답을 알지 못한다고 확신할 수 없다 . - 왜냐하면 두 수의 곱이 $P$인 두 수 $(x, y)$ 쌍은 1개만 존재하기 때문이다 . - 예컨대 A가 $P=21$을 알고 있다면 두 수는 3과 7뿐이므로 바로 정답을 맞힐 수 있다 . - 그런데 어떻게 $S=x+y$를 만족하는 소수 $x,y$가 존재하는지 판단할 수 있을까? . - 쉬운 방법으론 다음이 있다. $S=x+y$를 만족하는 가능한 모든 $(x,y)$ 쌍을 고려하자 . - 그리고 $x$와 $y$의 곱을 $P$라고 하자 . - 이때 $P=ab$를 만족하는 2 이상 100 이하의 $(a,b)$ 쌍이 단 1개라면 $x,y$는 소수이다 . - 즉, B는 당신이 모를 거란 것쯤은 이미 알고 있었어요와 같이 대답할 수 없으므로 모순이다 . 아래는 탐색 시간을 줄이는 알고리즘이다 | . - 일단 임의의 짝수 $S = x + y$에 대해선 소수 $x,y$가 항상 존재한다 . - 여기에는 골드바흐의 추측이 사용된다 (한 번쯤 들어봤을 법하다) . - 밀레니엄 7대 난제 중 하나인 골드바흐의 추측은 $4$이상의 모든 짝수는 두 소수의 합으로 표현 가능함을 뜻한다 . - 물론 완전히 증명된건 아니지만 충분히 큰 영역까지 성립함이 보여졌다 . - 따라서 이 문제에서 다루는 영역은 당연히 성립한다 . - 그럼 $S$가 홀수일 땐 괜찮을까? . - $S$가 홀수일려면 필연적으로 $x,y$ 중 하나는 짝수, 다른 하나는 홀수여야 한다 . - 둘 다 짝수이거나 홀수라면 $x+y$는 짝수이기 때문에 그렇다 . - $x$와 $y$는 서로 대칭적이므로 임의로 $x$를 짝수 $y$를 홀수라 가정하겠다 . - $x$가 만약 2이고 $y$가 소수라면 $xy$는 2와 y의 곱으로만 이루어진다 . - 하지만 $x$가 4이상의 짝수라면 $xy$는 합성수이다 . - 그런데 이는 상한 100을 고려하지 않은 것으로 $x$가 4이상의 짝수라도 $y$가 50이상의 소수라면 $xy$는 유일한 해 1개를 가진다 (곱의 쌍이 단 1개) . - 그런데 $x$가 4 이상의 짝수이고 $y$가 소수가 아닌 홀수여도 하한과 상한 조건에 의해 $xy$를 나타내는 곱의 쌍이 1개만 존재할 수 있을까? . - $x$가 98, $y$가 95이면 가능하다 . - 9310은 95와 98의 곱으로만 가능하다 . - 짝수인 $S$는 두 소수의 합으로 표현되므로 정답에서 제외하고 홀수인 $S$에 대해선 브루트 포스로 정답 여부를 판단하자 . - 즉, 홀수 $S(=x+y)$를 만족하는 $(x,y)$ 쌍에 대해 $xy$가 $x$와 $y$의 곱으로만 표현된다면 정답이 될 수 없다 . - 이 과정을 거쳐 정답으로 가능한 두 수의 합을 $S^*$라고 정의하겠다 . A: &#50500;, &#46160; &#49688;&#44032; &#47956;&#51648; &#50508;&#44192;&#49845;&#45768;&#45796; . - 기본적으로 곱의 쌍이 1개뿐인 수는 배제한다 (첫 단계에서 A가 정답을 맞혔을 것이다) . - $P=xy$를 만족하는 모든 $(x,y)$ 쌍에 대해 다음을 계산하자 . - $S=x+y$라 하고 $S=a+b$을 만족시키는 모든 $(a,b)$에 대해 $ab$을 계산하자 . - 만약 $ab$중 곱의 쌍이 1개뿐인 수가 존재한다면 B는 A가 모를거라고 확신할 수 없다 . - 즉, 해당 $x,y$는 정답이 아닌 것이다 . - 그런데 위를 만족하는 $(x,y)$ 조합이 단 1개뿐이라면 A는 두 수가 뭔지 안다 . - 예컨대 A가 처음에 전달 받은 $P$가 18이라고 해보자 . - 그럼 $x,y$는 2와 9 또는 3과 6이다 . - 따라서 A는 도저히 알 수 없다 . - 그런데 B는 A가 모를걸 알고 있었다 . - 곱이 18이므로 합은 9 아니면 11이다 . - 만약 두 수의 합 $S$가 $9$라면 $2,7$이 가능하다 . - 그러면 두 수의 곱은 14가 되는데 14는 오직 2와 7의 곱으로만 이루어진다 . - 따라서 B는 당신이 모를 거란 것쯤은 이미 알고 있었어요라고 생각할 수 없다 . - 이제 두 수의 합이 11이라고 해보자 . - 두 수의 합이 11인 쌍은 $(2,9), (3,8),(4,7),(5,6)$이다 . - 각 쌍의 원소 곱은 $18, 24, 28, 30$이다 . - 이들은 모두 합성수 이므로 A는 정답을 알지 못한다 . - 즉, B는 당신이 모를 거란 것쯤은 이미 알고 있었어요라고 생각할 수 있다 . - 따라서 A가 전달 받은 두 수의 곱이 18이라면 가능한 합은 11뿐이고 이 때의 $x,y$는 2와 9이다 . - 경우의 수가 1개뿐이므로 A는 두 수가 무엇인지 알 수 있다 . B: &#51200;&#46020; &#46160; &#49688;&#44032; &#47956;&#51648; &#50508;&#44192;&#49845;&#45768;&#45796; . - A가 아, 두 수가 뭔지 알겠습니다라고 말한 정보를 이용해보자 . - 일단 B는 당신이 모를 거란 것쯤은 이미 알고 있었어요라고 말했으므로 두 수의 합으로 가능한 것들은 $S^*$이다 . - $S^* = x+y$를 만족하는 $(x, y)$에 대해 $xy$를 계산하면 $xy=ab$를 만족하는 $(a,b)$쌍은 2개 이상이다 (만약 1개뿐이라면 $S^*$일 수 없다) . - 가능한 $(a,b)$쌍 각각에 대해 $a+b$가 $S^*$에 포함되는지 확인하자 . - 만약 $a+b$가 $S^*$에 포함되지 않는다면 해당 $(a,b)$는 정답이 될 수 없다 (B가 당신이 모를 거란 것쯤은 이미 알고 있었어요라고 말할 수 없다) . - 가능한 $(a,b)$쌍 중에서 $S^*$에 포함되는 $(a,b)$쌍이 단 1개뿐이라면 A는 아, 두 수가 뭔지 알겠습니다라고 말할 수 있다 . - 이 과정을 가능한 모든 $(x,y)$쌍에 적용한 후 단 하나의 $(x,y)$쌍에 대해서만 A가 아, 두 수가 뭔지 알겠습니다라고 말할 수 있다면 . - B는 저도 두 수가 뭔지 알겠습니다라고 말할 수 있다 . &#54028;&#51060;&#50028;&#51004;&#47196; &#54400;&#50612;&#48372;&#51088; . A: &#46020;&#51200;&#55176; &#47784;&#47476;&#44192;&#45348;&#50836; . - 로직을 정리하고 가자 . - 일단 두 수의 곱 $P$가 주어지면 $P = xy$를 만족하는 $(x,y)$ 쌍을 찾는다 . - 단, $ min leq x leq y leq max$ (여기서 $ min=2, max=100$) . - 곱의 조합 쌍이 2개 이상이면 A는 두 수가 무엇인지 알 수 없다 . 곱의 조합 쌍을 찾자 | . import math def find_product_pairs(n, minimum, maximum): product_pairs = [] for x in range(minimum, math.isqrt(n) + 1): if n % x != 0: continue y = n // x if not (x &lt;= y and minimum &lt;= x &lt;= maximum and minimum &lt;= y &lt;= maximum): continue product_pairs.append((x, y)) return product_pairs # 예시 n = 42 minimum = 2 maximum = 100 product_pairs = find_product_pairs(n, minimum, maximum) print(product_pairs) . [(2, 21), (3, 14), (6, 7)] . 곱의 조합쌍이 2개 이상이면 A는 정답을 맞힐 수 없다 | . def has_elements(sequence): return len(sequence) &gt;= 2 def step1(n, minimum, maximum): return find_product_pairs(n, minimum, maximum) def check_step1(pairs): &quot;&quot;&quot;A가 모르겠다고 한 것이 타당한지 확인&quot;&quot;&quot; return has_elements(pairs) # 예시 n = 20 minimum = 2 maximum = 100 pairs = step1(n, minimum, maximum) result = check_step1(pairs) answer = &quot;압니다&quot; * (1 - result) + &quot;모릅니다&quot; * result print(f&quot;두 수의 곱으로 {n}이(가) 주어졌을 때 A는 두 수가 무엇인지 압니까?: {answer}&quot;) print(f&quot;현재 A가 정답으로 고려하고 있는 후보군: {pairs}&quot;) . 두 수의 곱으로 20이(가) 주어졌을 때 A는 두 수가 무엇인지 압니까?: 모릅니다 현재 A가 정답으로 고려하고 있는 후보군: [(2, 10), (4, 5)] . B: &#45817;&#49888;&#51060; &#47784;&#47484; &#44144;&#46976; &#44163;&#51008; &#51060;&#48120; &#50508;&#44256; &#51080;&#50632;&#50612;&#50836; . - 짝수 $S$는 골드바흐의 추측에 의해 정답이 될 수 없다 . - 홀수 $S=x+y$를 만족하는 가능한 모든 $(x,y)$ 쌍을 고려하자 . - 모든 $(x,y)$쌍에 대해 $xy$를 계산하고 $xy$중에 곱의 쌍이 1개 뿐인 $xy$가 존재한다면 . - 해당 $S$는 처음에 B가 받은 수가 될 수 없다 . def use_goldbach_conjecture(num): if num &lt;= 2: return False return is_even(num) def is_even(num): return num % 2 == 0 def find_sum_pairs(n, minimum, maximum): sum_pairs = [] for x in range(minimum, maximum + 1): y = n - x if not (minimum &lt;= y &lt;= maximum and x &lt;= y): continue sum_pairs.append((x, y)) return sum_pairs def filter_sum_pairs_step2(sum_pairs, minimum, maximum): selected_pairs = [] for x, y in sum_pairs: n = x * y pairs = step1(n, minimum, maximum) if not check_step1(pairs): continue selected_pairs.append((x, y)) return selected_pairs def calculate_s_star(minimum, maximum): s_star_set = set() possible_summations = range(minimum * 2, maximum * 2 + 1) for sum_ in possible_summations: if use_goldbach_conjecture(sum_): continue sum_pairs = find_sum_pairs(sum_, minimum, maximum) selected_pairs = filter_sum_pairs_step2(sum_pairs, minimum, maximum) if len(sum_pairs) != len(selected_pairs): # B는 A의 답변을 듣기 전부터 A가 정답을 맞히지 못 할 것을 알고 있었다 continue s_star_set.add(sum_) return s_star_set def check_step2(num): &quot;&quot;&quot;B가 `A는 정답을 못 맞힐 거라고` 말한 것이 타당한지 확인&quot;&quot;&quot; return num in S_STAR . minimum = 2 maximum = 100 S_STAR = calculate_s_star(minimum, maximum) . S_STAR . {11, 17, 23, 27, 29, 35, 37, 41, 47, 53} . A: &#50500;, &#46160; &#49688;&#44032; &#47956;&#51648; &#50508;&#50520;&#49845;&#45768;&#45796; . - 주어진 곱을 $(x, y)$ 쌍으로 나눈다 . - 각 곱에 대해 A: 도저히 모르겠네요에서 사용한 알고리즘을 적용한다 (15, 21과 같은 수를 스킵하기 위함이다) . - 남은 곱에 대해 합을 구한다 . - 각 합에 대해 B: 당신이 모를 거란 것은 이미 알고 있었어요에서 사용한 알고리즘을 적용한다 . - 합이 $S^*$에 속해야 한다, 그렇지 않으면 제외한다 . - 하지만 A는 두 수가 무엇인지 알아냈으므로 이를 만족하는 곱의 쌍이 단 1개 뿐인 것을 의미한다 . 주어진 곱을 $(x, y)$ 쌍으로 나누자 . | 각 쌍에 대해 step1 함수의 알고리즘를 적용하고 남은 쌍에 대해 합을 구하자 . | 각 합에 대해 $S^*$에 속하는지 계산하자 . | $S^*$에 속하는 합이 1개만 남았다면 A는 정답을 맞힐 수 있다 . | . def filter_product_pairs_step3(product_pairs, minimum, maximum): selected_pairs = [] for x, y in product_pairs: s = x + y if not check_step2(s): continue selected_pairs.append((x, y)) return selected_pairs def step3(n, minimum, maximum): pairs = step1(n, minimum, maximum) if not check_step1(pairs): return [] selected_pairs = filter_product_pairs_step3(pairs, minimum, maximum) return selected_pairs def check_step3(pairs): &quot;&quot;&quot;A가 두 수가 무엇인지 알겠다고 한 것이 타당한지 확인&quot;&quot;&quot; return len(pairs) == 1 # 예시 n = 52 minimum = 2 maximum = 100 pairs = step3(n, minimum, maximum) result = check_step3(pairs) answer = &quot;압니다&quot; * result + &quot;모릅니다&quot; * (1 - result) print(f&quot;두 수의 곱으로 {n}이(가) 주어졌을 때 B의 답변을 들은 A는 두 수가 무엇인지 압니까?: {answer}&quot;) print(f&quot;현재 A가 정답으로 고려하고 있는 후보군: {pairs}&quot;) . 두 수의 곱으로 52이(가) 주어졌을 때 B의 답변을 들은 A는 두 수가 무엇인지 압니까?: 압니다 현재 A가 정답으로 고려하고 있는 후보군: [(4, 13)] . - A: 아, 두 수가 뭔지 알았습니다 상황까지 모순이 없음을 가정한다 . - 즉, 모든 step 함수에 대해 이전 step 함수까지 모순이 없음을 가정한다 . n = 15 minimum = 2 maximum = 100 pairs = step3(n, minimum, maximum) result = check_step3(pairs) answer = &quot;압니다&quot; * result + &quot;모릅니다&quot; * (1 - result) print(f&quot;두 수의 곱으로 {n}이(가) 주어졌을 때 B의 답변을 들은 A는 두 수가 무엇인지 압니까?: {answer}&quot;) print(f&quot;현재 A가 정답으로 고려하고 있는 후보군: {pairs}&quot;) . 두 수의 곱으로 15이(가) 주어졌을 때 B의 답변을 들은 A는 두 수가 무엇인지 압니까?: 모릅니다 현재 A가 정답으로 고려하고 있는 후보군: [] . - 두 수의 곱이 15라면 사실 A는 정답을 안다 (두 수는 3과 5이다) . - 하지만 이는 A: 아, 두 수가 뭔지 알았습니다 단계가 아닌 최초에 알았어야 하므로 모른다로 답변하게 설계했다 . B: &#51200;&#46020; &#46160; &#49688;&#44032; &#47956;&#51648; &#50508;&#44192;&#49845;&#45768;&#45796; . - 주어진 합을 $(x, y)$ 쌍으로 나누고 곱을 구한다 . - 이제 각 곱에 대해 생각해보자 . - 각 곱에 대해 A: 아, 두 수가 뭔지 알았습니다에서 사용한 알고리즘을 적용한다 . - 남은 곱이 단 하나뿐이라면 B는 정답을 맞힐 수 있다 . - 쉽게 말해 각 곱에 대해 다음을 생각하자 . - 내가 A라면 A: 아, 두 수가 뭔지 알았습니다라고 말하며 정답을 맞힐 수 있었을까? . - 그렇다면 통과시키고 아니라면 제외한다 . - 남은 곱이 1개뿐이면 B도 정답을 맞힐 수 있다 . def filter_sum_pairs_step4(sum_pairs, minimum, maximum): selected_pairs = [] for x, y in sum_pairs: n = x * y pair = step3(n, minimum, maximum) if not check_step3(pair): continue selected_pairs.append((x, y)) return selected_pairs def step4(n, minimum, maximum): if not check_step2(n): return [] sum_pairs = find_sum_pairs(n, minimum, maximum) selected_pairs = filter_sum_pairs_step4(sum_pairs, minimum, maximum) return selected_pairs def check_step4(pairs): &quot;&quot;&quot;B가 두 수가 무엇인지 알겠다고 한 것이 타당한지 확인&quot;&quot;&quot; return len(pairs) == 1 # 예시 n = 41 minimum = 2 maximum = 100 pairs = step4(n, minimum, maximum) result = check_step4(pairs) answer = &quot;압니다&quot; * result + &quot;모릅니다&quot; * (1 - result) print(f&quot;두 수의 합으로 {n}이(가) 주어졌을 때 A의 답변을 들은 B는 두 수가 무엇인지 압니까?: {answer}&quot;) print(f&quot;현재 B가 정답으로 고려하고 있는 후보군: {pairs}&quot;) . 두 수의 합으로 41이(가) 주어졌을 때 A의 답변을 들은 B는 두 수가 무엇인지 압니까?: 모릅니다 현재 B가 정답으로 고려하고 있는 후보군: [(3, 38), (4, 37), (7, 34), (9, 32), (10, 31), (12, 29), (13, 28), (14, 27), (15, 26), (16, 25), (17, 24), (18, 23), (19, 22)] . def solve(minimum, maximum, log=True): if log: print(&quot;#### 두 수의 합과 숫자 쌍 ####&quot;) answer = [] for n in range(minimum * 2, maximum * 2 + 1): pairs = step4(n, minimum, maximum) if log: print(f&quot;{n}: {pairs}&quot;) if not check_step4(pairs): continue pair = pairs[0] answer.append(pair) return answer . minimum = 2 maximum = 100 S_STAR = calculate_s_star(minimum, maximum) solution = solve(minimum, maximum) . #### 두 수의 합과 숫자 쌍 #### 4: [] 5: [] 6: [] 7: [] 8: [] 9: [] 10: [] 11: [(2, 9), (3, 8), (4, 7)] 12: [] 13: [] 14: [] 15: [] 16: [] 17: [(4, 13)] 18: [] 19: [] 20: [] 21: [] 22: [] 23: [(4, 19), (7, 16), (10, 13)] 24: [] 25: [] 26: [] 27: [(2, 25), (4, 23), (5, 22), (7, 20), (8, 19), (9, 18), (10, 17), (11, 16), (13, 14)] 28: [] 29: [(2, 27), (4, 25), (6, 23), (7, 22), (8, 21), (10, 19), (11, 18), (12, 17), (13, 16)] 30: [] 31: [] 32: [] 33: [] 34: [] 35: [(3, 32), (4, 31), (6, 29), (8, 27), (9, 26), (10, 25), (12, 23), (14, 21), (16, 19), (17, 18)] 36: [] 37: [(5, 32), (6, 31), (8, 29), (9, 28), (10, 27), (16, 21), (17, 20)] 38: [] 39: [] 40: [] 41: [(3, 38), (4, 37), (7, 34), (9, 32), (10, 31), (12, 29), (13, 28), (14, 27), (15, 26), (16, 25), (17, 24), (18, 23), (19, 22)] 42: [] 43: [] 44: [] 45: [] 46: [] 47: [(4, 43), (6, 41), (7, 40), (10, 37), (13, 34), (15, 32), (16, 31), (17, 30), (18, 29), (19, 28), (20, 27), (22, 25), (23, 24)] 48: [] 49: [] 50: [] 51: [] 52: [] 53: [(5, 48), (6, 47), (8, 45), (10, 43), (12, 41), (13, 40), (15, 38), (16, 37), (17, 36), (18, 35), (19, 34), (20, 33), (21, 32), (22, 31), (23, 30), (24, 29), (25, 28), (26, 27)] 54: [] 55: [] 56: [] 57: [] 58: [] 59: [] 60: [] 61: [] 62: [] 63: [] 64: [] 65: [] 66: [] 67: [] 68: [] 69: [] 70: [] 71: [] 72: [] 73: [] 74: [] 75: [] 76: [] 77: [] 78: [] 79: [] 80: [] 81: [] 82: [] 83: [] 84: [] 85: [] 86: [] 87: [] 88: [] 89: [] 90: [] 91: [] 92: [] 93: [] 94: [] 95: [] 96: [] 97: [] 98: [] 99: [] 100: [] 101: [] 102: [] 103: [] 104: [] 105: [] 106: [] 107: [] 108: [] 109: [] 110: [] 111: [] 112: [] 113: [] 114: [] 115: [] 116: [] 117: [] 118: [] 119: [] 120: [] 121: [] 122: [] 123: [] 124: [] 125: [] 126: [] 127: [] 128: [] 129: [] 130: [] 131: [] 132: [] 133: [] 134: [] 135: [] 136: [] 137: [] 138: [] 139: [] 140: [] 141: [] 142: [] 143: [] 144: [] 145: [] 146: [] 147: [] 148: [] 149: [] 150: [] 151: [] 152: [] 153: [] 154: [] 155: [] 156: [] 157: [] 158: [] 159: [] 160: [] 161: [] 162: [] 163: [] 164: [] 165: [] 166: [] 167: [] 168: [] 169: [] 170: [] 171: [] 172: [] 173: [] 174: [] 175: [] 176: [] 177: [] 178: [] 179: [] 180: [] 181: [] 182: [] 183: [] 184: [] 185: [] 186: [] 187: [] 188: [] 189: [] 190: [] 191: [] 192: [] 193: [] 194: [] 195: [] 196: [] 197: [] 198: [] 199: [] 200: [] . print(&quot;문제의 정답:&quot;, solution) . 문제의 정답: [(4, 13)] . - 빈 리스트는 중간에 모순이 발견되어 B: 저도 두 수가 뭔지 알겠습니다까지 도달하지 못한 것을 의미한다 . - 11과 같이 숫자 쌍이 2개 이상 존재하는 수는 B: 저도 두 수가 뭔지 알겠습니다에 모순되는 것을 의미한다 (B는 답이 어느 것인지 알지 못한다) . - 17처럼 숫자 쌍이 하나만 존재하는 것은 B: 저도 두 수가 뭔지 알겠습니다를 포함한 모든 대화가 모순 없이 이루어졌음을 뜻한다 (즉, 문제의 정답을 의미한다) . - 따라서 문제의 정답은 $(4,13)$이다 .",
            "url": "https://jaesu26.github.io/study-blog/math/python/2024/07/25/%EC%88%98%ED%95%99%EB%85%BC%EB%A6%AC%ED%80%B4%EC%A6%882.html",
            "relUrl": "/math/python/2024/07/25/%EC%88%98%ED%95%99%EB%85%BC%EB%A6%AC%ED%80%B4%EC%A6%882.html",
            "date": " • Jul 25, 2024"
        }
        
    
  
    
        ,"post7": {
            "title": "수학 논리 퀴즈",
            "content": "&#47928;&#51228; &#49345;&#54889; . - 2 이상 50 이하의 두 수 $x, y$를 고려하자 . - A에게는 두 수의 곱을 B에게는 두 수의 합을 알려주었다 . - 아래 A와 B의 대화를 바탕으로 $x, y$를 맞혀라 . A: 두 수가 뭔지 모르겠어 . B: 나도 모르겠어 . A: 두 수가 뭔지 알겠어! . B: 나도 알겠어! . - 문제적 남자에 출제된 문제이다 . - 문제 조건에 상한은 없었는데 다른 문제에는 상한이 있어 동일하게 50으로 설정했다 . &#54400;&#51060; . A: &#46160; &#49688;&#44032; &#47956;&#51648; &#47784;&#47476;&#44192;&#50612; . - A가 처음에 두 수가 뭔지 모르겠다고 했다 . - 그런데 두 수의 곱만을 알고서 두 수가 무엇인지 바로 알 수 있을까? . - 예컨대 $xy$가 34라고 해보자 . - 34는 2와 17의 곱으로만 만들어지므로 A는 두 수가 무엇인지 바로 알 수 있다 . - 하지만 만약 $xy$가 12라면 어떨까 . - A의 입장에서는 12가 3과 4의 곱인지 2와 6의 곱인지 현재로선 알 수 없다 . - 왜 1과 12는 고려하지 않는거지? &gt; 2 이상 50 이하의 수여야 하는데 1은 해당 범위에 포함되지 않음 . - $xy$에 대하여 1과 자기 자신을 제외한 약수가 2개를 초과한다면 A는 두 수가 무엇인지 알 수 없다 . - 즉 $xy$에 대하여 약수가 4개를 초과한다면 A는 두 수가 무엇인지 알 수 없다 . 알고리즘 | . - $xy$에 대하여 1과 자기 자신을 제외한 약수가 2개를 초과한다면 A는 두 수가 무엇인지 알 수 없다 . B: &#45208;&#46020; &#47784;&#47476;&#44192;&#50612; . - B는 A의 답변을 듣고 추가 정보를 얻어도 두 수가 뭔지 모르겠다고 했다 . - 그런데 A의 답변과 두 수의 합을 알고서 두 수가 무엇인지 알 수 있을까? . - 사실 A의 답변을 듣지 않아도 두 수가 무엇인지 알 수 있는 경우가 존재한다 . - 만약 $x+y$가 5 또는 99라고 해보자 . - $x+y$가 5라면 두 수는 2와 3이고 $x+y$가 99라면 두 수는 49와 50이다 . - $x+y$가 6 이상 98 이하라면 두 수를 무엇인지 바로 알 수 없게 된다 . - 이제 A의 답변 정보도 추가로 사용해보자 . - 일단 두 수는 2이상 50이하이므로 기본적으로 $x+y$의 범위는 4 이상 100 이하이다 . - 정답으로 가능한 $x+y$를 $T$라고 하자, $T$는 6 이상 98 이하이다 . - 그러면 $T$가 홀수일 때 두 수 $x,y$로 가능한 조합은 $(2, T-2), cdots, left( big lfloor frac{T}{2} big rfloor, big lfloor frac{T}{2} big rfloor + 1 right)$이고 . - $T$가 짝수일 때 두 수 $x,y$로 가능한 조합은 $(2, T-2), cdots, left( frac{T}{2}, frac{T}{2} right)$이다 . - 가능한 조합 각각에 대하여 $xy$를 계산하고 약수의 개수를 확인하자 . - 약수의 개수가 4개 이하라면 정답이 아니므로 제외하면 된다 . - 만약 4개 이하라면 A가 답을 맞혔을 것이다 . - 그렇게 해서 남아있는 조합이 1개 뿐이라면 B가 정답을 맞혔을 것이다 . - 예컨대 $x+y$가 8이라고 하자 . - 그러면 가능한 $x,y$의 조합은 $(2, 6), (3, 5), (4,4)$이다 . - 각 조합에 대하여 $xy$를 계산하면 $12, 15, 16$이다 . - 12의 약수의 개수는 $1,2,3,4,6,12$로 6개이다 . - 15의 약수의 개수는 $1,3,5,15$로 4개이다 . - 16의 약수의 개수는 $1,2,4,8,16$으로 5개이다 . - 만약 $x,y$가 3과 5라면 $xy$는 15이고 15는 3과 5의 곱으로만 이루어지므로 A가 처음에 답을 맞혔을 것이다 . - 따라서 약수의 개수가 4개 이하인 15는 $xy$로 가능하지 않다 . - 하지만 12와 16은 약수의 개수가 4개 초과이므로 $xy$로 가능하다 . - 즉, B는 A의 답변을 듣더라도 $x,y$가 2와 6인지 3과 5인지 알아낼 수 없다 . 알고리즘 | . - 더 간단하겐 가능한 $x,y$의 조합에 대해 $xy$를 계산한다 . - 그리고 해당 $xy$에 대해 A가 두 수가 뭔지 모르겠어라고 답변할 수 있으면 통과시키고 아니라면 제외한다 . - 남아 있는 $x,y$가 2개 이상이라면 B는 정답을 맞힐 수 없다 . A: &#46160; &#49688;&#44032; &#47956;&#51648; &#50508;&#44192;&#50612;! . - A는 B의 대답을 듣고 두 수가 무엇인지 알겠다고 했다 . - 그런데 A는 두 수의 곱만 알고 두 수의 합은 모르는데 B의 답변 정보를 두 수가 무엇인지 알아내는데 이용할 수 있을까? . - 사실 $xy$만 알아도 이를 바탕으로 $x+y$를 추론할 수 있다 . - 만약 $xy$가 12라고 해보자 . - 그러면 $x,y$는 2와 6이거나 3과 4이다 . - 다르게 얘기하면 $x+y$는 7이거나 8이다 . - 즉, $xy$로 $x+y$를 추론할 수 있으므로 B의 답변 정보를 사용할 수 있다! . - B가 나도 모르겠다라고 답변했으니 이를 사용해보자 . - 우선 $x+y$가 7이라고 가정해보자 . - 그러면 $xy$를 모르고 $x+y$만 알고 있는 B의 입장에서 가능한 $x,y$의 조합은 $(2,5),(3,4)$이다 . - 각 조합에 대해 $xy$를 계산하면 $10, 12$이다 . - 만약 $x, y$가 2와 5라면 $xy$는 10이며 10은 2와 5의 곱으로만 이루어진다 . - 그렇게 되면 A가 처음에 정답을 맞혔을 것이므로 처음에 모르겠다고 답변한 것과 모순된다 . - 하지만 $xy$가 12라면 약수의 개수가 6개로 가능한 곱의 조합이 2개 이상이다 . - 그러면 A가 처음에 모르겠다고 한 것이 합리적이다 . - 즉, B의 입장에서 $x+y$가 7일 때 가능한 $xy$는 12뿐이며 이때의 $x,y$는 3과 4이다 . - 그런데 이것이 사실이라면 B가 A의 답변을 듣고 정답을 모르겠다 답변한 것과 모순된다 . - 따라서 $x+y$는 7이 될 수 없다 . - 이제 $x+y$가 8이라고 가정해보자 . - 만약 $x+y$가 8이라고 가정했는데 모순이 안 된다면 A의 입장에선 $xy$는 12이고 $x+y$는 8이므로 $x,y$는 2와 6임을 알아낼 수 있다! . - $x+y$가 8일 때 B의 입장에서 가능한 $x,y$의 조합은 $(2,6), (3,5), (4,4)$이다 . - 각 조합에 대해 $xy$를 계산하면 $12, 15, 16$이다 . - 만약 $x, y$가 3과 5라면 $xy$는 15이며 15는 3과 5의 곱으로만 이루어진다 . - 그렇게 되면 A가 처음에 정답을 맞혔을 것이므로 처음에 모르겠다고 답변한 것과 모순된다 . - 하지만 $xy$가 12 또는 16이라면 약수의 개수가 4를 초과하므로 가능한 곱의 조합이 2개 이상이다 . - 12라면 2와 6 또는 3과 4. 16이라면 2와 8 또는 4와 4 . - 그러면 A가 처음에 모르겠다고 한 것이 합리적이다 . - 즉, $x+y$가 8이라면 B의 입장에서 가능한 $xy$는 12 또는 16이며 이때의 $x,y$는 2와 6 그리고 4와 4이다 . - 이러면 가능한 $x,y$ 조합이 2개 이상이므로 B의 입장에서는 $x,y$가 2와 6인지 4와 4인지 알 수 없다 . - 즉, $xy$가 12라면 B의 답변을 바탕으로 A는 $x+y$가 7이 아닌 8임을 알아낼 수 있다 . - 그렇게 되면 A는 $xy$는 12, $x+y$는 8이라는 정보를 바탕으로 $x,y$가 2와 6임을 알아내고 정답을 맞힐 수 있다 . 알고리즘 | . - A에게 주어진 $xy$를 바탕으로 가능한 $x+y$를 계산한다 . - 계산된 $x+y$ 각각에 대해 가능한 $xy$를 계산한다 . - $xy$ 집합에 대해 약수의 개수가 4개 이하인 것들을 제외한다 . - 그리고 남은 $xy$ 집합의 원소가 1개라면 B가 정답을 맞혔을 것이므로 해당 $x+y$는 제외한다 . - 이 과정을 $x+y$ 집합의 모든 원소에 대해 반복한 후 남아있는 원소가 1개 뿐이라면 A가 정답을 맞힐 수 있다 . - 더 간단하겐 가능한 $x,y$의 조합에 대해 $x+y$를 계산한다 . - 그리고 해당 $x+y$에 대해 B가 나도 모르겠어라고 답변할 수 있으면 통과시키고 아니라면 제외한다 . - 남아 있는 $x,y$가 1개라면 A는 정답을 맞힐 수 있다! . B: &#45208;&#46020; &#50508;&#44192;&#50612;! . - B는 A의 대답을 듣고 자신도 두 수가 무엇인지 알겠다고 했다 . - A의 대답을 이용하기 위해 A의 생각을 따라가보자 . - 만약 B에게 $x+y$가 8이라는 정보가 주어졌다고 해보자 . - 그러면 가능한 $x,y$의 조합은 $(2,6), (3,5), (4,4)$이다 . - 각 조합에 대해 $xy$를 계산하면 $12, 15, 16$이다 . 만약 $x, y$가 3과 5라면 $xy$는 15이며 15는 3과 5의 곱으로만 이루어진다 | . - 그렇게 되면 A가 처음에 정답을 맞혔을 것이므로 처음에 모르겠다고 답변한 것과 모순된다 . - 하지만 $xy$가 12 또는 16이라면 약수의 개수가 4를 초과하므로 가능한 곱의 조합이 2개 이상이다 . - 그러면 A가 처음에 모르겠다고 한 것이 합리적이다 . 만약 $xy$가 12라고 해보자 | . - A의 입장에서 볼 때 $xy$가 12라면 가능한 $x,y$의 조합은 $(2,6),(3,4)$이다 . - 각 조합에 대해 $x+y$를 계산하면 $7,8$이다 . - 우선 $x+y$가 7이라고 가정해보자 . - 그러면 A가 생각했을 때 $xy$를 모르는 B의 입장에서 가능한 $x,y$의 조합은 $(2,5),(3,4)$이다 . - 각 조합에 대해 $xy$를 계산하면 $10, 12$이다 . - 만약 $x, y$가 2와 5라면 $xy$는 10이며 10은 2와 5의 곱으로만 이루어진다 . - 그렇게 되면 A가 처음에 정답을 맞혔을 것이므로 처음에 모르겠다고 답변한 것과 모순된다 . - 하지만 $xy$가 12라면 약수의 개수가 6개로 가능한 곱의 조합이 2개 이상이다 . - 그러면 A가 처음에 모르겠다고 한 것이 합리적이다 . - 즉, A가 생각했을 때 $xy$를 모르는 B의 입장에서 $x+y$가 7이라면 가능한 $xy$는 12뿐이며 이때의 $x,y$는 3과 4이다 . - 그런데 이것이 사실이라면 B가 A의 답변을 듣고 정답을 모르겠다 답변한 것과 모순된다 . - 따라서 $x+y$는 7이 될 수 없다 . - 이제 $x+y$가 8이라고 가정해보자 . - $x+y$가 8이라면 A가 생각했을 때 $xy$를 모르는 B의 입장에서 가능한 $x,y$의 조합은 $(2,6), (3,5), (4,4)$이다 . - 각 조합에 대해 $xy$를 계산하면 $12, 15, 16$이다 . - 만약 $x, y$가 3과 5라면 $xy$는 15이며 15는 3과 5의 곱으로만 이루어진다 . - 그렇게 되면 A가 처음에 정답을 맞혔을 것이므로 처음에 모르겠다고 답변한 것과 모순된다 . - 하지만 $xy$가 12 또는 16이라면 약수의 개수가 4를 초과하므로 가능한 곱의 조합이 2개 이상이다 . - 12라면 2와 6 또는 3과 4, 16이라면 2와 8 또는 4와 4 . - 그러면 A가 처음에 모르겠다고 한 것이 합리적이다 . - 즉, A가 생각했을 때 $x+y$가 8이라고 가정하면 B의 입장에서 가능한 $xy$는 12 또는 16이며 이때의 $x,y$는 2와 6 그리고 4와 4이다 . - 이러면 가능한 $x,y$ 조합이 2개 이상이므로 B의 입장에선 $x,y$가 2와 6인지 4와 4인지 알 수 없다 . - 즉, A에게 주어진 $xy$가 12라면 B의 답변 정보를 바탕으로 A는 $x+y$가 7이 아닌 8임을 알아낼 수 있다 . - 그렇게 되면 A는 $xy$는 12, $x+y$는 8이라는 정보를 바탕으로 $x,y$가 2와 6임을 알아내고 정답을 맞힐 수 있다 . - 즉, $x,y$가 2와 6이라면 A: 두 수가 뭔지 모르겠어, B: 나도 모르겠어, A: 두 수가 뭔지 알겠어! 까지의 과정에 모순되는 점이 없다 . - 따라서 $x+y=8$이 주어진 B의 입장에선 $xy$의 후보군으로 12를 고려할 수 있다 . 그렇다면 이제 $xy$가 16이라고 가정하고 A의 입장이 되어 생각해보자 | . - A의 입장에서 볼 때 $xy$가 16이라면 가능한 $x,y$의 조합은 $(2,8),(4,4)$이다 . - 각 조합에 대해 $x+y$를 계산하면 $8,10$이다 . - 우선 $x+y$가 8이라고 가정해보자 . - 그러면 A가 생각했을 때 $xy$를 모르는 B의 입장에서 가능한 $x,y$의 조합은 $(2,6),(3,5),(4,4)$이다 . - 각 조합에 대해 $xy$를 계산하면 $12, 15,16$이다 . - 약수의 개수가 4개를 초과해야 하므로 가능한 $xy$는 12 또는 16이다 . - $x+y$가 8이라면 B: 나도 모르겠어라는 답변이 합리적이다 . - 이제 $x+y$가 10이라고 가정해보자 . - 그러면 A가 생각했을 때 $xy$를 모르는 B의 입장에서 가능한 $x,y$의 조합은 $(2,8),(3,7),(4,6),(5,5)$이다 . - 각 조합에 대해 $xy$를 계산하면 $16, 21,24,25$이다 . - 약수의 개수가 4개를 초과해야 하므로 가능한 $xy$는 16 또는 24이다 . - $x+y$가 10이라면 B: 나도 모르겠어라는 답변이 합리적이다 . - 따라서 만약 $xy$가 16이라면 A의 입장에서 볼 때 가능한 $x+y$는 8과 10이며 이때의 $x,y$는 4와 4 그리고 2와 8이다 . - 그런데 이렇게 되면 A의 입장에선 $x+y$가 8과 10 둘 다 가능하므로 둘 중 어느것인지 알지 못한다 . - 그러면 A: 두 수가 뭔지 알겠어!와 같이 대답할 수 없으므로 모순이다 . - 즉, 처음 B에게 주어진 $x+y$가 8이라면 $xy$는 16이 될 수 없다 . - 따라서 가능한 $xy$는 12이므로 B는 $x,y$가 2와 6임을 알 수 있고 B: 나도 알겠어!라고 대답할 수 있다 . 알고리즘 | . - $x+y$를 바탕으로 가능한 $x,y$의 조합에 대해 $xy$를 계산한다 . - 그리고 해당 $xy$에 대해 A가 두 수가 뭔지 알겠어!라고 답변할 수 있으면 통과시키고 아니라면 제외한다 . - 남아 있는 $x,y$가 1개라면 B는 정답을 맞힐 수 있다! . &#54028;&#51060;&#50028;&#51004;&#47196; &#54400;&#50612;&#48372;&#51088; . - 위의 풀이는 정답인 2와 6을 시작으로 접근했기에 쉽게 문제를 해결할 수 있었다 (사실 아무 두 수나 정한건데 그게 정답이었다;;) . - 모든 경우를 빠르게 고려하기 위해 파이썬을 사용해보자 . - 정답이 2와 6만 존재하는지 다른 경우도 존재하는지 알 수 있을 것이다 . A: &#46160; &#49688;&#44032; &#47956;&#51648; &#47784;&#47476;&#44192;&#45796; . - 로직을 정리하고 가자 . - 일단 두 수의 곱 $n$이 주어지면 $n = xy$를 만족하는 $(x,y)$ 쌍을 찾는다 . - 단, $ min leq x leq y leq max$ . - 곱의 조합 쌍이 2개 이상이면 A는 두 수가 무엇인지 알 수 없다 . 곱의 조합 쌍을 찾자 | . import math def find_product_pairs(n, minimum=2, maximum=50): product_pairs = [] for x in range(minimum, math.isqrt(n) + 1): if n % x != 0: continue y = n // x if not (x &lt;= y and minimum &lt;= x &lt;= maximum and minimum &lt;= y &lt;= maximum): continue product_pairs.append((x, y)) return product_pairs # 예시 n = 20 minimum = 2 maximum = 50 product_pairs = find_product_pairs(n, minimum, maximum) print(product_pairs) . [(2, 10), (4, 5)] . 곱의 조합쌍이 2개 이상이면 A는 정답을 맞힐 수 없다 | . def has_elements(sequence): return len(sequence) &gt;= 2 def step1(n, minimum=2, maximum=50): return find_product_pairs(n, minimum, maximum) def check_step1(pairs): &quot;&quot;&quot;A가 모르겠다고 한 것이 타당한지 확인&quot;&quot;&quot; return has_elements(pairs) # 예시 n = 12 minimum = 2 maximum = 50 pairs = step1(n, minimum, maximum) result = check_step1(pairs) answer = &quot;압니다&quot; * (1 - result) + &quot;모릅니다&quot; * result print(f&quot;두 수의 곱으로 {n}이(가) 주어졌을 때 A는 두 수가 무엇인지 압니까?: {answer}&quot;) print(f&quot;현재 A가 정답으로 고려하고 있는 후보군: {pairs}&quot;) . 두 수의 곱으로 12이(가) 주어졌을 때 A는 두 수가 무엇인지 압니까?: 모릅니다 현재 A가 정답으로 고려하고 있는 후보군: [(2, 6), (3, 4)] . B: &#45208;&#46020; &#47784;&#47476;&#44192;&#45796; . - 두 수의 합 $n$이 주어지면 $n = x+y$를 만족하는 $(x,y)$ 쌍을 찾는다 . - $(x,y)$ 쌍 각각에 대해 $xy$를 계산한다 . - $xy$에 대해 A: 두 수가 뭔지 모르겠어에서 사용한 알고리즘을 적용한다 . - 남은 $(x,y)$ 쌍이 2개 이상이면 B는 두 수가 뭔지 알 수 없다 . 합이 $n$인 $x, y$ 조합을 찾자 | . def find_sum_pairs(n, minimum=2, maximum=50): sum_pairs = [] for x in range(minimum, maximum + 1): y = n - x if not (minimum &lt;= y &lt;= maximum and x &lt;= y): continue sum_pairs.append((x, y)) return sum_pairs # 예시 실행 n = 8 minimum = 2 maximum = 50 sum_pairs = find_sum_pairs(n, minimum, maximum) print(sum_pairs) . [(2, 6), (3, 5), (4, 4)] . 각 조합에 대해 곱의 조합쌍이 2개 이상인지 파악하자 | . def filter_sum_pairs_step2(sum_pairs, minimum=2, maximum=50): selected_pairs = [] for x, y in sum_pairs: n = x * y pairs = step1(n, minimum, maximum) if not check_step1(pairs): continue selected_pairs.append((x, y)) return selected_pairs def step2(n, minimum=2, maximum=50): sum_pairs = find_sum_pairs(n, minimum, maximum) selected_pairs = filter_sum_pairs_step2(sum_pairs, minimum, maximum) return selected_pairs def check_step2(pairs): &quot;&quot;&quot;B가 모르겠다고 한 것이 타당한지 확인&quot;&quot;&quot; return has_elements(pairs) # 예시 n = 8 minimum = 2 maximum = 50 pairs = step2(n, minimum, maximum) result = check_step2(pairs) answer = &quot;압니다&quot; * (1 - result) + &quot;모릅니다&quot; * result print(f&quot;두 수의 합으로 {n}이(가) 주어졌을 때 A의 답변을 들은 B는 두 수가 무엇인지 압니까?: {answer}&quot;) print(f&quot;현재 B가 정답으로 고려하고 있는 후보군: {pairs}&quot;) . 두 수의 합으로 8이(가) 주어졌을 때 A의 답변을 들은 B는 두 수가 무엇인지 압니까?: 모릅니다 현재 B가 정답으로 고려하고 있는 후보군: [(2, 6), (4, 4)] . A: &#46160; &#49688;&#44032; &#47956;&#51648; &#50508;&#50520;&#50612;! . - 주어진 곱을 $(x, y)$ 쌍으로 나눈다 . - 각 곱에 대해 A: 두 수가 뭔지 모르겠어에서 사용한 알고리즘을 적용한다 (15, 21과 같은 수를 스킵하기 위함이다) . - 남은 곱에 대해 합을 구한다 . - 각 합에 대해 B: 나도 모르겠어에서 사용한 알고리즘을 적용한다 . - 이를 만족하는 합이 2개 이상이면 A는 정답을 맞히지 못한다 . - 하지만 A는 두 수가 무엇인지 알아냈으므로 이를 만족하는 합이 단 1개 뿐인 것을 의미한다 . 주어진 곱을 $(x, y)$ 쌍으로 나누자 . | 각 쌍에 대해 step1 함수의 알고리즘를 적용하고 남은 쌍에 대해 합을 구하자 . | 각 합에 대해 step2 함수를 적용하고 이를 만족하는 합을 고려하자 . | 합이 1개만 남았다면 A는 정답을 맞힐 수 있다 . | . def filter_product_pairs_step3(product_pairs, minimum=2, maximum=50): selected_pairs = [] for x, y in product_pairs: n = x + y pairs = step2(n, minimum, maximum) if not check_step2(pairs): continue selected_pairs.append((x, y)) return selected_pairs def step3(n, minimum=2, maximum=50): pairs = step1(n, minimum, maximum) if not check_step1(pairs): return [] selected_pairs = filter_product_pairs_step3(pairs, minimum, maximum) return selected_pairs def check_step3(pairs): &quot;&quot;&quot;A가 두 수가 무엇인지 알겠다고 한 것이 타당한지 확인&quot;&quot;&quot; return len(pairs) == 1 # 예시 n = 12 minimum = 2 maximum = 50 pairs = step3(n, minimum, maximum) result = check_step3(pairs) answer = &quot;압니다&quot; * result + &quot;모릅니다&quot; * (1 - result) print(f&quot;두 수의 곱으로 {n}이(가) 주어졌을 때 B의 답변을 들은 A는 두 수가 무엇인지 압니까?: {answer}&quot;) print(f&quot;현재 A가 정답으로 고려하고 있는 후보군: {pairs}&quot;) . 두 수의 곱으로 12이(가) 주어졌을 때 B의 답변을 들은 A는 두 수가 무엇인지 압니까?: 압니다 현재 A가 정답으로 고려하고 있는 후보군: [(2, 6)] . - A: 두 수가 뭔지 알겠어! 상황까지 모순이 없음을 가정한다 . - 즉, 모든 step 함수에 대해 이전 step 함수까지 모순이 없음을 가정한다 . n = 15 minimum = 2 maximum = 50 pairs = step3(n, minimum, maximum) result = check_step3(pairs) answer = &quot;압니다&quot; * result + &quot;모릅니다&quot; * (1 - result) print(f&quot;두 수의 곱으로 {n}이(가) 주어졌을 때 B의 답변을 들은 A는 두 수가 무엇인지 압니까?: {answer}&quot;) print(f&quot;현재 A가 정답으로 고려하고 있는 후보군: {pairs}&quot;) . 두 수의 곱으로 15이(가) 주어졌을 때 B의 답변을 들은 A는 두 수가 무엇인지 압니까?: 모릅니다 현재 A가 정답으로 고려하고 있는 후보군: [] . - 두 수의 곱이 15라면 사실 A는 정답을 안다 (두 수는 3과 5이다) . - 하지만 이는 A: 두 수가 뭔지 알겠어! 단계가 아닌 최초에 알았어야 하므로 모른다로 답변하게 설계했다 . B: &#45208;&#46020; &#50508;&#50520;&#50612;! . - 주어진 합을 $(x, y)$ 쌍으로 나누고 곱을 구한다 . - 이제 각 곱에 대해 생각해보자 . - 각 곱에 대해 A: 두 수가 뭔지 알겠어!에서 사용한 알고리즘을 적용한다 . - 남은 곱이 단 하나뿐이라면 B는 정답을 맞힐 수 있다 . def filter_sum_pairs_step4(sum_pairs, minimum=2, maximum=50): selected_pairs = [] for x, y in sum_pairs: n = x * y pair = step3(n, minimum, maximum) if not check_step3(pair): continue selected_pairs.append((x, y)) return selected_pairs def step4(n, minimum=2, maximum=50): sum_pairs = find_sum_pairs(n, minimum, maximum) pairs = step2(n, minimum, maximum) if not check_step2(pairs): return [] selected_pairs = filter_sum_pairs_step4(sum_pairs, minimum, maximum) return selected_pairs def check_step4(pairs): &quot;&quot;&quot;B가 두 수가 무엇인지 알겠다고 한 것이 타당한지 확인&quot;&quot;&quot; return len(pairs) == 1 # 예시 n = 8 minimum = 2 maximum = 50 pairs = step4(n, minimum, maximum) result = check_step4(pairs) answer = &quot;압니다&quot; * result + &quot;모릅니다&quot; * (1 - result) print(f&quot;두 수의 합으로 {n}이(가) 주어졌을 때 A의 답변을 들은 B는 두 수가 무엇인지 압니까?: {answer}&quot;) print(f&quot;현재 B가 정답으로 고려하고 있는 후보군: {pairs}&quot;) . 두 수의 합으로 8이(가) 주어졌을 때 A의 답변을 들은 B는 두 수가 무엇인지 압니까?: 압니다 현재 B가 정답으로 고려하고 있는 후보군: [(2, 6)] . def solve(minimum=2, maximum=50, log=True): if log: print(&quot;#### 두 수의 합과 숫자 쌍 ####&quot;) answer = [] for n in range(minimum * 2, maximum * 2 + 1): pairs = step4(n, minimum, maximum) if log: print(f&quot;{n}: {pairs}&quot;) if not check_step4(pairs): continue pair = pairs[0] answer.append(pair) return answer . minimum = 2 maximum = 50 solution = solve(minimum, maximum) . #### 두 수의 합과 숫자 쌍 #### 4: [] 5: [] 6: [] 7: [] 8: [(2, 6)] 9: [] 10: [] 11: [] 12: [] 13: [] 14: [] 15: [] 16: [] 17: [] 18: [] 19: [] 20: [] 21: [] 22: [] 23: [] 24: [] 25: [] 26: [] 27: [] 28: [] 29: [] 30: [] 31: [] 32: [] 33: [] 34: [] 35: [] 36: [] 37: [] 38: [] 39: [] 40: [] 41: [] 42: [] 43: [] 44: [] 45: [] 46: [] 47: [] 48: [] 49: [] 50: [] 51: [] 52: [] 53: [] 54: [] 55: [] 56: [] 57: [] 58: [] 59: [] 60: [] 61: [] 62: [] 63: [] 64: [] 65: [] 66: [] 67: [] 68: [] 69: [] 70: [] 71: [] 72: [] 73: [] 74: [] 75: [] 76: [] 77: [(35, 42)] 78: [] 79: [] 80: [(36, 44)] 81: [] 82: [(40, 42)] 83: [] 84: [] 85: [(36, 49), (40, 45)] 86: [] 87: [] 88: [] 89: [] 90: [] 91: [] 92: [] 93: [] 94: [] 95: [] 96: [] 97: [] 98: [] 99: [] 100: [] . print(&quot;문제의 정답:&quot;, solution) . 문제의 정답: [(2, 6), (35, 42), (36, 44), (40, 42)] . - 빈 리스트는 중간에 모순이 발견되어 B: 나도 알았어!까지 도달하지 못한 것을 의미한다 . - 두 수의 합이 85인 경우 숫자 쌍이 2개 존재하는데 이는 B: 나도 알았어!에 모순되는 것을 의미한다 (B는 둘 중 어느 것인지 알지 못한다) . - 8이나 77처럼 숫자 쌍이 하나만 존재하는 것은 B: 나도 알았어!를 포함한 모든 대화가 모순 없이 이루어졌음을 뜻한다 (즉, 문제의 정답을 의미한다) . - 따라서 문제의 정답은 $(2, 6), ,(35,42), ,(36,44), ,(40,42)$이다 . &#48512;&#47197; . &#54616;&#54620;&#51060; 2&#44032; &#50500;&#45768;&#46972; 10&#51060;&#46972;&#47732;? . minimum = 10 maximum = 50 solution = solve(minimum, maximum, log=False) . print(&quot;문제의 정답:&quot;, solution) . 문제의 정답: [(10, 21), (35, 42), (36, 44), (40, 42)] . - 이때의 정답은 $(10, 21), ,(35,42), ,(36,44), ,(40,42)$이다 . &#49345;&#54620;&#51060; 50&#51060; &#50500;&#45768;&#46972; 100&#51060;&#46972;&#47732;? . minimum = 2 maximum = 100 solution = solve(minimum, maximum, log=False) . print(&quot;문제의 정답:&quot;, solution) . 문제의 정답: [(2, 6), (84, 88)] . - 이때의 정답은 $(2, 6), ,(84,88)$이다 .",
            "url": "https://jaesu26.github.io/study-blog/math/python/2024/06/22/%EC%88%98%ED%95%99%EB%85%BC%EB%A6%AC%ED%80%B4%EC%A6%881.html",
            "relUrl": "/math/python/2024/06/22/%EC%88%98%ED%95%99%EB%85%BC%EB%A6%AC%ED%80%B4%EC%A6%881.html",
            "date": " • Jun 22, 2024"
        }
        
    
  
    
        ,"post8": {
            "title": "익스트림 스우 in 100에 포함되지 않는 직업이 존재할 확률은 1이다",
            "content": "- 전제 조건: 모든 직업에게 공평한 상황이라 익스우 in 100에 포함될 확률이 동일하다고 가정 . &#52649;&#48516;&#54620; &#51064;&#50896;&#51060; &#46020;&#51204;&#54616;&#45716; &#44221;&#50864; . - 익스우 in 100에 포함되지 않은 직업이 적어도 하나 이상 존재할 사건을 $A$라 하자 . - $A$의 여집합은 익스우 in 100에 모든 직업이 포함되는 것이다 . - 이때 $P(A) = 1 - P(A^c)$ . - 따라서 $P(A^c)$를 계산하면 $P(A)$를 알 수 있다 . - 간단하게 직업별로 10명씩 총 460명이 도전한다고 가정해보자 . - 사건 $A^c$의 경우 직업별로 적어도 한 명 이상 포함되야 하므로 직업별로 1명씩 총 46명을 뽑고 나머지 54명은 남은 414명에서 아무나 뽑으면 된다 . - 이제 414명에서 54명을 뽑는 방법에 대해 생각해보자 . - 동일 직업이면 동일 원소이므로 414명이란 수치는 46개 직업에 대하여 각 직업의 원소가 9개가 존재하여 도출된 값이다 . - 이러한 집합에서 원소를 뽑을 땐 중복 조합을 사용하면 된다 . - 즉, 46개의 직업에 대해 중복을 포함하여 54명을 뽑는 것이다 . - 여기서 문제가 발생하는데 각 직업에 대해서 최대로 뽑을 수 있는 인원이 9명으로 이는 54명 보다 작다 . - 따라서 하나의 직업에서만 뽑는 경우처럼 최대로 뽑을 수 있는 인원을 초과하는 방법은 제외해야 된다 . - 일단 뽑을 수 있는 최대 인원 수를 생각하지 말아보자 . - 46개의 직업에 대해 중복을 포함하여 54명을 뽑는 방법의 경우의 수는 $x_1 + x_2 + cdots + x_{46} = 54$를 만족하는 음이 아닌 정수 해의 개수와 동일하다 . - 뽑을 수 있는 최대 인원 수를 고려하는 것은 조건식 $0 le x_1, x_2, cdots ,x_{46} le 9$를 추가하는 것과 동일하다 . - 이 문제를 이론적으로 해결하기는 어려우니 일단 더 쉬운 조건을 고려하자 . - 처음 가정에서 직업별로 10명씩 총 460명이 도전한다고 했는데 10명이 아닌 100명으로 변경하자 . - 그러면 방정식은 $x_1 + x_2 + cdots + x_{46} = 54$로 동일하나 조건식이 $0 le x_1, x_2, cdots ,x_{46} le 99$로 변경된다 . - 해당 방정식을 만족하는 음이 아닌 정수 해의 개수는 $ _{46}H_{54} = , _{99}C_{54}$이다 . - 같은 방법으로 46개 직업에서 중복을 포함하여 100명을 뽑는 경우의 수는 $ _{46}H_{100} = , _{145}C_{100}$이다 . import math denominator = math.comb(145, 100) numerator = math.comb(99, 54) result = numerator / denominator print(result) . 4.688191145276719e-10 . - $P(A^c) approx 0$이므로 $P(A) approx 1$이다 . - 참고로 위와 같이 계산하게 되면 각 직업별로 인원 수가 동일하면서 100명 이상이기만 하면 $P(A)$는 동일하게 계산된다 . - 즉, 각 직업별 인원 수가 동일하면서 100명 이상이면 전체 인원 수와 $P(A)$는 상관이 없다 . &#52649;&#48516;&#54616;&#51648; &#50506;&#51008; &#51064;&#50896;&#51060; &#46020;&#51204;&#54616;&#45716; &#44221;&#50864; . - 각 직업별로 인원 수가 100명보다 적어 충분하지 않은 경우를 마저 생각하자 . - 최댓값이 제한되어 있는 조건식을 고려해야 되기 때문에 이론적으로 구하기는 복잡하다 . - 동적계획법 알고리즘을 통해 이를 해결해보자 . - i + 1개의 직업에서 최댓값 p를 고려하여 j명을 중복을 허용해 뽑는 것을 생각해보자 . - i + 1개의 직업은 i개의 직업과 새로 추가된 직업 x로 이루어졌다고 하자 . - i개의 직업으로 구성된 경우에 x를 추가한다면 최소 0개부터 최대 p개까지 가능하다 . - 만약 p보다 j가 더 작다면 최대 j개 까지 가능하다 . - 이제 dp[i][j]를 i개의 직업에서 최댓값 p를 고려하여 j명을 중복을 허용해 뽑는 가짓수라고 정의하자 . - 그러면 정의에 따라 dp[i + 1][j] = dp[i][j] + dp[i][j - 1] + ... + dp[i][j - min(j, p)]가 성립한다 . - 더 쉽게 생각해보면 x를 포함한 i + 1개의 직업이 p를 고려해 j명을 중복을 허용해 뽑혔다고 가정하자 . - 모든 경우에 대하여 x를 제거해보자 . - 그러면 남은 경우는 i개의 직업에서 p를 고려해 j - min(j, p)명부터 j명까지 각각에 대해 중복을 허용해 뽑은 것과 동일하다 . def reset_dp(target_sum, job_count): dp = [[0] * (target_sum + 1) for _ in range(job_count + 1)] dp[0][0] = 1 return dp def solution(target_sum, job_count, max_value): dp = reset_dp(target_sum, job_count) for i in range(job_count): for j in range(target_sum + 1): for k in range(min(j, max_value) + 1): dp[i + 1][j] += dp[i][j - k] return dp[job_count][target_sum] # 주어진 등식의 해의 개수 계산 target_sum = 54 job_count = 46 max_value = 9 result = solution(target_sum, job_count, max_value) print(&quot;음이 아닌 정수 해의 개수:&quot;, result) . 음이 아닌 정수 해의 개수: 31434811605304652607044605014 . target_sum = 100 job_count = 46 max_value = 10 result2 = solution(target_sum, job_count, max_value) print(&quot;음이 아닌 정수 해의 개수:&quot;, result2) . 음이 아닌 정수 해의 개수: 34275603444262175999828781553336591830 . result / result2 . 9.171191298330568e-10 . - 결론: 충분하지 않은 인원이 도전해도 결과는 동일하다 (확률이 동일하지는 않다) . &#52572;&#45843;&#44050;&#50640; &#46384;&#47480; &#54869;&#47456;&#51032; &#48320;&#54868; . def compute_p(max_value): result = solution(54, 46, max_value - 1) result2 = solution(100, 46, max_value) return result / result2 . compute_p(100) . 4.688191145276719e-10 . compute_p(73) . 4.688191145276719e-10 . - 소수점 아래 15번째 자리까지밖에 보여주지 않아서 최댓값이 73일 때와 100일 때의 확률이 동일해보인다 . - 하지만 완전히 동일한 값은 아님 . compute_p(3) . 0.004733319274428594 . compute_p(4) . 8.87196632830438e-06 . - 최댓값이 3일 때가 확률이 가장 크다 (최댓값인 2인 경우는 100명을 뽑을 수 없어서 불가능) . - 최댓값이 커질수록 확률이 작아지다가 100명부터는 동일해진다 .",
            "url": "https://jaesu26.github.io/study-blog/statistics/2024/04/24/%EC%9D%B5%EC%8A%A4%EC%9A%B0in100.html",
            "relUrl": "/statistics/2024/04/24/%EC%9D%B5%EC%8A%A4%EC%9A%B0in100.html",
            "date": " • Apr 24, 2024"
        }
        
    
  
    
        ,"post9": {
            "title": "고차원 공간일수록 대부분의 점들은 멀리 떨어져 있고 모든 점들 사이의 거리는 평균적으로 같다",
            "content": "import matplotlib.pyplot as plt import numpy as np . np.sum((np.random.uniform(size=2) - np.random.uniform(size=2))**2) . 0.19981770653490832 . n = 1000 dim2dist = {2: [], 30000: []} for dim in [2, 30000]: for _ in range(n): p1 = np.random.uniform(size=dim) p2 = np.random.uniform(size=dim) dist = np.sum((p1 - p2)**2) dim2dist[dim].append(dist) . min(dim2dist[2]), max(dim2dist[2]), np.mean(dim2dist[2]), np.var(dim2dist[2]), max(dim2dist[2]) / min(dim2dist[2]) . (0.0002096937034319855, 1.6285832729634961, 0.34593134346038984, 0.08637199565551319, 7766.4862907613715) . min(dim2dist[10]), max(dim2dist[10]), np.mean(dim2dist[10]) . (0.2289251283188965, 4.633467257926964, 1.7003609018743633) . min(dim2dist[30]), max(dim2dist[30]), np.mean(dim2dist[30]), np.var(dim2dist[30]) . (2.192176306989295, 8.60620714392669, 4.978863901249808, 1.1912929669596537) . min(dim2dist[300]), max(dim2dist[300]), np.mean(dim2dist[300]), np.var(dim2dist[300]), max(dim2dist[300]) / min(dim2dist[300]) . (38.47870755047428, 61.327182542855944, 49.74084821028326, 11.320344445619986, 1.5937952817778578) . min(dim2dist[3000]), max(dim2dist[3000]), np.mean(dim2dist[3000]), np.var(dim2dist[3000]), max(dim2dist[3000]) / min(dim2dist[3000]) . (463.4071309390999, 531.8547062483211, 500.192034811842, 116.15827310494751, 1.1477050540213125) . min(dim2dist[30000]), max(dim2dist[30000]), np.mean(dim2dist[30000]), np.var(dim2dist[30000]), max(dim2dist[30000]) / min(dim2dist[30000]) . (4902.3813668942985, 5133.469601321977, 5000.083729166341, 1228.961585304423, 1.0471379554410463) . plt.hist(dim2dist[2]) plt.show() . plt.hist(dim2dist[10]) plt.show() . plt.hist(dim2dist[30]) plt.show() . plt.hist(dim2dist[300]) plt.show() . plt.hist(dim2dist[3000]) plt.show() . plt.hist(dim2dist[30000]) plt.show() . - 증명할 것: $ lim limits_{d to infty} operatorname{Var} left[ dfrac{R}{ operatorname{E} left[R right]} right] = 0$ . - 참고로 $ lim limits_{d to infty} operatorname{E} left[ dfrac{R}{ operatorname{E} left[R right]} right] = 1$인데 이는 당연한 결과이다 . - 애초에 $ operatorname{E} left[ dfrac{R}{ operatorname{E} left[R right]} right] = dfrac{ operatorname{E} left[R right]}{ operatorname{E} left[R right]} = 1$이다 .",
            "url": "https://jaesu26.github.io/study-blog/statistics/2024/03/26/%EC%B0%A8%EC%9B%90%EC%9D%98%EC%A0%80%EC%A3%BC.html",
            "relUrl": "/statistics/2024/03/26/%EC%B0%A8%EC%9B%90%EC%9D%98%EC%A0%80%EC%A3%BC.html",
            "date": " • Mar 26, 2024"
        }
        
    
  
    
        ,"post10": {
            "title": "익몬 적합도 검정",
            "content": "&#44032;&#49444; &#49444;&#51221; . - 익몬을 하는데 빅풋이 체감상 마지막 탐색 위치(7시 방향)에 자주 나온다고 느꼈다 . - 그래서 적합도 검정을 위해 빅풋의 등장 위치를 기록하기로 했다 . - 한줄 요약: 빅풋의 등장 위치가 편향되었다 싶어서 시작 . - $H_0$: 각 위치별 빅풋 등장확률은 같다 . - $H_a$: 각 위치별 빅풋 등장확률은 같지 않다 . - 적합도 검정, 유의수준은 $0.99$로 결정했다 . - 일반적으로 기대 도수가 $5$이상인 범주가 $80 %$는 되야 하는데 표본 크기를 $45$로 하면 각 기대 도수는 $5$이다 . - 나는 유의수준을 크게 해서 신뢰구간도 크므로 유의 수준 $0.95$에 비해서 기각하기 쉽지 않다 . - 따라서 표본 크기 $n = 100$으로 하기로 결정했다 . from scipy import stats . data = {0: 12, # 제단 1: 8, 3: 15, 5: 13, 6: 7, 7: 13, 9: 15, 11: 4, 12: 13, } . n = len(data.keys()) expected_value = sum(data.values()) / n x = 0 for value in data.values(): x += (value - expected_value)**2 / expected_value . x . 10.700000000000001 . p_value = 1 - stats.chi2.cdf(x=x, df=n - 1) . p_value . 0.2192837586860077 . - p-value가 유의 수준보다 크므로 영가설을 기각할 수 없다 . - 따라서, 각 위치별로 빅풋의 등장 확률이 다르다고 할 수 없다 .",
            "url": "https://jaesu26.github.io/study-blog/statistics/2024/02/24/%EB%A9%94%EC%9D%B4%ED%94%8C%EC%9D%B5%EB%AA%AC%ED%99%95%EB%A5%A0%EA%B2%80%EC%A0%95.html",
            "relUrl": "/statistics/2024/02/24/%EB%A9%94%EC%9D%B4%ED%94%8C%EC%9D%B5%EB%AA%AC%ED%99%95%EB%A5%A0%EA%B2%80%EC%A0%95.html",
            "date": " • Feb 24, 2024"
        }
        
    
  
    
        ,"post11": {
            "title": "공격력/마력 확률 문제",
            "content": "&#47928;&#51228; &#49444;&#51221; . - 공격력 직업으로 공격력 2줄 옵션(12% / 9%)을 획득할 때까지 에디셔널 잠재 능력을 재설정하는 상황을 가정하자 . - 옵션을 재설정하다보면 공격력 2줄이 등장하기 전에 마력 2줄이 등장하는 경우를 쉽게 볼 수 있다 . - 누군가는 공격력 직업으로 옵션을 재설정할 경우 공격력보다 마력이 등장할 확률이 더 높다고 체감할 수 있다 . - 여기서 가설은 공격력 직업으로 옵션을 재설정할 경우 공격력 2줄보다 마력 2줄이 등장할 확률이 더 높다 이다 . - 이것이 진짜인지 확인하는 방법은 간단한데 공격력 직업으로 에디셔널 잠재 능력을 수많이 재설정하면 된다 . - 이를 혼자 진행하는 것은 어려우니 여러 명에게 데이터를 받아 진행할 수도 있다 . - 만약, 데이터를 받을 사람을 미리 무작위로 정하는 것이 아닌 아무나에게 데이터를 받는다면 해당 데이터가 편향될 가능성이 높다 . - 대개, 데이터를 제출하는 사람은 해당 가설이 참이라고 느낀 사람이 많을 것이다 . - 반대로 공격력 2줄 옵션을 마력 2줄 옵션보다 먼저 획득한 사람은 해당 가설이 거짓이라고 생각하며 굳이 데이터를 제출하진 않을 것이다 (가설이 거짓임을 체감했기 때문) . - 그러면 수집된 데이터에는 마력 2줄 옵션이 공격력 2줄보다 많이 포함되고 이는 가설이 참이라는 결론을 도출하게 된다 . - 무작위로 수집된 데이터라면 공격력 2줄이 등장할 확률과 마력 2줄이 등장할 확률은 같다 . - 이에 대해 보충 설명을 하면 다음과 같다 . - $n$명의 사람들에 대해 공격력 2줄 옵션이 나올 때까지 큐브를 사용한다고 가정하자 . - 이 중 평균적으로 $ frac{n}{2}$명은 공격력 2줄 옵션이 먼저 나왔을 것이며 나머지 $ frac{n}{2}$명은 마력 2줄 옵션이 먼저 나왔을 것이다 . - 여기서, 공격력 등장 횟수 = 마력 등장 횟수 = n / 2이다 . - 마력 2줄 옵션이 먼저 나온 $ frac{n}{2}$명은 공격력 2줄 옵션을 얻을 때까지 큐브를 사용한다 . - 그러면 $ frac{n}{2}$명 중 평균적으로 $ frac{n}{4}$명은 공격력 2줄 옵션이 먼저 나왔을 것이며 나머지 $ frac{n}{4}$명은 마력 2줄 옵션이 먼저 나왔을 것이다 . - 여기서, 공격력 등장 횟수 = 마력 등장 횟수 = n / 4이다 . - 이를 반복하면 $n$명의 사람들이 큐브를 사용해서 얻은 잠재능력 중 공격력 2줄 옵션이 등장한 횟수의 기댓값은 $ frac{n}{2} + frac{n}{4} + cdots = n$ 이며 마력도 동일하다 . - 그런데 공격력 2줄 옵션 또는 마력 2줄 옵션을 확인하는 것이 아니라 첫 번째줄 옵션이 공격력인지 마력인지 확인하는 경우는 어떨까? . - 마력 2줄이 많이 등장했더라도 첫 번째줄 옵션만 놓고보면 공격력이 마력보다 많이 등장했을 수도 있다 . - 하지만, 마력 2줄이 많이 등장했다는 것은 해당 수치만큼 첫 번째 줄 옵션에서 마력이 등장했다는 것을 의미한다 . - 즉, 첫 번째 줄 옵션에서 마력이 어느정도 등장했음을 보장하므로 첫 번째 줄에서 공격력보다 마력이 평균적으로 많이 등장했을 것이다 . - 궁금증: 마력 2줄을 여러 번 획득한 후 공격력 2줄을 획득했을 때 첫 번째 줄 옵션은 마력이 공격력보다 많이 획득되도록 편향되었을까? . . Note: 첫 번째 줄에서 공격력이 등장할 확률 = 마력이 등장할 확률 = $4.878 %$ . . Note: 두 번째 줄에서 공격력이 등장할 확률 = 마력이 등장할 확률 = $6.2791 %$ . . Note: 세 번째 줄에서 공격력이 등장할 확률 = 마력이 등장할 확률 = $6.907 %$ . from typing import Any, ClassVar, Dict, List, Literal, Tuple import matplotlib.pyplot as plt import numpy as np import pandas as pd from tqdm import tqdm Option = Literal[&quot;공격력&quot;, &quot;마력&quot;, &quot;잡옵&quot;] class Cube: _first_option2prob: ClassVar[Dict[Option, float]] _second_option2prob: ClassVar[Dict[Option, float]] _third_option2prob: ClassVar[Dict[Option, float]] def __init__(self, seed: int) -&gt; None: self.random_state = np.random.RandomState(seed) @property def first_option2prob(self) -&gt; Dict[Option, float]: return self._first_option2prob @property def second_option2prob(self) -&gt; Dict[Option, float]: return self._second_option2prob @property def third_option2prob(self) -&gt; Dict[Option, float]: return self._third_option2prob def roll(self) -&gt; Tuple[Option, Option, Option]: return ( self._get_random_option(self.first_option2prob), self._get_random_option(self.second_option2prob), self._get_random_option(self.third_option2prob), ) def _get_random_option(self, option2prob: Dict[Option, float]) -&gt; Option: rand = self.random_state.rand() cumulative_prob = 0.0 for option, prob in option2prob.items(): cumulative_prob += prob if rand &lt;= cumulative_prob: return option class AdditionalCube(Cube): _first_option2prob = {&quot;공격력&quot;: 0.04878, &quot;마력&quot;: 0.04878, &quot;잡옵&quot;: 0.90244} _second_option2prob = {&quot;공격력&quot;: 0.062791, &quot;마력&quot;: 0.062791, &quot;잡옵&quot;: 0.874418} _third_option2prob = {&quot;공격력&quot;: 0.06907, &quot;마력&quot;: 0.06907, &quot;잡옵&quot;: 0.86186} class CubeResultAnalyzer: def is_attack_power(self, option: Option) -&gt; bool: return option == &quot;공격력&quot; def is_magic_power(self, option: Option) -&gt; bool: return option == &quot;마력&quot; def is_valid_attack_power(self, first: Option, second: Option, third: Option) -&gt; bool: return self.is_attack_power(first) and (self.is_attack_power(second) or self.is_attack_power(third)) def is_valid_magic_power(self, first: Option, second: Option, third: Option) -&gt; bool: return self.is_magic_power(first) and (self.is_magic_power(second) or self.is_magic_power(third)) class History: def __init__(self) -&gt; None: self.data: List[Dict[str, Any]] = [] def record(self, data: Dict[str, Any]) -&gt; None: self.data.append(data) def reset(self) -&gt; None: self.data.clear def to_dataframe(self) -&gt; pd.DataFrame: return pd.DataFrame.from_records(self.data) class CubeSimulator: def __init__(self, cube: Cube) -&gt; None: self.cube = cube self.analyzer = CubeResultAnalyzer() self.history = History() self._reset_init_conditions() def reset(self) -&gt; None: self.history.reset() self._reset_init_conditions() def _reset_init_conditions(self) -&gt; None: self.n = 0 self.attack_power_count = 0 self.valid_attack_power_count = 0 self.magic_power_count = 0 self.valid_magic_power_count = 0 def simulate(self, size: int) -&gt; None: for _ in tqdm(range(size)): self._reset_init_conditions() self._simulate_until_attack2() data = { &quot;n&quot;: self.n, &quot;attack_power_count&quot;: self.attack_power_count, &quot;magic_power_count&quot;: self.magic_power_count, &quot;valid_magic_power_count&quot;: self.valid_magic_power_count, &quot;valid_attack_power_count&quot;: self.valid_attack_power_count, } self.history.record(data) def _simulate_until_attack2(self) -&gt; None: while self.valid_attack_power_count == 0: self._simulate_once() def _simulate_once(self) -&gt; None: first, second, third = self.cube.roll() self.n += 1 if self.analyzer.is_valid_attack_power(first, second, third): self.valid_attack_power_count += 1 elif self.analyzer.is_valid_magic_power(first, second, third): self.valid_magic_power_count += 1 if self.analyzer.is_attack_power(first): self.attack_power_count += 1 elif self.analyzer.is_magic_power(first): self.magic_power_count += 1 def export(self) -&gt; pd.DataFrame: return self.history.to_dataframe() . . seed = 2024 cube = AdditionalCube(seed) simulator = CubeSimulator(cube) . size = 50000 simulator.simulate(size) . 100%|██████████████████████████████████████████████████████████████████████████| 50000/50000 [00:45&lt;00:00, 1092.31it/s] . df = simulator.export() . df.head() . n attack_power_count magic_power_count valid_magic_power_count valid_attack_power_count . 0 148 | 5 | 7 | 1 | 1 | . 1 333 | 12 | 15 | 1 | 1 | . 2 11 | 1 | 0 | 0 | 1 | . 3 305 | 15 | 14 | 2 | 1 | . 4 50 | 1 | 4 | 0 | 1 | . &#50613;&#44620;&#45817;&#54620; &#44221;&#50864; . df_over_magic3 = df.query(&quot;valid_magic_power_count &gt;= 3&quot;) . df_over_magic3.head() . n attack_power_count magic_power_count valid_magic_power_count valid_attack_power_count . 5 358 | 19 | 18 | 4 | 1 | . 21 425 | 18 | 22 | 5 | 1 | . 27 308 | 12 | 15 | 3 | 1 | . 71 122 | 3 | 5 | 3 | 1 | . 77 424 | 22 | 24 | 3 | 1 | . - 마력 2줄을 3번 이상 획득한 후에 공격력 2줄을 획득한 경우 억까당했다고 볼 수 있을 것이다 . 억까당하고 공격력 2줄을 뽑기위해 시도한 횟수 | . ns = df_over_magic3[&quot;n&quot;].to_list() . plt.hist(ns, bins=50) plt.show() . print(sum(ns)) print(min(ns)) print(max(ns)) . 2529798 29 2148 . 억까당하고 공격력 2줄을 뽑았을 때 첫 줄 옵션에서 공격력보다 마력이 더 많이 등장했을까? | . attack_power_counts = df_over_magic3[&quot;attack_power_count&quot;].to_numpy() magic_power_counts = df_over_magic3[&quot;magic_power_count&quot;].to_numpy() . attack_power_counts[:10], magic_power_counts[:10] . (array([19, 18, 12, 3, 22, 13, 6, 4, 23, 24], dtype=int64), array([18, 22, 15, 5, 24, 8, 14, 7, 25, 32], dtype=int64)) . gaps = magic_power_counts - attack_power_counts . print(len(gaps)) . 6256 . gaps[:10] . array([-1, 4, 3, 2, 2, -5, 8, 3, 2, 8], dtype=int64) . sum(gaps) . 18989 . - 에디 마력 2줄을 3번 이상 획득한 후 공격력 2줄을 획득한 사람은 50000명 중 6256명이다 . - 이 6256명의 경우 총 2529798번 잠재능력을 재설정 했으며 첫 번째 줄에서 마력이 공격력보다 18989번 더 등장했다 . - 이 수치가 일반적인 경우와 비교했을 때 이상치인지 확인하겠다 . &#51068;&#48152;&#51201;&#51064; &#44221;&#50864; . ns = df[&quot;n&quot;].to_list() . 공격력 2줄을 뽑기위해 시도한 횟수 | . plt.hist(ns, bins=50) plt.show() . print(sum(ns)) print(min(ns)) print(max(ns)) . 8046085 1 2148 . 일반적인 상황에선 공격력 2줄을 뽑았을 때 첫 줄 옵션에서 공격력보다 마력이 더 많이 등장했을까? | . attack_power_counts = df[&quot;attack_power_count&quot;].to_numpy() magic_power_counts = df[&quot;magic_power_count&quot;].to_numpy() gaps = magic_power_counts - attack_power_counts print(len(gaps)) . 50000 . sum(gaps) . 147 . - 공격력 2줄을 뽑았을 때 첫 번째 줄에서 마력보다 공격력이 323번 더 등장했다 . - 50000명이 총 8046085번 잠재능력을 재설정 했으며 첫 번째 줄에서 마력이 공격력보다 147번 더 등장했다 . - 첫 번째 줄에서 공격력, 마력이 각각 등장할 확률 $p= 0.04878$이다 . - $n=8046085$이므로 이항분포 $B(8046085, 0.04878)$를 생각할 수 있다 . - 이는 한 번의 시행마다 공격력을 얻을 확률이 $0.04878$인 잠재능력 재설정을 8046085번 했을 때 등장한 공격력 옵션의 개수임을 뜻한다 (마력도 동일함) . - 그런데 표본을 수집할 때 $n=8046085$을 처음부터 정한 것은 아니며 여기서 $n$은 확률 변수의 실현치이다 (공격력 2줄을 50000번 얻을때까지 잠재능력 재설정을 한 횟수) . - 왜냐하면 8046085번 잠재능력을 설정한게 아니라 50000명의 사람들이 각각 공격력 2줄이 나올때까지 잠재능력을 재설정한 결과를 취합한 것이기 때문이다 . - 항상 잠재능력 재설정의 마지막 결과는 공격력 2줄(공격력 1줄은 당연히 포함)이므로 여기서 첫 번째 줄에서 공격력이 등장한 횟수의 분포는 정확하게 이항 분포를 따르지는 않는다 . - 하지만 표본 크기가 8046085로 매우 크므로 이항 분포로 근사 가능하다 . - 공격력 2줄을 50000번 얻을 때까지 잠재능력 재설정을 하여 총 8046085번 잠재능력을 재설정 했을 때 첫 번째 줄에서 공격력이 등장한 횟수를 $X$라 하자 . - 확률 변수 $X$는 근사적으로 이항 분포 $B(8046085, 0.04878)$를 따르며 마력의 경우도 이와 동일하며 확률 변수 $Y$라 칭하자 . - $np=8046085 times0.04878=392488$로 충분히 크므로 확률 변수 $X$와 $Y$는 $N(np, np(1-p))$로 근사 가능하다 . - 이때 확률 변수 $W=Y-X$는 정규분포의 성질에 의해 $N(0, 2np(1-p))$를 따른다 . - 정규분포에서 $95 %$의 데이터는 $( mu-2 sigma, mu+2 sigma)$에 존재하는데 이를 계산하면 $(-1771, 1771)$이다 . - 즉, 147이란 값은 충분히 등장할 수 있는 수치이다 . - 위에서는 $n$도 2529798로 더 작으며 확률 변수 실현치인 18989도 $(-1771, 1771)$ 구간을 벗어났으니 편향된 값이라 볼 수 있다 . - 결론: 억까인 상황에 대해서는 첫 줄에 마력이 공격력보다 더 많이 등장한다 . &#52572;&#49548;&#54620;&#51032; &#50613;&#44620;? . - 한편, 억까의 기준이 너무 높다고 생각할 수 있다 . - 위에서 정한 억까의 기준은 에디 마력 2줄을 3번 이상 획득한 후 공격력 2줄을 획득한 경우이다 . - 억까의 기준을 가장 약하게 정한다면 에디 마력 2줄을 단 1번 획득한 후 공격력 2줄을 획득한 경우로 정의할 수 있다 . df_magic1 = df.query(&quot;valid_magic_power_count == 1&quot;) . ns = df_magic1[&quot;n&quot;].to_list() . print(sum(ns)) print(min(ns)) print(max(ns)) . 2015066 3 1030 . attack_power_counts = df_magic1[&quot;attack_power_count&quot;].to_numpy() magic_power_counts = df_magic1[&quot;magic_power_count&quot;].to_numpy() gaps = magic_power_counts - attack_power_counts . print(len(gaps)) . 12561 . sum(gaps) . 372 . - 에디 마력 2줄을 단 1번 획득한 후 공격력 2줄을 획득한 사람은 50000명 중 12561명이다 . - 이 12561명의 경우 총 2015066번 잠재능력을 재설정 했으며 첫 번째 줄에서 마력이 공격력보다 372번 더 등장했다 . - 위에서 계산한 것과 동일하게 해보면 $95 %$의 데이터는 $(-864, 864)$에 존재한다 . - 이는 일반적인 기준과 비교했을 때 이상치로 취급되지 않는다 . - 따라서 일반적인 경우에서 샘플링한 것인지 에디 마력 2줄을 1번 획득한 후 공격력 2줄을 획득한 사람을 대상으로 샘플링한 것인지 구분할 수 없다 . - 생각해보면 당연한게 마력 2줄을 1번 획득했고 공격력 2줄도 동일하게 1번 획득했다 . - 즉, 둘의 비율이 $1:1$이다 . - 일반적인 경우도 맨 처음에 계산했듯이 둘의 비율이 $1:1$이다 . - 그러니 구분하지 못하는게 당연하고 오히려 첫 번째 줄에서 공격력 또는 마력이 나머지에 비해 $864$번 더 등장했다면 문제가 된다 . - 처음에 설정한 궁금증은 마력 2줄을 여러 번 획득한 후 공격력 2줄을 획득했을 때 첫 번째 줄 옵션은 마력이 공격력보다 많이 획득되도록 편향되었을까?였다 . - 이 궁금증은 에디 마력 2줄을 단 1번 획득한 후 공격력 2줄을 획득한 사람을 제외하곤 성립한다 .",
            "url": "https://jaesu26.github.io/study-blog/statistics/python/2024/01/11/%EB%A9%94%EC%9D%B4%ED%94%8C%ED%99%95%EB%A5%A0%EA%B2%80%EC%A0%95.html",
            "relUrl": "/statistics/python/2024/01/11/%EB%A9%94%EC%9D%B4%ED%94%8C%ED%99%95%EB%A5%A0%EA%B2%80%EC%A0%95.html",
            "date": " • Jan 11, 2024"
        }
        
    
  
    
        ,"post12": {
            "title": "희소 행렬",
            "content": "- 행렬 정리글: https://jaesu26.github.io/study-blog/math/2021/09/16/행렬.html . - ref: https://en.wikipedia.org/wiki/Sparse_matrix . &#55148;&#49548; &#54665;&#47148;&#51060;&#46976;? . - 희소 행렬(sparse matrix): 원소 대부분 $0$인 행렬 . - 희소성(sparsity): 행렬의 전체 원소 중 $0$인 원소의 비율 . - 희소(sparse)하다고 말할 수 있는 정확한 정의는 없지만 일반적인 기준은 $0$이 아닌 원소가 대략 행 또는 열의 수만큼 있는 것이다 . &#55148;&#49548; &#54665;&#47148;&#51032; &#51088;&#47308;&#44396;&#51312; . - 의미있는 원소($0$이 아닌 수)가 거의 없으므로 일반적인 행렬과 같이 자료를 저장하면 메모리 측면에서 매우 비효율적이다 . - 그렇기에 $0$이 아닌 원소만 저장하는 자료구조를 사용하여 메모리를 절약한다 . - 대표적으로 자연어 처리에서 텍스트를 토큰화할 때 희소 행렬의 자료구조를 사용한다 (전체 글에서 사용된 유니크한 단어 개수는 매우 많지만 문장 별로 사용된 유니크한 단어 개수는 적다) . - 만약 $0$이 의미있는 원소로 사용된다면 문제가 생긴다 ($0$은 저장을 안하므로) . import numpy as np arr = np.array([[1, 2, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 3, 0], [0, 0, 4, 0, 0], [5, 0, 0, 0, 0]]) print(arr) # 25개의 원소 중 19개가 0인 희소 행렬 . [[1 2 0 0 0] [0 0 0 0 0] [0 0 0 3 0] [0 0 4 0 0] [5 0 0 0 0]] . Dictionary of keys (DOK) . - (row, column)을 value로 매핑한 딕셔너리 구조 . from scipy.sparse import dok_matrix dok = dok_matrix((5, 5), dtype=np.float32) for i in range(5): for j in range(5): dok[i, j] = i + j # 원소를 갱신, 원소가 0이라면 저장하지 않음 . print(dok.toarray()) . [[0. 1. 2. 3. 4.] [1. 2. 3. 4. 5.] [2. 3. 4. 5. 6.] [3. 4. 5. 6. 7.] [4. 5. 6. 7. 8.]] . dok[0].nnz, dok[1].nnz # nnz는 0이 아닌 원소의 개수 . (4, 5) . List of lists (LIL) . - 각 행마다 열의 인덱스와 값을 하나의 리스트로 저장하는 구조 . from scipy.sparse import lil_matrix lil = lil_matrix(arr) . print(lil.rows) # 행마다 0이 아닌 값의 열 인덱스 . [list([0, 1]) list([]) list([3]) list([2]) list([0])] . print(lil.data) # 행마다 0이 아닌 값을 저장 . [list([1, 2]) list([]) list([3]) list([4]) list([5])] . Coordinate list (COO) . - (row, column, value) 튜플을 리스트에 저장한 구조 . from scipy.sparse import coo_matrix coo = coo_matrix(arr) print(coo.row, coo.col, coo.data) . [0 0 2 3 4] [0 1 3 2 0] [1 2 3 4 5] . for row, col, value in zip(coo.row, coo.col, coo.data): print(f&#39;{row + 1}행 {col + 1}열에 저장된 값: {value}&#39;) . 1행 1열에 저장된 값: 1 1행 2열에 저장된 값: 2 3행 4열에 저장된 값: 3 4행 3열에 저장된 값: 4 5행 1열에 저장된 값: 5 . Compressed sparse row (CSR, CRS or Yale format) . - 행을 기준으로 $0$이 아닌 값을 압축시킨 구조 . from scipy.sparse import csr_matrix csr = csr_matrix(arr) . print(arr) . [[1 2 0 0 0] [0 0 0 0 0] [0 0 0 3 0] [0 0 4 0 0] [5 0 0 0 0]] . csr.nnz # 0이 아닌 원소의 개수 . 5 . csr.indptr # index pointer, 처음 값은 0, 마지막 값은 nnz, i번째 인덱스의 값은 i번째 행까지 0이 아닌 원소의 개수, 길이는 row + 1 . array([0, 2, 2, 3, 4, 5], dtype=int32) . csr.indices # 0이 아닌 원소의 열 인덱스, 길이는 nnz . array([0, 1, 3, 2, 0], dtype=int32) . csr.data # 0이 아닌 원소 목록, 길이는 nnz . array([1, 2, 3, 4, 5], dtype=int32) . Compressed sparse column (CSC or CCS) . - 열을 기준으로 $0$이 아닌 값을 압축시킨 구조 . from scipy.sparse import csc_matrix csc = csc_matrix(arr) . csc.indptr, csc.indices, csc.data . (array([0, 2, 3, 4, 5, 5], dtype=int32), array([0, 4, 0, 3, 2], dtype=int32), array([1, 5, 2, 4, 3], dtype=int32)) .",
            "url": "https://jaesu26.github.io/study-blog/math/2023/02/19/%ED%9D%AC%EC%86%8C%ED%96%89%EB%A0%AC.html",
            "relUrl": "/math/2023/02/19/%ED%9D%AC%EC%86%8C%ED%96%89%EB%A0%AC.html",
            "date": " • Feb 19, 2023"
        }
        
    
  
    
        ,"post13": {
            "title": "SMOTE",
            "content": "- ref: N. V. Chawla, K. W. Bowyer, L. O.Hall, W. P. Kegelmeyer, &quot;SMOTE: synthetic minority over-sampling technique,&quot; Journal of artificial intelligence research, 321-357, 2002. . 글을 읽기 전 주의 사항 | . - 이진 분류인 경우 &quot;마이너 클래스$^c$ = 메이저 클래스&quot;이지만 다중 분류에서는 성립하지 않는다 . - 작성한 글에서는 이진 분류, 다중 분류를 고려하지 않고 마이너 클래스와 메이저 클래스만 언급했는데 다중 분류인 경우 메이저 클래스를 마이너 클래스가 아닌 클래스로 생각하자 . SMOTE &#51089;&#46041; &#48169;&#49885; . - 논문에 등장한 SMOTE는 이진 분류를 가정한다 . - SMOTE를 사용하기 위해선 변수들이 모두 양적 변수여야 한다 (데이터의 차원은 $n times p$, 이때 $n$은 샘플의 개수, $p$는 변수의 개수) . 1. 마이너 클래스의 각 샘플에 대하여 가장 가까운 마이너 클래스 이웃 $k$개의 인덱스를 계산한다 (유클리드 거리를 사용) . 2. 합성에 사용하기 위해 마이너 클래스에서 $N$개의 샘플을 복원추출하여 인덱스를 저장한다 . 3. 선택된 $N$개의 샘플 각각에 대하여 $k$개의 가장 가까운 이웃중 무작위로 하나를 선택한다 . 4. $N$개의 샘플 각각에 대하여 샘플과 그 샘플의 이웃간의 내분점을 무작위로 선택하여 새로운 샘플을 생성한다 (모든 변수에 대해 내분비는 동일) . &#50696;&#49884; . X1 X2 class . i1 | 3 | 7 | A | . i2 | 4 | 8 | A | . i3 | 2 | 5 | B | . i4 | 1 | 2 | B | . i5 | 2 | 1 | B | . i6 | 0 | 3 | B | . - 마이너 클래스는 A, 메이저 클래스는 B이다 . - 합성할 샘플 수 $N$은 $1$로 하겠다, 고려할 이웃의 개수 $k$는 1로 하겠다 . 1. 마이너 클래스 샘플끼리의 거리를 계산한다 . $$Dist(i_1,i_2) = sqrt{(3-4)^2 + (7-8)^2} = sqrt{2}$$ . 2. 마이너 클래스 샘플 중 무작위로 $N$개를 복원추출한다 $ Longrightarrow i_1$이 선택됐다고 가정 . 3. $i_1$에 가장 가까운 이웃 $k$개를 선택한다 $ Longrightarrow i_2$가 선택됐다고 가정 . 4. 새로운 샘플을 생성: $$i_7 = i_1 + 0.5*(i_2-i_1) = (3.5, 7.5), ; ( text{0.5는 내분비로 0과 1 사이에 있는 선택된 임의의 수})$$ . 5. 합성된 샘플 $i_7$의 class는 A이다 . - 위에선 표준화를 생략했지만 정확한 결과를 얻기 위해서는 표준화를 수행해야 한다 . &#51109;&#51216; . - 메이저 클래스의 결정 영역에 존재하는 마이너 클래스 샘플을 단순 복제할 경우 해당 마이너 클래스 샘플의 영향력이 커진다 . - 즉, 마이너 클래스의 결정 영역이 더욱 특별해지고 결정 트리는 새로운 분기를 생성하게 되어 오버피팅이 발생한다 . - 마이너 클래스의 단순 복제는 결정 영역을 메이저 클래스의 결정 영역으로 확장시키지 못한다 . - 하지만 SMOTE를 사용하면 기존에 존재하지 않던 새로운 마이너 클래스 샘플을 만들므로 마이너 클래스의 결정 영역을 확장시킬 수 있다 . - 합성된 샘플은 더 크고 덜 중요한 결정 영역을 만듦으로써 분류기가 작고 특정한 결정 영역에 오버피팅 되지 않고 일반화되도록 한다 . &#45800;&#51216; . - 마이너 클래스 샘플의 가장 가까운 $k$개의 이웃 대부분이 마이너 클래스가 아닐 수 있다 . - 즉, 마이너 클래스에 분산이 큰 변수가 존재하는 경우 합성된 샘플이 메이저 클래스 샘플과 겹칠 수 있다 . - 이상치에 민감하다 . &#49324;&#50857; &#49884; &#51452;&#51032;&#49324;&#54637; . - 유클리드 거리를 사용하므로 변수의 영향력을 동일시하기 위해 변수마다 표준화를 수행해야 한다 . - 훈련 데이터에만 적용해야 한다 (합성된 샘플이 검증 데이터를 대표하지 않을 경우 검증 결과를 신뢰할 수 없음) . - $k$는 $1$보다 큰 값을 사용해야 한다 ($k=1$일 경우 모집단의 분포를 따르지 않는 이상한 분포로 오버샘플링 된다) . $k$값에 따른 SMOTE 비교 | . - 각 클래스별 군집은 $1$개로 설정하여 데이터를 생성했다 . import matplotlib.pyplot as plt import seaborn as sns from sklearn.datasets import make_classification from imblearn.over_sampling import SMOTE ## 무작위 데이터 생성 data, label = make_classification(n_features=2, n_informative=2, n_redundant=0, n_samples=150, n_clusters_per_class=1, weights=[0.9], random_state=111) label = np.where(label == 0, &#39;majority&#39;, &#39;minority&#39;) ## 그래프 fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(10, 8)) # 기존 데이터 sns.scatterplot(x=data[:, 0], y=data[:, 1], hue=label, alpha=0.8, ax=ax1) ax1.set_title(&#39;original&#39;) # k = 1 data_res, label_res = SMOTE(k_neighbors=1, random_state=23).fit_resample(data, label) sns.scatterplot(x=data_res[:, 0], y=data_res[:, 1], hue=label_res, alpha=0.8, ax=ax2) ax2.set_title(&#39;SMOTE with k = 1&#39;) # k = 5 data_res, label_res = SMOTE(k_neighbors=5, random_state=23).fit_resample(data, label) sns.scatterplot(x=data_res[:, 0], y=data_res[:, 1], hue=label_res, alpha=0.8, ax=ax3) ax3.set_title(&#39;SMOTE with k = 5&#39;) # k = 11 data_res, label_res = SMOTE(k_neighbors=11, random_state=23).fit_resample(data, label) sns.scatterplot(x=data_res[:, 0], y=data_res[:, 1], hue=label_res, alpha=0.8, ax=ax4) ax4.set_title(&#39;SMOTE with k = 11&#39;) fig.tight_layout() plt.show() . . SMOTE &#53076;&#46300; &#49444;&#47749; . - 코드: https://github.com/scikit-learn-contrib/imbalanced-learn/blob/master/imblearn/over_sampling/_smote/base.py#L217 (0.10.1 버전) . - 다중 분류에서도 SMOTE를 사용할 수 있게 만들었다 . 가장 가까운 이웃 $k$개 계산 | . - check_neighbors_object 함수를 사용해 nn_k_ 라는 sklearn.neighbors.NearestNeighbors 인스턴스를 생성하여 가장 가까운 $k$개의 이웃을 계산한다 . - 참고로 자기 자신과의 거리는 $0$이므로 임의의 샘플에 대하여 가장 가까운 $k$개의 이웃을 찾으면 그 중 하나는 자기 자신이다 . - 그래서 check_neighbors_object 함수의 additional_neighbor 매개변수의 기본값을 $1$로 주어 자기 자신을 제외한 가장 가까운 $k$개의 이웃을 찾는다 . 거리 계산 | . - sklearn.neighbors.NearestNeighbors 오브젝트는 기본값으로 거리 계산 메트릭으로 유클리드 거리를 사용한다 . - 거리 계산 알고리즘으론 BallTree, KDTree, brute-force search 중에서 적절한 알고리즘을 찾아서 사용한다 . - 적절한 알고리즘을 찾는 방법: https://scikit-learn.org/stable/modules/neighbors.html#nearest-neighbor-algorithms . 샘플링 전략 | . - sampling_strategy 매개변수를 사용하여 클래스 라벨(i.g. male)에 합성할 샘플 수(i.g. 150)를 대응시킨 딕셔너리를 만든다 (= sampling_strategy_) . - sampling_strategy_ 딕셔너리를 순회하여 클래스를 합성할 샘플 수 만큼 오버샘플링 한다 . &#51452;&#50836; &#47700;&#49548;&#46300; . fit_resample . - sampling_strategy 매개변수를 사용하여 sampling_strategy_ 딕셔너리를 만든다 . - _fit_resample 메소드 호출한다 . _fit_resample . - _validate_estimator 메소드를 호출하여 nn_k라는 sklearn.neighbors.NearestNeighbors 인스턴스를 생성한다 . - sampling_strategy_를 순회하여 각 클래스(X_class)마다 새로운 샘플을 합성한다 . - nn_k에 X_class를 학습시켜 X_class의 각 샘플에 대하여 가장 가까운 $k$개의 이웃의 인덱스를 계산하여 nns에 저장한다 (nns의 차원은 (X_class의 원소 개수, k)) . - _make_samples 메소드를 호출한다 . _make_samples . 주요 파라미터 | . - nn_data: X_class와 동일 (n, p) . - nn_num: nns와 동일 (n, k) . - n_samples: 합성할 샘플 수 . 함수 구현부 | . - 합성할 데이터 샘플링: $0$부터 $nk$중에서 n_samples만큼 복원추출하여 samples_indices에 저장한다 . - steps는 내분비($0 sim 1$), n_samples 크기의 벡터 . - rows는 X_class에서 합성을 위해 인덱싱하기 위한 n_samples 크기의 벡터 . - cols는 $k$개의 이웃 중 몇 번째 이웃을 합성하는데 사용할지 나타낸 n_samples 크기의 벡터 . - _generate_samples 메소드를 호출한다 . _generate_samples . - 합성 공식에 따라 샘플을 합성하는 단계 . - diffs = nn_data[nn_num[rows, cols]] - X[rows] (X와 X_class는 동일) . - X_new = X[rows] + steps * diffs .",
            "url": "https://jaesu26.github.io/study-blog/machine%20learning/2023/02/08/smote.html",
            "relUrl": "/machine%20learning/2023/02/08/smote.html",
            "date": " • Feb 8, 2023"
        }
        
    
  
    
        ,"post14": {
            "title": "이진 분류에서 $F_1$ score와 $Macro-F_1$ score의 차이",
            "content": "&#48176;&#44221; &#51648;&#49885; . - 보통, 관심 있는 클래스를 양성(positive), 관심 없는 클래스를 음성(negative)으로 지정한다 . - 클래스: $y$가 가지는 카테고리 (ex: 개, 고양이) . - 정밀도와 재현율 개념을 짤막하게 요약하면 아래와 같다 (양성 클래스를 P, 음성 클래스를 N이라 하자) . - 정밀도 ($ frac{TP}{TP + FP}$): 모델이 샘플을 보고 P라고 예측한 것 중 진짜로 P인 비율 . - 재현율 ($ frac{TP}{TP + FN}$): 모든 P 샘플 중 모델이 P라고 예측해 정답을 맞춘 비율 . - TP, TN, FP, FN에서 뒤에 P 또는 N은 모델이 정답으로 추측한 클래스를 뜻하고 . - 앞에 T 또는 F는 모델이 추측한 결과가 True(정답)인지 False(오답)인지 나타낸 것이다 . - 예컨대, FP는 false positve라 읽으며 어떤 샘플 $X$를 보고 모델이 P라고 예측했는데 틀린(F)것을 의미한다 (이때 $X$의 클래스는 N임, 그러니까 모델이 틀렸겠지) . - $F_1$ score는 정밀도(precision)과 재현율(recall)의 조화 평균이다 . - 즉, $F_1$ score $= dfrac{2}{ text{precision}^{-1} + text{recall}^{-1}}$ . &#50577;&#49457; &#49368;&#54540;&#51060; &#51201;&#51008; &#49345;&#54889; . - 일반적으로 $F_1$ score는 클래스 불균형에서 정확도의 단점을 보완하고자 사용한다 . - 예컨대 $10000$개의 샘플중 $99 %$가 음성(0)이고 나머지 $1 %$가 양성(1)이라면 0으로 찍어도 정확도가 $0.99$이다 . - 즉, 입력으로 무엇이 들어오든 0으로 예측한다 (입력을 보기도 전에 답부터 말하는 꼴) . - 일반적으로 정확도가 $1$에 매우 가까운 $0.99$라면 샘플을 분류한 모델의 성능이 우수하다 생각하지만 위의 예시에선 전혀 아니다 . - 이러한 문제점을 보완하기 위해 $F_1$ score를 사용한다 . - 위와 같은 경우 정확도는 $0.99$일지라도 $F_1$ score는 $0$이다 (정확하게는 모든 예측 라벨이 음성이므로 $F_1$ score가 정의되지 않음) . - 따라서 양성 샘플이 매우 적은 클래스 불균형 상황이라면 $F_1$ score는 분류 성능을 제대로 표현할 수 있는 척도이다 . &#50577;&#49457; &#49368;&#54540;&#51060; &#47566;&#51008; &#49345;&#54889; . - 하지만 클래스 내에 양성 샘플이 음성 샘플보다 월등히 많은 불균형 상태라면 얘기는 달라진다 . - $10000$개의 샘플중 $1 %$가 음성(0)이고 나머지 $99 %$가 양성(1)이라면 1로 찍어도 정확도는 $0.99$이며 $F_1$ score는 대략 $0.995$이다 . - 위 상황에서 모든 샘플을 양성으로 찍으면 재현율은 $1$이며 정밀도에 따라 성능이 결정된다 . - 그런데 샘플의 대부분이 양성이므로 정밀도도 $1$에 근접한다 . - 따라서 클래스 불균형 상황에서 정확도의 단점을 보완하고자 사용한 $F_1$ score도 분류 성능을 제대로 나타내지 못하게 된다 . - 이러한 상황에서 $Macro-F_1$ score가 빛을 발하는데 $Macro-F_1$ score는 각 클래스를 양성, 나머지는 음성으로 놓은 뒤 $F_1$ score를 구하고 이를 평균내므로 하나의 라벨로만 찍게 되면 정확도와 $F_1$ score와 달리 점수가 매우 낮아지게 된다 . &#51032;&#47928;&#51216;? . - 양성 샘플이 많은 상황 &gt; 그냥 적은 클래스를 양성으로 하고 $F_1$ score로 평가하면 되는거 아닌가? . - 애초에 관심 있는 대상을 양성 클래스로 지정함 (ex: 금융 이상치 탐지, 게임 매크로 구분) . - 흔치 않는 케이스에 관심을 가질것이니 일반적으로 양성 샘플이 훨씬 적을 것이다 . - 그게 아니라 해도 그냥 적은 클래스를 양성으로 지정하고 $F_1$ score로 평가하면 될 것 같은데? . - 보통은 그렇지만 두 개의 클래스를 양성, 음성으로 구분하기 애매할 때가 존재한다 . - 예컨대 어떤 희귀한 종의 강아지, 희귀한 종의 고양이 이미지가 있을 때 클래스를 맞히고 싶을 수 있다 (강아지 이미지는 강아지라 하고 고양이 이미지는 고양이라 대답하기) . - 그런데 고양이 이미지는 데이터가 부족하여 강아지 이미지의 $ frac{1}{2}$만 존재한다고 해보자 . - 예컨대 강아지 이미지가 200장이면 고양이 이미지는 100장밖에 없다 . - 이런 상황에서 고양이를 양성(1), 강아지를 음성(0) 클래스로 지정하자 . - 어떤 무지성 모델이 있는데 이 모델은 어떤 이미지든 무조건 1로 예측한다 . - $ text{precision} = frac{100}{300} = frac{1}{3}, ; text{recall} = frac{100}{100} = 1$ . - 따라서 $F_1$ score는 $ frac{2}{3+1}= frac{2}{4}=0.5$이다 . - $0.5$면 찍은거치고 생각보다 높은 것 같다? . - 하지만 강아지 이미지는 단 1개도 맞히지 못했다 (강아지가 양성 클래스인 기준이라면 $F_1$ score는 $0$이다) . - 반면 $Macro-F_1$ score는 $ frac{0.5+0}{2}=0.25$이다 . - $F_1$ score는 양성 클래스만 포커스를 두므로 $0.5$라는 점수와 강아지 이미지는 구분 못하는 것 사이의 괴리감이 있다 . - 하지만 $Macro-F_1$ score는 강아지 이미지를 구분하지 못하는 것을 반영하여 $F_1$ score보다 낮은 $0.25$라는 점수를 가진다 . - 따라서 두 클래스가 동등하게 중요하다면 점수를 평균내는 $Macro-F_1$ score가 평가 지표로 더 적절하다 . - 근데 어차피 이진 분류이므로 모델의 성능이 좋아지면 $F_1$ score나 $Macro-F_1$ score나 비슷해지긴 하다 . - 그래도 두 클래스 모두 중요한 경우라면 $Macro-F_1$ score가 $F_1$ score보다 적절하다 생각한다 .",
            "url": "https://jaesu26.github.io/study-blog/machine%20learning/2023/02/07/f1-macrof1.html",
            "relUrl": "/machine%20learning/2023/02/07/f1-macrof1.html",
            "date": " • Feb 7, 2023"
        }
        
    
  
    
        ,"post15": {
            "title": "푸리에 변환",
            "content": ". - 위의 영상을 보자 .",
            "url": "https://jaesu26.github.io/study-blog/math/2022/08/23/%ED%91%B8%EB%A6%AC%EC%97%90%EB%B3%80%ED%99%98.html",
            "relUrl": "/math/2022/08/23/%ED%91%B8%EB%A6%AC%EC%97%90%EB%B3%80%ED%99%98.html",
            "date": " • Aug 23, 2022"
        }
        
    
  
    
        ,"post16": {
            "title": "플로이드-워셜 알고리즘",
            "content": "- 참고: https://en.wikipedia.org/wiki/Floyd%E2%80%93Warshall_algorithm . &#54540;&#47196;&#51060;&#46300;-&#50892;&#49500; &#50508;&#44256;&#47532;&#51608;&#51060;&#46976;? (Floyd-Warshall Algorithm) . - 변의 가중치가 음이거나 양인 (음수 사이클은 없는) 가중 그래프에서 최단 경로들을 찾는 알고리즘 . - 알고리즘을 한 번 수행하면 모든 꼭짓점 쌍 간의 최단 경로의 길이 (가중치의 합)을 찾는다 . &#46041;&#51089; &#50896;&#47532; . - $1$에서 $N$까지 번호가 매겨진 $V$를 꼭짓점으로 가지는 그래프 $G$를 고려하자 . - $D(i,j,k)$를 $i$에서 $j$로 가는데 집합 $ {1,2, cdots,k-1,k }$의 꼭짓점만을 경유지로 거쳐가는 최단 경로를 반환하는 함수라고 하자 . - 여기서 $D(i,j,k)$는 꼭짓점 $k$를 거치지 않는 경우(1)와 거치는 경우(2)로 나눌 수 있다 . (1)번의 경우 | . - $i$에서 $j$로 가는데 집합 $ {1,2, cdots,k-2,k-1 }$의 꼭짓점만을 경유지로 고려하므로 $D(i,j,k)=D(i,j,k-1)$이다 . (2)번의 경우 | . - $i$에서 $j$로 가는데 경유지로 꼭짓점 $k$를 거치므로 최단 경로는 $i to k to j$가 된다 . - $i to k$와 $k to j$를 생각하면 둘 모두 집합 $ {1,2, cdots,k-2,k-1 }$의 꼭짓점만을 경유지로 고려한다 . - 즉, (2)번의 경우 $D(i,j,k)=D(i,k,k-1)+D(k,j,k-1)$이다 . - 따라서 $D(i,j,k)= min left(D(i,j,k-1),D(i,k,k-1)+D(k,j,k-1) right)$이다 . - $k=1$일 때의 $D(i,j,k)$를 구하고 이를 바탕으로 $k=2$일 때를 계산하는 식으로 $k=N$일 때까지 반복하면 모든 $(i,j)$쌍에 대해서 최단 경로를 찾을 수 있다 . &#44396;&#54788; . def floyd_warsahll(graph): INF = 1e9 # 무한을 의미 dist = [[INF] * (V + 1) for _ in range(V + 1)] # V는 꼭짓점의 개수 (=그래프에 존재하는 노드의 개수) # 노드 번호가 1부터 시작하는데 파이썬 인덱스는 0부터 시작하므로 (V + 1) X (V + 1) 크기의 배열로 구성했다 for edge in graph: u, v, w = edge # 노드 u, 노드 v, u와 v 사이 간선의 가중치 w dist[u][v] = w for v in range(V): dist[v][v] = 0 # 여기서 v는 vertex, 당연하게도 v와 v 사이 간선의 가중치는 0이다 # bottom up 방식으로 구현한 동적계획법 for k in range(1, V + 1): # 경유지: {1, 2, ..., k-1} for i in range(1, V + 1): for j in range(1, V + 1): if dist[i][j] &gt; dist[i][k] + dist[k][j]: # 기존의 i -&gt; j보다 더 짧은 경로가 존재하면 dist[i][j] = dist[i][k] + dist[k][j] # relaxation else: pass # 이 경우 D(i, j, k) = min[D(i, j, k-1), D(i, k, k-1) + D(k, j, k-1)] = D(i, j, k-1) # 어차피 D(i, j, k)와 D(i, j, k-1)의 값이 같으니 아무것도 안해도 됨 (갱신할 필요가 없음) # 위의 for문은 모든 i와 j에 대해서 i = j일 때도 값을 갱신하려고 한다 # 초기에 dist[v][v] = 0으로 값을 설정했다 # 경로 [i -&gt; ... -&gt; k -&gt; ... -&gt; i]는 길이가 0보다 작을 때만 개선되므로 # 만약 알고리즘이 종료된 후에 모든 v에 대해 dist[v][v]가 음수라면 그래프내에 음수 사이클이 존재함을 의미한다 . - 간단한 코드 수정을 통해 두 끝점 사이의 실제 경로를 재현해보자 . def floyd_warsahll(graph): INF = 1e9 # 무한을 의미 dist = [[INF] * (V + 1) for _ in range(V + 1)] next_node = [[False] * (V + 1) for _ in range(V + 1)] for edge in graph: u, v, w = edge dist[u][v] = w next_node[u][v] = v # k = next_node[u][v]라고 하면 u -&gt; k -&gt; ... -&gt; v를 의미, 즉 u에서 v로 가기위해 노드 u 다음으로 가야할 노드를 나타냄 for v in range(V): dist[v][v] = 0 for k in range(1, V + 1): for i in range(1, V + 1): for j in range(1, V + 1): if dist[i][j] &gt; dist[i][k] + dist[k][j]: dist[i][j] = dist[i][k] + dist[k][j] # 기존에는 i -&gt; j가 최단경로였지만 갱신되면서 i -&gt; ... -&gt; k -&gt; ... -&gt; j가 최단 경로로 바뀜 # i -&gt; j로 가는 최단 경로는 i -&gt; k의 최단 경로와 j - &gt; k의 최단 경로의 합이므로 # i에서 j로 가기위해 거쳐야 할 다음(next) 노드는 실질적으로 i에서 k로 가기위해 거쳐야 할 다음(next) 노드와 같다 next_node[i][j] = next_node[i][k] def path(u, v, next_node): if not next_node[u][v]: # u에서 v로 가는 경로가 없다면 return [] # 빈 리스트 path = [u] # 출발 노드 while u != v: # u에서 출발하여 v에 도착할때까지 # 현재 상황: u -&gt; k -&gt; k2 -&gt; k3 -&gt; ... -&gt; v # next_node[u][v] = k # u를 k로 갱신!, 그리고 path에 갱신된 u를 append # k -&gt; k2 -&gt; k3 -&gt; ... -&gt; v # 다시 k에 대해 이를 반복! # 언제까지? v에 도착해서 u와 v가 똑같아질 때까지! u = next_node[u][v] path.append(u) return path . - 위의 코드로 경로를 재현하는 것이 가능한 이유는 최당 경로의 부분 경로 또한 최단 경로이기 때문이다 . - $u$에서 $v$로 가는 최단 경로를 $s$라고 하자 . - $s$의 부분 경로를 $t$라고 하자 . - 여기서 $t$는 $u to x$이다, 즉 $s$는 $u to x to v$ . - 만약 $u$에서 $x$로 가는 최단 경로가 $t$가 아니라 $p$라고 해보자 . - 그러면 기존의 경로 $u to x to v$에서 $u$에서 $x$로 갈 때 $t$가 아닌 $p$로 가는 것이 더 짧다 . - 즉 $s$에서 $t to v$가 아닌 $p to v$가 더 짧은 경로이고 이는 $s$가 $u$에서 $v$로 가는 최단 경로라는 가정에 모순된다 . - 따라서 귀류법에 의해 최단 경로의 부분 경로 또한 최단 경로이다 . &#49884;&#44036;&#48373;&#51105;&#46020;&#50752; &#44277;&#44036;&#48373;&#51105;&#46020; . - 아래에서 $V$는 노드의 개수이고 $E$는 간선의 개수이다 . - 위에서 구현한 플로이드-워셜 알고리즘 코드 내부를 보면 for문이 3번 중첩되어 있고 각 for문은 $V$번 동작한다 . - 따라서 시간복잡도는 $O big(V^3 big)$이다 . - 공간복잡도는 $(V+1) times (V+1)$ 크기의 2차원 배열을 사용하므로 $O big(V^2 big)$이다 . - 경로를 재현하는 part는 $O(E)$의 시간복잡도와 $O(V)$의 공간복잡도이다 . - $u to v$에서 최악의 경우 모든 간선을 거쳐야하므로 시간복잡도는 $O(E)$이고 . - 이때의 경로는 모든 노드를 포함하므로 이를 담기 위한 $O(V)$크기의 배열이 필요, 따라서 공간복잡도는 $O(V)$이다 .",
            "url": "https://jaesu26.github.io/study-blog/algorithm/2022/06/29/%ED%94%8C%EB%A1%9C%EC%9D%B4%EB%93%9C%EC%9B%8C%EC%85%9C-%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98.html",
            "relUrl": "/algorithm/2022/06/29/%ED%94%8C%EB%A1%9C%EC%9D%B4%EB%93%9C%EC%9B%8C%EC%85%9C-%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98.html",
            "date": " • Jun 29, 2022"
        }
        
    
  
    
        ,"post17": {
            "title": "통계적 추론",
            "content": "- 수리통계학 내용 정리(추정 파트) . - 참고 : 수리통계학 제5판 송성주$ cdot$전명식 지음 . &#52628;&#51221; . - 미지의 모수 $ theta in Omega$를 점추정하는 방법을 알아보자 . - 통계량(statistic) : 미지의 모수를 포함하지 않는 랜덤표본 $X_1,X_2, cdots,X_n$의 함수 . - 추정량(estimator) : $g( theta)$를 추정하기 위해 사용되는 통계량 $T( boldsymbol{X})=T(X_1,X_2, cdots,X_n)$ . - 추정값(estimate) : 확률변수의 실현값을 통해 구해진 추정량의 특정값 $T( boldsymbol{x})=T(x_1,x_2, cdots,x_n)$ . - 참고로 모수 $ theta$의 추정량은 $ hat theta$으로 표기함 . &#51201;&#47456;&#52628;&#51221;&#48277;(Method of Moment Estimation, MME) . - 대수의 법칙을 이용하여 모수를 추정: $m_r{&#39;} xrightarrow{~~p~~} u_r{&#39;}$ . - $ u_r{&#39;} = E left(X^{^r} right), quad m_r{&#39;} = dfrac{ sum limits_{i=1}^{n}{X_i}^{^{r}}}{n}$ . - 위에 대수의 법칙에서 $2$차 이상의 적률인 경우 ${X}^{^r} = Y$로 치환하면 된다 . &#52572;&#45824;&#44032;&#45733;&#46020; &#52628;&#51221;&#48277;(Maximum Likelihood Estimation, MLE) . - 우리가 알고있는 임의의 분포(모수만 모름)에서 뽑은 랜덤표본을 가지고 모수를 추정한다 . - 가능도함수: $L( theta)=L( theta;x_1,x_2, cdots,x_n)=f(x_1,x_2, cdots,x_n; theta)= prod limits^{n}_{i=1}f(x_i; theta)$ . - 확률밀도함수와 가능도함수는 특정한 $x_1,x_2, cdots,x_n$과 $ theta$에 대해서 동일한 값을 가진다 . - 가능도함수를 최대화하는 모수 $ theta$의 최대가능도 추정량을 구하면 된다 . - 참고로 함수의 최대값을 구하기 위해 미분을 사용하는데 미분을 할 때 가능도함수에 로그를 취한다 . - 로그를 취하면 미분이 편해지며 어차피 로그함수는 단조증가함수이므로 $L( theta)$를 최대로 만드는 $ theta$에서 $ ell( theta)$도 최대이다 . - 만약 가능도함수의 support(토대)에 모수가 포함되어 있으면 미분이 불가능하여 그래프를 그려서 최대가능도 추정량을 구해야 함 . - 참고로 최대가능도 추정량의 경우 불변성 원리가 성립한다 . &#52628;&#51221;&#51032; &#44592;&#51456; . - $T(X)$가 $g( theta)$의 추정량일 때 $E[T(X)]-g( theta)$를 $T(X)$의 편향(bias)이라고 하며 . - 편향이 $0$이면 $T(X)$를 $g( theta)$의 비편향추정량이라고 한다 . - $ operatorname{MSE} = Var left(T(X) right) + (bias)^2$ . - 일치성(consistency) : $T(X) xrightarrow{~~p~~}g( theta)$ . - $ lim limits_{n to infty} E big [T_n(X)-g( theta) big]^2=0$이 성립하면 $T_n(X)$는 일치성이 있다(확률부등식 사용) . - $g(x)$가 $ theta$에서 연속인 함수이면 불변성 성립! . 비편향성(불편성)과 일치성의 차이 | . - 불편성은 고정된 표본크기에 대한 추정량의 기댓값이 $g( theta)$인 것이고 . - 일치성은 표본크기가 무한히 커지면 추정량 자체의 값이 $g( theta)$로 확률수렴(확률적으로 수렴)하는 것 . &#52572;&#49548;&#48516;&#49328; &#48708;&#54200;&#54693;&#52628;&#51221;&#47049;(Minimum Variance Unbiased Estimator, MVUE) . - 다음을 만족하는 함수 $g( theta)$의 추정량 $T^*(X)$를 최소분산 비편향추정량이라고 한다 . 1. $T^*(X)$는 $g( theta)$의 비편향추정량 . 2. $Var left(T^*(X) right) leq Var left(T(X) right)$ . &#53356;&#47000;&#47672;-&#46972;&#50724; &#54616;&#54620;&#44050; . - 적절한 조건하에서 비편향추정량이 가질 수 있는 분산의 하한값을 제공(조건은 교재 참고) . - 어떤 비편향추정량이 분산의 하한값을 분산으로 가지면 최소분산 비편향추정량이다(단, 유일성을 보이기는 어려움) . - 피셔의 정보 : $I( theta)=E left[ left( frac{ partial}{ partial theta} log f(X; theta) right)^2 right]$ . - 참고로 $f(X)$는 다음과 같음 : 확률변수 $X$ $ xrightarrow{ text{$f$: pdf of $X$}} f(X)$ . - $f(X)$는 확률변수, $f(x)$는 확률변수 $f(X)$의 realization(?) . - 크래머-라오의 정보부등식: $Var(T(X)) geq dfrac{[g&#39;( theta)]^2}{nI( theta)}$ $ to$ 크래머-라오 하한값 . 주의할 점 | . 1. 크래머-라오 하한값을 갖지 않아도 최소분산 비편향추정량이 될 수 있다 . 2. 적절한 조건을 어기는 경우 크래머-라오 하한값보다 더 작은 분산을 가지는 비편향추정량이 존재할 수 있다 . &#52649;&#48516;&#53685;&#44228;&#47049;(sufficient statistic) . - 확률벡터 $ boldsymbol{X}$의 결합 확률밀도함수는 $f(x_1, cdots,x_n; theta_1, cdots, theta_k)$이고 $ boldsymbol{S}( boldsymbol{X})$를 $l$개의 통계량의 벡터라고 하자 . - 이때 조건부 확률변수 $(X_1,X_2, cdots,X_n) mid boldsymbol{S}( boldsymbol{X})$의 분포가 모수 $ boldsymbol{ theta}$에 의존하지 않으면 . - 통계량 $ boldsymbol{S}( boldsymbol{X})$를 결합 충분통계량(jointly sufficient statistic)이라고 한다 . - $l=1$인 경우 $ boldsymbol{S}( boldsymbol{X})$가 $ theta$의 충분통계량이라고 한다 . - 참고로 결합 충분통계량의 $1:1$ 함수도 결합 충분통계량이다 . 충분통계량의 의미 | . - 확률벡터 $ boldsymbol{X}$에는 모수에 대한 정보가 담겨있다 . - 그런데 누군가가 $ boldsymbol{S}( boldsymbol{X})$를 알려주면 더 이상 $ boldsymbol{X}$의 정보가 필요 없어짐 . - 왜냐하면 $ boldsymbol{S}( boldsymbol{X})$가 모수 $ boldsymbol{ theta}$에 대한 정보를 모두 가지고 있기 때문임 . 인수분해 정리 | . - 충분통계량을 구하기 위해서 매번 조건부 확률밀도함수를 계산하기 힘듦 . - 인수분해 정리를 통해 간편하게 주어진 통계량의 충분성을 확인할 수 있다 . - $ boldsymbol{S}$가 결합 충분통계량일 필요충분조건은 $f(x_1,x_2, cdots,x_n; boldsymbol{ theta})$가 $ boldsymbol{s}$와 $ boldsymbol{ theta}$만의 함수인 $g$와 . $(x_1,x_2, cdots,x_n)$만의 함수인 $h$와의 곱의 꼴로 나타내어지는 것이다 . - $f(x_1,x_2, cdots,x_n; boldsymbol{ theta})=g( boldsymbol{s}(x); boldsymbol{ theta}) times h(x_1,x_2, cdots,x_n)$ . - $X_1,X_2, cdots,X_n$의 결합 확률밀도함수를 구하고 통계량과 모수에 대한 함수와 $x_1,x_2, cdots,x_n$의 함수끼리의 곱으로 나타내면 되는 것 . - 만약 불가능하다면 $ boldsymbol{S}$는 결합 충분통계량이 아닌 것이다 . - 예제는 교재 확인 . &#46972;&#50724;-&#48660;&#47001;&#50928; &#51221;&#47532; . - $S$가 $g( theta)$의 충분통계량이고 $T(X)$를 $g( theta)$의 비편향추정량이라고 하자 . - $ delta(S)=E left(T(X) mid S right)$이면 $ delta(S)$도 $g( theta)$의 비편향추정량이며 모든 $ theta$에 대해 아래가 성립(분산 분해 사용) . $$ begin{aligned} Var left(T(X) right) &amp;= E left(Var left(T(X) mid S right) right) + Var left(E left(T(X) mid S right) right) [10pt] &amp;=E left[E left( left(T(X)- delta(S) right)^2 mid S right) right] +Var left( delta(S) right) [10pt] &amp; geq Var left( delta(S) right) end{aligned}$$ - 이중 기댓값 정리에 의하여 $E left( delta(S) right)=E left(E(T(X) mid S) right)=g( theta)$ 이므로 $ delta(S)$도 $g( theta)$의 비편향추정량이다 . &#50756;&#48708;&#53685;&#44228;&#47049;(complete statistic) . - 랜덤표본 $X_1,X_2, cdots,X_n$으로 부터 계산된 통계량 $S$에 대하여 . - $E left(g(S) right)=0$을 모든 $ theta in Omega$에 대해서 만족하는 $ theta$와 무관한 함수 $g$가 $g( cdot) equiv 0$ 뿐이라면 . - $S$를 완비통계량이라고 하며 만약 $S$가 $ theta$에 대한 충분통계량이라면 완비 충분통계량(C.S.S)라고 한다 . 예시 | . - $X_1, cdots,X_n overset{iid} sim Bernoulli(p)$ 라고 하자 . - $X_1-X_2$는 완비통계량이 아니다 $ to$ $g=I, S(X) = X_1-X_2$ 라고 하자 . - $E left[g left(S(X) right) right]=E(X_1-X_2)=0 to g left(S(X) right) = X_1-X_2 neq0$ . 완비성의 의미 | . - $S(X)$가 완비통계량이면 $S(X)$의 서로 다른 두 함수가 같은 기댓값을 가지지 못한다 . - $E left[g_{_1} left(S(X) right) right] = g( theta), E left[g_{_2} left(S(X) right) right] = g( theta) Longrightarrow E left[g_{_1} left(S(X) right)-g_{_2} left(S(X) right) right] =0$ . - 그런데 완비성에 의해 $S(X)$에 임의의 함수$g$ 를 취한 확률변수의 기댓값이 $0$이라면 $g left(S(X) right)=0$이므로 . - $g_{_1} left(S(X) right)=g_{_2} left(S(X) right)$이 성립한다 . - 같은 기댓값을 가지지 못한다는 것은 완비통계량의 함수로서 비편향추정량은 하나 뿐이라는 것이고 . - 이때의 비편향추정량은 하나 뿐이니 당연하게도 최소분산 비편향추정량이 된다 . &#47112;&#47564;-&#49744;&#54168; &#51221;&#47532; . - 모수 $ theta$에 대해 $S$가 완비 충분통계량이고 $T(X)$가 $g( theta)$의 비편향추정량이라고 하자 . - 이때 $ delta(S)=E left(T(X) mid S right)$는 $g( theta)$의 유일한 최소분산 비편향추정량(MVUE)이다 . 모수 $ theta$에 대한 MVUE 찾는 방법 | . 1. 크래머-라오 하한값을 분산으로 가지는 비편향추정량 찾기 . 2. 완비 충분통계량의 함수 중에서 비편향추정량 찾기 . 3. 비편향추정량에 완비 통계량으로 조건부 기댓값 취하기 . &#51648;&#49688;&#51313;(exponential family) . - 확률밀도함수 $f(x; boldsymbol{ theta})=a( boldsymbol theta)b(x) exp left[ sum limits_{i=1}^{k}c_i( boldsymbol theta)t_i(x) right]I(x:f(x; boldsymbol{ theta})&gt;0), boldsymbol theta=( theta_1, cdots, theta_n)$ . - 위의 확률밀도함수를 $k$개의 모수 $ theta_1, cdots, theta_k$를 가진 지수족에 속한다고 한다 . - 참고로 $f(x; boldsymbol{ theta})$의 support는 모수 $ boldsymbol{ theta}$에 의존하지 않는다 . - $X_1, cdots,X_n overset{iid}{ sim} f(x; boldsymbol theta)$일 때 통계량 $S_1= sum limits_{i=1}^{N}t_1(X_i), cdots,S_k= sum limits_{i=1}^{N}t_k (X_i)$는 모수 $ theta_1, cdots, theta_k$에 대한 결합 완비 충분통계량이다 . - 완비 충분통계량의 $1:1$ 함수도 완비 충분통계량이다 .",
            "url": "https://jaesu26.github.io/study-blog/statistics/2022/03/23/%ED%86%B5%EA%B3%84%EC%A0%81%EC%B6%94%EB%A1%A0.html",
            "relUrl": "/statistics/2022/03/23/%ED%86%B5%EA%B3%84%EC%A0%81%EC%B6%94%EB%A1%A0.html",
            "date": " • Mar 23, 2022"
        }
        
    
  
    
        ,"post18": {
            "title": "아나콘다 가상환경 만들기",
            "content": "- 가상환경 목록 확인 : conda env list . - 가상환경 간단한 명령어 : conda env . - 가상환경에서 커널 확인 : jupyter kernelspec list . - 가상환경에서 커널 삭제 : jupyter kernelspec uninstall unwanted-kernel . &#50500;&#45208;&#53080;&#45796; &#44032;&#49345;&#54872;&#44221;&#50640;&#49436; &#51452;&#54588;&#53552;&#47017; &#49324;&#50857; . - 간단히 정리하자 . 1. conda create -n 가상환경이름 python=3.8 $ longrightarrow$ 가상환경 생성 . 2. conda activate 가상환경이름 $ longrightarrow$ 가상환경 활성화 . 3. conda install -c conda-forge r-essentials=4.0 $ longrightarrow$ R 4.0 버전 설치 . 4. conda install -c conda-forge jupyterlab $ longrightarrow$ 주피터랩 설치 . 5. R $ longrightarrow$ R 환경진입 . 6. install.packages(&quot;IRkernel&quot;) . 7. library(IRkernel) . 8. IRkernel::installspec() . 9. q() . 10. jupyter lab $ longrightarrow$ 주피터랩 실행 .",
            "url": "https://jaesu26.github.io/study-blog/anaconda/2022/02/18/%EC%95%84%EB%82%98%EC%BD%98%EB%8B%A4-%EA%B0%80%EC%83%81%ED%99%98%EA%B2%BD.html",
            "relUrl": "/anaconda/2022/02/18/%EC%95%84%EB%82%98%EC%BD%98%EB%8B%A4-%EA%B0%80%EC%83%81%ED%99%98%EA%B2%BD.html",
            "date": " • Feb 18, 2022"
        }
        
    
  
    
        ,"post19": {
            "title": "데이터시각화 기말고사",
            "content": "- 문제: https://guebin.github.io/DV2021/2021/12/03/%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%8B%9C%EA%B0%81%ED%99%94-%EA%B8%B0%EB%A7%90%EA%B3%A0%EC%82%AC.html . - 1, 2번 푸는데 1시간 걸림... 어렵다... . - 아니 왜 plot HTML로 바꿔 올리면 에러남... . import pandas as pd import folium import json import requests . 1 . df = pd.read_html(&#39;https://ncv.kdca.go.kr/mainStatus.es?mid=a11702000000&#39;, encoding = &#39;utf-8&#39;)[1] . df . 구분 1차접종 2차접종 3차접종 . 구분 당일 실적 당일 누계 당일 실적 당일 누계 당일 실적 당일 누계 . 0 합계 | 44915 | 42871274 | 54713 | 41568595 | 439915 | 5289734 | . 1 서울 | 6632 | 7978215 | 7730 | 7760751 | 82159 | 988855 | . 2 부산 | 3359 | 2740631 | 3523 | 2653933 | 28332 | 320683 | . 3 대구 | 2196 | 1907860 | 2353 | 1845856 | 16526 | 195340 | . 4 인천 | 2446 | 2446083 | 3075 | 2370883 | 26230 | 279748 | . 5 광주 | 1480 | 1197383 | 1990 | 1156165 | 10386 | 147318 | . 6 대전 | 1288 | 1180917 | 1639 | 1142424 | 11252 | 135211 | . 7 울산 | 1203 | 914405 | 1171 | 886896 | 7737 | 85420 | . 8 세종 | 304 | 274389 | 371 | 264195 | 2292 | 30502 | . 9 경기 | 11172 | 11225014 | 11469 | 10888835 | 103816 | 1301726 | . 10 강원 | 1411 | 1286431 | 1967 | 1248659 | 17893 | 181907 | . 11 충북 | 1297 | 1359054 | 1874 | 1318878 | 14207 | 180186 | . 12 충남 | 1750 | 1799651 | 2594 | 1741052 | 20880 | 246609 | . 13 전북 | 2044 | 1523092 | 3994 | 1478776 | 21387 | 235253 | . 14 전남 | 1728 | 1582830 | 3270 | 1534876 | 17895 | 276074 | . 15 경북 | 2230 | 2171884 | 2790 | 2102489 | 23735 | 282803 | . 16 경남 | 3536 | 2729534 | 4141 | 2639330 | 29592 | 339109 | . 17 제주 | 839 | 553901 | 762 | 534597 | 5596 | 62990 | . - 합계는 필요없는것 같다 . df_ = df.copy() . df_ = df_.iloc[1:,:].reset_index(drop = True) ## df와 df2의 인덱스번호를 맞춰주기 위함 . global_url = &#39;https://raw.githubusercontent.com/southkorea/southkorea-maps/master/kostat/2018/json/skorea-provinces-2018-geo.json&#39; . global_dict = json.loads(requests.get(global_url).text) . df_.loc[:, (&#39;구분&#39;,&#39;구분&#39;)] = [global_dict[&#39;features&#39;][i][&#39;properties&#39;][&#39;name&#39;] for i in range(17)] . df2 = pd.read_csv(&#39;https://raw.githubusercontent.com/guebin/2021DV/master/_notebooks/2021-11-22-prov.csv&#39;) df2 . 행정구역(시군구)별 총인구수 (명) . 0 서울특별시 | 9532428 | . 1 부산광역시 | 3356311 | . 2 대구광역시 | 2390721 | . 3 인천광역시 | 2945009 | . 4 광주광역시 | 1442454 | . 5 대전광역시 | 1454228 | . 6 울산광역시 | 1122566 | . 7 세종특별자치시 | 368276 | . 8 경기도 | 13549577 | . 9 강원도 | 1537717 | . 10 충청북도 | 1596948 | . 11 충청남도 | 2118977 | . 12 전라북도 | 1789770 | . 13 전라남도 | 1834653 | . 14 경상북도 | 2627925 | . 15 경상남도 | 3318161 | . 16 제주특별자치도 | 676569 | . df2[&#39;prob&#39;] = df_[(&#39;2차접종&#39;, &#39;당일 누계&#39;)] / df2[&#39;총인구수 (명)&#39;] . df2 = df2.rename(columns = {&#39;행정구역(시군구)별&#39;:&#39;prov&#39;}).drop(&#39;총인구수 (명)&#39;, axis = 1) . df2 . prov prob . 0 서울특별시 | 0.814142 | . 1 부산광역시 | 0.790729 | . 2 대구광역시 | 0.772092 | . 3 인천광역시 | 0.805051 | . 4 광주광역시 | 0.801526 | . 5 대전광역시 | 0.785588 | . 6 울산광역시 | 0.790061 | . 7 세종특별자치시 | 0.717383 | . 8 경기도 | 0.803629 | . 9 강원도 | 0.812021 | . 10 충청북도 | 0.825874 | . 11 충청남도 | 0.821647 | . 12 전라북도 | 0.826238 | . 13 전라남도 | 0.836603 | . 14 경상북도 | 0.800057 | . 15 경상남도 | 0.795420 | . 16 제주특별자치도 | 0.790159 | . m = folium.Map(scrollWheelZoom = False, location = [36,128], zoom_start = 8.2) folium.Choropleth( data = df2, geo_data = global_dict, columns = [&#39;prov&#39;, &#39;prob&#39;], key_on = &#39;feature.properties.name&#39; ).add_to(m) # m . &lt;folium.features.Choropleth at 0x215edd70f70&gt; . 2 . df = pd.read_csv(&#39;https://raw.githubusercontent.com/guebin/2021DV/master/_notebooks/covid19_20211202.csv&#39;) df . 일자 계(명) 서울 부산 대구 인천 광주 대전 울산 세종 경기 강원 충북 충남 전북 전남 경북 경남 제주 검역 . 0 누적(명) | 457,612 | 158,774 | 16,555 | 19,114 | 25,299 | 6,353 | 8,809 | 5,675 | 1,588 | 136,546 | 8,889 | 8,942 | 13,174 | 6,453 | 4,498 | 11,471 | 15,236 | 3,762 | 6,474 | . 1 2020-01-20 | 1 | - | - | - | 1 | - | - | - | - | - | - | - | - | - | - | - | - | - | - | . 2 2020-01-21 | 0 | - | - | - | - | - | - | - | - | - | - | - | - | - | - | - | - | - | - | . 3 2020-01-22 | 0 | - | - | - | - | - | - | - | - | - | - | - | - | - | - | - | - | - | - | . 4 2020-01-23 | 0 | - | - | - | - | - | - | - | - | - | - | - | - | - | - | - | - | - | - | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 679 2021-11-28 | 3,925 | 1,673 | 148 | 106 | 278 | 52 | 53 | 4 | 5 | 1,090 | 63 | 25 | 121 | 45 | 25 | 103 | 89 | 35 | 10 | . 680 2021-11-29 | 3,308 | 1,393 | 144 | 88 | 233 | 61 | 43 | 2 | 15 | 910 | 56 | 33 | 52 | 49 | 28 | 68 | 86 | 44 | 3 | . 681 2021-11-30 | 3,032 | 1,186 | 79 | 78 | 192 | 52 | 43 | 3 | 22 | 909 | 84 | 59 | 81 | 50 | 36 | 68 | 60 | 22 | 8 | . 682 2021-12-01 | 5,123 | 2,222 | 143 | 86 | 326 | 29 | 88 | 17 | 20 | 1,582 | 105 | 48 | 96 | 50 | 40 | 97 | 127 | 27 | 20 | . 683 2021-12-02 | 5,266 | 2,268 | 158 | 70 | 355 | 39 | 166 | 18 | 8 | 1,495 | 145 | 49 | 149 | 71 | 39 | 106 | 94 | 31 | 5 | . 684 rows × 20 columns . df3 = pd.read_csv(&#39;https://raw.githubusercontent.com/guebin/2021DV/master/_notebooks/2021-11-22-prov.csv&#39;) df3 . 행정구역(시군구)별 총인구수 (명) . 0 서울특별시 | 9532428 | . 1 부산광역시 | 3356311 | . 2 대구광역시 | 2390721 | . 3 인천광역시 | 2945009 | . 4 광주광역시 | 1442454 | . 5 대전광역시 | 1454228 | . 6 울산광역시 | 1122566 | . 7 세종특별자치시 | 368276 | . 8 경기도 | 13549577 | . 9 강원도 | 1537717 | . 10 충청북도 | 1596948 | . 11 충청남도 | 2118977 | . 12 전라북도 | 1789770 | . 13 전라남도 | 1834653 | . 14 경상북도 | 2627925 | . 15 경상남도 | 3318161 | . 16 제주특별자치도 | 676569 | . df3 = df3.rename(columns = {&#39;행정구역(시군구)별&#39;:&#39;prov&#39;, &#39;총인구수 (명)&#39;:&#39;pop&#39;}) . - 검역은 지도에 표시 안할거니 제외 . df_ = df.copy() . df_.iloc[1:, 1:] = df_.iloc[1:, 1:].applymap(lambda x: int(x.replace(&#39;,&#39;, &#39;&#39;)) if x != &#39;-&#39; else 0) . df_ = df_.iloc[1:, :-1].drop(&#39;계(명)&#39;, axis = 1) . df_[&#39;일자&#39;] = df_[&#39;일자&#39;].apply(lambda x: str(x)[:-3]) df_ . 일자 서울 부산 대구 인천 광주 대전 울산 세종 경기 강원 충북 충남 전북 전남 경북 경남 제주 . 1 2020-01 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 2 2020-01 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 3 2020-01 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 4 2020-01 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 5 2020-01 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 679 2021-11 | 1673 | 148 | 106 | 278 | 52 | 53 | 4 | 5 | 1090 | 63 | 25 | 121 | 45 | 25 | 103 | 89 | 35 | . 680 2021-11 | 1393 | 144 | 88 | 233 | 61 | 43 | 2 | 15 | 910 | 56 | 33 | 52 | 49 | 28 | 68 | 86 | 44 | . 681 2021-11 | 1186 | 79 | 78 | 192 | 52 | 43 | 3 | 22 | 909 | 84 | 59 | 81 | 50 | 36 | 68 | 60 | 22 | . 682 2021-12 | 2222 | 143 | 86 | 326 | 29 | 88 | 17 | 20 | 1582 | 105 | 48 | 96 | 50 | 40 | 97 | 127 | 27 | . 683 2021-12 | 2268 | 158 | 70 | 355 | 39 | 166 | 18 | 8 | 1495 | 145 | 49 | 149 | 71 | 39 | 106 | 94 | 31 | . 683 rows × 18 columns . _df = df_.groupby(&#39;일자&#39;).agg(&#39;sum&#39;).reset_index(). rename(columns = dict(zip(df_.columns, [&#39;ym&#39;] + [global_dict[&#39;features&#39;][i][&#39;properties&#39;][&#39;name&#39;] for i in range(17)]))). query(&#39;&quot;2021-01&quot; &lt;= ym &lt;= &quot;2021-10&quot;&#39;). melt(id_vars = &#39;ym&#39;).rename(columns = {&#39;variable&#39;:&#39;prov&#39;, &#39;value&#39;:&#39;confirmed&#39;}) . _df = _df.assign(pop = [df3.query(&#39;prov == @_df[&quot;prov&quot;][@i]&#39;)[&#39;pop&#39;].pipe(int) for i in range(len(_df))]). eval(&#39;prop = confirmed / pop&#39;) . _df . ym prov confirmed pop prop . 0 2021-01 | 서울특별시 | 5160 | 9532428 | 0.000541 | . 1 2021-02 | 서울특별시 | 4080 | 9532428 | 0.000428 | . 2 2021-03 | 서울특별시 | 3794 | 9532428 | 0.000398 | . 3 2021-04 | 서울특별시 | 5807 | 9532428 | 0.000609 | . 4 2021-05 | 서울특별시 | 6078 | 9532428 | 0.000638 | . ... ... | ... | ... | ... | ... | . 165 2021-06 | 제주특별자치도 | 234 | 676569 | 0.000346 | . 166 2021-07 | 제주특별자치도 | 468 | 676569 | 0.000692 | . 167 2021-08 | 제주특별자치도 | 870 | 676569 | 0.001286 | . 168 2021-09 | 제주특별자치도 | 273 | 676569 | 0.000404 | . 169 2021-10 | 제주특별자치도 | 225 | 676569 | 0.000333 | . 170 rows × 5 columns . - 지금까지 고생해서 만든 데이터프레임은 시도별 월별 코로나수 확진자 수이다 . # from IPython.display import HTML # fig = px.choropleth_mapbox(_df, # geojson = global_dict, # color = &#39;prop&#39;, # locations = &#39;prov&#39;, # animation_frame = &#39;ym&#39;, # featureidkey = &#39;properties.name&#39;, # center = {&quot;lat&quot;: 36, &quot;lon&quot;: 128}, # mapbox_style = &#39;carto-positron&#39;, # range_color = (0, _df.prop.max()), # height = 1200, # zoom = 6.5) # fig.update_layout(margin = {&quot;r&quot;:0, &quot;t&quot;:0, &quot;l&quot;:0, &quot;b&quot;:0}) # _html = fig.to_html(include_mathjax = False, config = dict({&#39;scrollZoom&#39;:False})) # HTML(_html) . - 위 코드를 실행하면 컴퓨터가 맛이가서 전부 주석처리했다 . 3 . df4 = pd.read_csv(&#39;https://raw.githubusercontent.com/guebin/2021DV/master/_notebooks/covid19_20211202.csv&#39;) df4 . 일자 계(명) 서울 부산 대구 인천 광주 대전 울산 세종 경기 강원 충북 충남 전북 전남 경북 경남 제주 검역 . 0 누적(명) | 457,612 | 158,774 | 16,555 | 19,114 | 25,299 | 6,353 | 8,809 | 5,675 | 1,588 | 136,546 | 8,889 | 8,942 | 13,174 | 6,453 | 4,498 | 11,471 | 15,236 | 3,762 | 6,474 | . 1 2020-01-20 | 1 | - | - | - | 1 | - | - | - | - | - | - | - | - | - | - | - | - | - | - | . 2 2020-01-21 | 0 | - | - | - | - | - | - | - | - | - | - | - | - | - | - | - | - | - | - | . 3 2020-01-22 | 0 | - | - | - | - | - | - | - | - | - | - | - | - | - | - | - | - | - | - | . 4 2020-01-23 | 0 | - | - | - | - | - | - | - | - | - | - | - | - | - | - | - | - | - | - | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 679 2021-11-28 | 3,925 | 1,673 | 148 | 106 | 278 | 52 | 53 | 4 | 5 | 1,090 | 63 | 25 | 121 | 45 | 25 | 103 | 89 | 35 | 10 | . 680 2021-11-29 | 3,308 | 1,393 | 144 | 88 | 233 | 61 | 43 | 2 | 15 | 910 | 56 | 33 | 52 | 49 | 28 | 68 | 86 | 44 | 3 | . 681 2021-11-30 | 3,032 | 1,186 | 79 | 78 | 192 | 52 | 43 | 3 | 22 | 909 | 84 | 59 | 81 | 50 | 36 | 68 | 60 | 22 | 8 | . 682 2021-12-01 | 5,123 | 2,222 | 143 | 86 | 326 | 29 | 88 | 17 | 20 | 1,582 | 105 | 48 | 96 | 50 | 40 | 97 | 127 | 27 | 20 | . 683 2021-12-02 | 5,266 | 2,268 | 158 | 70 | 355 | 39 | 166 | 18 | 8 | 1,495 | 145 | 49 | 149 | 71 | 39 | 106 | 94 | 31 | 5 | . 684 rows × 20 columns . - 위의 데이터프레임을 전처리한것이 아래다 . - 누적과 합계를 제외하고 검역도 제외했다 . - 관찰치를 int형으로 바꾸고 -은 0으로 처리했다 . df4.iloc[1:, 1:] = df4.iloc[1:, 1:].applymap(lambda x: int(x.replace(&#39;,&#39;, &#39;&#39;)) if x != &#39;-&#39; else 0) . df4 = df4.iloc[1:, :-1].drop(&#39;계(명)&#39;, axis = 1) . df4.columns = [&#39;date&#39;] + [global_dict[&#39;features&#39;][i][&#39;properties&#39;][&#39;name_eng&#39;] for i in range(17)] . df4 . date Seoul Busan Daegu Incheon Gwangju Daejeon Ulsan Sejongsi Gyeonggi-do Gangwon-do Chungcheongbuk-do Chungcheongnam-do Jeollabuk-do Jeollanam-do Gyeongsangbuk-do Gyeongsangnam-do Jeju-do . 1 2020-01-20 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 2 2020-01-21 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 3 2020-01-22 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 4 2020-01-23 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 5 2020-01-24 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 679 2021-11-28 | 1673 | 148 | 106 | 278 | 52 | 53 | 4 | 5 | 1090 | 63 | 25 | 121 | 45 | 25 | 103 | 89 | 35 | . 680 2021-11-29 | 1393 | 144 | 88 | 233 | 61 | 43 | 2 | 15 | 910 | 56 | 33 | 52 | 49 | 28 | 68 | 86 | 44 | . 681 2021-11-30 | 1186 | 79 | 78 | 192 | 52 | 43 | 3 | 22 | 909 | 84 | 59 | 81 | 50 | 36 | 68 | 60 | 22 | . 682 2021-12-01 | 2222 | 143 | 86 | 326 | 29 | 88 | 17 | 20 | 1582 | 105 | 48 | 96 | 50 | 40 | 97 | 127 | 27 | . 683 2021-12-02 | 2268 | 158 | 70 | 355 | 39 | 166 | 18 | 8 | 1495 | 145 | 49 | 149 | 71 | 39 | 106 | 94 | 31 | . 683 rows × 18 columns . (1) matplotlib . import matplotlib.pyplot as plt . df4.plot.line(x = &#39;date&#39;, subplots = True, layout = (9, 2), figsize = (15, 15)) plt.tight_layout() . (2) plotly . - 데이터프레임을 tidy하게 만들면된다 . df4 ## 현재 데이터프레임 상태 . date Seoul Busan Daegu Incheon Gwangju Daejeon Ulsan Sejongsi Gyeonggi-do Gangwon-do Chungcheongbuk-do Chungcheongnam-do Jeollabuk-do Jeollanam-do Gyeongsangbuk-do Gyeongsangnam-do Jeju-do . 1 2020-01-20 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 2 2020-01-21 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 3 2020-01-22 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 4 2020-01-23 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 5 2020-01-24 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 679 2021-11-28 | 1673 | 148 | 106 | 278 | 52 | 53 | 4 | 5 | 1090 | 63 | 25 | 121 | 45 | 25 | 103 | 89 | 35 | . 680 2021-11-29 | 1393 | 144 | 88 | 233 | 61 | 43 | 2 | 15 | 910 | 56 | 33 | 52 | 49 | 28 | 68 | 86 | 44 | . 681 2021-11-30 | 1186 | 79 | 78 | 192 | 52 | 43 | 3 | 22 | 909 | 84 | 59 | 81 | 50 | 36 | 68 | 60 | 22 | . 682 2021-12-01 | 2222 | 143 | 86 | 326 | 29 | 88 | 17 | 20 | 1582 | 105 | 48 | 96 | 50 | 40 | 97 | 127 | 27 | . 683 2021-12-02 | 2268 | 158 | 70 | 355 | 39 | 166 | 18 | 8 | 1495 | 145 | 49 | 149 | 71 | 39 | 106 | 94 | 31 | . 683 rows × 18 columns . df4_ = df4.melt(id_vars = &#39;date&#39;).rename(columns = {&#39;variable&#39;:&#39;prov&#39;}) . df4_ . date prov value . 0 2020-01-20 | Seoul | 0 | . 1 2020-01-21 | Seoul | 0 | . 2 2020-01-22 | Seoul | 0 | . 3 2020-01-23 | Seoul | 0 | . 4 2020-01-24 | Seoul | 1 | . ... ... | ... | ... | . 11606 2021-11-28 | Jeju-do | 35 | . 11607 2021-11-29 | Jeju-do | 44 | . 11608 2021-11-30 | Jeju-do | 22 | . 11609 2021-12-01 | Jeju-do | 27 | . 11610 2021-12-02 | Jeju-do | 31 | . 11611 rows × 3 columns . # fig = df4_.plot.line(backend = &#39;plotly&#39;, # x = &#39;date&#39;, # y = &#39;value&#39;, # color = &#39;prov&#39;, # facet_col = &#39;prov&#39;, # facet_col_wrap = 3, # height = 1000) # fig.update_yaxes(matches = None) # HTML(fig.to_html(include_mathjax = False, config = dict({&#39;scrollZoom&#39;:False}))) . 4 . (1) . df5 = pd.read_csv(&#39;https://raw.githubusercontent.com/guebin/2021DV/master/_notebooks/2021-10-25-FIFA22_official_data.csv&#39;) df5.head() . ID Name Age Photo Nationality Flag Overall Potential Club Club Logo ... SlidingTackle GKDiving GKHandling GKKicking GKPositioning GKReflexes Best Position Best Overall Rating Release Clause DefensiveAwareness . 0 212198 | Bruno Fernandes | 26 | https://cdn.sofifa.com/players/212/198/22_60.png | Portugal | https://cdn.sofifa.com/flags/pt.png | 88 | 89 | Manchester United | https://cdn.sofifa.com/teams/11/30.png | ... | 65.0 | 12.0 | 14.0 | 15.0 | 8.0 | 14.0 | CAM | 88.0 | €206.9M | 72.0 | . 1 209658 | L. Goretzka | 26 | https://cdn.sofifa.com/players/209/658/22_60.png | Germany | https://cdn.sofifa.com/flags/de.png | 87 | 88 | FC Bayern München | https://cdn.sofifa.com/teams/21/30.png | ... | 77.0 | 13.0 | 8.0 | 15.0 | 11.0 | 9.0 | CM | 87.0 | €160.4M | 74.0 | . 2 176580 | L. Suárez | 34 | https://cdn.sofifa.com/players/176/580/22_60.png | Uruguay | https://cdn.sofifa.com/flags/uy.png | 88 | 88 | Atlético de Madrid | https://cdn.sofifa.com/teams/240/30.png | ... | 38.0 | 27.0 | 25.0 | 31.0 | 33.0 | 37.0 | ST | 88.0 | €91.2M | 42.0 | . 3 192985 | K. De Bruyne | 30 | https://cdn.sofifa.com/players/192/985/22_60.png | Belgium | https://cdn.sofifa.com/flags/be.png | 91 | 91 | Manchester City | https://cdn.sofifa.com/teams/10/30.png | ... | 53.0 | 15.0 | 13.0 | 5.0 | 10.0 | 13.0 | CM | 91.0 | €232.2M | 68.0 | . 4 224334 | M. Acuña | 29 | https://cdn.sofifa.com/players/224/334/22_60.png | Argentina | https://cdn.sofifa.com/flags/ar.png | 84 | 84 | Sevilla FC | https://cdn.sofifa.com/teams/481/30.png | ... | 82.0 | 8.0 | 14.0 | 13.0 | 13.0 | 14.0 | LB | 84.0 | €77.7M | 80.0 | . 5 rows × 65 columns . abilities = [&#39;Crossing&#39;, &#39;Finishing&#39;, &#39;HeadingAccuracy&#39;, &#39;ShortPassing&#39;, &#39;Volleys&#39;, &#39;Dribbling&#39;, &#39;Curve&#39;, &#39;FKAccuracy&#39;, &#39;LongPassing&#39;, &#39;BallControl&#39;, &#39;Acceleration&#39;, &#39;SprintSpeed&#39;, &#39;Agility&#39;, &#39;Reactions&#39;, &#39;Balance&#39;, &#39;ShotPower&#39;, &#39;Jumping&#39;, &#39;Stamina&#39;, &#39;Strength&#39;, &#39;LongShots&#39;, &#39;Aggression&#39;, &#39;Interceptions&#39;, &#39;Positioning&#39;, &#39;Vision&#39;, &#39;Penalties&#39;, &#39;Composure&#39;, &#39;StandingTackle&#39;, &#39;SlidingTackle&#39;] . - 일단 Korea Republic을 Korea로 바꾼다 . df5[&#39;Nationality&#39;] = df5[&#39;Nationality&#39;].replace(&#39;Korea Republic&#39;, &#39;Korea&#39;) . mean_ = [&#39;mean&#39;] * len(abilities) . df5_ = df5.query(&#39;Nationality == &quot;Korea&quot; or Nationality == &quot;Japan&quot;&#39;). groupby(&#39;Nationality&#39;).agg(dict(zip(abilities, mean_))). stack().reset_index().rename(columns = {&#39;level_1&#39;:&#39;aility&#39;, 0:&#39;value&#39;}) . df5_[&#39;value&#39;] = round(df5_[&#39;value&#39;], 2) . df5_ . Nationality aility value . 0 Japan | Crossing | 54.42 | . 1 Japan | Finishing | 50.67 | . 2 Japan | HeadingAccuracy | 51.07 | . 3 Japan | ShortPassing | 62.35 | . 4 Japan | Volleys | 46.54 | . 5 Japan | Dribbling | 59.53 | . 6 Japan | Curve | 51.18 | . 7 Japan | FKAccuracy | 46.57 | . 8 Japan | LongPassing | 57.50 | . 9 Japan | BallControl | 62.29 | . 10 Japan | Acceleration | 67.31 | . 11 Japan | SprintSpeed | 66.84 | . 12 Japan | Agility | 68.63 | . 13 Japan | Reactions | 62.05 | . 14 Japan | Balance | 68.37 | . 15 Japan | ShotPower | 59.14 | . 16 Japan | Jumping | 67.12 | . 17 Japan | Stamina | 66.35 | . 18 Japan | Strength | 62.54 | . 19 Japan | LongShots | 51.57 | . 20 Japan | Aggression | 54.74 | . 21 Japan | Interceptions | 46.55 | . 22 Japan | Positioning | 55.34 | . 23 Japan | Vision | 58.00 | . 24 Japan | Penalties | 48.74 | . 25 Japan | Composure | 58.93 | . 26 Japan | StandingTackle | 48.48 | . 27 Japan | SlidingTackle | 45.37 | . 28 Korea | Crossing | 49.76 | . 29 Korea | Finishing | 47.74 | . 30 Korea | HeadingAccuracy | 51.69 | . 31 Korea | ShortPassing | 58.76 | . 32 Korea | Volleys | 43.68 | . 33 Korea | Dribbling | 55.82 | . 34 Korea | Curve | 48.52 | . 35 Korea | FKAccuracy | 45.63 | . 36 Korea | LongPassing | 53.37 | . 37 Korea | BallControl | 57.70 | . 38 Korea | Acceleration | 65.85 | . 39 Korea | SprintSpeed | 66.11 | . 40 Korea | Agility | 67.11 | . 41 Korea | Reactions | 61.94 | . 42 Korea | Balance | 66.66 | . 43 Korea | ShotPower | 56.83 | . 44 Korea | Jumping | 64.88 | . 45 Korea | Stamina | 64.63 | . 46 Korea | Strength | 65.23 | . 47 Korea | LongShots | 48.94 | . 48 Korea | Aggression | 56.08 | . 49 Korea | Interceptions | 47.47 | . 50 Korea | Positioning | 54.62 | . 51 Korea | Vision | 57.27 | . 52 Korea | Penalties | 47.97 | . 53 Korea | Composure | 58.48 | . 54 Korea | StandingTackle | 46.63 | . 55 Korea | SlidingTackle | 44.28 | . # y = &#39;aility&#39;, # x = &#39;value&#39;, # barmode = &#39;group&#39;, # color = &#39;Nationality&#39;, # text = &#39;value&#39;, # height = 1500, # width = 800) # HTML(fig.to_html(include_mathjax = False, config = dict({&#39;scrollZoom&#39;:False}))) . - plotly는 따로 barh가 없으니 x와 y를 바꾸자 . (2) . _df5 = df5.copy() . players = _df5.groupby(&#39;Nationality&#39;).agg(&#39;size&#39;).reset_index(). sort_values(0, ascending = False).iloc[:20, 0].pipe(set) . players . {&#39;Argentina&#39;, &#39;Belgium&#39;, &#39;Brazil&#39;, &#39;Colombia&#39;, &#39;Denmark&#39;, &#39;England&#39;, &#39;France&#39;, &#39;Germany&#39;, &#39;Italy&#39;, &#39;Japan&#39;, &#39;Mexico&#39;, &#39;Netherlands&#39;, &#39;Norway&#39;, &#39;Poland&#39;, &#39;Portugal&#39;, &#39;Republic of Ireland&#39;, &#39;Scotland&#39;, &#39;Spain&#39;, &#39;Sweden&#39;, &#39;United States&#39;} . - 위는 선수 수가 많은 상위 20개 나라 . overall = set(_df5.groupby(&#39;Nationality&#39;).agg({&#39;Overall&#39;:&#39;mean&#39;}). sort_values(&#39;Overall&#39;, ascending = False).iloc[:20,:].T.columns.tolist()) . overall . {&#39;Algeria&#39;, &#39;Argentina&#39;, &#39;Brazil&#39;, &#39;Cape Verde Islands&#39;, &#39;Central African Republic&#39;, &#39;Croatia&#39;, &#39;Czech Republic&#39;, &#39;Egypt&#39;, &#39;Fiji&#39;, &#39;Gabon&#39;, &#39;Libya&#39;, &#39;Mozambique&#39;, &#39;Namibia&#39;, &#39;Portugal&#39;, &#39;Russia&#39;, &#39;Serbia&#39;, &#39;Syria&#39;, &#39;Tanzania&#39;, &#39;Ukraine&#39;, &#39;Uruguay&#39;} . - 위는 Overall이 높은 상위 20개 나라 . best = list(overall.intersection(players)) best . [&#39;Argentina&#39;, &#39;Brazil&#39;, &#39;Portugal&#39;] . - 위는 overall과 players의 교집합 . df5.query(&#39;Nationality in @best&#39;). groupby(&#39;Nationality&#39;).agg({&#39;Age&#39;:&#39;mean&#39;}). sort_values(&#39;Age&#39;, ascending = False). plot.bar() . &lt;AxesSubplot:xlabel=&#39;Nationality&#39;&gt; . - Argentina 선수들의 평균 연령이 제일 높고 그 다음은 Brazil 마지막은 Portugal 이다 . 5 . - 내가 임의로 만든 데이터 . from plotnine import * . gdp = [500, 600, 620, 700, 900, 800, 770, 765, 1102, 1155, 1320, 1500, 1900, 1950, 2200] year = list(range(1990, 2005)) unfair = [58, 60, 61, 57, 58.2, 59.7, 63.5, 62.7, 57.5, 56.8, 60.2, 59.2, 58.2, 57.8, 61.3] govern = [&#39;A&#39;] * 5 + [&#39;B&#39;] * 5 + [&#39;C&#39;] * 5 . Data = pd.DataFrame({&#39;gdp&#39;:gdp, &#39;year&#39;:year, &#39;unfair&#39;:unfair, &#39;govern&#39;:govern}) . Data . gdp year unfair govern . 0 500 | 1990 | 58.0 | A | . 1 600 | 1991 | 60.0 | A | . 2 620 | 1992 | 61.0 | A | . 3 700 | 1993 | 57.0 | A | . 4 900 | 1994 | 58.2 | A | . 5 800 | 1995 | 59.7 | B | . 6 770 | 1996 | 63.5 | B | . 7 765 | 1997 | 62.7 | B | . 8 1102 | 1998 | 57.5 | B | . 9 1155 | 1999 | 56.8 | B | . 10 1320 | 2000 | 60.2 | C | . 11 1500 | 2001 | 59.2 | C | . 12 1900 | 2002 | 58.2 | C | . 13 1950 | 2003 | 57.8 | C | . 14 2200 | 2004 | 61.3 | C | . a = Data.loc[[5]] b = Data.loc[[10]] . a[&#39;govern&#39;] = &#39;A&#39; b[&#39;govern&#39;] = &#39;B&#39; . Data = pd.concat([Data.loc[:4], a, Data.loc[5:9], b, Data.loc[10:]]) . Data . gdp year unfair govern . 0 500 | 1990 | 58.0 | A | . 1 600 | 1991 | 60.0 | A | . 2 620 | 1992 | 61.0 | A | . 3 700 | 1993 | 57.0 | A | . 4 900 | 1994 | 58.2 | A | . 5 800 | 1995 | 59.7 | A | . 5 800 | 1995 | 59.7 | B | . 6 770 | 1996 | 63.5 | B | . 7 765 | 1997 | 62.7 | B | . 8 1102 | 1998 | 57.5 | B | . 9 1155 | 1999 | 56.8 | B | . 10 1320 | 2000 | 60.2 | B | . 10 1320 | 2000 | 60.2 | C | . 11 1500 | 2001 | 59.2 | C | . 12 1900 | 2002 | 58.2 | C | . 13 1950 | 2003 | 57.8 | C | . 14 2200 | 2004 | 61.3 | C | . - C만 5개여서 불편... . ggplot(Data, aes(x = &#39;gdp&#39;, y = &#39;unfair&#39;)) + geom_point() + geom_text(aes(label = &#39;year&#39;), size = 8, va = &#39;bottom&#39;, ha = &#39;left&#39;) + geom_path(aes(color = &#39;govern&#39;), size = 2, alpha = 0.7) . &lt;ggplot: (194634680408)&gt; . ggplot(Data, aes(x = &#39;gdp&#39;, y = &#39;unfair&#39;)) + geom_point() + geom_text(aes(label = &#39;year&#39;), size = 8, va = &#39;bottom&#39;, ha = &#39;left&#39;) + geom_line(aes(color = &#39;govern&#39;), size = 2, alpha = 0.7) . &lt;ggplot: (194634631623)&gt; . - geom_line과 geom_path의 차이 . - geom_path는 선이 year를 따라간다 . - geom_line는 선이 왼쪽에서 오른쪽으로 간다(예컨대 1993다음은 1994이지만 1993 바로 오른쪽(같은 색깔중)에 1995가 있어서 1995로 간다) . (1) . - 실제 문제 . from plotnine import * . df = pd.read_csv(&#39;https://raw.githubusercontent.com/guebin/2021DV/master/_notebooks/gdp_df1.csv&#39;) df . GDP Inequality Government . 0 500 | 56 | A | . 1 550 | 58 | A | . 2 530 | 59 | A | . 3 480 | 61 | A | . 4 550 | 64 | A | . 5 550 | 64 | B | . 6 750 | 66 | B | . 7 560 | 68 | B | . 8 800 | 70 | B | . 9 900 | 65 | B | . 10 900 | 65 | C | . 11 910 | 62 | C | . 12 1100 | 61 | C | . 13 1250 | 58 | C | . 14 1350 | 63 | C | . 15 1350 | 63 | D | . 16 1500 | 57 | D | . 17 1660 | 55 | D | . df2 = pd.read_csv(&#39;https://raw.githubusercontent.com/guebin/2021DV/master/_notebooks/gdp_df2.csv&#39;, index_col = 0) df2 . A B C D . pop 54232.213 | 48823.432 | 46823.453 | 45232.119 | . df_ = df2.T.reset_index().rename(columns = {&#39;index&#39;:&#39;Government&#39;}).merge(df) df_ . Government pop GDP Inequality . 0 A | 54232.213 | 500 | 56 | . 1 A | 54232.213 | 550 | 58 | . 2 A | 54232.213 | 530 | 59 | . 3 A | 54232.213 | 480 | 61 | . 4 A | 54232.213 | 550 | 64 | . 5 B | 48823.432 | 550 | 64 | . 6 B | 48823.432 | 750 | 66 | . 7 B | 48823.432 | 560 | 68 | . 8 B | 48823.432 | 800 | 70 | . 9 B | 48823.432 | 900 | 65 | . 10 C | 46823.453 | 900 | 65 | . 11 C | 46823.453 | 910 | 62 | . 12 C | 46823.453 | 1100 | 61 | . 13 C | 46823.453 | 1250 | 58 | . 14 C | 46823.453 | 1350 | 63 | . 15 D | 45232.119 | 1350 | 63 | . 16 D | 45232.119 | 1500 | 57 | . 17 D | 45232.119 | 1660 | 55 | . ggplot(df_) + geom_path(aes(x = &#39;GDP&#39;, y = &#39;Inequality&#39;, size = &#39;pop&#39;, color = &#39;Government&#39;)) . &lt;ggplot: (194634670827)&gt; . (2) . df3 = pd.read_csv(&#39;https://raw.githubusercontent.com/guebin/2021DV/master/_notebooks/gdp_df3.csv&#39;, index_col = 0) df3 . type . A prog | . B cons | . C prog | . D cons | . df__ = df3.reset_index().rename(columns = {&#39;index&#39;:&#39;Government&#39;}).merge(df_) df__ . Government type pop GDP Inequality . 0 A | prog | 54232.213 | 500 | 56 | . 1 A | prog | 54232.213 | 550 | 58 | . 2 A | prog | 54232.213 | 530 | 59 | . 3 A | prog | 54232.213 | 480 | 61 | . 4 A | prog | 54232.213 | 550 | 64 | . 5 B | cons | 48823.432 | 550 | 64 | . 6 B | cons | 48823.432 | 750 | 66 | . 7 B | cons | 48823.432 | 560 | 68 | . 8 B | cons | 48823.432 | 800 | 70 | . 9 B | cons | 48823.432 | 900 | 65 | . 10 C | prog | 46823.453 | 900 | 65 | . 11 C | prog | 46823.453 | 910 | 62 | . 12 C | prog | 46823.453 | 1100 | 61 | . 13 C | prog | 46823.453 | 1250 | 58 | . 14 C | prog | 46823.453 | 1350 | 63 | . 15 D | cons | 45232.119 | 1350 | 63 | . 16 D | cons | 45232.119 | 1500 | 57 | . 17 D | cons | 45232.119 | 1660 | 55 | . ggplot(df__) + geom_path(aes(x = &#39;GDP&#39;, y = &#39;Inequality&#39;, size = &#39;pop&#39;, color = &#39;Government&#39;, linetype = &#39;type&#39;)) . &lt;ggplot: (194634935881)&gt; . 6 . df6 = pd.read_csv(&#39;https://raw.githubusercontent.com/guebin/2021DV/master/_notebooks/phone.csv&#39;) df6 . Date Samsung Apple Huawei Xiaomi Oppo Mobicel Motorola LG Others Realme Google Nokia Lenovo OnePlus Sony Asus . 0 2019-10 | 461 | 324 | 136 | 109 | 76 | 81 | 43 | 37 | 135 | 28 | 39 | 14 | 22 | 17 | 20 | 17 | . 1 2019-11 | 461 | 358 | 167 | 141 | 86 | 61 | 29 | 36 | 141 | 27 | 29 | 20 | 23 | 10 | 19 | 27 | . 2 2019-12 | 426 | 383 | 143 | 105 | 53 | 45 | 51 | 48 | 129 | 30 | 20 | 26 | 28 | 18 | 18 | 19 | . 3 2020-01 | 677 | 494 | 212 | 187 | 110 | 79 | 65 | 49 | 158 | 23 | 13 | 19 | 19 | 22 | 27 | 22 | . 4 2020-02 | 593 | 520 | 217 | 195 | 112 | 67 | 62 | 71 | 157 | 25 | 18 | 16 | 24 | 18 | 23 | 20 | . 5 2020-03 | 637 | 537 | 246 | 187 | 92 | 66 | 59 | 67 | 145 | 21 | 16 | 24 | 18 | 31 | 22 | 14 | . 6 2020-04 | 647 | 583 | 222 | 154 | 98 | 59 | 48 | 64 | 113 | 20 | 23 | 25 | 19 | 19 | 23 | 21 | . 7 2020-05 | 629 | 518 | 192 | 176 | 91 | 87 | 50 | 66 | 150 | 43 | 27 | 15 | 18 | 19 | 19 | 13 | . 8 2020-06 | 663 | 552 | 209 | 185 | 93 | 69 | 54 | 60 | 140 | 39 | 16 | 16 | 17 | 29 | 25 | 16 | . 9 2020-07 | 599 | 471 | 214 | 193 | 89 | 78 | 65 | 59 | 130 | 40 | 27 | 25 | 21 | 18 | 18 | 12 | . 10 2020-08 | 615 | 567 | 204 | 182 | 105 | 82 | 62 | 42 | 129 | 47 | 16 | 23 | 21 | 27 | 23 | 20 | . 11 2020-09 | 621 | 481 | 230 | 220 | 102 | 88 | 56 | 49 | 143 | 54 | 14 | 15 | 17 | 15 | 19 | 15 | . 12 2020-10 | 637 | 555 | 232 | 203 | 90 | 52 | 63 | 49 | 140 | 33 | 17 | 20 | 22 | 9 | 22 | 21 | . (1) . df6.set_index(&#39;Date&#39;). plot.line(figsize = (10, 7)) . &lt;AxesSubplot:xlabel=&#39;Date&#39;&gt; . (2) . df6.set_index(&#39;Date&#39;). plot.line(figsize = (10, 15), subplots = True, layout = (8, 2)) plt.tight_layout() . (3) . df6.set_index(&#39;Date&#39;).stack().reset_index().rename(columns = {&#39;level_1&#39;:&#39;variable&#39;, 0:&#39;value&#39;}). groupby(&#39;variable&#39;).agg(&#39;sum&#39;).sort_values(&#39;value&#39;, ascending = False). plot.bar() . &lt;AxesSubplot:xlabel=&#39;variable&#39;&gt; . (4) . df6_ = df6.copy() . df6_.Date = df6_.Date.apply(lambda x: str(x)[:4]) . _df6 = df6_.query(&#39;Date == &quot;2019&quot;&#39;).melt(id_vars = &#39;Date&#39;).groupby(&#39;variable&#39;).agg(&#39;sum&#39;) . _df6[&#39;value&#39;] = _df6[&#39;value&#39;] / _df6.value.sum() . _df6 . value . variable . Apple 0.224873 | . Asus 0.013302 | . Google 0.018581 | . Huawei 0.094172 | . LG 0.025549 | . Lenovo 0.015414 | . Mobicel 0.039485 | . Motorola 0.025971 | . Nokia 0.012669 | . OnePlus 0.009502 | . Oppo 0.045397 | . Others 0.085515 | . Realme 0.017948 | . Samsung 0.284628 | . Sony 0.012035 | . Xiaomi 0.074958 | . _df6.rename(columns = {&#39;value&#39;:&#39;2019&#39;}). plot.pie(y = &#39;2019&#39;, figsize = (7, 7)) . &lt;AxesSubplot:ylabel=&#39;2019&#39;&gt; . (5) . df7 = df6.set_index(&#39;Date&#39;).stack().reset_index().rename(columns = {&#39;level_1&#39;:&#39;variable&#39;, 0:&#39;value&#39;}). groupby(&#39;Date&#39;).agg(&#39;sum&#39;).reset_index() . df7 . Date value . 0 2019-10 | 1559 | . 1 2019-11 | 1635 | . 2 2019-12 | 1542 | . 3 2020-01 | 2176 | . 4 2020-02 | 2138 | . 5 2020-03 | 2182 | . 6 2020-04 | 2138 | . 7 2020-05 | 2113 | . 8 2020-06 | 2183 | . 9 2020-07 | 2059 | . 10 2020-08 | 2165 | . 11 2020-09 | 2139 | . 12 2020-10 | 2165 | . df7.Date = df7.Date.apply(lambda x: str(x)[:4]) . df7 . Date value . 0 2019 | 1559 | . 1 2019 | 1635 | . 2 2019 | 1542 | . 3 2020 | 2176 | . 4 2020 | 2138 | . 5 2020 | 2182 | . 6 2020 | 2138 | . 7 2020 | 2113 | . 8 2020 | 2183 | . 9 2020 | 2059 | . 10 2020 | 2165 | . 11 2020 | 2139 | . 12 2020 | 2165 | . df7.groupby(&#39;Date&#39;).agg(&#39;mean&#39;). plot.bar() . &lt;AxesSubplot:xlabel=&#39;Date&#39;&gt; . 7 . (1) . import matplotlib matplotlib.rcParams[&#39;font.family&#39;] = &#39;Malgun Gothic&#39; # 한글이 깨지지 않도록 설정 matplotlib.rcParams[&#39;axes.unicode_minus&#39;] = False # 한글이 깨지지 않도록 설정 . df7 = pd.read_html(&#39;https://ko.wikipedia.org/wiki/%EB%8C%80%ED%95%9C%EB%AF%BC%EA%B5%AD%EC%9D%98_%EC%9D%B8%EA%B5%AC&#39;)[17] df7 . 지역 출생아 수(천명) 조출생률 합계출산율 거주인구(2021년 주민등록 인구) . 0 서울 | 47.4 | 5.0 | 0.64 | 9588711 | . 1 부산 | 15.1 | 4.5 | 0.75 | 3369704 | . 2 대구 | 11.2 | 4.6 | 0.81 | 2406296 | . 3 대전 | 7.5 | 5.1 | 0.81 | 1457619 | . 4 광주 | 7.3 | 5.1 | 0.81 | 1444787 | . 5 인천 | 16.0 | 5.5 | 0.83 | 2936214 | . 6 경기도 | 77.8 | 5.9 | 0.88 | 13479798 | . 7 전라북도 | 8.2 | 4.5 | 0.91 | 1796331 | . 8 경상남도 | 16.8 | 5.1 | 0.95 | 3329623 | . 9 충청북도 | 8.6 | 5.4 | 0.98 | 1596303 | . 10 울산 | 6.6 | 5.8 | 0.99 | 1128163 | . 11 경상북도 | 12.9 | 4.9 | 1.00 | 2635896 | . 12 제주도 | 4.0 | 6.0 | 1.02 | 674484 | . 13 충청남도 | 11.9 | 5.7 | 1.03 | 2116452 | . 14 강원도 | 7.8 | 5.1 | 1.04 | 1536175 | . 15 전라남도 | 9.7 | 5.3 | 1.15 | 1844148 | . 16 세종 | 3.5 | 10.0 | 1.28 | 361396 | . 17 대한민국(전체) | 272.4 | 5.3 | 0.84 | 51702100 | . df7.iloc[:-1, :].set_index(&#39;지역&#39;) . 출생아 수(천명) 조출생률 합계출산율 거주인구(2021년 주민등록 인구) . 지역 . 서울 47.4 | 5.0 | 0.64 | 9588711 | . 부산 15.1 | 4.5 | 0.75 | 3369704 | . 대구 11.2 | 4.6 | 0.81 | 2406296 | . 대전 7.5 | 5.1 | 0.81 | 1457619 | . 광주 7.3 | 5.1 | 0.81 | 1444787 | . 인천 16.0 | 5.5 | 0.83 | 2936214 | . 경기도 77.8 | 5.9 | 0.88 | 13479798 | . 전라북도 8.2 | 4.5 | 0.91 | 1796331 | . 경상남도 16.8 | 5.1 | 0.95 | 3329623 | . 충청북도 8.6 | 5.4 | 0.98 | 1596303 | . 울산 6.6 | 5.8 | 0.99 | 1128163 | . 경상북도 12.9 | 4.9 | 1.00 | 2635896 | . 제주도 4.0 | 6.0 | 1.02 | 674484 | . 충청남도 11.9 | 5.7 | 1.03 | 2116452 | . 강원도 7.8 | 5.1 | 1.04 | 1536175 | . 전라남도 9.7 | 5.3 | 1.15 | 1844148 | . 세종 3.5 | 10.0 | 1.28 | 361396 | . df7.iloc[:-1, :].set_index(&#39;지역&#39;).plot.pie(y = &#39;출생아 수(천명)&#39;) . &lt;AxesSubplot:ylabel=&#39;출생아 수(천명)&#39;&gt; . (2) . df8 = pd.read_html(&#39;https://ko.wikipedia.org/wiki/%EB%8C%80%ED%95%9C%EB%AF%BC%EA%B5%AD%EC%9D%98_%EC%9D%B8%EA%B5%AC&#39;)[18] df8 . Unnamed: 0 2019 2018 2017 2016 2015 2014 2013 2012 2011 2010 2009 2008 2007 2006 2005 2004 2003 2002 2001 . 0 전국 | 0.918 | 0.977 | 1.052 | 1.172 | 1.239 | 1.205 | 1.187 | 1.297 | 1.244 | 1.226 | 1.149 | 1.192 | 1.259 | 1.132 | 1.085 | 1.164 | 1.191 | 1.178 | 1.309 | . 1 서울특별시 | 0.717 | 0.761 | 0.836 | 0.940 | 1.001 | 0.983 | 0.968 | 1.059 | 1.014 | 1.015 | 0.962 | 1.010 | 1.068 | 0.980 | 0.932 | 1.015 | 1.014 | 1.006 | 1.111 | . 2 부산광역시 | 0.827 | 0.899 | 0.976 | 1.095 | 1.139 | 1.090 | 1.049 | 1.135 | 1.078 | 1.045 | 0.940 | 0.980 | 1.024 | 0.915 | 0.887 | 0.953 | 0.988 | 0.975 | 1.103 | . 3 대구광역시 | 0.932 | 0.987 | 1.067 | 1.186 | 1.216 | 1.169 | 1.127 | 1.217 | 1.146 | 1.109 | 1.029 | 1.072 | 1.137 | 1.011 | 1.001 | 1.087 | 1.116 | 1.076 | 1.216 | . 4 인천광역시 | 0.940 | 1.006 | 1.007 | 1.144 | 1.216 | 1.212 | 1.195 | 1.301 | 1.232 | 1.214 | 1.143 | 1.186 | 1.257 | 1.116 | 1.075 | 1.158 | 1.213 | 1.185 | 1.324 | . 5 광주광역시 | 0.913 | 0.972 | 1.053 | 1.168 | 1.207 | 1.199 | 1.170 | 1.295 | 1.234 | 1.223 | 1.137 | 1.198 | 1.262 | 1.152 | 1.105 | 1.203 | 1.278 | 1.264 | 1.421 | . 6 대전광역시 | 0.883 | 0.952 | 1.075 | 1.192 | 1.277 | 1.250 | 1.234 | 1.315 | 1.261 | 1.205 | 1.156 | 1.215 | 1.274 | 1.158 | 1.107 | 1.181 | 1.221 | 1.207 | 1.330 | . 7 울산광역시 | 1.084 | 1.131 | 1.261 | 1.418 | 1.486 | 1.437 | 1.391 | 1.481 | 1.393 | 1.369 | 1.308 | 1.338 | 1.403 | 1.242 | 1.186 | 1.241 | 1.280 | 1.242 | 1.423 | . 8 세종특별자치시 | 1.472 | 1.566 | 1.668 | 1.821 | 1.893 | 1.354 | 1.435 | 1.597 | - | - | - | - | - | - | - | - | - | - | - | . 9 경기도 | 0.943 | 1.002 | 1.069 | 1.194 | 1.272 | 1.241 | 1.226 | 1.355 | 1.314 | 1.309 | 1.226 | 1.285 | 1.361 | 1.239 | 1.183 | 1.280 | 1.321 | 1.305 | 1.437 | . 10 강원도 | 1.082 | 1.067 | 1.123 | 1.237 | 1.311 | 1.248 | 1.249 | 1.374 | 1.338 | 1.313 | 1.248 | 1.253 | 1.356 | 1.202 | 1.188 | 1.261 | 1.279 | 1.317 | 1.413 | . 11 충청북도 | 1.050 | 1.172 | 1.235 | 1.358 | 1.414 | 1.363 | 1.365 | 1.485 | 1.428 | 1.402 | 1.317 | 1.319 | 1.398 | 1.233 | 1.195 | 1.272 | 1.270 | 1.294 | 1.426 | . 12 충청남도 | 1.112 | 1.186 | 1.276 | 1.395 | 1.480 | 1.421 | 1.442 | 1.571 | 1.496 | 1.479 | 1.408 | 1.444 | 1.506 | 1.356 | 1.267 | 1.357 | 1.358 | 1.361 | 1.532 | . 13 전라북도 | 0.971 | 1.044 | 1.151 | 1.251 | 1.352 | 1.329 | 1.320 | 1.440 | 1.405 | 1.374 | 1.279 | 1.305 | 1.380 | 1.213 | 1.184 | 1.239 | 1.274 | 1.275 | 1.426 | . 14 전라남도 | 1.234 | 1.240 | 1.325 | 1.466 | 1.549 | 1.497 | 1.518 | 1.642 | 1.568 | 1.537 | 1.445 | 1.449 | 1.542 | 1.337 | 1.290 | 1.360 | 1.389 | 1.391 | 1.566 | . 15 경상북도 | 1.089 | 1.167 | 1.256 | 1.396 | 1.464 | 1.408 | 1.379 | 1.489 | 1.434 | 1.377 | 1.274 | 1.313 | 1.369 | 1.208 | 1.173 | 1.203 | 1.253 | 1.232 | 1.402 | . 16 경상남도 | 1.046 | 1.122 | 1.227 | 1.358 | 1.437 | 1.409 | 1.367 | 1.503 | 1.446 | 1.413 | 1.323 | 1.368 | 1.434 | 1.254 | 1.189 | 1.266 | 1.290 | 1.272 | 1.417 | . 17 제주특별자치도 | 1.145 | 1.220 | 1.305 | 1.432 | 1.477 | 1.481 | 1.427 | 1.598 | 1.487 | 1.463 | 1.378 | 1.386 | 1.489 | 1.372 | 1.310 | 1.365 | 1.438 | 1.394 | 1.564 | . df9 = df8.rename(columns = {&#39;Unnamed: 0&#39;:&#39;지역&#39;}).iloc[1:, :]. sort_values(&#39;지역&#39;).set_index(&#39;지역&#39;). applymap(lambda x: float(x) if x != &#39;-&#39; else 0) df9 . 2019 2018 2017 2016 2015 2014 2013 2012 2011 2010 2009 2008 2007 2006 2005 2004 2003 2002 2001 . 지역 . 강원도 1.082 | 1.067 | 1.123 | 1.237 | 1.311 | 1.248 | 1.249 | 1.374 | 1.338 | 1.313 | 1.248 | 1.253 | 1.356 | 1.202 | 1.188 | 1.261 | 1.279 | 1.317 | 1.413 | . 경기도 0.943 | 1.002 | 1.069 | 1.194 | 1.272 | 1.241 | 1.226 | 1.355 | 1.314 | 1.309 | 1.226 | 1.285 | 1.361 | 1.239 | 1.183 | 1.280 | 1.321 | 1.305 | 1.437 | . 경상남도 1.046 | 1.122 | 1.227 | 1.358 | 1.437 | 1.409 | 1.367 | 1.503 | 1.446 | 1.413 | 1.323 | 1.368 | 1.434 | 1.254 | 1.189 | 1.266 | 1.290 | 1.272 | 1.417 | . 경상북도 1.089 | 1.167 | 1.256 | 1.396 | 1.464 | 1.408 | 1.379 | 1.489 | 1.434 | 1.377 | 1.274 | 1.313 | 1.369 | 1.208 | 1.173 | 1.203 | 1.253 | 1.232 | 1.402 | . 광주광역시 0.913 | 0.972 | 1.053 | 1.168 | 1.207 | 1.199 | 1.170 | 1.295 | 1.234 | 1.223 | 1.137 | 1.198 | 1.262 | 1.152 | 1.105 | 1.203 | 1.278 | 1.264 | 1.421 | . 대구광역시 0.932 | 0.987 | 1.067 | 1.186 | 1.216 | 1.169 | 1.127 | 1.217 | 1.146 | 1.109 | 1.029 | 1.072 | 1.137 | 1.011 | 1.001 | 1.087 | 1.116 | 1.076 | 1.216 | . 대전광역시 0.883 | 0.952 | 1.075 | 1.192 | 1.277 | 1.250 | 1.234 | 1.315 | 1.261 | 1.205 | 1.156 | 1.215 | 1.274 | 1.158 | 1.107 | 1.181 | 1.221 | 1.207 | 1.330 | . 부산광역시 0.827 | 0.899 | 0.976 | 1.095 | 1.139 | 1.090 | 1.049 | 1.135 | 1.078 | 1.045 | 0.940 | 0.980 | 1.024 | 0.915 | 0.887 | 0.953 | 0.988 | 0.975 | 1.103 | . 서울특별시 0.717 | 0.761 | 0.836 | 0.940 | 1.001 | 0.983 | 0.968 | 1.059 | 1.014 | 1.015 | 0.962 | 1.010 | 1.068 | 0.980 | 0.932 | 1.015 | 1.014 | 1.006 | 1.111 | . 세종특별자치시 1.472 | 1.566 | 1.668 | 1.821 | 1.893 | 1.354 | 1.435 | 1.597 | 0.000 | 0.000 | 0.000 | 0.000 | 0.000 | 0.000 | 0.000 | 0.000 | 0.000 | 0.000 | 0.000 | . 울산광역시 1.084 | 1.131 | 1.261 | 1.418 | 1.486 | 1.437 | 1.391 | 1.481 | 1.393 | 1.369 | 1.308 | 1.338 | 1.403 | 1.242 | 1.186 | 1.241 | 1.280 | 1.242 | 1.423 | . 인천광역시 0.940 | 1.006 | 1.007 | 1.144 | 1.216 | 1.212 | 1.195 | 1.301 | 1.232 | 1.214 | 1.143 | 1.186 | 1.257 | 1.116 | 1.075 | 1.158 | 1.213 | 1.185 | 1.324 | . 전라남도 1.234 | 1.240 | 1.325 | 1.466 | 1.549 | 1.497 | 1.518 | 1.642 | 1.568 | 1.537 | 1.445 | 1.449 | 1.542 | 1.337 | 1.290 | 1.360 | 1.389 | 1.391 | 1.566 | . 전라북도 0.971 | 1.044 | 1.151 | 1.251 | 1.352 | 1.329 | 1.320 | 1.440 | 1.405 | 1.374 | 1.279 | 1.305 | 1.380 | 1.213 | 1.184 | 1.239 | 1.274 | 1.275 | 1.426 | . 제주특별자치도 1.145 | 1.220 | 1.305 | 1.432 | 1.477 | 1.481 | 1.427 | 1.598 | 1.487 | 1.463 | 1.378 | 1.386 | 1.489 | 1.372 | 1.310 | 1.365 | 1.438 | 1.394 | 1.564 | . 충청남도 1.112 | 1.186 | 1.276 | 1.395 | 1.480 | 1.421 | 1.442 | 1.571 | 1.496 | 1.479 | 1.408 | 1.444 | 1.506 | 1.356 | 1.267 | 1.357 | 1.358 | 1.361 | 1.532 | . 충청북도 1.050 | 1.172 | 1.235 | 1.358 | 1.414 | 1.363 | 1.365 | 1.485 | 1.428 | 1.402 | 1.317 | 1.319 | 1.398 | 1.233 | 1.195 | 1.272 | 1.270 | 1.294 | 1.426 | . lst = df7.iloc[:-1, :].sort_values(&#39;지역&#39;).loc[:, [&#39;지역&#39;, &#39;합계출산율&#39;]]. rename(columns = {&#39;합계출산율&#39;:&#39;2020&#39;}).set_index(&#39;지역&#39;).index.tolist() lst . [&#39;강원도&#39;, &#39;경기도&#39;, &#39;경상남도&#39;, &#39;경상북도&#39;, &#39;광주&#39;, &#39;대구&#39;, &#39;대전&#39;, &#39;부산&#39;, &#39;서울&#39;, &#39;세종&#39;, &#39;울산&#39;, &#39;인천&#39;, &#39;전라남도&#39;, &#39;전라북도&#39;, &#39;제주도&#39;, &#39;충청남도&#39;, &#39;충청북도&#39;] . - matplotlib 사용(untidy data) . df7.iloc[:-1, :].sort_values(&#39;지역&#39;).loc[:, [&#39;지역&#39;, &#39;합계출산율&#39;]]. rename(columns = {&#39;합계출산율&#39;:&#39;2020&#39;}).set_index(&#39;지역&#39;). rename(index = dict(zip(lst, df9.index))).reset_index(). merge(df9.reset_index()).set_index(&#39;지역&#39;).T. plot.line(figsize = (10, 6)) . &lt;AxesSubplot:&gt; . - plotly 사용(tidy data) . # rename(columns = {&#39;합계출산율&#39;:&#39;2020&#39;}).set_index(&#39;지역&#39;). # rename(index = dict(zip(lst, df9.index))).reset_index(). # merge(df9.reset_index()).melt(id_vars = &#39;지역&#39;). # rename(columns = {&#39;variable&#39;:&#39;year&#39;, &#39;value&#39;:&#39;birth_rate&#39;}). # plot.line(x = &#39;year&#39;, y =&#39;birth_rate&#39;, color = &#39;지역&#39;, backend = &#39;plotly&#39;) .",
            "url": "https://jaesu26.github.io/study-blog/python/visualization/2021/12/05/%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%8B%9C%EA%B0%81%ED%99%94_%EA%B8%B0%EB%A7%90%EA%B3%A0%EC%82%AC.html",
            "relUrl": "/python/visualization/2021/12/05/%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%8B%9C%EA%B0%81%ED%99%94_%EA%B8%B0%EB%A7%90%EA%B3%A0%EC%82%AC.html",
            "date": " • Dec 5, 2021"
        }
        
    
  
    
        ,"post20": {
            "title": "데이터시각화 중간고사",
            "content": "- 시험문제 : https://guebin.github.io/2021STDV/2021/11/07/mid.html . - 문제에 대한 나의 풀이(틀릴 수 있음) . import pandas as pd import numpy as np from plotnine import * import matplotlib.pyplot as plt import seaborn as sns . 1 . - (a)-(c) . - (b)-(d) . 2 . x = [1, 2, 3, 4] y = [1, 2, 4, 3] . fig, axs = plt.subplots(2,2) . (ax1, ax2), (ax3, ax4) = axs . ax1.plot(x, y, &#39;o:r&#39;) ax2.plot(x, y, &#39;Xb&#39;) ax3.plot(x, y, &#39;xm&#39;) ax4.plot(x, y, &#39;.--k&#39;) . [&lt;matplotlib.lines.Line2D at 0x25605a16100&gt;] . fig . 3 . - 하니, 홍두깨, 고은애, 이창수 . 4 . - 하니, 홍두깨, 고은애 . 5 . df = pd.read_csv(&#39;https://raw.githubusercontent.com/guebin/2021DV/master/_notebooks/2021-10-25-FIFA22_official_data.csv&#39;) . df.head() . ID Name Age Photo Nationality Flag Overall Potential Club Club Logo ... SlidingTackle GKDiving GKHandling GKKicking GKPositioning GKReflexes Best Position Best Overall Rating Release Clause DefensiveAwareness . 0 212198 | Bruno Fernandes | 26 | https://cdn.sofifa.com/players/212/198/22_60.png | Portugal | https://cdn.sofifa.com/flags/pt.png | 88 | 89 | Manchester United | https://cdn.sofifa.com/teams/11/30.png | ... | 65.0 | 12.0 | 14.0 | 15.0 | 8.0 | 14.0 | CAM | 88.0 | €206.9M | 72.0 | . 1 209658 | L. Goretzka | 26 | https://cdn.sofifa.com/players/209/658/22_60.png | Germany | https://cdn.sofifa.com/flags/de.png | 87 | 88 | FC Bayern München | https://cdn.sofifa.com/teams/21/30.png | ... | 77.0 | 13.0 | 8.0 | 15.0 | 11.0 | 9.0 | CM | 87.0 | €160.4M | 74.0 | . 2 176580 | L. Suárez | 34 | https://cdn.sofifa.com/players/176/580/22_60.png | Uruguay | https://cdn.sofifa.com/flags/uy.png | 88 | 88 | Atlético de Madrid | https://cdn.sofifa.com/teams/240/30.png | ... | 38.0 | 27.0 | 25.0 | 31.0 | 33.0 | 37.0 | ST | 88.0 | €91.2M | 42.0 | . 3 192985 | K. De Bruyne | 30 | https://cdn.sofifa.com/players/192/985/22_60.png | Belgium | https://cdn.sofifa.com/flags/be.png | 91 | 91 | Manchester City | https://cdn.sofifa.com/teams/10/30.png | ... | 53.0 | 15.0 | 13.0 | 5.0 | 10.0 | 13.0 | CM | 91.0 | €232.2M | 68.0 | . 4 224334 | M. Acuña | 29 | https://cdn.sofifa.com/players/224/334/22_60.png | Argentina | https://cdn.sofifa.com/flags/ar.png | 84 | 84 | Sevilla FC | https://cdn.sofifa.com/teams/481/30.png | ... | 82.0 | 8.0 | 14.0 | 13.0 | 13.0 | 14.0 | LB | 84.0 | €77.7M | 80.0 | . 5 rows × 65 columns . (a) . df[&#39;Loaned From&#39;] . 0 NaN 1 NaN 2 NaN 3 NaN 4 NaN ... 16705 NaN 16706 NaN 16707 NaN 16708 NaN 16709 NaN Name: Loaned From, Length: 16710, dtype: object . df[&#39;Loaned From&#39;].isnull().sum() . 15578 . df[&#39;Marking&#39;] . 0 NaN 1 NaN 2 NaN 3 NaN 4 NaN ... 16705 5.0 16706 NaN 16707 NaN 16708 NaN 16709 15.0 Name: Marking, Length: 16710, dtype: float64 . df[&#39;Marking&#39;].isnull().sum() . 15818 . - 결측치가 많다 . (b) . df = df.drop([&#39;Loaned From&#39;, &#39;Marking&#39;], axis = 1) . df.isnull().sum().sum() . 5404 . (c) . df = df.dropna() . df.isnull().sum().sum() . 0 . - 5404개의 결측치가 제거되었다 . (d) . def convert_currency(value): floatvalue = 0.0 strvalue=&quot;&quot; if &quot;M&quot; in value: strvalue=value.replace(&quot;M&quot;,&quot;&quot;).replace(&quot;€&quot;,&quot;&quot;) floatvalue=float(float(strvalue)*1000000) elif &quot;K&quot; in value: strvalue=value.replace(&quot;K&quot;,&quot;&quot;).replace(&quot;€&quot;,&quot;&quot;) floatvalue=float(float(strvalue)*1000) else: floatvalue=value.replace(&quot;€&quot;,&quot;&quot;) return floatvalue . - 코드출처: https://www.kaggle.com/talhademirezen/cost-effective-youth-players-fifa22 . df[&#39;Wage&#39;] = list(map(convert_currency, df[&#39;Wage&#39;])) . df[&#39;Wage&#39;] . 0 250000.0 1 140000.0 2 135000.0 3 350000.0 4 45000.0 ... 16703 650 16704 950 16706 550 16707 700 16708 500 Name: Wage, Length: 14398, dtype: object . (e) . df[&#39;Value&#39;] = list(map(convert_currency, df[&#39;Value&#39;])) . df2 = df.groupby(by = &#39;Best Position&#39;).agg({&#39;Value&#39;:np.mean}) . - 신기한점 : 컴퓨터마다(?) &#39;Value&#39;가 object 타입인지 float 타입인지가 다른것같다 . - 나의 경우는 자료형을 변환하지 않아도 위와 같이 잘되는데 안되는 경우도 있나봄 . df2 . Value . Best Position . CAM 4.356162e+06 | . CB 3.038834e+06 | . CDM 3.539740e+06 | . CF 9.122222e+06 | . CM 5.630414e+06 | . GK 2.703686e+06 | . LB 3.051887e+06 | . LM 3.439977e+06 | . LW 6.443137e+06 | . LWB 3.451340e+06 | . RB 3.203283e+06 | . RM 2.550153e+06 | . RW 3.977832e+06 | . RWB 3.023522e+06 | . ST 3.295080e+06 | . df2 = df2.stack().reset_index() . df2 = df2.rename(columns={&#39;level_1&#39;:&#39;group1&#39;, 0:&#39;mean(Value)&#39;}) . df2 . Best Position group1 mean(Value) . 0 CAM | Value | 4.356162e+06 | . 1 CB | Value | 3.038834e+06 | . 2 CDM | Value | 3.539740e+06 | . 3 CF | Value | 9.122222e+06 | . 4 CM | Value | 5.630414e+06 | . 5 GK | Value | 2.703686e+06 | . 6 LB | Value | 3.051887e+06 | . 7 LM | Value | 3.439977e+06 | . 8 LW | Value | 6.443137e+06 | . 9 LWB | Value | 3.451340e+06 | . 10 RB | Value | 3.203283e+06 | . 11 RM | Value | 2.550153e+06 | . 12 RW | Value | 3.977832e+06 | . 13 RWB | Value | 3.023522e+06 | . 14 ST | Value | 3.295080e+06 | . df2 = df2.sort_values(by = [&#39;mean(Value)&#39;], axis = 0, ascending = False) . df2 = df2.reset_index(drop = True) . df2 . Best Position group1 mean(Value) . 0 CF | Value | 9.122222e+06 | . 1 LW | Value | 6.443137e+06 | . 2 CM | Value | 5.630414e+06 | . 3 CAM | Value | 4.356162e+06 | . 4 RW | Value | 3.977832e+06 | . 5 CDM | Value | 3.539740e+06 | . 6 LWB | Value | 3.451340e+06 | . 7 LM | Value | 3.439977e+06 | . 8 ST | Value | 3.295080e+06 | . 9 RB | Value | 3.203283e+06 | . 10 LB | Value | 3.051887e+06 | . 11 CB | Value | 3.038834e+06 | . 12 RWB | Value | 3.023522e+06 | . 13 GK | Value | 2.703686e+06 | . 14 RM | Value | 2.550153e+06 | . cnt = 0 . def z(x): global cnt cnt += 1 if cnt &lt;= 3: return &#39;True&#39; else: return &#39;False&#39; . df2[&#39;Highlight&#39;] = list(map(z, df2[&#39;mean(Value)&#39;])) . df2 . Best Position group1 mean(Value) Highlight . 0 CF | Value | 9.122222e+06 | True | . 1 LW | Value | 6.443137e+06 | True | . 2 CM | Value | 5.630414e+06 | True | . 3 CAM | Value | 4.356162e+06 | False | . 4 RW | Value | 3.977832e+06 | False | . 5 CDM | Value | 3.539740e+06 | False | . 6 LWB | Value | 3.451340e+06 | False | . 7 LM | Value | 3.439977e+06 | False | . 8 ST | Value | 3.295080e+06 | False | . 9 RB | Value | 3.203283e+06 | False | . 10 LB | Value | 3.051887e+06 | False | . 11 CB | Value | 3.038834e+06 | False | . 12 RWB | Value | 3.023522e+06 | False | . 13 GK | Value | 2.703686e+06 | False | . 14 RM | Value | 2.550153e+06 | False | . ggplot(df2) + geom_bar(aes(x = &#39;Best Position&#39;, y = &#39;mean(Value)&#39;, fill = &#39;Highlight&#39;), stat = &#39;identity&#39;) . &lt;ggplot: (160530408406)&gt; . (f) . - 문제는 alpha = 0.5로 하라고 했는데 시각화 예시는 alpha = 0.2임... . ggplot(df) + geom_point(aes(x = &#39;Dribbling&#39;, y = &#39;SlidingTackle&#39;, color = &#39;Age&#39;), alpha = 0.5, size = 0.5) + facet_wrap(&#39;Best Position&#39;) . &lt;ggplot: (160533279925)&gt; . (g) . - 하니, 홍두깨, 고은애 . (h) . df3 = df.loc[lambda df:(df[&#39;Best Position&#39;] ==&#39;CAM&#39;) | (df[&#39;Best Position&#39;] ==&#39;CB&#39;)] . - 이유는 모르겠는데 query로는 안되서 위와 같이 했음 . - 문제에는 CB가 아니라 CM인데 plot은 CB로 되어있어서 CB로 했음 + (i)문제에서도 CB라고 언급함 . ggplot(df3) + geom_point(aes(x = &#39;Dribbling&#39;, y = &#39;SlidingTackle&#39;, color = &#39;Age&#39;, size = &#39;Value&#39;), alpha = 0.2 ) + facet_wrap(&#39;Best Position&#39;) . &lt;ggplot: (160531860947)&gt; . (i) . - 홍두깨 . 6 . x = [0, 1, 4, 5] y = [0, 2, 3, 5] x2 = [5, 4.1, 1, 0] y2 = [5, 3, 0.5, 0] . df_ = pd.DataFrame({&#39;x&#39;:x ,&#39;y&#39;:y}) . df_[&#39;course&#39;] = &#39;A&#39; . df_ . x y course . 0 0 | 0 | A | . 1 1 | 2 | A | . 2 4 | 3 | A | . 3 5 | 5 | A | . df2_ = pd.DataFrame({&#39;x&#39;:x2 ,&#39;y&#39;:y2}) . df2_[&#39;course&#39;] = &#39;B&#39; . df2_ . x y course . 0 5.0 | 5.0 | B | . 1 4.1 | 3.0 | B | . 2 1.0 | 0.5 | B | . 3 0.0 | 0.0 | B | . stamina = 100 ## 집에서 출발시 체력 x_ = 0 y_ = 0 def f(x,y): global x_ global y_ global stamina stamina = stamina - (((x-x_)**2 + (y-y_)**2)**0.5) ## 두 점 사이의 거리 x_ = x y_ = y return stamina . df_[&#39;stamina&#39;] = list(map(f, df_[&#39;x&#39;], df_[&#39;y&#39;])) . df_ . x y course stamina . 0 0 | 0 | A | 100.000000 | . 1 1 | 2 | A | 97.763932 | . 2 4 | 3 | A | 94.601654 | . 3 5 | 5 | A | 92.365586 | . stamina -= 70 ## A지점 도착지점에서 B지점 출발지점까지 가는데 70이 소모됨 . df2_[&#39;stamina&#39;] = list(map(f, df2_[&#39;x&#39;], df2_[&#39;y&#39;])) . df2_ . x y course stamina . 0 5.0 | 5.0 | B | 22.365586 | . 1 4.1 | 3.0 | B | 20.172415 | . 2 1.0 | 0.5 | B | 16.189954 | . 3 0.0 | 0.0 | B | 15.071920 | . df3_ = pd.concat([df_, df2_]) ## 두 데이터프레임 합치기 . df3_ . x y course stamina . 0 0.0 | 0.0 | A | 100.000000 | . 1 1.0 | 2.0 | A | 97.763932 | . 2 4.0 | 3.0 | A | 94.601654 | . 3 5.0 | 5.0 | A | 92.365586 | . 0 5.0 | 5.0 | B | 22.365586 | . 1 4.1 | 3.0 | B | 20.172415 | . 2 1.0 | 0.5 | B | 16.189954 | . 3 0.0 | 0.0 | B | 15.071920 | . ggplot(df3_) + geom_point(aes(x = &#39;x&#39;, y = &#39;y&#39;)) + geom_line(aes(x = &#39;x&#39;, y = &#39;y&#39;, size = &#39;stamina&#39;, color = &#39;course&#39;), alpha = 0.5) . &lt;ggplot: (160530609351)&gt; . 7 . - 문제 풀고나니 느낀건데 국어를 너무 못함 &gt; 문제를 제대로 파악을 못함 . p = [&#39;A&#39;] * 2 + [&#39;B&#39;] * 2 s1 = [10, 20, 30, 4] s2 = [7, 19, 23, 4] s3 = [&#39;one&#39;, &#39;two&#39;] * 2 . data = pd.DataFrame({&#39;person&#39;:p, &#39;count&#39;:s1, &#39;goal&#39;:s2, &#39;season&#39;:s3}) . data . person count goal season . 0 A | 10 | 7 | one | . 1 A | 20 | 19 | two | . 2 B | 30 | 23 | one | . 3 B | 4 | 4 | two | . data[&#39;prob&#39;] = data[&#39;goal&#39;] / data[&#39;count&#39;] . data . person count goal season prob . 0 A | 10 | 7 | one | 0.700000 | . 1 A | 20 | 19 | two | 0.950000 | . 2 B | 30 | 23 | one | 0.766667 | . 3 B | 4 | 4 | two | 1.000000 | . data2 = data.groupby([&#39;person&#39;]).agg({&#39;count&#39;:np.sum, &#39;goal&#39;:np.sum}).reset_index().rename(columns = {&#39;count&#39;:&#39;sum&#39;, &#39;goal&#39;:&#39;goal_sum&#39;}) . data2 . person sum goal_sum . 0 A | 30 | 26 | . 1 B | 34 | 27 | . td = pd.merge(data, data2) . td . person count goal season prob sum goal_sum . 0 A | 10 | 7 | one | 0.700000 | 30 | 26 | . 1 A | 20 | 19 | two | 0.950000 | 30 | 26 | . 2 B | 30 | 23 | one | 0.766667 | 34 | 27 | . 3 B | 4 | 4 | two | 1.000000 | 34 | 27 | . td[&#39;prob2&#39;] = (td[&#39;goal_sum&#39;] / td[&#39;sum&#39;]) / 2 ## 시즌이 2개라 값이 2번 들어가서 2로 나눠줌 . td . person count goal season prob sum goal_sum prob2 . 0 A | 10 | 7 | one | 0.700000 | 30 | 26 | 0.433333 | . 1 A | 20 | 19 | two | 0.950000 | 30 | 26 | 0.433333 | . 2 B | 30 | 23 | one | 0.766667 | 34 | 27 | 0.397059 | . 3 B | 4 | 4 | two | 1.000000 | 34 | 27 | 0.397059 | . ggplot(data) + geom_bar(aes(x = &#39;person&#39;, y = &#39;prob&#39;, fill = &#39;person&#39;), stat = &#39;identity&#39;) + facet_wrap(&#39;season&#39;) . &lt;ggplot: (160530787118)&gt; . - 시즌별 성공확률은 B가 더 높다 . - 하지만 전체 성공확률을 보면? . ggplot(td) + geom_bar(aes(x = &#39;person&#39;, y = &#39;prob2&#39;, fill = &#39;person&#39;), stat = &#39;identity&#39;) . &lt;ggplot: (160532310432)&gt; . - A가 더 높은것을 확인할수있다 . - B가 100%확률을 기록했을 때 전체횟수가 모종의 이유(부상 치료 등)로 인해 4회밖에 되지않아 전체에 끼치는 영향력이 작아져 위와같은 결과가 발생했다 .",
            "url": "https://jaesu26.github.io/study-blog/python/visualization/2021/11/08/%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%8B%9C%EA%B0%81%ED%99%94%EC%A4%91%EA%B0%84%EC%8B%9C%ED%97%98.html",
            "relUrl": "/python/visualization/2021/11/08/%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%8B%9C%EA%B0%81%ED%99%94%EC%A4%91%EA%B0%84%EC%8B%9C%ED%97%98.html",
            "date": " • Nov 8, 2021"
        }
        
    
  
    
        ,"post21": {
            "title": "데이터시각화 중간고사 연습문제",
            "content": "- 시험문제 : https://guebin.github.io/2021DV/2021/11/05/(A2)-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%8B%9C%EA%B0%81%ED%99%94-%EC%A4%91%EA%B0%84%EA%B3%A0%EC%82%AC-%EB%8C%80%EB%B9%84%EB%AC%B8%EC%A0%9C.html . import pandas as pd import numpy as np from plotnine import * import matplotlib.pyplot as plt import seaborn as sns . - 흠 20분 걸렸는데... 조금 느리다 . Type I. &#54532;&#47196;&#44536;&#47016; &#44396;&#54788;&#45733;&#47141; &#54217;&#44032; . np.random.seed(202016248) . x1 = np.random.normal(0, 1, 10000) x2 = np.random.normal(1, 1, 10000) . sns.histplot([x1, x2]) . &lt;AxesSubplot:ylabel=&#39;Count&#39;&gt; . x = [1, 2, 3, 4] y = [1, 2, 4, 3] . fig, axs = plt.subplots(2,2) . (ax1, ax2), (ax3, ax4) = axs . ax1.plot(x, y, &#39;o:r&#39;) ax2.plot(x, y, &#39;Xb&#39;) ax3.plot(x, y, &#39;xm&#39;) ax4.plot(x, y, &#39;.--k&#39;) . [&lt;matplotlib.lines.Line2D at 0x1f9133fc730&gt;] . fig . Type II. &#44060;&#45392;&#51032; &#51060;&#54644; &#54217;&#44032; . (1) 하니, 홍두깨 . (2) 하니, 나애리 . Type III. &#51088;&#47308;&#48516;&#49437; &#48143; &#49884;&#44033;&#54868; &#45733;&#47141; &#51333;&#54633;&#54217;&#44032; . df = pd.read_csv(&#39;https://raw.githubusercontent.com/PacktPublishing/Pandas-Cookbook/master/data/employee.csv&#39;) df . UNIQUE_ID POSITION_TITLE DEPARTMENT BASE_SALARY RACE EMPLOYMENT_TYPE GENDER EMPLOYMENT_STATUS HIRE_DATE JOB_DATE . 0 0 | ASSISTANT DIRECTOR (EX LVL) | Municipal Courts Department | 121862.0 | Hispanic/Latino | Full Time | Female | Active | 2006-06-12 | 2012-10-13 | . 1 1 | LIBRARY ASSISTANT | Library | 26125.0 | Hispanic/Latino | Full Time | Female | Active | 2000-07-19 | 2010-09-18 | . 2 2 | POLICE OFFICER | Houston Police Department-HPD | 45279.0 | White | Full Time | Male | Active | 2015-02-03 | 2015-02-03 | . 3 3 | ENGINEER/OPERATOR | Houston Fire Department (HFD) | 63166.0 | White | Full Time | Male | Active | 1982-02-08 | 1991-05-25 | . 4 4 | ELECTRICIAN | General Services Department | 56347.0 | White | Full Time | Male | Active | 1989-06-19 | 1994-10-22 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 1995 1995 | POLICE OFFICER | Houston Police Department-HPD | 43443.0 | White | Full Time | Male | Active | 2014-06-09 | 2015-06-09 | . 1996 1996 | COMMUNICATIONS CAPTAIN | Houston Fire Department (HFD) | 66523.0 | Black or African American | Full Time | Male | Active | 2003-09-02 | 2013-10-06 | . 1997 1997 | POLICE OFFICER | Houston Police Department-HPD | 43443.0 | White | Full Time | Male | Active | 2014-10-13 | 2015-10-13 | . 1998 1998 | POLICE OFFICER | Houston Police Department-HPD | 55461.0 | Asian/Pacific Islander | Full Time | Male | Active | 2009-01-20 | 2011-07-02 | . 1999 1999 | FIRE FIGHTER | Houston Fire Department (HFD) | 51194.0 | Hispanic/Latino | Full Time | Male | Active | 2009-01-12 | 2010-07-12 | . 2000 rows × 10 columns . (a) . df.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 2000 entries, 0 to 1999 Data columns (total 10 columns): # Column Non-Null Count Dtype -- -- 0 UNIQUE_ID 2000 non-null int64 1 POSITION_TITLE 2000 non-null object 2 DEPARTMENT 2000 non-null object 3 BASE_SALARY 1886 non-null float64 4 RACE 1965 non-null object 5 EMPLOYMENT_TYPE 2000 non-null object 6 GENDER 2000 non-null object 7 EMPLOYMENT_STATUS 2000 non-null object 8 HIRE_DATE 2000 non-null object 9 JOB_DATE 1997 non-null object dtypes: float64(1), int64(1), object(8) memory usage: 156.4+ KB . df.isnull().sum() . UNIQUE_ID 0 POSITION_TITLE 0 DEPARTMENT 0 BASE_SALARY 114 RACE 35 EMPLOYMENT_TYPE 0 GENDER 0 EMPLOYMENT_STATUS 0 HIRE_DATE 0 JOB_DATE 3 dtype: int64 . df.isnull().sum().sum() . 152 . df = df.dropna() . df.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; Int64Index: 1853 entries, 0 to 1999 Data columns (total 10 columns): # Column Non-Null Count Dtype -- -- 0 UNIQUE_ID 1853 non-null int64 1 POSITION_TITLE 1853 non-null object 2 DEPARTMENT 1853 non-null object 3 BASE_SALARY 1853 non-null float64 4 RACE 1853 non-null object 5 EMPLOYMENT_TYPE 1853 non-null object 6 GENDER 1853 non-null object 7 EMPLOYMENT_STATUS 1853 non-null object 8 HIRE_DATE 1853 non-null object 9 JOB_DATE 1853 non-null object dtypes: float64(1), int64(1), object(8) memory usage: 159.2+ KB . df.isnull().sum() . UNIQUE_ID 0 POSITION_TITLE 0 DEPARTMENT 0 BASE_SALARY 0 RACE 0 EMPLOYMENT_TYPE 0 GENDER 0 EMPLOYMENT_STATUS 0 HIRE_DATE 0 JOB_DATE 0 dtype: int64 . df.isnull().sum().sum() . 0 . (b) . df_ = df.groupby(by = &#39;GENDER&#39;).agg({&#39;BASE_SALARY&#39;:np.mean}) df_ . BASE_SALARY . GENDER . Female 52474.665487 | . Male 57670.031832 | . df_ = df_.stack().reset_index() df_ . GENDER level_1 0 . 0 Female | BASE_SALARY | 52474.665487 | . 1 Male | BASE_SALARY | 57670.031832 | . (df_.query(&#39;GENDER == &quot;Female&quot;&#39;))[0].to_list() &gt; (df_.query(&#39;GENDER == &quot;Male&quot;&#39;))[0].to_list() . False . - 남자 급여평균이 더 크다 . (c) . df2 = df.groupby(by = [&#39;RACE&#39;,&#39;GENDER&#39;]).agg({&#39;BASE_SALARY&#39;:[np.mean, min, max]}) . df2 . BASE_SALARY . mean min max . RACE GENDER . American Indian or Alaskan Native Female 60238.800000 | 26125.0 | 98536.0 | . Male 60305.400000 | 26125.0 | 81239.0 | . Asian/Pacific Islander Female 63226.300000 | 26125.0 | 130416.0 | . Male 61033.906667 | 27914.0 | 163228.0 | . Black or African American Female 48965.790378 | 24960.0 | 150416.0 | . Male 51118.867374 | 26125.0 | 275000.0 | . Hispanic/Latino Female 46503.316176 | 26125.0 | 126115.0 | . Male 54767.541538 | 26104.0 | 165216.0 | . Others Female 63785.000000 | 63785.0 | 63785.0 | . Male 38771.000000 | 38771.0 | 38771.0 | . White Female 66793.352941 | 27955.0 | 178331.0 | . Male 63940.388119 | 26125.0 | 210588.0 | . - tidydata로 만들자! . df2.stack() . BASE_SALARY . RACE GENDER . American Indian or Alaskan Native Female mean 60238.800000 | . min 26125.000000 | . max 98536.000000 | . Male mean 60305.400000 | . min 26125.000000 | . max 81239.000000 | . Asian/Pacific Islander Female mean 63226.300000 | . min 26125.000000 | . max 130416.000000 | . Male mean 61033.906667 | . min 27914.000000 | . max 163228.000000 | . Black or African American Female mean 48965.790378 | . min 24960.000000 | . max 150416.000000 | . Male mean 51118.867374 | . min 26125.000000 | . max 275000.000000 | . Hispanic/Latino Female mean 46503.316176 | . min 26125.000000 | . max 126115.000000 | . Male mean 54767.541538 | . min 26104.000000 | . max 165216.000000 | . Others Female mean 63785.000000 | . min 63785.000000 | . max 63785.000000 | . Male mean 38771.000000 | . min 38771.000000 | . max 38771.000000 | . White Female mean 66793.352941 | . min 27955.000000 | . max 178331.000000 | . Male mean 63940.388119 | . min 26125.000000 | . max 210588.000000 | . df3 = df2.stack().reset_index().rename(columns={&#39;level_2&#39;:&#39;aggtype&#39;}) . df3 . RACE GENDER aggtype BASE_SALARY . 0 American Indian or Alaskan Native | Female | mean | 60238.800000 | . 1 American Indian or Alaskan Native | Female | min | 26125.000000 | . 2 American Indian or Alaskan Native | Female | max | 98536.000000 | . 3 American Indian or Alaskan Native | Male | mean | 60305.400000 | . 4 American Indian or Alaskan Native | Male | min | 26125.000000 | . 5 American Indian or Alaskan Native | Male | max | 81239.000000 | . 6 Asian/Pacific Islander | Female | mean | 63226.300000 | . 7 Asian/Pacific Islander | Female | min | 26125.000000 | . 8 Asian/Pacific Islander | Female | max | 130416.000000 | . 9 Asian/Pacific Islander | Male | mean | 61033.906667 | . 10 Asian/Pacific Islander | Male | min | 27914.000000 | . 11 Asian/Pacific Islander | Male | max | 163228.000000 | . 12 Black or African American | Female | mean | 48965.790378 | . 13 Black or African American | Female | min | 24960.000000 | . 14 Black or African American | Female | max | 150416.000000 | . 15 Black or African American | Male | mean | 51118.867374 | . 16 Black or African American | Male | min | 26125.000000 | . 17 Black or African American | Male | max | 275000.000000 | . 18 Hispanic/Latino | Female | mean | 46503.316176 | . 19 Hispanic/Latino | Female | min | 26125.000000 | . 20 Hispanic/Latino | Female | max | 126115.000000 | . 21 Hispanic/Latino | Male | mean | 54767.541538 | . 22 Hispanic/Latino | Male | min | 26104.000000 | . 23 Hispanic/Latino | Male | max | 165216.000000 | . 24 Others | Female | mean | 63785.000000 | . 25 Others | Female | min | 63785.000000 | . 26 Others | Female | max | 63785.000000 | . 27 Others | Male | mean | 38771.000000 | . 28 Others | Male | min | 38771.000000 | . 29 Others | Male | max | 38771.000000 | . 30 White | Female | mean | 66793.352941 | . 31 White | Female | min | 27955.000000 | . 32 White | Female | max | 178331.000000 | . 33 White | Male | mean | 63940.388119 | . 34 White | Male | min | 26125.000000 | . 35 White | Male | max | 210588.000000 | . ggplot(data = df3) + geom_bar(aes(x = &#39;aggtype&#39;, y = &#39;BASE_SALARY&#39;, fill = &#39;GENDER&#39;), stat = &#39;identity&#39;, position = &#39;dodge&#39;) + coord_flip() + facet_wrap(facets = &#39;RACE&#39;) . &lt;ggplot: (135580437071)&gt; .",
            "url": "https://jaesu26.github.io/study-blog/python/visualization/2021/11/05/%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%8B%9C%EA%B0%81%ED%99%94_%EC%A4%91%EA%B0%84%EA%B3%A0%EC%82%AC%EC%97%B0%EC%8A%B5%EB%AC%B8%EC%A0%9C.html",
            "relUrl": "/python/visualization/2021/11/05/%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%8B%9C%EA%B0%81%ED%99%94_%EC%A4%91%EA%B0%84%EA%B3%A0%EC%82%AC%EC%97%B0%EC%8A%B5%EB%AC%B8%EC%A0%9C.html",
            "date": " • Nov 5, 2021"
        }
        
    
  
    
        ,"post22": {
            "title": "R입문 중간고사",
            "content": "- 시험문제 : https://guebin.github.io/2021IR/2024/01/01/R%EC%9E%85%EB%AC%B8%EC%A4%91%EA%B0%84%EA%B3%A0%EC%82%AC.html . - 파이썬 연습겸 R입문 중간고사 문제 파이썬으로 풀어봄 . 1&#48264; &#47928;&#51228; . (a) . 2**-5 + 2**3 . 8.03125 . (b) . 33**0.5 . 5.744562646538029 . (c) . sum_ = 0 for k in range(1, 101): sum_ += 1 / ((k+1) ** 2) print(sum_) . 0.6350819297898338 . - 리스트 컴프리핸션 . sum([1/((k+1)**2) for k in range(1, 101)]) . 0.6350819297898338 . 2&#48264; &#47928;&#51228; . (a) . import numpy as np x = np.arange(-10, 10.5, 0.5) print(x) . [-10. -9.5 -9. -8.5 -8. -7.5 -7. -6.5 -6. -5.5 -5. -4.5 -4. -3.5 -3. -2.5 -2. -1.5 -1. -0.5 0. 0.5 1. 1.5 2. 2.5 3. 3.5 4. 4.5 5. 5.5 6. 6.5 7. 7.5 8. 8.5 9. 9.5 10. ] . (b) . def f(x): if abs(x) &gt; 5: return x elif abs(x) &lt; 2: return 0 else: return 5 y = list(map(f, x)) print(y) . [-10.0, -9.5, -9.0, -8.5, -8.0, -7.5, -7.0, -6.5, -6.0, -5.5, 5, 5, 5, 5, 5, 5, 5, 0, 0, 0, 0, 0, 0, 0, 5, 5, 5, 5, 5, 5, 5, 5.5, 6.0, 6.5, 7.0, 7.5, 8.0, 8.5, 9.0, 9.5, 10.0] . 3&#48264; &#47928;&#51228; . from math import exp def f(x): return 2*x + 3 def g(x): return exp(x) / (1 + exp(x)) def h(x): return max(x, 0) x1 = list(map(f, x)) x2 = list(map(g, x1)) x3 = list(map(h, x2)) print(x3) . [4.1399375473943306e-08, 1.12535162055095e-07, 3.059022269256247e-07, 8.315280276641321e-07, 2.2603242979035742e-06, 6.144174602214718e-06, 1.670142184809518e-05, 4.5397868702434395e-05, 0.00012339457598623172, 0.00033535013046647816, 0.0009110511944006454, 0.0024726231566347748, 0.006692850924284856, 0.017986209962091555, 0.04742587317756679, 0.11920292202211755, 0.2689414213699951, 0.5, 0.7310585786300049, 0.8807970779778824, 0.9525741268224333, 0.9820137900379085, 0.9933071490757152, 0.9975273768433652, 0.9990889488055994, 0.9996646498695335, 0.9998766054240138, 0.9999546021312976, 0.9999832985781519, 0.9999938558253978, 0.999997739675702, 0.9999991684719723, 0.9999996940977731, 0.9999998874648379, 0.9999999586006245, 0.9999999847700205, 0.9999999943972036, 0.9999999979388464, 0.999999999241744, 0.9999999997210532, 0.9999999998973812] . 4&#48264; &#47928;&#51228; . (a) . import matplotlib.pyplot as plt n = 10 l = [0]*n for i in range(1, n+1): l[i-1] = 1/(2**i) l_ = np.cumsum(l) plt.plot(list(range(n)), l_) . [&lt;matplotlib.lines.Line2D at 0x15879d61f70&gt;] . sum = 0 n = 10 x = 5 ## 예시 for i in range(n): sum += x**i print(exp(x),&quot; n&quot;, sum) . 148.4131591025766 2441406 . - 모든 x에 대해 성립해야 되는데 아니다 . 5&#48264; &#47928;&#51228; . x = a = 10 #예시 salary = a for i in range(1, 19): a *= 1.08 salary += a for j in range(20, 29): a *= 0.75 salary += a print(salary / x) . 52.53420212516463 . 6&#48264; &#47928;&#51228; . - (a) : 참 . - (b) : 거짓 . - (c) : 거짓 . - (d) : 거짓 . 7&#48264; &#47928;&#51228; . n = 100 doors = [False] * (n+1) for i in range(1, n+1): for j in range(i, n+1): if j % i == 0: if doors[j] == True: doors[j] = False else: doors[j] = True sum_ = 0 for k in range(1, n+1): if doors[k] == True: sum_ += 1 print(sum_) . 10 . 8&#48264; &#47928;&#51228; . dist = 35 dp = [0] * 456 dp2 = [0] * 456 x = np.array(range(1, 457)) / 100 for i in np.arange(10, 0, -0.5): for j in range(456): if dp2[j] == 0: dp[j] = round(dp[j] + round(x[j], 3), 3) if x[j] &gt; i and dp2[j] == 0: ## 0은 False이다 if dp[j] - round((x[j] - i), 3) &lt; dist: dp2[j] = -1 elif dp[j] - round((x[j] - i), 3) &gt;= dist: dp2[j] = 1 elif x[j] &lt;= i and dp[j] &gt;= dist and dp2[j] == 0: dp2[j] = 1 x += 1 . (a) . dp2[0] # 사망 . -1 . dp2[66] # 사망 . -1 . dp2[217] # 생존 . 1 . dp2[455] # 사망 . -1 . (b) . sum_ = 0 for k in range(456): if dp2[k] == 1: sum_ += 1 print(sum_) . 85 . - 전체 생존자는 85명 . - 고찰 . - 이것때문에 정신나감 . - 그리고 처음 dp 설정할 때 전부 0으로 해야됐는데 -1로 해서 또 정신나감 . a = np.array([0, 0]) b = [0] * 2 a[0] += 0.01 print(a[0]) . 0 . - 왜 0인지 이해가 안됨 . - 왜 0.01이 아니냐? . b[0] += 0.01 print(b[0]) . 0.01 . - ㅋㅋㅋㅋㅋㅋㅋㅋㅋ . - 넘파이 어레이는 0인데 그냥 리스트는 0.01이다 . - 이유는 모른다 . 9&#48264; &#47928;&#51228; . import pandas as pd df = pd.read_csv(&quot;https://raw.githubusercontent.com/miruetoto/yechan/master/_notebooks/round2.csv&quot;) mat = np.matrix(df) . mat.shape . (5513, 2) . (a) . plt.plot(mat[:,0], mat[:,1], &#39;.k&#39;) . [&lt;matplotlib.lines.Line2D at 0x200885d74c0&gt;] . (b) . mat[0,:] . matrix([[ 12, 313]], dtype=int64) . (c) . np.matrix([[0,-1], [-1,0]]) @ np.matrix([12,313]).T . matrix([[-313], [ -12]]) . (d) . mat2 = mat for i in range(5513): mat2[i,:] = (np.matrix([[0,-1], [-1,0]]) @ mat[i,:].T).T . (e) . plt.plot(mat2[:,0], mat2[:,1], &#39;.r&#39;) . [&lt;matplotlib.lines.Line2D at 0x200886dc190&gt;] . - 위에서 mat2 = mat이라고 했는데 그러면 안됨 . id(mat2), id(mat) . (2203309972272, 2203309972272) . - 메모리 주소가 동일해서 mat2를 바꾸면 mat도 바뀌어서 아래와 같이 된다 . plt.plot(mat[:,0], mat[:,1], &#39;.r&#39;) . [&lt;matplotlib.lines.Line2D at 0x20088745760&gt;] . - 그럼 어떻게? &gt; 깊은복사! . - mat 다시 초기화 . mat = np.matrix(df) . plt.plot(mat[:,0], mat[:,1], &#39;.k&#39;) . [&lt;matplotlib.lines.Line2D at 0x200887ad7c0&gt;] . mat3 = mat.copy() . for i in range(5513): mat3[i,:] = (np.matrix([[0,-1], [-1,0]]) @ mat[i,:].T).T . plt.plot(mat3[:,0], mat2[:,1], &#39;.r&#39;) . [&lt;matplotlib.lines.Line2D at 0x20088815970&gt;] . id(mat), id(mat3) . (2201311857904, 2201313255712) . - 메모리 주소가 다르다 . plt.plot(mat[:,0], mat[:,1], &#39;.k&#39;) . [&lt;matplotlib.lines.Line2D at 0x20088877850&gt;] . - mat3를 바꿨지만 깊은복사를 하였기에 mat에는 영향을 끼치지 않음 .",
            "url": "https://jaesu26.github.io/study-blog/python/2021/11/04/R%EC%9E%85%EB%AC%B8_%EC%A4%91%EA%B0%84%EA%B3%A0%EC%82%AC.html",
            "relUrl": "/python/2021/11/04/R%EC%9E%85%EB%AC%B8_%EC%A4%91%EA%B0%84%EA%B3%A0%EC%82%AC.html",
            "date": " • Nov 4, 2021"
        }
        
    
  
    
        ,"post23": {
            "title": "혈압-혈당 데이터 분석",
            "content": "&#54056;&#53412;&#51648; import &#48143; &#45936;&#51060;&#53552; &#51204;&#52376;&#47532; . - 데이터 출처 : https://nhiss.nhis.or.kr/bd/ab/bdabf003cv.do . - 한글 깨짐 참고 : https://mirae-kim.tistory.com/14 . import pandas as pd import numpy as np import matplotlib.pyplot as plt import matplotlib import seaborn as sns import scipy.stats as stats from scipy.stats import norm import statsmodels.formula.api as smf fig_dims = (10, 6) sns.set(rc = {&#39;figure.figsize&#39;:fig_dims}) # plot 사이즈 및 스타일 통일 sns.set_theme() # 테마 설정 matplotlib.rcParams[&#39;font.family&#39;] = &#39;Malgun Gothic&#39; # 한글이 깨지지 않도록 설정 matplotlib.rcParams[&#39;axes.unicode_minus&#39;] = False # 한글이 깨지지 않도록 설정 . df = pd.read_csv(&#39;https://raw.githubusercontent.com/gkswotn9999/data/main/blood_data.csv&#39;, header = 0) ## 2013~2014년에 실시된 백만개의 국가건강검진_혈압혈당데이터 . df.shape ## matrix는 1000000 × 7 크기 . (1000000, 7) . df.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 1000000 entries, 0 to 999999 Data columns (total 7 columns): # Column Non-Null Count Dtype -- -- 0 SEX 1000000 non-null int64 1 BTH_G 1000000 non-null int64 2 SBP 1000000 non-null int64 3 DBP 1000000 non-null int64 4 FBS 1000000 non-null int64 5 DIS 1000000 non-null int64 6 BMI 1000000 non-null float64 dtypes: float64(1), int64(6) memory usage: 53.4 MB . - 결측치는 없다 . - 우선 열 이름을 한글로 변경한다 . df.columns = [&#39;성별&#39;, &#39;연령대&#39;, &#39;수축기혈압&#39;, &#39;이완기혈압&#39;, &#39;공복혈당&#39;, &#39;고혈압_당뇨_진료내역&#39;, &#39;BMI&#39;] . df.head(6) . 성별 연령대 수축기혈압 이완기혈압 공복혈당 고혈압_당뇨_진료내역 BMI . 0 1 | 1 | 116 | 78 | 94 | 4 | 16.6 | . 1 1 | 1 | 100 | 60 | 79 | 4 | 22.3 | . 2 1 | 1 | 100 | 60 | 87 | 4 | 21.9 | . 3 1 | 1 | 111 | 70 | 72 | 4 | 20.2 | . 4 1 | 1 | 120 | 80 | 98 | 4 | 20.0 | . 5 1 | 1 | 115 | 79 | 95 | 4 | 23.1 | . - 변수별 요약통계량은 아래와 같다 . df.describe().round(2) . 성별 연령대 수축기혈압 이완기혈압 공복혈당 고혈압_당뇨_진료내역 BMI . count 1000000.00 | 1000000.00 | 1000000.00 | 1000000.00 | 1000000.00 | 1000000.00 | 1000000.0 | . mean 1.49 | 13.91 | 121.87 | 75.79 | 98.86 | 3.47 | 23.8 | . std 0.50 | 7.01 | 14.56 | 9.79 | 22.98 | 0.95 | 3.3 | . min 1.00 | 1.00 | 82.00 | 50.00 | 60.00 | 1.00 | 14.8 | . 25% 1.00 | 9.00 | 110.00 | 70.00 | 87.00 | 3.00 | 21.5 | . 50% 1.00 | 14.00 | 120.00 | 76.00 | 94.00 | 4.00 | 23.6 | . 75% 2.00 | 19.00 | 130.00 | 80.00 | 104.00 | 4.00 | 25.8 | . max 2.00 | 27.00 | 190.00 | 120.00 | 358.00 | 4.00 | 40.3 | . - 수축기혈압은 82~190의 범위를 가지고 중앙값은 120, 평균은 121.87이다 . - 이완기혈압은 50~120의 범위를 가지고 중앙값은 76, 평균은 75.79이다 . - 공복혈당은 60~358의 범위를 가지고 중앙값은 94, 평균은 98.86이다 . - BMI은 14.8~40.3의 범위를 가지고 중앙값은 23.6, 평균은 23.8이다 . - 양적변수들을 보면 중앙값과 평균이 거의 비슷한데 대칭인 분포인 것 같다 . - 각 변수에 대한 설명은 아래와 같다 . 변수명 범위 비고 . 수축기혈압 | 82-190 mmHg | 상·하위 극단값 0.05% 제거 | . 이완기혈압 | 50-120 mmHg | 〃(위와 동일함) | . 공복혈당 | 60-358 mg/dL | 〃 | . BMI | 14.8-40.3 kg/m2 | $ cfrac{w}{t^2}$키가 t미터, 몸무게가 w킬로그램〃(위와 동일함) | . 성별 숫자 . 남자 | 1 | . 여자 | 2 | . 고혈압/당뇨병 진료내역 숫자 . 고혈압/당뇨병 진료내역 있음 | 1 | . 고혈압 진료내역 있음 | 2 | . 당뇨병 진료내역 있음 | 3 | . 고혈압/당뇨병 진료내역 없음 | 4 | . - 고혈압, 당뇨 진료내역의 의미는 다음과 같다 . - 현재 고혈압을 앓고있을 수 도 있고 아니면 과거에 고혈압에 걸렸었던 것일 수 도 있다 . - 즉 현재 고혈압인 경우와 과거에 고혈압이었던 경우로 나뉘며 당뇨도 마찬가지이다 . &#50672;&#47161;&#45824; &#48276;&#51452; &#48320;&#44221; . - 현재 연령대 column 이 가지는 값은 1부터 27 까지인데 이들에는 1 =&gt; 20~24, 2 부터는 24살부터 2세 간격으로 끊어진 연령대가 할당되고 마지막은 27 =&gt; 75+ 이다 . ft = df[&#39;연령대&#39;].value_counts() rft = df[&#39;연령대&#39;].value_counts() / len(df[&#39;연령대&#39;]) age_group_table = pd.DataFrame({&#39;Freq&#39;: ft, &#39;Relative freq&#39;: rft}) age_group_table.sort_index() . Freq Relative freq . 1 26699 | 0.026699 | . 2 22398 | 0.022398 | . 3 26925 | 0.026925 | . 4 30595 | 0.030595 | . 5 34984 | 0.034984 | . 6 33797 | 0.033797 | . 7 29666 | 0.029666 | . 8 30074 | 0.030074 | . 9 53811 | 0.053811 | . 10 50787 | 0.050787 | . 11 50881 | 0.050881 | . 12 49544 | 0.049544 | . 13 46303 | 0.046303 | . 14 46373 | 0.046373 | . 15 52352 | 0.052352 | . 16 53382 | 0.053382 | . 17 47760 | 0.047760 | . 18 45048 | 0.045048 | . 19 37174 | 0.037174 | . 20 33846 | 0.033846 | . 21 30824 | 0.030824 | . 22 32253 | 0.032253 | . 23 22906 | 0.022906 | . 24 22720 | 0.022720 | . 25 24530 | 0.024530 | . 26 18463 | 0.018463 | . 27 45905 | 0.045905 | . - 변수가 가지는 범주가 너무 많고 범주가 가지는 나이의 범위가 현재 2세인데 조금 더 늘려도 크게 차이가 있을 것 같지는 않다 . - 표본수가 많으므로 10세 간격으로 끊지 않고 5세 간격으로 끊어 비슷한 연령끼리 그룹화 하겠다 . - 애매한 것은 연령대 데이터가 31-32, 33-34, 35-36, 37-38, 39-40 이런식으로 되어있어 5개씩 나눌 수 가 없는 점이다 . - 0~4 과 5~9으로 나누면 균등해지고 좋을 것 같다 . - 혈압혈당데이터는 건강검진을 받은 사람들 중 백만명을 무작위 층화추출했다 . - 그렇기에 주기성이 없을 것이니 하나의 난수를 가지고 20~70세의 초반, 후반을 나누겠다 . - 5세 간격으로 끊어 편의상 0~4는 &#39;초반&#39;, 5~9는 &#39;후반&#39;으로 표기했다 . - 위의 범주를 무작위로 50%씩 나눠서 반절은 &#39;초반&#39;에 나머지 반절은 &#39;후반&#39;에 할당하겠다 . np.random.seed(2021) rs = np.random.binomial(n = 1, p = 0.5, size = 60000) # 최대가 53000이라 넉넉히 60000개 뽑았다 . c = 2 age = 2 cnt = 3 df.loc[df[&#39;연령대&#39;] == 1, &#39;연령대&#39;] = &#39;20대초반&#39; for idx in [4, 9, 14, 19, 24]: # 변수에 대한 설명을 보면 9~10 에 해당하는 범주의 값은 4, 9, 14, 19, 24이다 df_ = df.loc[df[&#39;연령대&#39;] == idx, &#39;연령대&#39;] df.loc[df[&#39;연령대&#39;] == idx, &#39;연령대&#39;] = rs[: len(df_)] df.loc[df[&#39;연령대&#39;] == 0, &#39;연령대&#39;] = str(c) + &#39;0대후반&#39; c += 1 df.loc[df[&#39;연령대&#39;] == 1, &#39;연령대&#39;] = str(c) + &#39;0대초반&#39; for i in range(2, 27): if cnt &lt; 3: str_ = &#39;초반&#39; else: str_ = &#39;후반&#39; df.loc[df[&#39;연령대&#39;] == i, &#39;연령대&#39;] = str(age) + &#39;0대&#39; + str_ if cnt == 5: age += 1 cnt = 0 cnt += 1 df.loc[df[&#39;연령대&#39;] == 27, &#39;연령대&#39;] = &#39;75세이상&#39; . - 연령대의 도수분포표를 그려보겠다 . ft = df[&#39;연령대&#39;].value_counts() rft = df[&#39;연령대&#39;].value_counts() / len(df[&#39;연령대&#39;]) . age_group_table = pd.DataFrame({&#39;Freq&#39;: ft, &#39;Relative freq&#39;: rft}) age_group_table.sort_index() . Freq Relative freq . 20대초반 26699 | 0.026699 | . 20대후반 64616 | 0.064616 | . 30대초반 84083 | 0.084083 | . 30대후반 86639 | 0.086639 | . 40대초반 128580 | 0.128580 | . 40대후반 118978 | 0.118978 | . 50대초반 128976 | 0.128976 | . 50대후반 111352 | 0.111352 | . 60대초반 83300 | 0.083300 | . 60대후반 66487 | 0.066487 | . 70대초반 54385 | 0.054385 | . 75세이상 45905 | 0.045905 | . &#45936;&#51060;&#53552; EDA . - 기본적으로 고혈압_당뇨 진료내역에 따른 특성들을 확인할 것이다 . &#48276;&#51452;&#54805;&#48320;&#49688; &#53456;&#49353; . &#44256;&#54792;&#50517;, &#45817;&#45544; &#51652;&#47308;&#45236;&#50669; &#48712;&#46020; . - 우선 고혈압, 당뇨 진료내역 범주의 비율을 확인했다 . ft = df[&#39;고혈압_당뇨_진료내역&#39;].value_counts() rft = df[&#39;고혈압_당뇨_진료내역&#39;].value_counts() / len(df[&#39;고혈압_당뇨_진료내역&#39;]) . DIS_table = pd.DataFrame({&#39;Freq&#39;: ft, &#39;Relative freq&#39;: rft}) DIS_table . Freq Relative freq . 4 740662 | 0.740662 | . 2 162826 | 0.162826 | . 1 53398 | 0.053398 | . 3 43114 | 0.043114 | . count_by_cut = df.groupby(&#39;고혈압_당뇨_진료내역&#39;).size() count_by_cut . 고혈압_당뇨_진료내역 1 53398 2 162826 3 43114 4 740662 dtype: int64 . plt.pie(x = count_by_cut, labels = [&#39;고혈압,당뇨&#39;, &#39;고혈압&#39;, &#39;당뇨&#39;, &#39;없음&#39;], autopct = &#39;%.2f%%&#39;) plt.show() . - 고혈압/당뇨 둘 다 진료내역 없음이 74%로 가장 많이 차지한다 . - 당뇨 진료내역만 있는 경우는 4%, 고혈압 진료내역만 있는 경우는 16%, 둘다 있는 경우는 5%이다 . - 둘 다 진료내역이 있는 경우가 당뇨 진료내역만 있는 경우보다 많은 것으로 보아 당뇨가 있는 경우 고혈압도 있는 경우가 빈번한 것 같다 . - 고혈압/당뇨 진료내역에 따른 사람들의 연령대와 성별을 확인하겠다 . - 우선 고혈압/당뇨 진료내역에 따른 연령대를 확인하겠다 . &#44256;&#54792;&#50517;, &#45817;&#45544; &#51652;&#47308;&#45236;&#50669;&#44284; &#50672;&#47161;&#45824; &#48516;&#54624;&#54364; . # df[&#39;연령대&#39;] = pd.Categorical(df[&#39;연령대&#39;], [&#39;20대초반&#39;, &#39;20대후반&#39;, &#39;30대초반&#39;, &#39;30대후반&#39;, &#39;40대초반&#39;, &#39;40대후반&#39;, &#39;50대초반&#39;, &#39;50대후반&#39;, &#39;60대초반&#39;, &#39;60대후반&#39;, &#39;70대초반&#39;, &#39;75세이상&#39;]) . DIS_AGE_table = df.groupby([&#39;연령대&#39;, &#39;고혈압_당뇨_진료내역&#39;]).size().reset_index(name = &#39;cnt&#39;).pivot(index = &#39;고혈압_당뇨_진료내역&#39;, columns = &#39;연령대&#39;, values = &#39;cnt&#39;) # DIS_AGE_table = pd.crosstab(df[&#39;고혈압_당뇨&#39;], df[&#39;연령대&#39;], margins = True) . DIS_AGE_table . 연령대 20대초반 20대후반 30대초반 30대후반 40대초반 40대후반 50대초반 50대후반 60대초반 60대후반 70대초반 75세이상 . 고혈압_당뇨_진료내역 . 1 9 | 35 | 137 | 431 | 1358 | 2763 | 5362 | 7861 | 8818 | 9232 | 9300 | 8092 | . 2 80 | 359 | 1104 | 2936 | 7607 | 13091 | 21954 | 26180 | 24447 | 23256 | 21241 | 20571 | . 3 79 | 253 | 543 | 1233 | 2865 | 4400 | 6555 | 7371 | 6648 | 5524 | 4479 | 3164 | . 4 26531 | 63969 | 82299 | 82039 | 116750 | 98724 | 95105 | 69940 | 43387 | 28475 | 19365 | 14078 | . - 공통적으로 확인되는것은 4번의 경우가 가장 많은 것과 2번의 경우가 3번의 경우보다 더 많다는 것이다 . - 당뇨병보다는 고혈압이 흔한것 같다 . - 그리고 젊은 연령대에서는 1의 경우가 2, 3인 경우보다 더 적은데 50대 초반부터는 늙을수록 1의 경우가 3의 경우보다 더 많아진다 . - 50대 부터는 당뇨가 있는 경우 고혈압도 있는 경우가 흔한것같고 이는 연령대가 높아질수록 더 심해진다 . - 그런데 연령마다 총인원수가 다르기에 사람수로 판단하기 보다는 비율로 판단하는게 좋아보인다 . - 예로 70대초반에서 고혈압_당뇨 범주값이 1인 경우 count는 9300이고 75세이상의 경우는 8092여서 감소한것 같지만 70대초반 인구수와 75세이상 인구수가 다르기에 비율로 따져야 정확하다 . DIS_AGE_table_prob = DIS_AGE_table.apply(lambda x: x*100 / sum(x), axis = 0) # 상대도수를 구함 DIS_AGE_table_prob . 연령대 20대초반 20대후반 30대초반 30대후반 40대초반 40대후반 50대초반 50대후반 60대초반 60대후반 70대초반 75세이상 . 고혈압_당뇨_진료내역 . 1 0.033709 | 0.054166 | 0.162934 | 0.497466 | 1.056152 | 2.322278 | 4.157363 | 7.059595 | 10.585834 | 13.885421 | 17.100303 | 17.627709 | . 2 0.299637 | 0.555590 | 1.312988 | 3.388774 | 5.916161 | 11.002874 | 17.021771 | 23.511028 | 29.348139 | 34.978266 | 39.056725 | 44.812112 | . 3 0.295891 | 0.391544 | 0.645790 | 1.423147 | 2.228185 | 3.698163 | 5.082341 | 6.619549 | 7.980792 | 8.308391 | 8.235727 | 6.892495 | . 4 99.370763 | 98.998700 | 97.878287 | 94.690613 | 90.799502 | 82.976685 | 73.738525 | 62.809828 | 52.085234 | 42.827921 | 35.607245 | 30.667683 | . DIS_AGE_table_prob.T.plot.bar(stacked = True, rot = 0, figsize=(12 , 6)) plt.legend([&#39;고혈압, 당뇨&#39;, &#39;고혈압&#39;, &#39;당뇨&#39;, &#39;없음&#39;]) . &lt;matplotlib.legend.Legend at 0x19789d29880&gt; . - 일단 4(고혈압,당뇨 둘 다 없음)인 경우를 확인하겠다 . - 20대초반의 99%는 4인데 나이가 들어감에 따라 비율이 감소하여 75세이상에서는 4의 경우가 30%이다 . - 1과 2의 경우는 4의 경우와 반대로 나이가 들어가면서 비율이 높아진다 . - 3의 경우는 60대후반까지는 증가하다가 그 이후부터 줄어든다 . - 요약하면 나이를 먹을수록 4는 증가하고 1,2,3은 감소한다(건강한 사람보다는 병을 앓던 사람이 많다는 의미이다) . - 고혈압_당뇨 범주마다 연령대의 비율은 어느정도인지 시각화하겠다 . sequential_colors = sns.color_palette(&#39;RdPu&#39;, 12) . DIS_AGE_table_prob2 = DIS_AGE_table.apply(lambda x: x*100 / sum(x), axis = 1) # 상대도수를 구함 DIS_AGE_table_prob2.plot.bar(stacked = True, rot = 0, color = sequential_colors) plt.legend(loc = &#39;center left&#39;, bbox_to_anchor = (1, 0.5)) plt.show() . - 막대그래프의 밑에서부터 20대초반, 20대후반, $ cdots$, 70대 초반, 75세이상이다(색이 연하면 나이가 적고 진하면 많도록 설정했다) . - 고혈압_당뇨가 1, 2, 3인 경우는 비슷해보인다 . - 고혈압/당뇨 둘 다 진료내역이 없는 경우(4)에는 확실히 다르다(색이 전체적으로 연하다) . - 고혈압/당뇨가 1, 2, 3인 경우 30대 후반까지 차지하는 비중이 낮다(연한색의 비율이 작다) . - 하지만 4인 경우에는 30대 후반까지 차지하는 비중이 높아졌다(연한색의 비율이 크다) . &#44256;&#54792;&#50517;, &#45817;&#45544; &#51652;&#47308;&#45236;&#50669;&#44284; &#49457;&#48324; &#48516;&#54624;&#54364; . - 이제 고혈압/당뇨 진료내역에 따른 성별을 확인하겠다 . count = df.groupby(&#39;성별&#39;).size() plt.pie(x = count, labels = [&#39;남자&#39;, &#39;여자&#39;], autopct = &#39;%.2f%%&#39;) plt.show() . - 우선 전체 백만명중 남자가 51% 여자가 49%로 둘이 비슷하다 . DIS_SEX_table = df.groupby([&#39;성별&#39;, &#39;고혈압_당뇨_진료내역&#39;]).size().reset_index(name = &#39;cnt&#39;).pivot(index = &#39;고혈압_당뇨_진료내역&#39;, columns = &#39;성별&#39;, values = &#39;cnt&#39;) . DIS_SEX_table . 성별 1 2 . 고혈압_당뇨_진료내역 . 1 27979 | 25419 | . 2 79892 | 82934 | . 3 23900 | 19214 | . 4 378456 | 362206 | . DIS_SEX_table_prob = DIS_SEX_table.apply(lambda x: x*100 / sum(x), axis = 1) # 상대도수를 구함 DIS_SEX_table_prob . 성별 1 2 . 고혈압_당뇨_진료내역 . 1 52.397094 | 47.602906 | . 2 49.065874 | 50.934126 | . 3 55.434430 | 44.565570 | . 4 51.096992 | 48.903008 | . DIS_SEX_table_prob.plot.bar(stacked = True, rot = 0) plt.legend([&#39;남자&#39;, &#39;여자&#39;]) . &lt;matplotlib.legend.Legend at 0x1978b011df0&gt; . - 당뇨진료내역이 있는 경우 남자의 비율이 여자보다 살짝 높고 나머지는 비슷하다 . - 표본크기가 매우커서 55%, 45%(당뇨 진료내역 있음) 정도면 차이가 있다고 할 수 있다 . - 그리고 52.4%, 47.6%(고혈압, 당뇨 진료내역 있음) 도 차이가 있다고 할 수 있다 . - 마찬가지로 고혈압 진료내역이 있는 경우도 차이가 있다고 할 수 있다 . - 비율 차이 검정을 통해 정확히 확인하겠다 . df.groupby([&#39;고혈압_당뇨_진료내역&#39;, &#39;성별&#39;]).size().reset_index(). rename(columns = {0:&#39;count&#39;}). merge(df.groupby([&#39;고혈압_당뇨_진료내역&#39;]).agg({&#39;성별&#39;:&#39;size&#39;}). rename(columns = {&#39;성별&#39;:&#39;total&#39;}).reset_index()).eval(&#39;prop = count / total&#39;). query(&#39;성별 == 1&#39;).eval(&#39;z = (prop - 0.5102) / sqrt(prop * (1-prop) / total)&#39;). assign(right_z_0 = norm.ppf(0.975), left_z_0 = norm.ppf(0.275)) . 고혈압_당뇨_진료내역 성별 count total prop z right_z_0 left_z_0 . 0 1 | 1 | 27979 | 53398 | 0.523971 | 6.371704 | 1.959964 | -0.59776 | . 2 2 | 1 | 79892 | 162826 | 0.490659 | -15.773216 | 1.959964 | -0.59776 | . 4 3 | 1 | 23900 | 43114 | 0.554344 | 18.441415 | 1.959964 | -0.59776 | . 6 4 | 1 | 378456 | 740662 | 0.510970 | 1.325525 | 1.959964 | -0.59776 | . - 고혈압, 당뇨 진료내역이 없는 경우를 제외하면 . - 고혈압, 당뇨 진료내역에 따라 남자와 여자의 비율에 차이가 있음을 알 수 있다 . - 고혈압 진료내역만 있는 경우는 여자가 남자보다 비율이 높고 . - 고혈압, 당뇨 진료내역과 당뇨 진료내역만 있는 경우는 남자가 여자보다 비율이 높다 . &#50577;&#51201;&#48320;&#49688; &#53456;&#49353; . &#44060;&#48324; &#48320;&#49688;&#51032; &#49884;&#44033;&#54868; . &#49688;&#52629;&#44592;&#54792;&#50517; . - 양적 변수인 수축기혈압, 이완기혈압, 공복혈당, BMI의 분포를 확인하겠다 . sns.histplot(data = df, x = &#39;수축기혈압&#39;, binwidth = 5) . &lt;AxesSubplot:xlabel=&#39;수축기혈압&#39;, ylabel=&#39;Count&#39;&gt; . - 분포의 모양을 크게 눈에 띄는 봉우리가 4개(100, 110, 120, 130) 존재한다 . - 즉 몇 군데(봉우리)에 데이터가 많이 몰려있다는 의미이다 . sns.boxplot(x = df[&#39;수축기혈압&#39;]) . &lt;AxesSubplot:xlabel=&#39;수축기혈압&#39;&gt; . - boxplot을 보니 수축기혈압의 이상점은 160을 넘는 경우인 듯 하다 . - 성별에 따라 수축기혈압이 다른지 궁금하다 . sns.violinplot(x = &#39;성별&#39;, y = &#39;수축기혈압&#39;, data = df) . &lt;AxesSubplot:xlabel=&#39;성별&#39;, ylabel=&#39;수축기혈압&#39;&gt; . df.groupby(&#39;성별&#39;)[&#39;수축기혈압&#39;].describe() . count mean std min 25% 50% 75% max . 성별 . 1 510227.0 | 124.279954 | 13.547532 | 82.0 | 115.0 | 123.0 | 132.0 | 190.0 | . 2 489773.0 | 119.363001 | 15.146169 | 82.0 | 110.0 | 119.0 | 130.0 | 190.0 | . - 남자인 경우 여자인 경우보다 평균적으로 수축기혈압이 5정도 높다 . - 신기한건 남자가 여자보다 이완기 혈압이 평균적으로 4정도 높지만 두 봉우리의 위치는 남자와 여자가 동일하다 . - 그리고 표준편차는 여자가 1.5정도 더 높다(변동성이 더 크다) &gt; 남자쪽 봉우리가 더 뾰족해서인듯 하다(데이터가 몰려있다) . - 그런데 고혈압, 당뇨 진료내역에 따라 수축기혈압의 분포를 살펴봤는데 이 때도 봉우리의 위치는 4개다 동일하다 . - 남자가 여자보다 혈압이 평균적으로 더 높지만 봉우리의 위치가 같은건 어떤 의미인지 깊게 생각할 필요가 있다 . - 수축기혈압 분포에서 봉우리가 연령대에 의한건지 궁금하다 . b = sns.FacetGrid(data = df, row = &#39;연령대&#39;, height = 7) b.map(sns.histplot, &#39;수축기혈압&#39;, kde = False, binwidth = 5, color = &#39;gray&#39;) . &lt;seaborn.axisgrid.FacetGrid at 0x2117500c760&gt; . - 수축기혈압 분포에서 봉우리가 여러개인것이 연령대 때문은 아니다 . - 그런데 사실 고혈압/당뇨인 사람들은 어떤 특성을 가진 사람들인지가 궁금하다 . - 고혈압/당뇨에 따라 plot을 그려보겠다 . sns.boxplot(x = &#39;고혈압_당뇨_진료내역&#39;, y = &#39;수축기혈압&#39;, data = df) . &lt;AxesSubplot:xlabel=&#39;고혈압_당뇨_진료내역&#39;, ylabel=&#39;수축기혈압&#39;&gt; . - 분포는 모두 대칭이고 종모양으로 보이며 봉우리가 많다 . - 고혈압_당뇨가 1,2인 경우는 130이 중심으로 보인다 . - 고혈압_당뇨가 3,4인 경우는 120이 중심으로 보인다 . - 고혈압/당뇨 둘다 진료내역이 없는 그룹은 수축기혈압이 낮은쪽에서는 이상점이 없다 . - 바이올린플랏을 그려 분포의 모양도 같이 확인하겠다 . sns.violinplot(x = &#39;고혈압_당뇨_진료내역&#39;, y = &#39;수축기혈압&#39;, data = df) . &lt;AxesSubplot:xlabel=&#39;고혈압_당뇨_진료내역&#39;, ylabel=&#39;수축기혈압&#39;&gt; . - 봉우리가 많은 이유가 고혈압_당뇨 진료내역에 따라 분포가 상이하여 그럴것 같았지만 아니었다 . - 고혈압/당뇨 진료내역이 없는 사람들의 수축기 혈압은 다른 경우 비해 몇군데에 더욱 많이 몰렸있다 . - 봉우리가 많은 분포임은 넷다 동일하다 . - 데이터를 보면 1은 고혈압 당뇨 둘 다 진료내역이 있고 2는 고혈압만 3은 당뇨만 있고 4는 둘 다 진료 내역이 없는 경우이다 . - 2와 3을 보면 2가 수축기 혈압이 평균적으로 더 높다 . - 그런데 1과 2를 보면 거의 차이가 없어보인다 . - 3과 4를 보면 당뇨 진료내역이 있는 사람들이 그렇지 않은 사람보다 평균이 조금 더 크고 분포도 더 넓게 퍼져있다 . - 고협압/당뇨 둘 다 진료내역이 없는 상황에서 당뇨 진료내역이 추가되면 수축기 혈압이 높아지고 더 넓게 분포한다 . - 하지만 고혈압 진료내역이 있는 상태라면 당뇨 진료내역의 유무는 수축기 혈압에 거의 영향을 끼치지 못하는 것으로 보인다 . - 수치로 정확히 확인하겠다 . df.groupby(&#39;고혈압_당뇨_진료내역&#39;)[&#39;수축기혈압&#39;].describe() . count mean std min 25% 50% 75% max . 고혈압_당뇨_진료내역 . 1 53398.0 | 130.563972 | 14.981472 | 82.0 | 120.0 | 130.0 | 140.0 | 190.0 | . 2 162826.0 | 130.551300 | 14.851658 | 82.0 | 120.0 | 130.0 | 140.0 | 190.0 | . 3 43114.0 | 123.322146 | 13.618274 | 83.0 | 114.0 | 122.0 | 130.0 | 190.0 | . 4 740662.0 | 119.252575 | 13.484496 | 82.0 | 110.0 | 120.0 | 130.0 | 190.0 | . - 고혈압 진료내역만 있는 경우와 둘 다 진료내역이 있는 경우에 둘의 수축기 혈압 분포는 거의 똑같다 . - 표준편차는 약 15이고 평균은 약 130이다 . - 둘 다 진료내역이 없는 경우가 당뇨 진료내역만 있는 경우보다 수축기 혈압이 평균 4정도 낮다 . - 표준편차는 두 분포 모두 약 13.5이다 . - 고혈압이 있는 경우 그렇지 않은 경우보다 수축기 혈압이 평균 10정도 높다 . - 위에서 말했듯이 고혈압 진료내역이 있는 상태라면 당뇨병 진료내역과 수축기혈압은 상관이 없다 . - 하지만 고혈압이 없고 당뇨만 있는 상태라면 없는 경우보다 수축기혈압이 높다 . - 고혈압, 당뇨 진료내역 말고도 연령대별 수축기혈압에 차이가 있을 수 있다 . - 일반적으로 연령대가 높아질수록 수축기혈압이 높아진다고 한다 . - 이를 확인해볼 필요가 있다 . - 이상점에 영향을 덜받고자 중앙값을 선택했다 . df_mid = df.groupby([&#39;연령대&#39;]).agg({&#39;수축기혈압&#39;:np.median}) df_mid . 수축기혈압 . 연령대 . 20대초반 113 | . 20대후반 115 | . 30대초반 118 | . 30대후반 119 | . 40대초반 120 | . 40대후반 120 | . 50대초반 120 | . 50대후반 122 | . 60대초반 125 | . 60대후반 128 | . 70대초반 130 | . 75세이상 130 | . plt.figure(figsize = (12, 6)) sns.lineplot(x = &#39;연령대&#39;, y = &#39;수축기혈압&#39;, data = df_mid) sns.scatterplot(x = &#39;연령대&#39;, y = &#39;수축기혈압&#39;, data = df_mid, legend = False) . &lt;AxesSubplot:xlabel=&#39;연령대&#39;, ylabel=&#39;수축기혈압&#39;&gt; . - 위 plot을 보면 연령별 수축기혈압의 평균은 증가함을 알 수 있다 . - 그런데 40대초반~50대초반에서 수축기혈압의 중앙값은 120으로 동일하다 . - 이는 70대초반과 75세이상의 경우에도 마찬가지이다(130) . - 중간에 정체하는 구간을 기준으로 나눠봤을 때 구간 전보다 후가 증가폭이 더 크다($7.5 to 10$) . - 그런데 연령대 말고도 고혈압, 당뇨 진료내역마다 수축기혈압에 차이가 존재한다 . - 연령대별 고혈압, 당뇨 진료내역마다 수축기혈압의 중앙값들을 구하고 연령대에 따른 변화를 살펴보겠다 . df_median = df.groupby([&#39;연령대&#39;, &#39;고혈압_당뇨_진료내역&#39;])[&#39;수축기혈압&#39;].median().reset_index(name = &#39;수축기혈압&#39;) . tab10_colors = sns.color_palette(&#39;tab10&#39;, 4) . plt.figure(figsize = (12, 6)) sns.lineplot(x = &#39;연령대&#39;, y = &#39;수축기혈압&#39;, hue = &#39;고혈압_당뇨_진료내역&#39;, palette = tab10_colors, data = df_median) sns.scatterplot(x = &#39;연령대&#39;, y = &#39;수축기혈압&#39;, hue = &#39;고혈압_당뇨_진료내역&#39;, palette = tab10_colors, data = df_median, legend = False) plt.legend([&#39;고혈압, 당뇨&#39;, &#39;고혈압&#39;, &#39;당뇨&#39;, &#39;없음&#39;]) . &lt;matplotlib.legend.Legend at 0x21101cffb80&gt; . - 고혈압, 당뇨 둘 다 진료내역이 있는 경우와 고혈압만 진료내역이 있는 경우는 거의 동일한 양상을 보인다 . - 위의 경우 30대후반부터 수축기혈압의 중앙값은 130으로 동일하다 . - 당뇨 진료내역만 있는 경우 50대후반까진 수축기혈압의 중앙값이 120이다가 증가한다 . - 고혈압, 당뇨 진료내역이 둘 다 없는 경우도 증가하는 양상을 보이는데 40대초반에 살짝 감소한다 . - 그리고 40대후반부터 60대초반까지 수축기혈압 중앙값은 120으로 동일하다가 증가한다 . - 이완기 혈압도 수축기 혈압과 비슷한 양상을 보이는지 확인하겠다 . &#51060;&#50756;&#44592;&#54792;&#50517; . sns.histplot(data = df, x = &#39;이완기혈압&#39;, binwidth = 2) . &lt;AxesSubplot:xlabel=&#39;이완기혈압&#39;, ylabel=&#39;Count&#39;&gt; . - 이완기 혈압도 수축기 혈압의 분포처럼 몇 군에데 데이터가 많이 몰려있는 분포(봉우리)이다 . - 짜잘한 봉우리가 많이 있긴한데 눈에 띄는 봉우리는 2개가 존재한다(쌍봉분포) . - 왜 봉우리가 2개(70, 80)인지 궁금하다 . - 연령대 때문인지가 궁금하다 . b = sns.FacetGrid(data = df, row = &#39;연령대&#39;, height = 7) b.map(sns.histplot, &#39;이완기혈압&#39;, kde = False, binwidth = 2, color = &#39;gray&#39;) . &lt;seaborn.axisgrid.FacetGrid at 0x2ba411253a0&gt; . - 그렇지는 않다 . - 30대 초반까진 70부근이 최빈값이고 그 이후부터는 80부근이 최빈값이다 . - 나이가 많은 사람은 이완기혈압이 크다고 해석할 수 있다 . sns.violinplot(x = &#39;성별&#39;, y = &#39;이완기혈압&#39;, data = df) . &lt;AxesSubplot:xlabel=&#39;성별&#39;, ylabel=&#39;이완기혈압&#39;&gt; . df.groupby(&#39;성별&#39;)[&#39;이완기혈압&#39;].describe() . count mean std min 25% 50% 75% max . 성별 . 1 510227.0 | 77.614977 | 9.504481 | 50.0 | 70.0 | 79.0 | 83.0 | 120.0 | . 2 489773.0 | 73.884467 | 9.727230 | 50.0 | 68.0 | 73.0 | 80.0 | 120.0 | . - 남자인 경우 여자인 경우보다 평균적으로 이완기혈압이 4정도 높다 . - 신기한건 남자가 여자보다 이완기 혈압이 평균적으로 4정도 높지만 두 봉우리의 위치는 남자와 여자가 동일하다 . - 수축기혈압의 경우 여성이 편차가 더 컸는데 이완기혈압의 경우는 비슷하다 . - 수축기 혈압 분포와 이완기 혈압 분포를 같이 놓고 비교하겠다 . fig, (ax1, ax2) = plt.subplots(1,2) fig.set_figwidth(12) sns.histplot(data = df, x = &#39;수축기혈압&#39;, binwidth = 5, ax = ax1) sns.histplot(data = df, x = &#39;이완기혈압&#39;, binwidth = 2, ax = ax2) fig.tight_layout() . - 수축기 혈압 분포의 봉우리가 이완기 혈압 분포의 봉우리 개수보다 많다 . - 변동계수를 계산하면 비슷하다 &gt; 수축기혈압과 이완기혈압의 변동성은 비슷하다 . - 고혈압/당뇨에 따른 이완기 혈압 분포를 확인하겠다 . b = sns.FacetGrid(data = df, row = &#39;고혈압_당뇨_진료내역&#39;, height = 7) b.map(sns.histplot, &#39;이완기혈압&#39;, kde = False, binwidth = 2, color = &#39;gray&#39;) . &lt;seaborn.axisgrid.FacetGrid at 0x2ba452396d0&gt; . - 고혈압, 당뇨 둘 다 없는 경우 이완기혈압은 50~105에 분포하는 것으로 보이고 나머지는 60~105에 분포하는 것 같다 . sns.violinplot(x = &#39;고혈압_당뇨_진료내역&#39;, y = &#39;이완기혈압&#39;, data = df) . &lt;AxesSubplot:xlabel=&#39;고혈압_당뇨_진료내역&#39;, ylabel=&#39;이완기혈압&#39;&gt; . - 이완기 혈압도 수축기혈압과 동일한 양상을 보인다 . - 수치를 통해 정확히 확인해보면 다음과 같다 . df.groupby(&#39;고혈압_당뇨_진료내역&#39;)[&#39;이완기혈압&#39;].describe() . count mean std min 25% 50% 75% max . 고혈압_당뇨_진료내역 . 1 53398.0 | 78.366193 | 9.874400 | 50.0 | 70.0 | 80.0 | 84.0 | 120.0 | . 2 162826.0 | 80.040417 | 10.050473 | 50.0 | 72.0 | 80.0 | 86.0 | 120.0 | . 3 43114.0 | 75.679478 | 9.137214 | 50.0 | 70.0 | 76.0 | 80.0 | 120.0 | . 4 740662.0 | 74.673427 | 9.471040 | 50.0 | 70.0 | 75.0 | 80.0 | 120.0 | . - 둘 다 없는 경우보다 당뇨만 있는 경우 이완기혈압의 평균이 1정도 높다 . - 고혈압이 있으면 위의 경우보다 혈압이 평균적으로 4~5정도 높다 . - 신기한건 고혈압만 있는 경우가 고혈압, 당뇨 둘 다 있는 경우보다 사분위수와 평균이 약 2정도 더 크다 . - 당뇨 진료내역 여부는 혈압에 영향을 별로 끼치지 못하는 것처럼 보인다 . - 정말로 그런지 진료내역이 없는 경우와 당뇨 진료내역만 있는 경우의 평균 차이에 대해 검정하도록 하겠다 . - 특정 값에 데이터가 많이 몰려있어 정규분포는 아닌것처럼 보이지만 표본크기가 매우 크고 종모양이기에 t검정을 실시하겠다 . - 우선 등분산인지 검정하겠다 . x_B = df.query(&#39;고혈압_당뇨_진료내역 == 3&#39;)[&#39;이완기혈압&#39;] x_NB = df.query(&#39;고혈압_당뇨_진료내역 == 4&#39;)[&#39;이완기혈압&#39;] # print(stats.bartlett(x_B, x_NB)) print(stats.levene(x_B, x_NB)) . LeveneResult(statistic=108.15121732780896, pvalue=2.4998221943218063e-25) . - p-value가 0이다 . - 그러니 이분산 가정하에 t검정을 실시하겠다 . t_stat, pvalue = stats.ttest_ind(x_B, x_NB, equal_var = False) . print(t_stat, pvalue) . 22.179011908568423 1.892237004554513e-108 . - t통계량에 근거한 p-value가 0이다 . - 당뇨 진료내역만 있는 경우와 진료내역이 없는 경우의 이완기혈압 평균의 차이는 존재한다 . - 하지만 그 차이가 1 뿐이기에 통계적으로는 유의한 차이지만 실질적인 차이는 거의 없다 . - 고혈압 진료내역이 있는 경우 수축기혈압과 이완기 혈압이 높은데 이는 당연하다(고혈압은 혈압이 높은것) . - 그리고 고혈압이 있는 경우가 그렇지 않은 경우보다 혈압이 높은데 수축기혈압의 증가폭(10)이 이완기혈압의 증가폭(5)보다 더 크다 . - 고혈압, 당뇨 진료내역 말고도 연령대별 이완기혈압에 차이가 있을 수 있다 . - 일반적으로 연령대가 높아질수록 이완기혈압이 높아진다고 한다 . - 이를 확인해볼 필요가 있다 . - 수축기혈압때처럼 연령대별 이완기혈압의 중앙값들을 구하고 연령대에 따른 변화를 살펴보겠다 . df_mid2 = df.groupby([&#39;연령대&#39;]).agg({&#39;이완기혈압&#39;:np.median}) df_mid2 . 이완기혈압 . 연령대 . 20대초반 70 | . 20대후반 70 | . 30대초반 74 | . 30대후반 75 | . 40대초반 75 | . 40대후반 77 | . 50대초반 78 | . 50대후반 78 | . 60대초반 78 | . 60대후반 78 | . 70대초반 78 | . 75세이상 78 | . plt.figure(figsize = (12, 6)) sns.lineplot(x = &#39;연령대&#39;, y = &#39;이완기혈압&#39;, data = df_mid2) sns.scatterplot(x = &#39;연령대&#39;, y = &#39;이완기혈압&#39;, data = df_mid2, legend = False) . &lt;AxesSubplot:xlabel=&#39;연령대&#39;, ylabel=&#39;이완기혈압&#39;&gt; . - 위 plot을 보면 이완기혈압의 중앙값은 증가함을 알 수 있다 . - 그런데 50대초반부터는 이완기혈압의 중앙값은 78로 동일하다 . - 그리고 30대후반~40대초반에 이완기혈압이 75로 동일하다 . - 중간에 정체하는 구간을 기준으로 나눠봤을 때 구간 전보다 후가 증가폭이 더 크다($5 to 3$) . - 그런데 연령대 말고도 고혈압, 당뇨 진료내역마다 이완기혈압에 차이가 존재한다 . - 연령대별 고혈압, 당뇨 진료내역마다 이완기혈압의 중앙값들을 구하고 연령대에 따른 변화를 살펴보겠다 . df_median2 = df.groupby([&#39;연령대&#39;, &#39;고혈압_당뇨_진료내역&#39;])[&#39;이완기혈압&#39;].median().reset_index(name = &#39;이완기혈압&#39;) . plt.figure(figsize = (12, 6)) sns.lineplot(x = &#39;연령대&#39;, y = &#39;이완기혈압&#39;, hue = &#39;고혈압_당뇨_진료내역&#39;, palette = tab10_colors, data = df_median2) sns.scatterplot(x = &#39;연령대&#39;, y = &#39;이완기혈압&#39;, hue = &#39;고혈압_당뇨_진료내역&#39;, palette = tab10_colors, data = df_median2, legend = False) plt.legend([&#39;고혈압, 당뇨&#39;, &#39;고혈압&#39;, &#39;당뇨&#39;, &#39;없음&#39;]) . &lt;matplotlib.legend.Legend at 0x1978bc6f280&gt; . - 이완기혈압을 연령대별로 라인플랏을 그려봤을땐 감소하는 구간이 없었다 . - 또한 히스토그램을 확인했을 때도 마찬가지였다 . - 그런데 고혈압, 당뇨 진료내역에 따라 그래프를 나눠그리니 감소하는 구간이 생겼다 . - 위에서 나이가 들수록 이완기혈압이 높아진다고 했는데 고혈압, 당뇨 진료내역이 없는 사람을 제외하면 그렇지 않다 . - 공통적으로 30대 후반까지는 이완기혈압 중앙값이 증가한다 . - 그런데 그 이후부터는 고혈압, 당뇨 둘다 없는 경우를 제외하면 이완기혈압 중앙값이 감소한다 . - 중앙값이 문제일 수 있어서 평균으로 바꿔 그려봤으나 문제가 없었다 . - 수축기혈압 중앙값은 나이가 들수록 증가하는 반면 이완기혈압 중앙값은 진료내역이 없는 경우를 제외하면 증가하다가 감소한다 . &#49688;&#52629;&#44592;&#54792;&#50517;&#44284; &#51060;&#50756;&#44592;&#54792;&#50517; &#44256;&#52272; . - 위에서 수축기혈압과 이완기혈압의 분포를 살펴봤는데 고혈압 진료내역이 있지만 혈압이 낮은 사람도 있고 고혈압 진료내역이 없지만 혈압이 높은사람도 있었다 . - 고혈압 진료내역이 있지만 혈압이 정상범주안에 있는 사람은 혈압관리가 잘되고 있는것으로 간주할 수 있을 것 같다 . - 이들의 비율을 확인하겠다 . - 고혈압은 우리나라 기준 수축기 혈압 140mmHg 이상이거나 이완기 혈압 90mmHg 이상인 경우라고 한다 . - 참고 : http://hqcenter.snu.ac.kr/archives/jiphyunjeon/%EA%B3%A0%ED%98%88%EC%95%95 . - 위에 고혈압 기준을 넘어가는 혈압을 가진 사람들은 고혈압으로 그렇지 않는 사람은 정상혈압으로 간주하겠다 . - 그런데 수축기혈압, 이완기혈압의 분포를 보면 혈압이 매우 낮은 사람도 존재함을 알 수 있다 . - 이들은 저혈압으로 간주할 수 있을 것 같다 . - 저혈압은 일반적으로 수축기 혈압 90mmHg 미만이거나 이완기 혈압 60mmHg 미만인 경우라고한다 . - 참고 : https://health.kdca.go.kr/healthinfo/biz/health/gnrlzHealthInfo/gnrlzHealthInfo/gnrlzHealthInfoView.do?cntnts_sn=4616 . def f(x, y): if x &gt;= 140 or y &gt;= 90: z = &#39;고혈압&#39; elif x &lt; 90 or y &lt; 60: z = &#39;저혈압&#39; else: z = &#39;정상혈압&#39; return z . df[&#39;혈압범주&#39;] = list(map(f, df[&#39;수축기혈압&#39;], df[&#39;이완기혈압&#39;])) . df.head() . 성별 연령대 수축기혈압 이완기혈압 공복혈당 고혈압_당뇨_진료내역 BMI 혈압범주 . 0 1 | 20대초반 | 116 | 78 | 94 | 4 | 16.6 | 정상혈압 | . 1 1 | 20대초반 | 100 | 60 | 79 | 4 | 22.3 | 정상혈압 | . 2 1 | 20대초반 | 100 | 60 | 87 | 4 | 21.9 | 정상혈압 | . 3 1 | 20대초반 | 111 | 70 | 72 | 4 | 20.2 | 정상혈압 | . 4 1 | 20대초반 | 120 | 80 | 98 | 4 | 20.0 | 정상혈압 | . count = df.groupby(&#39;혈압범주&#39;).size() . plt.pie(x = count, labels = [&#39;고혈압&#39;, &#39;저혈압&#39;, &#39;정상혈압&#39;], autopct = &#39;%.2f%%&#39;) plt.show() . - 정상혈압은 약 84%, 고혈압은 약 14%, 저혈압은 약 3% 이다 . - 저혈압보다는 고혈압이 흔한것같다 . - 고혈압 진료내역이 있는 사람이 약 22%정도였는데 7%p정도 차이가 있다 . tab = pd.crosstab(df[&#39;혈압범주&#39;], df[&#39;고혈압_당뇨_진료내역&#39;]) tab . 고혈압_당뇨_진료내역 1 2 3 4 . 혈압범주 . 고혈압 16318 | 51261 | 5696 | 62049 | . 저혈압 773 | 1518 | 1056 | 23435 | . 정상혈압 36307 | 110047 | 36362 | 655178 | . tab.apply(lambda x: x*100 / sum(x), axis = 0) . 고혈압_당뇨_진료내역 1 2 3 4 . 혈압범주 . 고혈압 30.559197 | 31.482073 | 13.211486 | 8.377506 | . 저혈압 1.447620 | 0.932284 | 2.449320 | 3.164061 | . 정상혈압 67.993183 | 67.585644 | 84.339194 | 88.458433 | . - 위를 보면 고혈압_당뇨 둘 다 없더라도 12%정도는 혈압에 문제가 있는것을 알 수 있다 . - 신기한건 고혈압 진료내역이 있는 경우인데 고혈압 진료내역이 있지만 실제 고혈압인 경우는 약 31%이고 68%는 정상혈압 나머지 1%는 저혈압이다 . tab2 = pd.crosstab(df[&#39;혈압범주&#39;], df[&#39;성별&#39;]) tab2.apply(lambda x: x*100 / sum(x), axis = 0) . 성별 1 2 . 혈압범주 . 고혈압 15.345719 | 11.643353 | . 저혈압 1.360375 | 4.051060 | . 정상혈압 83.293906 | 84.305586 | . - 남자가 여자보다 혈압이 더 높은건 고혈압 환자가 많아서였다 . - 참고로 백만명중 남자는 51% 여자는 49%이다 . &#54792;&#50517;&#48276;&#51452; &#49464;&#48516;&#54868; . - 같은 고혈압이더라도 수축기혈압만 높은지 이완기혈압만 높은지 아니면 둘 다 높은지가 다를것이다 . - 그런데 위와 같이 나누면 이를 구분할 수 없다 . - 게다가 수축기혈압은 고혈압인데 이완기혈압은 저혈압인 경우도 있다고 한다 . - 혈압범주를 세분화시키면 정확도는 올라가지만 편의성이 떨어진다 . - 세분화시킬 필요가 있을지 확인하겠다 . ref : https://m.health.chosun.com/svc/news_view.html?contid=2018053103892 | . - 일단 혈압범주를 세분화시킨 새로운 컬럼을 만들고 시각화하겠다 . def blood_pressure(x, y): if x &gt;= 140 and y &gt;= 90: z = &#39;HH&#39; elif x &lt; 90 and y &lt; 60: z = &#39;LL&#39; elif x &gt;= 140 and 60 &lt;= y &lt; 90: z = &#39;HN&#39; elif x &gt;= 140 and 60 &gt; y: z = &#39;HL&#39; elif 90 &lt;= x &lt; 140 and 60 &lt;= y &lt; 90: z = &#39;NN&#39; elif 90 &lt;= x &lt; 140 and 60 &gt; y: z = &#39;NL&#39; elif 90 &lt;= x &lt; 140 and y &gt;= 90: z = &#39;NH&#39; elif 90 &gt; x and 90 &lt;= y: z = &#39;LH&#39; elif 90 &gt; x and 60 &lt;= y &lt; 90: z = &#39;LN&#39; return z . - 혈압세부범주를 혈압범주로 치환하면 아래와 같다 . - HH, HN, HL, NH, LH &gt; 고혈압 . - LL, NL, LN &gt; 저혈압 . - NN &gt; 정상혈압 . - 혈압범주에서는 수축기고혈압 + 이완기저혈압이면 고혈압으로 표기했다(하지만 저혈압이기도 함) . - 혈압범주를 나누는 함수내부를 보면 if else문에서 고혈압을 먼저 판단하고 저혈압을 판단해서 그렇다 . - 하지만 혈압세부범주에서는 그럴일은 없다 . - 진료내역별 혈압세부범주를 확인하겠다 . df[&#39;혈압세부범주&#39;] = list(map(blood_pressure, df[&#39;수축기혈압&#39;], df[&#39;이완기혈압&#39;])) . df.head() . 성별 연령대 수축기혈압 이완기혈압 공복혈당 고혈압_당뇨_진료내역 BMI 맥압 혈압범주 혈압세부범주 . 0 1 | 20대초반 | 116 | 78 | 94 | 4 | 16.6 | 38 | 정상혈압 | NN | . 1 1 | 20대초반 | 100 | 60 | 79 | 4 | 22.3 | 40 | 정상혈압 | NN | . 2 1 | 20대초반 | 100 | 60 | 87 | 4 | 21.9 | 40 | 정상혈압 | NN | . 3 1 | 20대초반 | 111 | 70 | 72 | 4 | 20.2 | 41 | 정상혈압 | NN | . 4 1 | 20대초반 | 120 | 80 | 98 | 4 | 20.0 | 40 | 정상혈압 | NN | . tab = pd.crosstab(df[&#39;혈압세부범주&#39;], df[&#39;고혈압_당뇨_진료내역&#39;]) tab . 고혈압_당뇨_진료내역 1 2 3 4 . 혈압세부범주 . HH 6348 | 23684 | 2141 | 28800 | . HL 25 | 44 | 7 | 17 | . HN 8059 | 19684 | 2503 | 16395 | . LL 12 | 37 | 42 | 1443 | . LN 5 | 33 | 24 | 952 | . NH 1886 | 7849 | 1045 | 16837 | . NL 756 | 1448 | 990 | 21040 | . NN 36307 | 110047 | 36362 | 655178 | . tab.apply(lambda x: x*100 / sum(x), axis = 0) . 고혈압_당뇨_진료내역 1 2 3 4 . 혈압세부범주 . HH 11.888086 | 14.545589 | 4.965904 | 3.888413 | . HL 0.046818 | 0.027023 | 0.016236 | 0.002295 | . HN 15.092326 | 12.088978 | 5.805539 | 2.213560 | . LL 0.022473 | 0.022724 | 0.097416 | 0.194826 | . LN 0.009364 | 0.020267 | 0.055666 | 0.128534 | . NH 3.531967 | 4.820483 | 2.423807 | 2.273237 | . NL 1.415783 | 0.889293 | 2.296238 | 2.840702 | . NN 67.993183 | 67.585644 | 84.339194 | 88.458433 | . - 그런데 위에서 확인했듯이 고혈압 진료내역이 있다고 현재도 고혈압인것은 아니다 . - 그러니 혈압범주와 혈압세부범주를 비교하겠다 . - 또한 혈압범주를 혈압세부범주로 나눈것이 얼마나 유용할지도 판단하겠다 . tab2 = pd.crosstab(df[&#39;혈압세부범주&#39;], df[&#39;혈압범주&#39;]) tab2 . 혈압범주 고혈압 저혈압 정상혈압 . 혈압세부범주 . HH 60973 | 0 | 0 | . HL 93 | 0 | 0 | . HN 46641 | 0 | 0 | . LL 0 | 1534 | 0 | . LN 0 | 1014 | 0 | . NH 27617 | 0 | 0 | . NL 0 | 24234 | 0 | . NN 0 | 0 | 837894 | . - 우선 수축기고혈압이면서 이완기저혈압인사람은 93명이다 &gt; 백만명중에 93명이니 무시할만한 수준이다 . - 그리고 수축기저혈압이면서 이완기고혈압인 사람은 없다! . - 또한 혈압범주에서 정상이었으면 혈압세부범주에서도 정상이다 . - 저혈압인 사람중에서 둘다 저혈압인 사람은 적은데 고혈압인 사람중에서 둘다 고혈압인 사람은 50%정도이다 . - 그래서 혈압범주와 혈압세부범주는 얼마나 차이가 있는가? . - 간단히 plot을 통해 확인하겠다 . sns.violinplot(x = &#39;혈압세부범주&#39;, y = &#39;공복혈당&#39;, data = df) . &lt;AxesSubplot:xlabel=&#39;혈압세부범주&#39;, ylabel=&#39;공복혈당&#39;&gt; . sns.violinplot(x = &#39;혈압세부범주&#39;, y = &#39;BMI&#39;, data = df) . &lt;AxesSubplot:xlabel=&#39;혈압세부범주&#39;, ylabel=&#39;BMI&#39;&gt; . - 일단 혈압범주나 혈압세부범주를 가지고 수축기혈압이나 이완기혈압의 boxplot등을 그려보는것은 별로 유용하지 않다 . - 왜냐하면 애초애 수축기, 이완기혈압을 통해 혈압범주들을 구했기 때문이다(상관관계 매우큼) . - 또한 수축기혈압과 이완기혈압의 상관계수는 0.7이 넘는다 . - 당연히 고혈압인 사람은 혈압이 높게나오고 저혈압인 사람은 혈압이 낮게 나올것이다 . sns.violinplot(x = &#39;혈압범주&#39;, y = &#39;수축기혈압&#39;, data = df) . &lt;AxesSubplot:xlabel=&#39;혈압범주&#39;, ylabel=&#39;수축기혈압&#39;&gt; . sns.violinplot(x = &#39;혈압세부범주&#39;, y = &#39;수축기혈압&#39;, data = df) . &lt;AxesSubplot:xlabel=&#39;혈압세부범주&#39;, ylabel=&#39;수축기혈압&#39;&gt; . sns.violinplot(x = &#39;혈압범주&#39;, y = &#39;이완기혈압&#39;, data = df) . &lt;AxesSubplot:xlabel=&#39;혈압범주&#39;, ylabel=&#39;이완기혈압&#39;&gt; . sns.violinplot(x = &#39;혈압세부범주&#39;, y = &#39;이완기혈압&#39;, data = df) . &lt;AxesSubplot:xlabel=&#39;혈압세부범주&#39;, ylabel=&#39;이완기혈압&#39;&gt; . - 그래서 결론은 혈압세부범주는 사용안하고 혈압범주만 사용할것이다 . - 문제가 되었던 고혈압과 저혈압을 둘다 가지고 있지만 혈압범주를 나누는 함수에서 고혈압을 먼저 처리하여 고혈압이 된 사람들은 문제가 없다 . - 왜냐하면 HL인 사람은 93명밖에 없으면 LH인 사람은 0명이기 때문이다 . - 애초애 저혈압인 사람은 3만명도 안되는데 고혈압인 사람은 12만명이 넘는다 . - 정상혈압인 사람은 혈압세부범주에서 NN인 사람으로 동일하다 . - 그리고 저혈압인 경우 HL, NL, LL 총 3가지가 있는데 대부분 HL(90%)이어서 문제 없다 . - 제일 차이가 나는건 고혈압인 경우이다(HH, HN, NH) . - HH인경우가 50%이고 HN은 30%, NH는 20%정도이다 . - 만약 둘다 고혈압인 경우와 하나만 고혈압인 경우가 많이 다르다면 고려할만 하지만 차이가 별로 없다 . - 하지만 위에서 그린 공복혈당, BMI 바이올린플랏을 보면 알수있듯이 거의 차이가 없다 . - 혈압범주를 세분화시킨건 여러개의 봉우리가 생긴원인이 이때문인지 확인하려고 한 것이다 . - 그런데 세분화시켰음에도 이는 동일하다 &gt; 그러니 혈압은 고혈압, 저혈압, 정상혈압으로만 나누겠다 . - 결론 : 혈압을 세분화시켜도 차이가 거의 없으니 시각화하기 편하게 3가지로만 나눈다 . df = df.drop(&#39;혈압세부범주&#39;, axis = 1) . &#47589;&#50517; . - 수축기혈압과 이완기혈압의 차이를 맥압이라고 하는데 수축기혈압과 이완기혈압 둘다 정상 범주에 속하더라도 맥압이 높다면 건강상에 문제가 있을 수 있다고 한다 . - 성인의 경우 35~45mmHg가 정상범주라고 한다 . - 참고 : http://assinmun.kr/m/page/view.php?no=4162&amp;code=20140925141337_5787&amp;d_code=20140925150830_7887&amp;ds_code= . - 맥압의 분포는 어떻게 되는지 살펴보도록 하겠다 . df[&#39;맥압&#39;] = df[&#39;수축기혈압&#39;] - df[&#39;이완기혈압&#39;] . df.head() . 성별 연령대 수축기혈압 이완기혈압 공복혈당 고혈압_당뇨_진료내역 BMI 혈압범주 맥압 . 0 1 | 20대초반 | 116 | 78 | 94 | 4 | 16.6 | 정상혈압 | 38 | . 1 1 | 20대초반 | 100 | 60 | 79 | 4 | 22.3 | 정상혈압 | 40 | . 2 1 | 20대초반 | 100 | 60 | 87 | 4 | 21.9 | 정상혈압 | 40 | . 3 1 | 20대초반 | 111 | 70 | 72 | 4 | 20.2 | 정상혈압 | 41 | . 4 1 | 20대초반 | 120 | 80 | 98 | 4 | 20.0 | 정상혈압 | 40 | . sns.histplot(data = df, x = &#39;맥압&#39;, binwidth = 5) . &lt;AxesSubplot:xlabel=&#39;맥압&#39;, ylabel=&#39;Count&#39;&gt; . - 눈에 띄는 봉우리가 2개 보인다(쌍봉 분포) . - 이완기혈압의 히스토그램을 그려봤을 때 봉우리가 2개(70, 80)였는데 10차이이다 . - 맥압의 경우 40과 50부근에 봉우리가 있는데 이역시 10차이이다 . - 맥압은 수축기혈압과 이완기혈압의 차이이므로 이완기혈압에 영향을 당연히 받는다 . - 중요한건 이완기혈압의 분포가 왜 쌍봉 분포인지를 파악하는것이다 . - 고혈압, 당뇨 진료내역에 따른 박스플랏을 그려보겠다 . sns.violinplot(x = &#39;고혈압_당뇨_진료내역&#39;, y = &#39;맥압&#39;, data = df) . &lt;AxesSubplot:xlabel=&#39;고혈압_당뇨_진료내역&#39;, ylabel=&#39;맥압&#39;&gt; . - 고혈압, 당뇨 진료내역에 따른 수축기혈압, 이완기혈압 분포를 확인했을땐 당뇨병만 진료내역이 있는 경우와 둘 다 없는 경우의 분포가 비슷했는데 맥압의 경우는 다르다 . - 고혈압 진료내역이 있지만 현재는 혈압이 정상범주에 속해있을 수 도 있다 . - 그러니 고혈압, 당뇨 진료내역의 따른 맥압의 분포말고 건강검진을 받았을 당시의 혈압으로 구분하겠다 . - 혈압이 정상범주인 경우의 맥압의 분포와 그렇지 않은 경우 맥압의 분포를 비교하겠다 . sns.violinplot(x = &#39;혈압범주&#39;, y = &#39;맥압&#39;, data = df) . &lt;AxesSubplot:xlabel=&#39;혈압범주&#39;, ylabel=&#39;맥압&#39;&gt; . - 저혈압의 경우 종모양을 띄고있다 . - 고혈압의 경우 눈에띄는 봉우리가 4개정도 보인다 . - 바이올린플랏을 보면 정상혈압에서 유달리 눈에띄는 2개의 봉우리를 볼 수 있는데 이 때문에 맥압이 쌍봉분포의 형태를 띄는것으로 보인다 . - 고혈압인 경우 맥압이 정상혈압, 저혈압인 경우보다 높다 . - 혈압이 오르면 수축기혈압의 상승폭이 이완기혈압의 상승폭보다 높다고 해석할 수 있다 . - 수축기혈압이 이완기혈압보다 기본적으로 높기에 어찌보면 당연하다 . - 한편 위의 출처에 나와있는 설명을 보면 나이가 들어감에따라 맥압이 높아진다고 한다 . - 연령대에 따른 박스플랏을 그려보겠다 . plt.figure(figsize = (12, 6)) sns.violinplot(x = &#39;연령대&#39;, y = &#39;맥압&#39;, data = df) . &lt;AxesSubplot:xlabel=&#39;연령대&#39;, ylabel=&#39;맥압&#39;&gt; . - 연령대가 높아질수록 평균 맥압은 증가하는것으로 보인다 . sns.violinplot(x = &#39;성별&#39;, y = &#39;맥압&#39;, data = df) . &lt;AxesSubplot:xlabel=&#39;성별&#39;, ylabel=&#39;맥압&#39;&gt; . df.groupby(&#39;성별&#39;)[&#39;맥압&#39;].describe() . count mean std min 25% 50% 75% max . 성별 . 1 510227.0 | 46.664977 | 9.35818 | 8.0 | 40.0 | 46.0 | 51.0 | 130.0 | . 2 489773.0 | 45.478534 | 10.20447 | 4.0 | 40.0 | 44.0 | 50.0 | 140.0 | . - 남자인 경우 여자인 경우보다 평균적으로 수축기혈압이 5정도 높았고 이완기혈압은 4정도 높았는데 맥압의 경우는 1정도 차이가 난다 . - 수축기혈압(5) - 이완기혈압(4) = 맥압(1) . - 하지만 통계적으로 유의한 차이가 아닐 수 도 있기에 평균차이검정을 실시하겠다 . - 특정값에 집중적으로 몰려있어 정규분포라 하기 어려울 수 있지만 종모양이고 표본 크기가 매우 크므로 t검정을 실행할 것이다 . x_B = df.query(&#39;성별 == 1&#39;)[&#39;맥압&#39;] ## 남자 x_NB = df.query(&#39;성별 == 2&#39;)[&#39;맥압&#39;] ## 여자 . # print(stats.bartlett(x_B, x_NB)) print(stats.levene(x_B, x_NB)) . LeveneResult(statistic=1875.218691424608, pvalue=0.0) . - 분산의 동일성 검정에서 p-value가 각각 0.0, 0.0으로 전체적으로 판단했을 때 . - 두 그룹의 분산이 동일하지 않으므로 이분산 가정 하에서 t검정을 실시한다 . t_stat, pvalue = stats.ttest_ind(x_B, x_NB, equal_var = False) print(t_stat, pvalue) . 60.525582091193876 0.0 . - t통계량에 근거한 p-value가 0.0이므로 남자와 여자의 맥압은 다르다고 할 수 있다 . &#54792;&#50517;&#51032; &#45149;&#51088;&#47532;&#49688; &#54200;&#54693; . - 혈압의 끝자리수 편향에 대해 얘기하기전에 수축기혈압과 이완기혈압의 분포를 다시한번 시각화하겠다 . fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2,2) sns.histplot(data = df, x = &#39;수축기혈압&#39;, hue = &#39;고혈압_당뇨_진료내역&#39;, palette = tab10_colors[::-1], binwidth = 5, ax = ax1) sns.histplot(data = df, x = &#39;이완기혈압&#39;, hue = &#39;고혈압_당뇨_진료내역&#39;, palette = tab10_colors[::-1], binwidth = 2, ax = ax2) sns.histplot(data = df, x = &#39;수축기혈압&#39;, hue = &#39;혈압범주&#39;, binwidth = 5, ax = ax3) sns.histplot(data = df, x = &#39;이완기혈압&#39;, hue = &#39;혈압범주&#39;, binwidth = 2, ax = ax4) ax1.legend([&#39;없음&#39;, &#39;당뇨&#39;, &#39;고혈압&#39;, &#39;고혈압, 당뇨&#39;]) ax2.legend([&#39;없음&#39;, &#39;당뇨&#39;, &#39;고혈압&#39;, &#39;고혈압, 당뇨&#39;]) fig.tight_layout() . - 일단 고혈압, 당뇨 진료내역이 둘 다 없는 경우가 대부분이다 . - 진료내역이 아닌 고혈압, 정상혈압, 저혈압으로 나눠도 정상혈압이 대부분이다(혈당의 경우도 정상혈당이 대부분) . - 처음에 수축기혈압과 이완기혈압의 히스토그램을 그려봤을 때 봉우리가 많은것이 신기했다 . - 혈당이나 BMI의 히스토그램같이 종모양일 줄 알았기 때문이었다 . - 왜 혈압분포의 경우 봉우리가 많은지에 대해 성별, 연령대, 혈압범주로 나누어 살펴봤지만 알 수 없었다 . - 위의 분포를 보면 알겠지만 혈압범주로 나누는건 의미가 없고 성별, 연령대의 경우도 마찬가지었다 . - 봉우리가 너무 특정구간에만 몰려있는것이 이상했다 . - 그래서 혈압을 측정함에 있어 문제가 있는것이 아닐까 생각했다 . - 혈압을 측정하여 소수점이 나오면 이를 자연수로 만듦으로써 소수점 이하를 없애는데 측정자의 주관이 개입한것이다 . - 예컨대 수축기혈압이 138.7mmHg가 나왔다면 반올림하면 139mmHg이지만 숫자를 깔끔하게 하기 위해 140mmHg로 처리하는 것이다 . - 정말 그런건지 확인하겠다 . df[&#39;수축기_혈압_끝자리수&#39;] = list(map(lambda x: int(str(x)[-1]), df[&#39;수축기혈압&#39;])) df[&#39;이완기_혈압_끝자리수&#39;] = list(map(lambda x: int(str(x)[-1]), df[&#39;이완기혈압&#39;])) . df.head() . 성별 연령대 수축기혈압 이완기혈압 공복혈당 고혈압_당뇨_진료내역 BMI 혈압범주 맥압 수축기_혈압_끝자리수 이완기_혈압_끝자리수 . 0 1 | 20대초반 | 116 | 78 | 94 | 4 | 16.6 | 정상혈압 | 38 | 6 | 8 | . 1 1 | 20대초반 | 100 | 60 | 79 | 4 | 22.3 | 정상혈압 | 40 | 0 | 0 | . 2 1 | 20대초반 | 100 | 60 | 87 | 4 | 21.9 | 정상혈압 | 40 | 0 | 0 | . 3 1 | 20대초반 | 111 | 70 | 72 | 4 | 20.2 | 정상혈압 | 41 | 1 | 0 | . 4 1 | 20대초반 | 120 | 80 | 98 | 4 | 20.0 | 정상혈압 | 40 | 0 | 0 | . - 특정 숫자가 혈압의 끝자리수로 많이 등장할 이유는 없을 것이다 . - 그렇다면 끝자리수로 숫자마다 대략 10만개씩 등장할 것이다 . df.groupby(by = [&#39;수축기_혈압_끝자리수&#39;]).agg(&#39;size&#39;).reset_index().rename(columns = {0:&#39;count&#39;}). plot.bar(x = &#39;수축기_혈압_끝자리수&#39;, y = &#39;count&#39;, rot = 0, legend = False) . &lt;AxesSubplot:xlabel=&#39;수축기_혈압_끝자리수&#39;&gt; . - 수축기혈압의 전체 count수가 100만인데 약 40만개의 끝자리수가 $0$이다! . - $0$ 다음으로 많이 등장하는 숫자는 $5$이다 . - $0$과 $5$를 제외하고보면 홀수보다는 짝수가 더 많이 등장한다 . - 이완기혈압도 수축기혈압과 같은 양상을 보이는지 확인하겠다 . df.groupby(by = [&#39;이완기_혈압_끝자리수&#39;]).agg(&#39;size&#39;).reset_index().rename(columns = {0:&#39;count&#39;}). plot.bar(x = &#39;이완기_혈압_끝자리수&#39;, y = &#39;count&#39;, rot = 0, legend = False) . &lt;AxesSubplot:xlabel=&#39;이완기_혈압_끝자리수&#39;&gt; . - 이완기혈압도 수축기혈압과 마찬가지다 . - 수축기혈압과 이완기혈압의 분포에서 봉우리가 많이보인것은 끝자리수 편향 때문이었다 . - 눈에 띄게 높은 봉우리는 편향에 의한 끝자리수 $0$에 의한것이었고 자잘자잘한 봉우리는 $5$와 홀수보다 짝수가 더 선호되기 때문이었다 . - 수축기혈압의 봉우리가 이완기혈압의 봉우리보다 많은것은 수축기혈압이 이완기혈압보다 더 넓게 분포되었기 때문이다(ex) 끝자리가 $0$인 숫자의 개수가 더 많다) . df = df.drop([&#39;수축기_혈압_끝자리수&#39;, &#39;이완기_혈압_끝자리수&#39;], axis = 1) . - 이제 공복혈당의 분포를 확인하겠다 . &#44277;&#48373;&#54792;&#45817; . sns.histplot(data = df, x = &#39;공복혈당&#39;, binwidth = 5) . &lt;AxesSubplot:xlabel=&#39;공복혈당&#39;, ylabel=&#39;Count&#39;&gt; . - 오른쪽으로 꼬리가 긴 분포이다 . - 성별에 따라 공복혈당이 다른지 확인하겠다 . sns.violinplot(x = &#39;성별&#39;, y = &#39;공복혈당&#39;, data = df) . &lt;AxesSubplot:xlabel=&#39;성별&#39;, ylabel=&#39;공복혈당&#39;&gt; . - 성별에 따라 공복혈당은 비슷해보인다 . - 수치로 확인하겠다 . df.groupby(&#39;성별&#39;)[&#39;공복혈당&#39;].describe() . count mean std min 25% 50% 75% max . 성별 . 1 510227.0 | 101.141925 | 24.891629 | 60.0 | 88.0 | 96.0 | 106.0 | 358.0 | . 2 489773.0 | 96.491818 | 20.538645 | 60.0 | 86.0 | 93.0 | 101.0 | 358.0 | . - 남자가 여자보다 공복혈당이 평균 5정도 높고 표준편차가 4정도 높다 . - 혈압과 혈당을 보면 남자가 여자보다 살짝 높은정도를 제외하면 차이가 없다 . - $ text{남자} = text{여자} + alpha$ 와 같이 어느 한쪽으로 나머지를 나타낼 수 있어 보인다 . - 이제껏 분석한 내용을 보면 성별은 그다지 중요한 정보가 아닌것 같다 . - 고혈압_당뇨 진료내역에 따른 공복혈당의 분포를 확인하겠다 . sns.violinplot(x = &#39;고혈압_당뇨_진료내역&#39;, y = &#39;공복혈당&#39;, data = df) . &lt;AxesSubplot:xlabel=&#39;고혈압_당뇨_진료내역&#39;, ylabel=&#39;공복혈당&#39;&gt; . df.groupby(&#39;고혈압_당뇨_진료내역&#39;)[&#39;공복혈당&#39;].describe() . count mean std min 25% 50% 75% max . 고혈압_당뇨_진료내역 . 1 53398.0 | 130.447114 | 40.524698 | 60.0 | 104.0 | 122.0 | 145.0 | 358.0 | . 2 162826.0 | 99.671023 | 16.816511 | 60.0 | 90.0 | 97.0 | 106.0 | 351.0 | . 3 43114.0 | 134.759892 | 45.923753 | 60.0 | 104.0 | 124.0 | 151.0 | 358.0 | . 4 740662.0 | 94.320677 | 15.557456 | 60.0 | 86.0 | 93.0 | 100.0 | 358.0 | . - 4개의 분포 모두 공복혈당이 큰 쪽에 이상점이 매우 많다 . - 고혈압, 당뇨 둘 다 진료내역이 있는 경우와 당뇨 진료내역이 있는 경우의 분포는 당뇨만 있는 경우가 조금 더 넓게 퍼진것을 빼면 동일하다 . - 분포의 중심은 125인것으로 보인다 . - 고혈압, 당뇨 둘 다 진료내역이 없는 경우와 고혈압만 있는 경우의 분포는 고혈압만 있는 경우가 조금 더 넓게 퍼진것을 빼면 동일하다 . - 분포의 중심은 95인것으로 보인다 . - 당뇨가 있다면 공복혈당이 평균적으로 30정도 높다 . - 위의 그림을 통해 공복혈당의 분포는 당뇨병의 진료내역이 좌지우지하는것으로 보인다(고혈압 진료내역은 거의 영향을 끼치지 못한다) . sns.violinplot(x = &#39;혈압범주&#39;, y = &#39;공복혈당&#39;, data = df) . &lt;AxesSubplot:xlabel=&#39;혈압범주&#39;, ylabel=&#39;공복혈당&#39;&gt; . - 고혈압인 경우 공복혈당이 고혈압이 아닌경우보다 더 높은것으로 보인다 . - 고혈압이 있는 사람들중 공복혈당이 높은 사람이 많다 . &#44277;&#48373;&#54792;&#45817; &#44256;&#52272; . - 위에서 공복혈당 분포를 살펴봤는데 당뇨 진료내역이 있지만 공복혈당이 낮은 사람도 있고 당뇨 진료내역이 없지만 공복혈당이 높은사람도 있었다 . - 당뇨 진료내역이 있지만 공복혈당이 정상범주안에 있는 사람은 혈당조절을 잘하고 있는것으로 간주할 수 있을 것 같다 . - 이들의 비율을 확인하겠다 . - 당뇨병의 진단에 있어 혈당치의 기준은 공복 혈당치 126 mg/dL 이상(고혈당)이라고 한다 . - 참고 : https://www.diabetes.or.kr/general/class/index.php?idx=5 . - 위에서 기준을 넘어가는 혈당을 가진 사람들은 고혈당으로 그렇지 않는 사람은 정상혈당으로 간주하겠다 . - 공복혈당이 너무 낮으면(60 mg/dL이하) 저혈당으로 간주하나 거의 최소값이 60 mg/dL임으로 무시하겠다 . def g(x): if x &gt;= 126: y = &#39;고혈당&#39; else: y = &#39;정상혈당&#39; return y . df[&#39;혈당범주&#39;] = list(map(g, df[&#39;공복혈당&#39;])) . df.head() . 성별 연령대 수축기혈압 이완기혈압 공복혈당 고혈압_당뇨_진료내역 BMI 혈압범주 혈당범주 . 0 1 | 20대초반 | 116 | 78 | 94 | 4 | 16.6 | 정상혈압 | 정상혈당 | . 1 1 | 20대초반 | 100 | 60 | 79 | 4 | 22.3 | 정상혈압 | 정상혈당 | . 2 1 | 20대초반 | 100 | 60 | 87 | 4 | 21.9 | 정상혈압 | 정상혈당 | . 3 1 | 20대초반 | 111 | 70 | 72 | 4 | 20.2 | 정상혈압 | 정상혈당 | . 4 1 | 20대초반 | 120 | 80 | 98 | 4 | 20.0 | 정상혈압 | 정상혈당 | . count = df.groupby(&#39;혈당범주&#39;).size() . plt.pie(x = count, labels = [&#39;고혈당&#39;, &#39;정상혈당&#39;], autopct = &#39;%.2f%%&#39;) plt.show() . - 정상혈당은 약 93%, 고혈당은 약 7% 이다 . tab = pd.crosstab(df[&#39;혈당범주&#39;], df[&#39;고혈압_당뇨_진료내역&#39;]) tab.apply(lambda x: x*100 / sum(x), axis = 0) . 고혈압_당뇨_진료내역 1 2 3 4 . 혈당범주 . 고혈당 44.911794 | 5.178534 | 47.938025 | 2.412976 | . 정상혈당 55.088206 | 94.821466 | 52.061975 | 97.587024 | . - 위를 보면 고혈압_당뇨 둘 다 없는경우 2.5%정도는 혈당에 문제가 있는것을 알 수 있다 . - 앞서 봤던 고혈압(12%)에 비하면 매우 적은 수치이다 . - 고혈압만 있는 경우 고혈당인 경우는 5%정도로 고혈압 당뇨 둘다 없는경우와 비슷한 수치이다 . - 당뇨 진료내역이 있는 경우 고혈당인 경우는 47%정도이다 . - 고혈압 진료내역이 있는 경우 고혈압인 경우는 31%정도였다 . - 이와 비교하면 고혈압에서 정상혈압에 속하는 것보다 고혈당에서 정상혈당에 속하는것이 흔치않음을 알 수 있다 . - 전체 인구를 혈압, 혈당에 따라 나타내 확인하겠다 . tab = pd.crosstab(df[&#39;혈압범주&#39;], df[&#39;혈당범주&#39;]) tab*100 / 1000000 . 혈당범주 고혈당 정상혈당 . 혈압범주 . 고혈압 1.7877 | 11.7447 | . 저혈압 0.0918 | 2.5864 | . 정상혈압 5.2159 | 78.5735 | . - 전체 중 고혈당은 8%, 고혈압은 12%이다 . - 혈압, 혈당 모두 정상인 사람은 78%이다 . - 결론 : 당뇨가 고혈압보다 흔하며 당뇨인 사람중 고혈압인 비율보다 고혈압인 사람중 당뇨인 비율이 더 낮다 . &#54792;&#50517;, &#54792;&#45817; &#48276;&#51452; vs &#44256;&#54792;&#50517;, &#45817;&#45544; &#51652;&#47308;&#45236;&#50669; . - 한가지 의문점이 든다 . - 위에서 봤듯이 고혈압, 당뇨 진료내역이 있다고 현재도 고혈압, 당뇨인것은 아니다 . - 그러면 고혈압, 당뇨 진료내역은 쓸모있는지가 의문이다 . - 그냥 혈압, 혈당 범주로 대체하면 될것같다 . - 고혈압, 당뇨 진료내역에 따라 수축기혈압에 차이가 있었다 . - 그런데 이 차이가 그냥 고혈압에 의한것이라면?? . - 고혈압 진료내역이 있으면 혈압이 정상범주더라도 높은쪽에 위치할것이라 생각했다 . - 이것이 아니라면 굳이 애매모호한 고혈압 진료내역 대신에 혈압범주를 사용하는것이 좋을것이다(당뇨도 마찬가지) . - 이를 평균 차이 검정을 통해 확인하겠다 . - 혈압(수축기, 이완기)과 혈당에 대해 특정 값에 데이터가 많이 몰려있어 정규분포는 아닌것처럼 보이지만 . - 표본크기가 매우 크고 종모양이기에 t검정을 실시하겠다 . - 우선 등분산인지 검정하겠다 . &#49688;&#52629;&#44592; &#54792;&#50517; . sns.boxplot(data = df.query(&#39;혈압범주 == &quot;정상혈압&quot;&#39;), y = &#39;수축기혈압&#39;, x = &#39;고혈압_당뇨_진료내역&#39;) . &lt;AxesSubplot:xlabel=&#39;고혈압_당뇨_진료내역&#39;, ylabel=&#39;수축기혈압&#39;&gt; . x_B = df.query(&#39;(혈압범주 == &quot;정상혈압&quot; and 고혈압_당뇨_진료내역 == 1) or (혈압범주 == &quot;정상혈압&quot; and 고혈압_당뇨_진료내역 == 2)&#39;)[&#39;수축기혈압&#39;] x_NB = df.query(&#39;(혈압범주 == &quot;정상혈압&quot; and 고혈압_당뇨_진료내역 == 3) or (혈압범주 == &quot;정상혈압&quot; and 고혈압_당뇨_진료내역 == 4)&#39;)[&#39;수축기혈압&#39;] # print(stats.bartlett(x_B, x_NB)) print(stats.levene(x_B, x_NB)) . LeveneResult(statistic=3281.337451885476, pvalue=0.0) . - p-value가 0이다 . - 그러니 이분산 가정하에 t검정을 실시하겠다 . np.mean(x_B),np.mean(x_NB) . (123.56359921833364, 117.8503658501316) . t_stat, pvalue = stats.ttest_ind(x_B, x_NB, equal_var = True, alternative = &#39;greater&#39;) . print(t_stat, pvalue) . 183.60168146108893 0.0 . - t통계량에 근거한 p-value가 0이다 . - 정상혈압 범주에 속하더라도 고혈압 진료내역이 있는 경우 그렇지 않은 경우보다 . - 평균 수축기혈압이 높다고 할 수 있다 . sns.boxplot(data = df.query(&#39;혈압범주 == &quot;고혈압&quot;&#39;), y = &#39;수축기혈압&#39;, x = &#39;고혈압_당뇨_진료내역&#39;) . &lt;AxesSubplot:xlabel=&#39;고혈압_당뇨_진료내역&#39;, ylabel=&#39;수축기혈압&#39;&gt; . x_B = df.query(&#39;(혈압범주 == &quot;고혈압&quot; and 고혈압_당뇨_진료내역 == 1) or (혈압범주 == &quot;고혈압&quot; and 고혈압_당뇨_진료내역 == 2)&#39;)[&#39;수축기혈압&#39;] x_NB = df.query(&#39;(혈압범주 == &quot;고혈압&quot; and 고혈압_당뇨_진료내역 == 3) or (혈압범주 == &quot;고혈압&quot; and 고혈압_당뇨_진료내역 == 4)&#39;)[&#39;수축기혈압&#39;] # print(stats.bartlett(x_B, x_NB)) print(stats.levene(x_B, x_NB)) . LeveneResult(statistic=5.967971491616882, pvalue=0.014569299214451329) . - p-value가 0.015이다 . - 그러니 이분산 가정하에 t검정을 실시하겠다 . np.mean(x_B),np.mean(x_NB) . (146.45712425457612, 143.02040002952248) . t_stat, pvalue = stats.ttest_ind(x_B, x_NB, equal_var = False, alternative = &#39;greater&#39;) . print(t_stat, pvalue) . 56.10982828533957 0.0 . - t통계량에 근거한 p-value가 0이다 . - 고혈압 범주에 속하더라도 고혈압 진료내역이 있는 경우 그렇지 않은 경우보다 . - 평균 수축기혈압이 높다고 할 수 있다 . sns.boxplot(data = df.query(&#39;혈압범주 == &quot;저혈압&quot;&#39;), y = &#39;수축기혈압&#39;, x = &#39;고혈압_당뇨_진료내역&#39;) . &lt;AxesSubplot:xlabel=&#39;고혈압_당뇨_진료내역&#39;, ylabel=&#39;수축기혈압&#39;&gt; . x_B = df.query(&#39;(혈압범주 == &quot;저혈압&quot; and 고혈압_당뇨_진료내역 == 1) or (혈압범주 == &quot;저혈압&quot; and 고혈압_당뇨_진료내역 == 2)&#39;)[&#39;수축기혈압&#39;] x_NB = df.query(&#39;(혈압범주 == &quot;저혈압&quot; and 고혈압_당뇨_진료내역 == 3) or (혈압범주 == &quot;저혈압&quot; and 고혈압_당뇨_진료내역 == 4)&#39;)[&#39;수축기혈압&#39;] # print(stats.bartlett(x_B, x_NB)) print(stats.levene(x_B, x_NB)) . LeveneResult(statistic=294.86340294030697, pvalue=9.754371916406274e-66) . - p-value가 0이다 . - 그러니 이분산 가정하에 t검정을 실시하겠다 . np.mean(x_B),np.mean(x_NB) . (108.05237887385421, 100.26552611163285) . t_stat, pvalue = stats.ttest_ind(x_B, x_NB, equal_var = False, alternative = &#39;greater&#39;) . print(t_stat, pvalue) . 32.08308134495256 1.7389384139189746e-190 . - t통계량에 근거한 p-value가 0이다 . - 저혈압 범주에 속하더라도 고혈압 진료내역이 있는 경우 그렇지 않은 경우보다 . - 평균 수축기혈압이 높다고 할 수 있다 . &#51060;&#50756;&#44592; &#54792;&#50517; . sns.boxplot(data = df.query(&#39;혈압범주 == &quot;정상혈압&quot;&#39;), y = &#39;이완기혈압&#39;, x = &#39;고혈압_당뇨_진료내역&#39;) . &lt;AxesSubplot:xlabel=&#39;고혈압_당뇨_진료내역&#39;, ylabel=&#39;이완기혈압&#39;&gt; . x_B = df.query(&#39;(혈압범주 == &quot;정상혈압&quot; and 고혈압_당뇨_진료내역 == 1) or (혈압범주 == &quot;정상혈압&quot; and 고혈압_당뇨_진료내역 == 2)&#39;)[&#39;이완기혈압&#39;] x_NB = df.query(&#39;(혈압범주 == &quot;정상혈압&quot; and 고혈압_당뇨_진료내역 == 3) or (혈압범주 == &quot;정상혈압&quot; and 고혈압_당뇨_진료내역 == 4)&#39;)[&#39;이완기혈압&#39;] # print(stats.bartlett(x_B, x_NB)) print(stats.levene(x_B, x_NB)) . LeveneResult(statistic=2356.370080988216, pvalue=0.0) . np.mean(x_B),np.mean(x_NB) . (75.8151400030064, 73.81038696243168) . t_stat, pvalue = stats.ttest_ind(x_B, x_NB, equal_var = False, alternative = &#39;greater&#39;) . print(t_stat, pvalue) . 98.5367189947476 0.0 . sns.boxplot(data = df.query(&#39;혈압범주 == &quot;고혈압&quot;&#39;), y = &#39;이완기혈압&#39;, x = &#39;고혈압_당뇨_진료내역&#39;) . &lt;AxesSubplot:xlabel=&#39;고혈압_당뇨_진료내역&#39;, ylabel=&#39;이완기혈압&#39;&gt; . x_B = df.query(&#39;(혈압범주 == &quot;고혈압&quot; and 고혈압_당뇨_진료내역 == 1) or (혈압범주 == &quot;고혈압&quot; and 고혈압_당뇨_진료내역 == 2)&#39;)[&#39;이완기혈압&#39;] x_NB = df.query(&#39;(혈압범주 == &quot;고혈압&quot; and 고혈압_당뇨_진료내역 == 3) or (혈압범주 == &quot;고혈압&quot; and 고혈압_당뇨_진료내역 == 4)&#39;)[&#39;이완기혈압&#39;] # print(stats.bartlett(x_B, x_NB)) print(stats.levene(x_B, x_NB)) . LeveneResult(statistic=886.1776754493117, pvalue=4.221002676847139e-194) . np.mean(x_B),np.mean(x_NB) . (88.67230944524186, 90.75784190715181) . t_stat, pvalue = stats.ttest_ind(x_B, x_NB, equal_var = False, alternative = &#39;greater&#39;) . print(t_stat, pvalue) . -43.85799935873388 1.0 . sns.boxplot(data = df.query(&#39;혈압범주 == &quot;저혈압&quot;&#39;), y = &#39;이완기혈압&#39;, x = &#39;고혈압_당뇨_진료내역&#39;) . &lt;AxesSubplot:xlabel=&#39;고혈압_당뇨_진료내역&#39;, ylabel=&#39;이완기혈압&#39;&gt; . x_B = df.query(&#39;(혈압범주 == &quot;저혈압&quot; and 고혈압_당뇨_진료내역 == 1) or (혈압범주 == &quot;저혈압&quot; and 고혈압_당뇨_진료내역 == 2)&#39;)[&#39;이완기혈압&#39;] x_NB = df.query(&#39;(혈압범주 == &quot;저혈압&quot; and 고혈압_당뇨_진료내역 == 3) or (혈압범주 == &quot;저혈압&quot; and 고혈압_당뇨_진료내역 == 4)&#39;)[&#39;이완기혈압&#39;] # print(stats.bartlett(x_B, x_NB)) print(stats.levene(x_B, x_NB)) . LeveneResult(statistic=15.370482832670643, pvalue=8.85777173868185e-05) . np.mean(x_B),np.mean(x_NB) . (56.317765168048886, 56.322322485811114) . t_stat, pvalue = stats.ttest_ind(x_B, x_NB, equal_var = False, alternative = &#39;greater&#39;) . print(t_stat, pvalue) . -0.07423781188396941 0.5295867869938078 . - 이완기혈압은 수축기혈압과 다른 양상을 보였다 . - 정상혈압에 속하는 경우를 제외하면 고혈압 진료내역이 있는 경우 그렇지 않은 경우보다 . - 이완기혈압이 더 높다고 할 수 없다 . &#44277;&#48373;&#54792;&#45817; . sns.boxplot(data = df.query(&#39;혈당범주 == &quot;고혈당&quot;&#39;), y = &#39;공복혈당&#39;, x = &#39;고혈압_당뇨_진료내역&#39;) . &lt;AxesSubplot:xlabel=&#39;고혈압_당뇨_진료내역&#39;, ylabel=&#39;공복혈당&#39;&gt; . x_B = df.query(&#39;(혈당범주 == &quot;고혈당&quot; and 고혈압_당뇨_진료내역 == 1) or (혈당범주 == &quot;고혈당&quot; and 고혈압_당뇨_진료내역 == 3)&#39;)[&#39;공복혈당&#39;] x_NB = df.query(&#39;(혈당범주 == &quot;고혈당&quot; and 고혈압_당뇨_진료내역 == 2) or (혈당범주 == &quot;고혈당&quot; and 고혈압_당뇨_진료내역 == 4)&#39;)[&#39;공복혈당&#39;] # print(stats.bartlett(x_B, x_NB)) print(stats.levene(x_B, x_NB)) . LeveneResult(statistic=723.8340005554786, pvalue=1.234539994480611e-158) . - p-value가 0.015이다 . - 그러니 이분산 가정하에 t검정을 실시하겠다 . np.mean(x_B),np.mean(x_NB) . (165.37926091825307, 152.71555656934308) . t_stat, pvalue = stats.ttest_ind(x_B, x_NB, equal_var = False, alternative = &#39;greater&#39;) . print(t_stat, pvalue) . 41.82511929437937 0.0 . - t통계량에 근거한 p-value가 0이다 . - 고혈당 범주에 속하더라도 당뇨 진료내역이 있는 경우 그렇지 않은 경우보다 . - 평균 공복혈당이 높다고 할 수 있다 . sns.boxplot(data = df.query(&#39;혈당범주 == &quot;정상혈당&quot;&#39;), y = &#39;공복혈당&#39;, x = &#39;고혈압_당뇨_진료내역&#39;) . &lt;AxesSubplot:xlabel=&#39;고혈압_당뇨_진료내역&#39;, ylabel=&#39;공복혈당&#39;&gt; . x_B = df.query(&#39;(혈당범주 == &quot;정상혈당&quot; and 고혈압_당뇨_진료내역 == 1) or (혈당범주 == &quot;정상혈당&quot; and 고혈압_당뇨_진료내역 == 3)&#39;)[&#39;공복혈당&#39;] x_NB = df.query(&#39;(혈당범주 == &quot;정상혈당&quot; and 고혈압_당뇨_진료내역 == 2) or (혈당범주 == &quot;정상혈당&quot; and 고혈압_당뇨_진료내역 == 4)&#39;)[&#39;공복혈당&#39;] # print(stats.bartlett(x_B, x_NB)) print(stats.levene(x_B, x_NB)) . LeveneResult(statistic=7492.881978979407, pvalue=0.0) . - p-value가 0.015이다 . - 그러니 이분산 가정하에 t검정을 실시하겠다 . np.mean(x_B),np.mean(x_NB) . (103.95798465157533, 93.5627473825332) . t_stat, pvalue = stats.ttest_ind(x_B, x_NB, equal_var = False, alternative = &#39;greater&#39;) . print(t_stat, pvalue) . 171.357714380074 0.0 . - t통계량에 근거한 p-value가 0이다 . - 정상혈당 범주에 속하더라도 당뇨 진료내역이 있는 경우 그렇지 않은 경우보다 . - 평균 공복혈당이 높다고 할 수 있다 . - plot을 그려보고 가설검정을 통해 진료내역이 영향을 끼치는 것을 알 수 있었다 . - 이제 BMI의 분포를 확인하겠다 . BMI . sns.histplot(data = df, x = &#39;BMI&#39;, hue = &#39;성별&#39;, binwidth = 0.5) . &lt;AxesSubplot:xlabel=&#39;BMI&#39;, ylabel=&#39;Count&#39;&gt; . - 종모양인 것 같지만 오른쪽으로 꼬리가 조금 길다 . - BMI도 다른 양적변수와 마찬가지로 남자가 여자보다 조금 더 높은것을 제외하면 동일하다 . - BMI의 분포를 혈압범주, 혈당범주에 따라 시각화해보자 . sns.boxplot(x = &#39;혈압범주&#39;, y = &#39;BMI&#39;, data = df) . &lt;AxesSubplot:xlabel=&#39;혈압범주&#39;, ylabel=&#39;BMI&#39;&gt; . df.groupby(&#39;혈압범주&#39;)[&#39;BMI&#39;].describe() . count mean std min 25% 50% 75% max . 혈압범주 . 고혈압 135324.0 | 25.242038 | 3.448873 | 14.8 | 22.9 | 25.0 | 27.3 | 40.3 | . 저혈압 26782.0 | 21.835046 | 2.736182 | 14.8 | 19.9 | 21.6 | 23.5 | 38.0 | . 정상혈압 837894.0 | 23.634720 | 3.213817 | 14.8 | 21.4 | 23.4 | 25.6 | 40.3 | . - 고혈압은 정상혈압보다 BMI가 평균적으로 1.6 크다 . - 정상혈압은 저혈압보다 BMI가 평균적으로 1.8 크다 . sns.boxplot(x = &#39;혈당범주&#39;, y = &#39;BMI&#39;, data = df) . &lt;AxesSubplot:xlabel=&#39;혈당범주&#39;, ylabel=&#39;BMI&#39;&gt; . df.groupby(&#39;혈당범주&#39;)[&#39;BMI&#39;].describe() . count mean std min 25% 50% 75% max . 혈당범주 . 고혈당 70954.0 | 25.168695 | 3.396526 | 14.8 | 22.9 | 24.9 | 27.1 | 40.3 | . 정상혈당 929046.0 | 23.699806 | 3.266234 | 14.8 | 21.4 | 23.5 | 25.7 | 40.3 | . - 고혈당인 경우 정상혈당보다 BMI가 평균적으로 1.5정도 크다 . - 고혈압과 당뇨가 끼치는 영향을 같이 확인하겠다 . sns.boxplot(x = &#39;고혈압_당뇨_진료내역&#39;, y = &#39;BMI&#39;, data = df) . &lt;AxesSubplot:xlabel=&#39;고혈압_당뇨_진료내역&#39;, ylabel=&#39;BMI&#39;&gt; . - 고혈압 진료내역만 있는 경우가 당뇨 진료내역만 있는 경우보다 BMI가 크다 . - 여기까지 개별 양적변수에 대한 분포를 확인했다 . - 그런데 수축기혈압과 이완기혈압같이 두 변수사이에 관계가 있을 수 있다 . - 그렇기에 산점도를 그려 변수사이에 관계를 확인하겠다 . &#46160; &#48320;&#49688;&#51032; &#49884;&#44033;&#54868; . &#49345;&#44288;&#44288;&#44228; &#54665;&#47148; . - 우선 양적변수간의 상관관계 행렬을 그려보겠다 . corr_df = df.loc[:, (&#39;수축기혈압&#39;, &#39;이완기혈압&#39;, &#39;맥압&#39;, &#39;공복혈당&#39;, &#39;BMI&#39;)] . corr_matrix = corr_df.corr(method = &#39;pearson&#39;) # 상관관계 행렬 . corr_matrix . 수축기혈압 이완기혈압 맥압 공복혈당 BMI . 수축기혈압 1.000000 | 0.743006 | 0.743398 | 0.186501 | 0.304383 | . 이완기혈압 0.743006 | 1.000000 | 0.104699 | 0.138717 | 0.275492 | . 맥압 0.743398 | 0.104699 | 1.000000 | 0.138498 | 0.176977 | . 공복혈당 0.186501 | 0.138717 | 0.138498 | 1.000000 | 0.173688 | . BMI 0.304383 | 0.275492 | 0.176977 | 0.173688 | 1.000000 | . sns.heatmap(corr_matrix, annot = True, cbar = False) . &lt;AxesSubplot:&gt; . - 수축기혈압과 이완기혈압은 상관계수가 0.74로 높다 . - 혈압과 혈당끼리는 상관관계가 강하지 않다 . - BMI와 혈압과는 약한 양의 상관관계가 있다 . - BMI는 혈당보다는 혈압에 영향을 더 받는다 . - 신기한게 맥압은 수축기혈압과 이완기혈압의 차이여서 이완기혈압과의 상관관계가 당연히 크다고 생각했는데 아니었다 . - 맥압과 이완기혈압의 상관계수는 0.1이다(서로 상관이 없는 수준이다) . - 이제 두 변수 사이의 관계를 시각화하겠다 . def jitter(values, i): return values + np.random.normal(i, 0.5, len(values)) . sns.scatterplot(x = jitter(df.수축기혈압, 1), y = jitter(df.이완기혈압, 1), alpha = 0.01, s = 20) . &lt;AxesSubplot:xlabel=&#39;수축기혈압&#39;, ylabel=&#39;이완기혈압&#39;&gt; . - 문제가 있는데 관측치(점의 개수)가 너무 많아 시각화가 제대로 되지 않는다 . - 전체의 1%(10000개) 정도만 무작위 추출하여 산점도를 그려보겠다 . - 참고 : https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sample.html . np.random.seed(2021) df_s = df.sample(frac = 0.01) . ft = df_s[&#39;고혈압_당뇨_진료내역&#39;].value_counts() rft = df_s[&#39;고혈압_당뇨_진료내역&#39;].value_counts() / len(df_s[&#39;고혈압_당뇨_진료내역&#39;]) DIS_table2 = pd.DataFrame({&#39;Freq&#39;: ft, &#39;Relative freq&#39;: rft}) DIS_table2 . Freq Relative freq . 4 7336 | 0.7336 | . 2 1664 | 0.1664 | . 1 560 | 0.0560 | . 3 440 | 0.0440 | . - 원본과 비율이 거의 동일하다 . - 새로운 데이터프레임을 사용해 시각화하겠다 . &#49688;&#52629;&#44592;&#54792;&#50517;&#44284; &#51060;&#50756;&#44592;&#54792;&#50517; . sns.lmplot(x = &#39;수축기혈압&#39;, y = &#39;이완기혈압&#39;, scatter_kws = {&#39;alpha&#39;:0.4, &#39;s&#39;:20}, height = 7, data = df_s) . &lt;seaborn.axisgrid.FacetGrid at 0x21109aacac0&gt; . - 수축기혈압은 90~140, 이완기 혈압은 60~90사이에 데이터가 많이 몰려있다 . model = smf.ols(formula = &#39;이완기혈압 ~ 수축기혈압&#39;, data = df) result = model.fit() result.params # 추정된 직선의 기울기 및 절편 . Intercept 14.887860 수축기혈압 0.499706 dtype: float64 . - 임의로 이완기혈압을 종속변수, 수축기혈압을 독립변수로 설정하고 회귀선을 추정하면 다음과 같다 . - 추정된 회귀선 : $ widehat{ text{이완기혈압}}=14.887860+0.499706 times text{수축기혈압}$ . - 이를 통해 수축기혈압이 1단위 올라갈 때 이완기혈압은 0.5단위 올라간다는 것을 알 수 있다 . - 위에서 수축기혈압에 대해 얘기할 때 수축기혈압의 증가폭(10)이 이완기혈압의 증가폭(5)보다 더 크다고 했었다 . - 이를 추정된 회귀선을 통해 해석하면 수축기혈압이 10mmHg 상승했으니 이완기혈압이 5mmHg 상승했다고 할 수 있다 . - 근데 사실 시각화의 목적은 진료내역에 따른 차이를 확인하는 것이다 . - 고혈압_당뇨 진료내역을 색깔변수로 하여 산점도를 그려보겠다 . lmplot = sns.lmplot(x = &#39;수축기혈압&#39;, y = &#39;이완기혈압&#39;, hue = &#39;고혈압_당뇨_진료내역&#39;, scatter_kws = {&#39;alpha&#39;:0.4, &#39;s&#39;:20}, height = 7, data = df_s) for lh in lmplot._legend.legendHandles: lh.set_alpha(1) lh._sizes = [50] . str_ = [&#39;고혈압, 당뇨&#39;, &#39;고혈압&#39;, &#39;당뇨&#39;, &#39;없음&#39;] for i in [1, 2, 3, 4]: model = smf.ols(formula = &#39;이완기혈압 ~ 수축기혈압&#39;, data = df.query(&#39;고혈압_당뇨_진료내역 == @i&#39;)) result = model.fit() print(str_[i-1]) print(result.params) # 추정된 직선의 기울기 및 절편 print(&#39;-&#39;) . 고혈압, 당뇨 Intercept 24.020584 수축기혈압 0.416237 dtype: float64 - 고혈압 Intercept 20.632209 수축기혈압 0.455056 dtype: float64 - 당뇨 Intercept 20.112536 수축기혈압 0.450584 dtype: float64 - 없음 Intercept 11.217272 수축기혈압 0.532116 dtype: float64 - . - 진료내역이 없는 경우 회귀선의 기울기가 고혈압 진료내역이 있는 경우 회귀선의 기울기보다 더 크다 . - 즉 고혈압 진료내역이 있는 경우 진료내역이 없는 경우보다 수축기혈압이 상승했을 때 이완기혈압의 상승폭이 작다는 의미이다 . - 고혈압, 당뇨병 진료내역 둘다 없는 사람들의 경우 수축기혈압은 80~140, 이완기 혈압은 50~90사이에 데이터가 많이 몰려있다 . - 우선 고혈압_당뇨가 진료내역이 2(고혈압만)인 경우와 1(둘 다 있음)인 경우 비슷한 산점도를 보인다 . - 그런데 고혈압_당뇨가 진료내역이 3(당뇨만)인 경우 고혈압_당뇨 진료내역이 1,2인 경우보다 이완기혈압과 수축기혈압이 낮은쪽에 점이 위치하고 있음을 알 수 있다 . &#49688;&#52629;&#44592;&#54792;&#50517;&#44284; &#44277;&#48373;&#54792;&#45817; . lmplot = sns.lmplot(x = &#39;수축기혈압&#39;, y = &#39;공복혈당&#39;, hue = &#39;고혈압_당뇨_진료내역&#39;, scatter_kws = {&#39;alpha&#39;:0.4, &#39;s&#39;:20}, height = 7, data = df_s) for lh in lmplot._legend.legendHandles: lh.set_alpha(1) lh._sizes = [50] . - 고혈압, 당뇨 진료내역 둘 다 없는 경우 산점도를 보면 공복혈당은 60~140 수축기혈압은 90~150사이에 대부분의 데이터가 존재한다 . - 당뇨 진료내역은 없고 고혈압 진료내역만 있는 경우 확실히 당뇨 진료내익이 있는 경우보다 공복혈당이 낮은곳에 데이터가 분포함을 확인할 수 있다 . - 고혈압 진료내역만 있는 경우는 고혈압, 당뇨 진료내역 둘 다 없는 경우의 산점도와 비슷하다 . - 당뇨 진료내역이 있다면 추가로 고혈압 진료내역이 있다고해서 산점도가 달라지지는 않는것으로 보이며 둘이 비슷하다 . - 추세선을 보면 당뇨 진료내역 유무에 따른 차이가 확실히 보인다 . - 당뇨 진료내역 없다면 공복혈당은 확실히 낮다 . - 당뇨병은 혈당으로 판단하기에 당연한 결과이긴 하다 . &#49688;&#52629;&#44592;&#54792;&#50517;&#44284; BMI . lmplot = sns.lmplot(x = &#39;수축기혈압&#39;, y = &#39;BMI&#39;, hue = &#39;고혈압_당뇨_진료내역&#39;, scatter_kws = {&#39;alpha&#39;:0.4, &#39;s&#39;:20}, height = 7, data = df_s) for lh in lmplot._legend.legendHandles: lh.set_alpha(1) lh._sizes = [50] . str_ = [&#39;고혈압, 당뇨&#39;, &#39;고혈압&#39;, &#39;당뇨&#39;, &#39;없음&#39;] for i in [1, 2, 3, 4]: model = smf.ols(formula = &#39;BMI ~ 수축기혈압&#39;, data = df.query(&#39;고혈압_당뇨_진료내역 == @i&#39;)) result = model.fit() print(str_[i-1]) print(result.params) # 추정된 직선의 기울기 및 절편 print(&#39;-&#39;) . 고혈압, 당뇨 Intercept 22.524843 수축기혈압 0.021394 dtype: float64 - 고혈압 Intercept 22.313435 수축기혈압 0.019930 dtype: float64 - 당뇨 Intercept 18.758148 수축기혈압 0.044647 dtype: float64 - 없음 Intercept 14.351341 수축기혈압 0.076078 dtype: float64 - . - 위의 회귀선을 보면 진료내역이 없는 경우의 기울기가 크고 . - 고혈압 진료내역 있는 경우의 기울기는 작다 . - 하지만 절편을 보면 고혈압 진료내역이 있는 경우가 진료내역이 없는 경우보다 더 크다 . - 이는 진료내역이 없는 경우 변동성이 꽤 있어 기울기가 크고 . - 고혈압 진료내역이 있는 경우 기본적으로 BMI가 높으므로 더 높아지기 어려우니 기울기가 작다고 볼 수 있다 . - 한편 고혈압, 당뇨 진료내역 둘 다 없는 경우 산점도를 보면 BMI은 17~30 수축기혈압은 90~150사이에 대부분의 데이터가 존재하며 . - 진료내역이 있는 경우보다 BMI와 수축기혈압이 낮은곳에 더 많은 데이터가 분포한다 . - 산점도를 보면 당뇨 진료내역만 있는 경우 수축기혈압이 낮은 곳에 데이터가 분포하고 있으며 . - BMI도 고혈압 진료내역이 있는 경우보다 낮은 곳에 분포함을 알 수 있다 . - 당뇨 진료내역만 있는 경우 수축기혈압은 90~140, BMI는 17~30사이에 데이터가 몰려있다 . - 고혈압 진료내역이 있는 경우에는 수축기혈압은 100~160, BMI는 17~33사이에 데이터가 몰려있다 . - 고혈압 진료내역만 있는 경우와 둘 다 있는 경우의 분포는 서로 유사하다 . - 추세선을 보면 약한 양의 상관관계가 있긴하다 . - 당뇨 진료내역만 있는 경우 추세선의 기울기 조금더 가파르다 . - 당뇨 진료내역만 있는 경우의 데이터가 고혈압 진료내역만 있는 경우의 데이터보다 덜 퍼져있어서 그런것으로 보인다 . &#51060;&#50756;&#44592;&#54792;&#50517;&#44284; &#44277;&#48373;&#54792;&#45817; . lmplot = sns.lmplot(x = &#39;이완기혈압&#39;, y = &#39;공복혈당&#39;, hue = &#39;고혈압_당뇨_진료내역&#39;, scatter_kws = {&#39;alpha&#39;:0.4, &#39;s&#39;:20}, height = 7, data = df_s) for lh in lmplot._legend.legendHandles: lh.set_alpha(1) lh._sizes = [50] . - 고혈압, 당뇨 진료내역 둘 다 없는 경우 산점도를 보면 공복혈당은 60~140 이완기혈압은 50~90사이에 대부분의 데이터가 존재한다 . - 당뇨 진료내역은 없고 고혈압 진료내역만 있는 경우 확실히 당뇨 진료내역이 있는 경우보다 공복혈당이 낮은곳에 데이터가 분포함을 확인할 수 있다 . - 고혈압 진료내역만 있는 경우는 고혈압, 당뇨 진료내역 둘 다 없는 경우의 산점도와 비슷하다 . - 당뇨 진료내역이 있다면 추가로 고혈압 진료내역이 있다고해서 산점도가 달라지지는 않는것으로 보이며 둘이 비슷하다 . - 추세선을 보면 당뇨 진료내역 유무에 따른 차이가 확실히 보인다 . - 당뇨 진료내역이 없다면 공복혈당은 확실히 낮다 . - 이완기혈압은 혈압의 일종이며 상관계수도 높기에 수축기혈압과 거의 동일한 양상을 보였다 . &#51060;&#50756;&#44592;&#54792;&#50517;&#44284; BMI . lmplot = sns.lmplot(x = &#39;이완기혈압&#39;, y = &#39;BMI&#39;, hue = &#39;고혈압_당뇨_진료내역&#39;, scatter_kws = {&#39;alpha&#39;:0.4, &#39;s&#39;:20}, height = 7, data = df_s) for lh in lmplot._legend.legendHandles: lh.set_alpha(1) lh._sizes = [50] . str_ = [&#39;고혈압, 당뇨&#39;, &#39;고혈압&#39;, &#39;당뇨&#39;, &#39;없음&#39;] for i in [1, 2, 3, 4]: model = smf.ols(formula = &#39;BMI ~ 이완기혈압&#39;, data = df.query(&#39;고혈압_당뇨_진료내역 == @i&#39;)) result = model.fit() print(str_[i-1]) print(result.params) # 추정된 직선의 기울기 및 절편 print(&#39;-&#39;) . 고혈압, 당뇨 Intercept 21.618056 이완기혈압 0.047214 dtype: float64 - 고혈압 Intercept 22.023624 이완기혈압 0.036128 dtype: float64 - 당뇨 Intercept 19.093825 이완기혈압 0.068319 dtype: float64 - 없음 Intercept 16.095016 이완기혈압 0.098144 dtype: float64 - . - 위의 회귀선을 보면 수축기혈압의 경우와 마찬가지로 진료내역이 없는 경우의 기울기가 크고 . - 고혈압 진료내역 있는 경우의 기울기는 작다 . - 하지만 절편을 보면 고혈압 진료내역이 있는 경우가 진료내역이 없는 경우보다 더 크다 . - 이는 진료내역이 없는 경우 변동성이 꽤 있어 기울기가 크고 . - 고혈압 진료내역이 있는 경우 기본적으로 BMI가 높으므로 더 높아지기 어려우니 기울기가 작다고 볼 수 있다 . - 한편 고혈압, 당뇨 진료내역 둘 다 없는 경우 산점도를 보면 BMI은 16~30 이완기혈압은 55~90사이에 대부분의 데이터가 존재하며 . - 고혈압 또는 당뇨 진료내역이 있는 경우보다 BMI와 이완기혈압이 낮은곳에 더 많은 데이터가 분포한다 . - 산점도를 보면 당뇨 진료내역만 있는 경우 이완기혈압이 낮은 곳에 데이터가 분포하고 있으며 . - BMI도 고혈압 진료내역이 있는 경우보다 낮은 곳에 분포함을 알 수 있다 . - 당뇨 진료내역만 있는 경우 이완기혈압은 60~90, BMI는 17~28사이에 데이터가 몰려있다 . - 고혈압 진료내역이 있는 경우에는 이완기혈압은 60~100, BMI는 17~33사이에 데이터가 몰려있다 . - 고혈압 진료내역만 있는 경우와 고혈압, 당뇨 진료내역이 둘다 있는 경우의 산점도는 서로 유사하다 . - 추세선을 보면 약한 양의 상관관계가 있긴하다 . - 당뇨 진료내역만 있는 경우 추세선의 기울기 조금더 가파르다 . - 당뇨 진료내역만 있는 경우의 데이터가 고혈압 진료내역만 있는 경우의 데이터보다 덜 퍼져있어서 그런것으로 보인다 . - 이완기혈압과 BMI의 산점도는 수축기혈압과 BMI의 산점도와 비슷한 양상을 보였다 . &#44277;&#48373;&#54792;&#45817;&#44284; BMI . lmplot = sns.lmplot(x = &#39;공복혈당&#39;, y = &#39;BMI&#39;, hue = &#39;고혈압_당뇨_진료내역&#39;, scatter_kws = {&#39;alpha&#39;:0.4, &#39;s&#39;:20}, height = 7, data = df_s) for lh in lmplot._legend.legendHandles: lh.set_alpha(1) lh._sizes = [50] . str_ = [&#39;고혈압, 당뇨&#39;, &#39;고혈압&#39;, &#39;당뇨&#39;, &#39;없음&#39;] for i in [1, 2, 3, 4]: model = smf.ols(formula = &#39;BMI ~ 공복혈당&#39;, data = df.query(&#39;고혈압_당뇨_진료내역 == @i&#39;)) result = model.fit() print(str_[i-1]) print(result.params) # 추정된 직선의 기울기 및 절편 print(&#39;-&#39;) . 고혈압, 당뇨 Intercept 24.775887 공복혈당 0.004156 dtype: float64 - 고혈압 Intercept 22.707251 공복혈당 0.022154 dtype: float64 - 당뇨 Intercept 23.707968 공복혈당 0.004127 dtype: float64 - 없음 Intercept 19.893091 공복혈당 0.037433 dtype: float64 - . - 위의 회귀선을 보면 진료내역이 없는 경우와 고혈압 진료내역 있는 경우 기울기가 크고 . - 당뇨 진료내역 있는 경우의 기울기는 작다 . - 절편도 진료내역이 없는 경우를 제외하면 큰 차이가 있지는 않다 . - 이는 진료내역이 없는 경우 변동성이 꽤 있어 기울기가 크고 . - 당뇨 진료내역이 있는 경우 기본적으로 공복혈당이 높으므로 더 높아지기 어려우니 기울기가 작다고 볼 수 있다 . - 한편 고혈압, 당뇨 진료내역이 없는 산점도를 보면 BMI는 16~33, 공복혈당은 60~130인 구간에 대부분의 데이터가 존재함을 알 수 있다 . - 당뇨 진료내역 유무에 따라 공복혈당에는 큰 차이가 있다 . - 고혈압 진료내역만 있는 경우에 그렇지않은 경우보다 BMI가 더 넓게 퍼져있다 . - 당뇨 진료내역만 있는 경우에는 BMI가 조금 더 좁게 퍼져있는 것으로 보인다 . - 추세선을 보면 당뇨 진료내역만 있는 경우에는 약한 양의 상관관계가 있는 것으로 보여진다 . - 그 외에 경우에는 BMI와 공복혈당은 관계가 없는 것으로 보인다 . &#44208;&#47200; . - 고혈압/당뇨 둘 다 진료내역 없음이 74%로 가장 많이 차지한다 . - 당뇨 진료내역만 있는 경우는 4%, 고혈압 진료내역만 있는 경우는 16%, 둘다 있는 경우는 5%이다 . - 대체로 남자는 여자보다 수축기혈압과 이완기혈압, 맥압, 공복혈당, BMI가 높다 . - 수축기혈압과 이완기혈압의 상관계수는 0.74이고 BMI와 혈압의 상관계수는 약 0.3이다 . - 이들을 제외한 나머지 변수사이의 상관계수는 0.2보다 작은 수준이다 . - 연령대가 높아질수록 수축기혈압, 이완기혈압은 높아지는 경향을 보인다 . - 그러나 이완기혈압의 경우 고혈압, 당뇨 진료내역이 없는 경우를 제외하면 높아지다가 내려가는 경향을 보인다 . - 고혈압 또는 당뇨 진료내역이 있는 사람은 진료내역이 없는 사람과 비교하여 . - 이완기혈압을 제외하면 평균적으로 혈압 또는 혈당이 높다 . - 정상혈압인 경우를 제외하면 오히려 이완기 혈압이 더 낮았다 . - 수축기혈압과 이완기혈압의 분포에서 많은 봉우리를 관찰할 수 있는데 이는 혈압의 끝자리수 편향때문이다 .",
            "url": "https://jaesu26.github.io/study-blog/visualization/2021/10/01/%ED%98%88%EC%95%95%ED%98%88%EB%8B%B9%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D.html",
            "relUrl": "/visualization/2021/10/01/%ED%98%88%EC%95%95%ED%98%88%EB%8B%B9%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D.html",
            "date": " • Oct 1, 2021"
        }
        
    
  
    
        ,"post24": {
            "title": "자료구조 덱",
            "content": "&#45937; (Deque) . - 양쪽 끝에서 삽입과 삭제가 모두 가능한 자료 구조의 한 형태 . - 두 개의 포인터를 사용하여 양쪽에서 삭제와 삽입을 발생 시킬 수 있음 &gt; 큐와 스택을 합친 형태 . - 참고: 자료구조 덱 . &#45937; &#49324;&#50857; . - 파이썬에서 덱은 from collections import deque를 실행한 후 deque()통해 구현할 수 있다 . - deque.append(x)를 통해 덱에 x를 오른쪽(뒤)에 push한다 . - deque.appendleft(x)를 통해 덱에 x를 왼쪽(앞)에 push한다 . - deque.pop()를 통해 덱에서 뒤의 원소를 pop한다 . - deque.popleft()를 통해 덱에서 앞의 원소를 pop한다 . - 참고: deque in python . &#50696;&#51228; . from collections import deque # 덱(deque)를 사용하기 위해 deque 라이브러리 import deque = deque([1, 2, 3, 4, 5]) # 큐(queue) 자료구조 생성 &gt; deque([1, 2, 3, 4, 5]) deque.append(1) # 덱의 뒤에 1 추가 &gt; deque([1, 2, 3, 4, 5, 1]) deque.appendleft(2) # 덱의 앞에 2 추가 &gt; deque([2, 1, 2, 3, 4, 5, 1]) deque.popleft() # 덱에서 앞의 원소를 추출함 &gt; deque([1, 2, 3, 4, 5, 1]) deque.pop() # 덱에서 뒤의 원소를 추출함 &gt; deque([1, 2, 3, 4, 5]) deque . deque([1, 2, 3, 4, 5]) .",
            "url": "https://jaesu26.github.io/study-blog/data%20structure/2021/09/19/%EC%9E%90%EB%A3%8C%EA%B5%AC%EC%A1%B0-%EB%8D%B1.html",
            "relUrl": "/data%20structure/2021/09/19/%EC%9E%90%EB%A3%8C%EA%B5%AC%EC%A1%B0-%EB%8D%B1.html",
            "date": " • Sep 19, 2021"
        }
        
    
  
    
        ,"post25": {
            "title": "행렬",
            "content": "- 참고 교재1 : SAS와 R을 활용한 선형회귀분석(자유아카데미) . - 참고 교재2 : 통계수학강의(자유아카데미) . - 행렬의 기초를 간단히 정리하자 . &#54665;&#47148; (Matrix) . - 행렬(matrix): 아래와 같이 $m$ 개의 행(row) 과 $n$ 개의 열(column) 을 $mn$ 개의 숫자로 채운 모양 . $$ boldsymbol{A} = begin{pmatrix} a_{11} &amp; a_{12} &amp; cdots &amp; a_{1n} a_{21} &amp; a_{22} &amp; cdots &amp; a_{2n} vdots &amp; vdots &amp; ddots &amp; vdots a_{m1} &amp; a_{m2} &amp; cdots &amp; a_{mn} end{pmatrix}$$- 벡터와 행렬은 볼드체로 적어야 함 . - 행렬의 원소는 볼드체 사용 안함 &gt; 행렬의 원소가 벡터 또는 행렬이면 볼드체 사용 . - 행렬의 기본인 벡터를 알고가자 . - 열벡터($ boldsymbol{a}$) : $m times 1$ 행렬 &gt; 보통 벡터라고 하면 열벡터임 . - 행벡터($ boldsymbol{a&#39;}$) : $1 times n$ 행렬 . - 스칼라 : 원소가 하나인 행렬 . - ${ bf 0}$ : 모든 원소가 $0$인 벡터 . - ${ bf 1}$ : 모든 원소가 $1$인 벡터 . - $ boldsymbol{e_i}$ : $i$번째 원소만 $1$이고 나머지 원소는 모두 $0$인 벡터 . &#54665;&#47148;&#51032; &#51333;&#47448; . - 정사각행렬(square matrix) : $m=n$ 인 행렬 . - 대각행렬(diagonal matrix, $ boldsymbol{D}$) : 정사각행렬 중에 대각원소를 제외한 모든 원소가 $0$인 행렬 . - 단위행렬(identity matrix, $ boldsymbol{I}$) : 대각행렬 중에 대각의 원소가 모두 $1$인 행렬 &gt; $ boldsymbol{I_m}$(차수가 $m$) . - 위삼각행렬(upper triangular matrix) : 대각원소와 그 오른쪽 위의 원소를 제외한 나머지 원소는 모두 $0$인 행렬 . - 아래삼각행렬(lower triangular matrix) : 대각원소와 그 왼쪽 아래의 원소를 제외한 나머지 원소는 모두 $0$인 행렬 . - 전치행렬(transpose matrix) : 행과 열이 바뀐 행렬 &gt; $m times n$ 행렬의 전치행렬은 $n times m$ 이 되고 $ boldsymbol{A&#39;}$ 또는 $ boldsymbol A^ top$ 로 표현 . - 대칭행렬(symmetric matrix) : $ boldsymbol{A = A^ top}$ . &#54665;&#47148;&#51032; &#50672;&#49328; . - 행렬의 덧셈 뺄셈은 교재 참고 . &#54665;&#47148;&#51032; &#44273; . - 각 행렬은 행벡터 또는 열벡터로 분할될 수 있음 . - 행렬의 곱 $ boldsymbol{AB}$ 는 행렬 $ boldsymbol A$ 가 $m$ 개의 행벡터로 분할되어 있고 행렬 $ boldsymbol B$ 가 $n$ 개의 열벡터로 분할되어 있다고 할 때 곱의 계산을 나타낸 것 &gt; 교재 참고 . $$ boldsymbol{AB}= begin{pmatrix} { boldsymbol{a_{1 , cdot}}} ,&#39; { boldsymbol{a_{2 , cdot}}} ,&#39; vdots { boldsymbol{a_{m , cdot}}} ,&#39; end{pmatrix} big( boldsymbol{b_{ , cdot ,1}}, , boldsymbol{b_{ , cdot ,2}}, , cdots, , boldsymbol{b_{ , cdot , n}} big) = begin{pmatrix} { boldsymbol{a_{1 , cdot}}} ,&#39; boldsymbol{b_{ , cdot ,1}} &amp; { boldsymbol{a_{1 , cdot}}} ,&#39; boldsymbol{b_{ , cdot ,2}} &amp; cdots &amp; { boldsymbol{a_{1 , cdot}}} ,&#39; boldsymbol{b_{ , cdot ,n}} { boldsymbol{a_{2 , cdot}}} ,&#39; boldsymbol{b_{ , cdot ,1}} &amp; { boldsymbol{a_{2 , cdot}}} ,&#39; boldsymbol{b_{ , cdot ,2}} &amp; cdots &amp; { boldsymbol{a_{2 , cdot}}} ,&#39; boldsymbol{b_{ , cdot ,n}} vdots &amp; vdots &amp; ddots &amp; vdots { boldsymbol{a_{m , cdot}}} ,&#39; boldsymbol{b_{ , cdot ,1}} &amp; { boldsymbol{a_{m , cdot}}} ,&#39; boldsymbol{b_{ , cdot ,2}} &amp; cdots &amp; { boldsymbol{a_{m , cdot}}} ,&#39; boldsymbol{b_{ , cdot ,n}} end{pmatrix}$$ . . - ${ boldsymbol{a_{1 , cdot}}} ,&#39; boldsymbol{b_{ , cdot ,1}}$ 부터 ${ boldsymbol{a_{m , cdot}}} ,&#39; boldsymbol{b_{ , cdot ,n}}$ 까지 각각은 스칼리임 . - 위 식에서 행렬 $ boldsymbol{A}$ 가 $p$ 개의 열벡터로 행렬 $ boldsymbol{B}$ 가 $p$ 개의 행벡터로 분할되어 있다고 하자 . - 그러면 행렬의 곱 $ boldsymbol{AB}$ 는 아래와 같이도 표현 가능함 . $$ boldsymbol{AB}= big( boldsymbol{a_{ , cdot ,1}}, , boldsymbol{a_{ , cdot ,2}}, , cdots, , boldsymbol{a_{ , cdot , p}} big) begin{pmatrix} { boldsymbol{b_{1 , cdot}}} ,&#39; { boldsymbol{b_{2 , cdot}}} ,&#39; vdots { boldsymbol{b_{p , cdot}}} ,&#39; end{pmatrix} = boldsymbol{a_{ , cdot ,1}}{ boldsymbol{b_{1 , cdot}}} ,&#39; + cdots + boldsymbol{a_{ , cdot ,p}}{ boldsymbol{b_{p , cdot}}} ,&#39;$$ . . - $ boldsymbol{a_{ , cdot ,1}}{ boldsymbol{b_{1 , cdot}}} ,&#39;$ 부터 $ boldsymbol{a_{ , cdot ,p}}{ boldsymbol{b_{p , cdot}}} ,&#39;$ 까지 각각은 $p times p$ 행렬임 . &#45824;&#44033;&#54633;(trace) . - 정사각행렬의 특성을 나타내는 수치 . - 행렬의 대각원소의 합 . - $ operatorname{tr}( boldsymbol{A}) = sum limits_{i=1}^{m}a_{ii}$ . &#45824;&#44033;&#54633;&#51032; &#49457;&#51656; . - $ operatorname{tr}( boldsymbol{A}) = operatorname{tr}( boldsymbol{A&#39;})$ . - $ operatorname{tr}( boldsymbol{AB}) = operatorname{tr}( boldsymbol{BA})$ . - 나머지는 간단하니 교재 참고 . &#50669;&#54665;&#47148; . . - 행렬식(determinant) : $ begin{vmatrix} boldsymbol{A} end{vmatrix}$ or $ det( boldsymbol{A})$ . - 행렬 $ begin{vmatrix} boldsymbol{A} end{vmatrix}$ 가 $m times m$ 일 때 $| boldsymbol{A}|= sum limits_{i=1}^{m}(-1)^{i+1}a_{1i} begin{vmatrix} boldsymbol{M_{1i}} end{vmatrix}$ . - $ boldsymbol{M_{ij}}$ 는 행렬 $ boldsymbol{A}$ 에서 $i$ 번째 행과 $j$ 번째 열을 제외한 $(m-1) times(m-1)$ 부분행렬 . - $ boldsymbol{A_{ij}} = (-1)^{i+j} boldsymbol{M_{ij}} longrightarrow boldsymbol{A_{ij}}$ 를 원소 $a_{ij}$ 의 여인수라고 함 . - 행렬 $ boldsymbol{A}$ 의 역행렬의 $(i,j)$ 번째 원소 $ boldsymbol{{(A^{-1})}_{ij}} = cfrac{1}{ begin{vmatrix} boldsymbol{A} end{vmatrix}}(-1)^{i+j} begin{vmatrix} boldsymbol{M_{ij}} end{vmatrix}$ . - 대각행렬, 위삼각행렬, 아래삼각행렬의 행렬식은 대각선 원소들의 곱 . - 특이행렬(singular matrix) : 행렬식이 $0$인 행렬 . - 정칙행렬(nonsingular matrix) : 행렬식이 $0$이 아닌 행렬 . . &#54665;&#47148;&#49885;&#51032; &#49457;&#51656; . - 스칼라 $ alpha$ 와 $m times m$ 행렬 $ boldsymbol{A,B}$ 에 대하여 다음이 성립 . $ det( boldsymbol{A}) = det( boldsymbol{A&#39;})$ . | $ det( alpha boldsymbol{A}) = alpha^{m}( det( boldsymbol{A}))$ . | $ boldsymbol{A}$ 가 대각행렬이면 $ det( boldsymbol{A}) = a_{11} times a_{22} times cdots times a_{mm}$ . | 행렬 $ det( boldsymbol{AB}) = det( boldsymbol{A}) times det( boldsymbol{B})$ . | 정사각행렬 $ boldsymbol{P, ,Q}$ 에 대하여 $ begin{vmatrix} begin{pmatrix} boldsymbol{P} &amp; boldsymbol{0} boldsymbol{X} &amp; boldsymbol{Q} end{pmatrix} end{vmatrix} = begin{vmatrix} boldsymbol{P} end{vmatrix} cdot begin{vmatrix} boldsymbol{Q} end{vmatrix}$ . | . $n$ &#52264; &#50672;&#47549;&#48169;&#51221;&#49885;&#51032; &#54644; . - $n$ 개의 미지수 $(x_1,x_2, cdots,_n)&#39;=x$에 대하여 $n$ 차 연립방정식을 생각해보자 . $$a_{11}x_1 + a_{12}x_2+ cdots+a_{1n}x_n=d_1 a_{21}x_1 + a_{22}x_2+ cdots+a_{2n}x_n=d_2 quad vdots a_{n1}x_1 + a_{n2}x_2+ cdots+a_{nn}x_n=d_n$$- 위의 $n$ 차 연립방정식은 다음과 같이 표현이 가능 $ to boldsymbol{Ax} = boldsymbol{d}$ . - 만약 $ boldsymbol{A^-1}$이 존재하면 $ boldsymbol{A^{-1}Ax} = boldsymbol{A^{-1}d} Longrightarrow boldsymbol{x} = boldsymbol{A^{-1}d}$ . &#50669;&#54665;&#47148;&#51032; &#49457;&#51656; . - 스칼라 $ alpha$ 와 $m times m$ 정칙행렬 $ boldsymbol{A,B}$ 에 대하여 다음을 만족 . $( alpha boldsymbol{A})^{ boldsymbol{-1}}= alpha^{-1} boldsymbol{A^{-1}}$ . | $( boldsymbol{A&#39;})^{ boldsymbol{-1}}=( boldsymbol{A^{-1}})&#39;$ . | $ begin{vmatrix} boldsymbol{A^{-1}} end{vmatrix}= begin{vmatrix} boldsymbol{A} end{vmatrix}^{-1}$ . | $ boldsymbol{A} = operatorname{diag}(a_{11},a_{22}, cdots,a_{mm}) Longrightarrow boldsymbol{A^{-1}} = operatorname{diag}(a_{11}^{ ,-1},a_{22}^{ ,-1}, cdots,a_{mm}^{ ,-1})$ . | $( boldsymbol{AB})^{ boldsymbol{-1}}= boldsymbol{B^{-1}} boldsymbol{A^{-1}}$ . | 정칙행렬 $ boldsymbol{P}, boldsymbol{Q}$ 에 대하여 $ begin{pmatrix} boldsymbol{P} &amp; 0 0 &amp; boldsymbol{Q} end{pmatrix}^{ boldsymbol{-1}} = begin{pmatrix} boldsymbol{P^{-1}} &amp; 0 0 &amp; boldsymbol{Q^{-1}} end{pmatrix}$ . | &#51649;&#44368;&#54665;&#47148; . - 직교행렬(orthogonal matrix) : 정사각행렬 중에 전치행렬이 역행렬인 행렬 $ longrightarrow boldsymbol{A&#39;} = boldsymbol{A^{-1}}$ . &#51649;&#44368;&#54665;&#47148;&#51032; &#51312;&#44148; . $${a_j}&#39;a_j = begin{cases} 1 &amp; text{for $i=j$} 0 &amp; text{for $i neq j$} end{cases}$$ . - 각 열벡터는 길이가 $1$이고 다른 열벡터와 직교한다 &gt; 정규직교벡터 . - $ boldsymbol{P}$ 가 직교행렬이면 $ begin{vmatrix} boldsymbol{PP&#39;} end{vmatrix} = { begin{vmatrix} boldsymbol{P} end{vmatrix}}^{2} = 1$ 이므로 직교행렬의 행렬식은 $ pm 1$ . &#47729;&#46321;&#54665;&#47148; . - 멱등행렬(idempotent matrix) : $ boldsymbol{A}^2= boldsymbol{AA}= boldsymbol{A}$ 를 만족하는 행렬 . - 멱등행렬의 대표적인 예(회귀분석) &gt; $ boldsymbol{H} = boldsymbol{X{(X{ ,&#39;}X)}^{-1}X{ ,&#39;}}$ . - 다양한 예는 교재 참고 . 2&#52264;&#54805;&#49885; . - 2차형식(quadratic form) : 대칭행렬을 사이에 두고 양옆에 같은 벡터가 곱해지는 형태($ boldsymbol{x&#39;Ax}$) . (&#51456;)&#51221;&#48512;&#54840;&#54665;&#47148; . - 모든 벡터 $ boldsymbol{x} neq 0$ 에 대하여 각 조건을 만족시키는 대칭행렬 $ boldsymbol{A}$ 는 다음과 같이 정의함 . $ boldsymbol{x&#39;Ax} &gt; 0$ 이면 $ boldsymbol{A}$ : 양의 정부호행렬(positive definite matrix) &gt; 양정치 . | $ boldsymbol{x&#39;Ax} geq 0$ 이면 $ boldsymbol{A}$ : 양의 준정부호행렬(positive semi-definite matrix) &gt; 양반정치 . | &#48289;&#53552;&#44277;&#44036; . &#48289;&#53552;&#44277;&#44036;(vector space) . - 벡터들을 포함하는 집합 $S$가 다음을 만족하면 벡터공간이라 한다 . 1. $ boldsymbol{0} in S$ . 2. $ boldsymbol{x} in S, ; boldsymbol{y} in S longrightarrow boldsymbol{x}+ boldsymbol{y} in S$ . 3. $ boldsymbol{x} in S longrightarrow alpha boldsymbol{x} in S$ . &#49440;&#54805;&#44208;&#54633; . - 다음과 같은 벡터 $ boldsymbol{v}= sum limits_{i=1}^{n} alpha_i boldsymbol{x_i} $를 벡터 $ boldsymbol{x_1}, cdots, boldsymbol{x_n}$의 선형결합(linear combination)이라고 한다 . &#49373;&#49457;&#51665;&#54633; . - 벡터공간 $S$에 속하는 모든 벡터 $ boldsymbol{s}$에 대해 $ boldsymbol{s}=c_1 boldsymbol{x_1}+ cdots+c_m boldsymbol{x_m}$을 만족하는 . - 벡터 $ boldsymbol{c}=(c_1, cdots,c_m)^ top in mathbb{R}^m$가 존재할 때 $ { boldsymbol{x_1}, cdots, boldsymbol{x_m} }$을 $S$의 생성집합(spanning set)이라고 한다 . - 예컨대 $S_2 = (a,b,a+b)^ top$의 경우 $ {(1,0,1)^ top,(0,1,1)^ top }$가 생성집합의 예가 될 수 있다 . - 두 개의 벡터공간 $S_a,S_b$에 대해 $S_a subset S_b$이면 $S_a$를 $S_b$의 벡터 부분공간(subspace)라고 표현하기도 한다 . &#49440;&#54805;&#46021;&#47549;&#44284; &#49440;&#54805;&#51333;&#49549; . - 벡터공간 $S$에 포함되는 영벡터가 아닌 $m$개의 벡터로 이루어진 집합 $ { boldsymbol{x_1}, cdots, boldsymbol{x_m} }$에 대해 . - $ sum limits_{i=1}^{m} alpha_i boldsymbol{x_i}= boldsymbol{0}$을 만족시키는 벡터 $ alpha neq boldsymbol{0}$가 존재하면 . - $ { boldsymbol{x_1}, cdots, boldsymbol{x_m} }$는 선형종속(linearly dependent)이다 . - $ sum limits_{i=1}^{m} alpha_i boldsymbol{x_i}= boldsymbol{0}$을 만족시키는 벡터 $ alpha neq boldsymbol{0}$가 존재하지 않을 때 . - $ { boldsymbol{x_1}, cdots, boldsymbol{x_m} }$는 선형독립(linearly independent)이다 . . Note: 임의의 벡터집합이 선형종속이기 위한 필요충분조건은 벡터집합의 최소한 하나의 벡터는 다른 벡터들의 선형결합으로 표현되는 것 . &#54665;&#47148;&#51032; &#44228;&#49688; . - 선형독립인 벡터들의 모임 $ boldsymbol{x_1}, cdots, boldsymbol{x_m}$이 벡터공간 $S$의 생성집할일 때 . - 이를 벡터공간 $S$의 기저(basis)라고 하고 벡터의 수 $m$을 벡터공간 $S$의 차원(dimension)이라고 한다 . - 정규직교기저(orthonormal basis) : 벡터공간 $S$의 기저 $B$를 이루는 다음을 만족하는 벡터, $ lVert boldsymbol{x} rVert= 1, lVert boldsymbol{y} rVert = 1, ; boldsymbol{x^ top} boldsymbol{y} = 0, ; forall boldsymbol{x}, boldsymbol{y} in B$ . - 쉽게 말하면 각 벡터의 크기는 $1$이며 벡터들은 서로 직교한다 . &#54665;&#47148;&#51032; &#44228;&#49688;&#50752; &#44288;&#47144;&#46108; &#49457;&#51656; . - $ boldsymbol{A} : m times n$ 행렬, $ boldsymbol{B} : n times p$ 행렬, $ boldsymbol{C} : n times n$ 행렬, $ boldsymbol{H} :$ 멱등행렬 . 1. $ operatorname{rank}( boldsymbol{A}) = operatorname{rank}( boldsymbol {A^ top}) = operatorname{rank}( boldsymbol {AA^ top}) = operatorname{rank}( boldsymbol{A^{ top}A})$ . 2. $ operatorname{rank}( boldsymbol{A}) leq min(m,n)$ . 3. $ operatorname{rank}( boldsymbol{AB}) leq min( operatorname{rank}( boldsymbol{A}), , operatorname{rank}( boldsymbol{B}))$ . 4. $m=n$ 일 때, $ det( boldsymbol{A})=0$이면 $ operatorname{rank}( boldsymbol{A})&lt;m$ . 5. $ operatorname{rank}( boldsymbol{AC}) = operatorname{rank}( boldsymbol{A})$ . 6. $ operatorname{rank}( boldsymbol{H}) = operatorname{tr}( boldsymbol{H})$ . &#44256;&#50976;&#44050;&#44284; &#44256;&#50976;&#48289;&#53552; . - $m times m$ 정사각행렬 $ boldsymbol{A}$에 대하여 $ boldsymbol{0}$이 아닌 벡터 $ boldsymbol{x} in mathbb{R}^m$와 스칼라 $ lambda$가 $ boldsymbol{Ax}= lambda boldsymbol{x}$를 만족할 때 . - $ boldsymbol{x}$를 고유값(eigenvalue) $ lambda$에 대응하는 고유벡터(eigenvector)라고 한다 . - $ boldsymbol{x} neq boldsymbol{0}$에 대하여 $ boldsymbol{Ax}- lambda boldsymbol{Ix}=( boldsymbol{A}- lambda boldsymbol{I}) boldsymbol{x}= boldsymbol{0}$ . - 한편, $ boldsymbol{B}=( boldsymbol{A}- lambda boldsymbol{I})$일 때 만약 $ boldsymbol{B}$의 역행렬이 존재한다면 . - $ boldsymbol{B^{-1}Bx} = boldsymbol{B^{-1}0}$이므로 $ boldsymbol{x}$는 영벡터인데 조건에서 $ boldsymbol{x}$는 영벡터가 아니라고 했으므로 . - $( boldsymbol{A}- lambda boldsymbol{I})$는 특이행렬이고 그 행렬식은 $0$이다 . - 즉 $ operatorname{det}( boldsymbol{A}- lambda boldsymbol{I}) = 0$을 통해 고유값 $ lambda$를 구하고 . - 각 고유값 $ lambda$에 대하여 $ boldsymbol{Ax}= lambda boldsymbol{x}$를 통해 고유벡터 $ boldsymbol{x}$를 구한다 . &#44256;&#50976;&#44050;&#44284; &#44256;&#50976;&#48289;&#53552;&#50640; &#45824;&#54620; &#49457;&#51656; . 1. 행렬 $ boldsymbol{A}$의 고유값과 행렬 $ boldsymbol{A^ top}$의 고유값은 동일하다 . 2. $ lambda_{i}^{k}$는 행렬 $ boldsymbol{A^k}$의 고유값이고 이에 대응하는 고유벡터는 $ boldsymbol{x_i}$이다(고유벡터는 동일함) . 3. $f( boldsymbol{A})$의 고유값은 $f( lambda)$이다(ex : $ boldsymbol{A} to lambda, ; boldsymbol{A^2+A} to lambda^2 + lambda$ . &#54665;&#47148;&#51032; &#48516;&#54644; . &#53945;&#51060;&#44050; &#48516;&#54644;(SVD) . - 임의의 $n times m$ 매트릭스 $ boldsymbol{X}_{n times m}$은 다음과 같은 매트릭스들의 행렬곱으로 나타낼 수 있다 . - $ boldsymbol{X}_{n times m} = boldsymbol{U}_{n times n} boldsymbol{D}_{n times m} boldsymbol{V&#39;}_{m times m}$ . - 여기서 $ boldsymbol{U}, boldsymbol{V}$는 직교행렬이며 $ boldsymbol{D}$는 대각행렬은 아니다 . - 위의 식을 살짝 변형하면 다음과 같이 나타낼 수 있다 . $n geq m$ | $$ boldsymbol{X}_{n times m} = boldsymbol{U}_{n times m} boldsymbol{D}_{m times m} boldsymbol{V&#39;}_{m times m}$$ . - $ boldsymbol{V^ top} boldsymbol{V}= boldsymbol{V} boldsymbol{V^ top}= boldsymbol{I}_{m}$ . - $ boldsymbol{U^ top} boldsymbol{U}= boldsymbol{I}_{n}$ . $n leq m$ | $$ boldsymbol{X}_{n times m} = boldsymbol{U}_{n times n} boldsymbol{D}_{n times n} boldsymbol{V&#39;}_{n times m}$$ . - $ boldsymbol{U^ top} boldsymbol{U}= boldsymbol{U} boldsymbol{U^ top}= boldsymbol{I}_{m}$ . - $ boldsymbol{V^ top} boldsymbol{V}= boldsymbol{I}_{n}$ . 분해 표현 | . $$ boldsymbol{X}_{n times m} = boldsymbol{U} boldsymbol{D} boldsymbol{V^ top}= sum limits_{i=1}^{n wedge m}d_iU_iV_i^ top$$ . &#49828;&#54169;&#53944;&#47100; &#48516;&#54644; . - 모든 원소가 실수인 대칭행렬 $ boldsymbol{A}$(대각화가 가능, 실수인 고유값을 가짐, 고유벡터행렬이 직교행렬)는 다음과 같이 표현이 가능하다 . $$ boldsymbol{A}= boldsymbol{ Psi} boldsymbol{ Lambda} boldsymbol{ Psi^ top}$$ . - 행렬 $ boldsymbol{A}$를 직교대각화(orthogonally diagonalizable)가 가능하다고 부른다 . - 위에서 $ boldsymbol{ Lambda}$는 $ boldsymbol{A}$의 고유값행렬이고 $ boldsymbol{ Psi}$는 $ boldsymbol{A}$의 고유벡터행렬이다 .",
            "url": "https://jaesu26.github.io/study-blog/math/2021/09/16/%ED%96%89%EB%A0%AC.html",
            "relUrl": "/math/2021/09/16/%ED%96%89%EB%A0%AC.html",
            "date": " • Sep 16, 2021"
        }
        
    
  
    
        ,"post26": {
            "title": "Boole's inequality and Bonferroni's inequality",
            "content": "Boole&#39;s inequality . - Boole의 부등식: $P bigg( bigcup limits_{i=1}^{ infty} A_i bigg) leq sum limits_{i=1}^{ infty}P(A_i)$ . Boole&#51032; &#48512;&#46321;&#49885; &#51613;&#47749; . - $B_1=A_1, ,B_2=A_2 cap A^c_1, , cdots, ,B_i = A_i cap bigg( bigcup limits_{j=1}^{i-1}A_j bigg)^c$ . - 사건 $B_i$는 사건 $A_i$에는 속하면서 사건 $A_j ,(1 leq j &lt;i$)에는 속하지 않는다 . - 그렇기에 $B_i$와 $B_j(i neq j)$는 서로 배반 사건임 &gt; 배반 사건이므로 $P( cup B_i) = sum P(B_i)$ . - 그리고 $ cup A_i= cup B_i$ 임을 알 수 있음 . - 또 $B_i subset A_i$ 이므로 $P( cup A_i)= P( cup B_i)= sum P(B_i) leq sum P(A_i)$ 가 성립한다 . Bonferroni&#39;s inequality . - Bonferroni의 부등식: $P bigg( bigcap limits^{k}_{i=1}A_i bigg) geq 1 - sum limits_{i=1}^{k}P(A_i^c)$ . Bonferroni&#51032; &#48512;&#46321;&#49885; &#51613;&#47749; . - 드 모르간의 법칙: $ bigg( bigcap limits_{i=1}^{k}A_i bigg)^c = bigcup limits_{i=1}^{k}A^c_i longrightarrow bigcap limits_{i=1}^{k}A_i= bigg( bigcup limits_{i=1}^{k}A^c_i bigg)^c$ . $P bigg( bigcap limits^{k}_{i=1}A_i bigg) geq 1 - sum limits_{i=1}^{k}P(A_i^c) qquad therefore bigcap limits_{i=1}^{k}A_i= bigg( bigcup limits_{i=1}^{k}A^c_i bigg)^c$ . | $P bigg( bigg( bigcup limits_{i=1}^{k}A^c_i bigg)^c bigg) geq 1 - sum limits_{i=1}^{k}P(A_i^c) qquad therefore P(A^c)=1-P(A)$ . | $1-P bigg( bigcup limits_{i=1}^{k}A^c_i bigg) geq 1 - sum limits_{i=1}^{k}P(A_i^c)$ . | $P bigg( bigcup limits_{i=1}^{k}A^c_i bigg) leq sum limits_{i=1}^{k}P(A_i^c) qquad therefore$ $A^c_i$ 대신 $A_i$ 사용해도 상관없음 . | $P bigg( bigcup limits_{i=1}^{k}A_i bigg) leq sum limits_{i=1}^{k}P(A_i) longrightarrow $ 이 식이 성립하는지 수학적 귀납법을 사용하여 증명하자 . | . - $k=1$일 때 $P(A_1) leq P(A_1)$이므로 성립한다 . - $k=n$일 때 성립한다 가정하고 $k=n+1$일 때도 성립하는지 확인하자 . $P bigg( bigcup limits_{i=1}^{n+1}A_i bigg)= P bigg( bigg( bigcup limits_{i=1}^{n}A_i bigg) cup A_{n+1} bigg) = P bigg( bigcup limits_{i=1}^{n}A_i bigg)+P(A_{n+1})-P bigg( bigg( bigcup limits_{i=1}^{n}A_i bigg) cap A_{n+1} bigg)$ . | $P bigg( bigcup limits_{i=1}^{n+1}A_i bigg) leq P bigg( bigcup limits_{i=1}^{n}A_i bigg) + P(A_{n+1}) qquad therefore P bigg( bigg( bigcup limits_{i=1}^{n}A_i bigg) cap A_{n+1} bigg) geq 0$ . | $P bigg( bigcup limits_{i=1}^{n+1}A_i bigg) leq P bigg( bigcup limits_{i=1}^{n}A_i bigg) + P(A_{n+1}) leq sum limits_{i=1}^{n}P(A_i)+P(A_{n+1})= sum limits_{i=1}^{n+1}P(A_i)$ . | . - 따라서 $k=n+1$일 때도 성립한다 . - 수학적 귀납법에 의해 모든 유한개의 사건 $k$에 대해 $P bigg( bigcap limits^{k}_{i=1}A_i bigg) geq 1 - sum limits_{i=1}^{k}P(A_i^c)$ 가 성립함 . - ref: https://dawoum.ddns.net/wiki/Boole%27s_inequality .",
            "url": "https://jaesu26.github.io/study-blog/statistics/math/2021/09/12/%EB%B6%80%EC%9A%B8-%EB%B3%B8%ED%8E%98%EB%A5%B4%EB%8B%88-%EB%B6%80%EB%93%B1%EC%8B%9D.html",
            "relUrl": "/statistics/math/2021/09/12/%EB%B6%80%EC%9A%B8-%EB%B3%B8%ED%8E%98%EB%A5%B4%EB%8B%88-%EB%B6%80%EB%93%B1%EC%8B%9D.html",
            "date": " • Sep 12, 2021"
        }
        
    
  
    
        ,"post27": {
            "title": "포함배제의 원리",
            "content": "- 수통 과제에 포함배제의 원리 증명이 있는데 헷갈려서 따로 정리함 . &#54252;&#54632;&#48176;&#51228;&#51032; &#50896;&#47532;(&#54869;&#47456;&#51032; &#44221;&#50864;) . - 임의의 유한개의 사건 $A_1, cdots, A_k in S$ 에 대하여 아래가 성립함 . $P Big( bigcup limits^{K}_{i=1}A_i Big) = sum limits_{i=1}^{k}P(A_i) - sum limits_{1 leq i &lt; j leq k}^{k}P(A_i cap A_j) + cdots+(-1)^{k-1}P Big( bigcap limits_{i=1}^{k}A_i Big)$ | . - 이제 증명을 해보자 &gt; 수학적 귀납법을 활용할 것 임 . - $n = 1$일 때 식이 성립함을 증명 &gt; $n=k$일 때 성립한다 가정하고 $n=k+1$일 때 식이 성립함을 증명 . - $n=k$일 때 성립하면 $n=k+1$일 때도 성립한다고 했음 &gt; $n = 1$일 때 성립하면 $n=2$일 때도 성립 &gt; $n = 1$일 때 식이 성립함 &gt; $n=2$일 때 식이 성립 . - 이제 $n=2$일 때 성립하면 $n=3$일 때도 성립 &gt; $n = 2$일 때 식이 성립함 &gt; $n=3$일 때 식이 성립 . - 이런식으로 나아가면 모든 자연수에 대해서 성립함을 알 수 있음 . - $n=1$대신 $n=a$로 바뀐다면 $a$이후의 자연수에 대해서 성립함을 알 수 있음 . &#54252;&#54632;&#48176;&#51228;&#51032; &#50896;&#47532; &#51613;&#47749; . - $A cap B = C to C cap A = C, ; C cap B = C,C cup A = A, ; C cup B = B$ &gt; 당연하지만 알아두자 . - $n=1$일 때 $P(A_1) = P(A_1)$이므로 성립함 . - 이제 $n=k$일 때 성립한다 가정하고 $n=k+1$일 때 성립하는지 살펴보자 . $P bigg( bigcup limits_{i=1}^{k+1}A_i bigg) = P bigg( bigg( bigcup limits_{i=1}^{k}A_i bigg) bigcup A_{k+1} bigg) quad therefore text{나열해서 보면 당연한 소리} = P bigg( bigcup limits_{i=1}^{k}A_i bigg) + P(A_{k+1}) - P bigg( bigg( bigcup limits_{i=1}^{k}A_i bigg) bigcap A_{k+1} bigg) therefore P(X cup Y) = P(X)+P(Y)-P(X cap Y), quad X to bigcup limits^k_{i=1}A_i, ;Y to A_{k+1} =P bigg( bigcup limits_{i=1}^{k}A_i bigg) + P(A_{k+1}) - P bigg( bigcup limits_{i=1}^{k} big(A_i cap A_{k+1} big) bigg) therefore text{집합의 분배법칙,} ; P bigg( bigcup limits_{i=1}^{k} X_i bigg) = sum limits_{i=1}^{k}P(X_i) - sum limits_{1 leq i &lt; j leq k}^{k}P(X_i cap X_j) + cdots+(-1)^{k-1}P bigg( bigcap limits_{i=1}^{k}X_i bigg) = bigg { sum limits_{i=1}^{k}P(A_i) - sum limits_{1 leq i &lt; j leq k}^{k}P(A_i cap A_j) + cdots+(-1)^{k-1}P bigg( bigcap limits_{i=1}^{k}A_i bigg) bigg } +P(A_{k+1})- bigg { sum limits_{i=1}^{k}P(A_i cap A_{k+1}) - sum limits_{1 leq i &lt; j leq k}^{k}P((A_i cap A_{k+1}) cap A_j) + cdots+(-1)^{k-1}P bigg( bigcap limits_{i=1}^{k}(A_i cap A_{k+1}) bigg) bigg } = sum limits_{i=1}^{k}P(A_i) - sum limits_{1 leq i &lt; j leq k}^{k}P(A_i cap A_j) + cdots+(-1)^{k-1}P bigg( bigcap limits_{i=1}^{k}A_i bigg) +P(A_{k+1})- sum limits_{i=1}^{k}P(A_i cap A_{k+1}) + sum limits_{1 leq i &lt; j leq k}^{k}P((A_i cap A_{k+1}) cap A_j) - cdots+(-1)^{k+1-1}P bigg( bigcap limits_{i=1}^{k+1}A_i bigg) therefore- ,(-1)^{k-1}P bigg( bigcap limits_{i=1}^{k}(A_i cap A_{k+1}) bigg) = (-1)^{k+1-1}P bigg( bigcap limits_{i=1}^{k+1}A_i bigg) = sum limits_{i=1}^{k+1}P(A_i) - sum limits_{1 leq i &lt; j leq k+1}^{k+1}P(A_i cap A_j) + cdots+(-1)^{k+1-1}P bigg( bigcap limits_{i=1}^{k+1}A_i bigg) therefore text{그러므로 $n=k+1$일 때도 성립한다}$ | . - 마지막 부분이 이해가 안될 수 도 있음 . - 일단 $ sum limits_{i=1}^{k}P(A_i)$ 와 $P(A_{k+1})$를 더해서 $ sum limits_{i=1}^{k+1}P(A_i)$가 되는것은 알 것임 . - 그건 맞다고 치자 &gt; 그 다음부터는 뭐임?? . - $- sum limits_{1 leq i &lt; j leq k+1}^{k+1}P(A_i cap A_j)$ &gt; 이건 어떻게 도출됨?? . - 아래식을 보자 . - $ - sum limits_{1 leq i &lt; j leq k}^{k}P(A_i cap A_j)- sum limits_{i=1}^{k}P(A_i cap A_{k+1}) = - sum limits_{1 leq i &lt; j leq k+1}^{k+1}P(A_i cap A_j)$ . - 위 식이 성립하는 것만 이해하면 전부다 이해 가능 &gt; 왜 성립함? &gt; 그냥 나열해보면 성립하는 것을 알 수 있음 &gt; 설명을 더 해보자 . - $P bigg( bigcup limits^{K}_{i=1}A_i bigg)$에서 $P bigg( bigcup limits^{K+1}_{i=1}A_i bigg)$로 업그레이드(?)시킬 수 있다는 것은 $n=k$가 성립하면 $n=k+1$일 때 도 성립한다는 뜻 . - 잘보면 왼쪽식에서 오른쪽식으로 나아가기 위해서는 사건$A_{k+1}$과 연관된 식이 있어야 함 . - 예컨데 $k=3$이라고 해보자 . - $ sum limits_{1 leq i &lt; j leq 3}^{3}P(A_i cap A_j)=P(A_1 cap A_2)+P(A_1 cap A_3)+P(A_2 cap A_3) ; cdots text{식 (1)}$ . - 여기서 $k$대신 $k+1$을 넣어보자 . - $ sum limits_{1 leq i &lt; j leq 3+1}^{3+1}P(A_i cap A_j)=P(A_1 cap A_2)+P(A_1 cap A_3)+P(A_1 cap A_4)+P(A_2 cap A_3)+P(A_2 cap A_4)+P(A_3 cap A_4)$ . - 즉 우리에겐 $n=k$일 때는 존재하지 않는 사건 $A_{k+1}$과 연관된 식인 $P(A_1 cap A_4)+P(A_2 cap A_4)+P(A_3 cap A_4) ; cdots text{식 (2)}$가 있어야 $n=k+1$일 때의 식으로 나아갈 수 있음 &gt; 이 식이 바로 $- sum limits_{i=1}^{k}P(A_i cap A_{k+1})$ . - 식 (1)과 식 (2)가 합쳐져서 $n=k+1$일 때의 식을 만들어 내는 것임 . - $ sum limits_{i=1}^{k}P(A_i) - sum limits_{1 leq i &lt; j leq k}^{k}P(A_i cap A_j) + cdots+(-1)^{k-1}P bigg( bigcap limits_{i=1}^{k}A_i bigg)$ &gt; 식 (1)의 역할, $P(A_{k+1})- sum limits_{i=1}^{k}P(A_i cap A_{k+1}) + sum limits_{1 leq i &lt; j leq k}^{k}P((A_i cap A_{k+1}) cap A_j) - cdots+(-1)^{k+1-1}P bigg( bigcap limits_{i=1}^{k+1}A_i bigg)$ &gt; 식 (2)의 역할 . - 위의 두 식($n leq k$까지의 정보와 $n=k+1$일 때의 정보)이 합쳐져서 $P bigg( bigcup limits^{K+1}_{i=1}A_i bigg)= sum limits_{i=1}^{k+1}P(A_i) - sum limits_{1 leq i &lt; j leq k+1}^{k+1}P(A_i cap A_j) + cdots+(-1)^{k+1-1}P bigg( bigcap limits_{i=1}^{k+1}A_i bigg)$ ($n leq k$까지의 정보)가 되는 것임 .",
            "url": "https://jaesu26.github.io/study-blog/statistics/math/2021/09/11/%ED%8F%AC%ED%95%A8%EB%B0%B0%EC%A0%9C%EC%9D%98%EC%9B%90%EB%A6%AC.html",
            "relUrl": "/statistics/math/2021/09/11/%ED%8F%AC%ED%95%A8%EB%B0%B0%EC%A0%9C%EC%9D%98%EC%9B%90%EB%A6%AC.html",
            "date": " • Sep 11, 2021"
        }
        
    
  
    
        ,"post28": {
            "title": "자료구조 큐",
            "content": "&#53328; (Queue) . - 스택(stack)과 반대되는 개념으로 먼저 집어 넣은(push) 데이터가 먼저 나오는(pop) FIFO(First In First Out)구조 . - 참고: 자료구조 큐 . &#53328; &#49324;&#50857; . - 파이썬에서 큐는 from collections import deque를 실행한 후 deque()통해 구현할 수 있다 . - queue.append(x)를 통해 큐에 x를 오른쪽(뒤)에 push한다 . - queue.popleft()를 통해 큐에서 앞의 원소(왼쪽)를 pop한다 . - 참고: queue in python . &#50696;&#51228; . from collections import deque ## 큐(queue)를 사용하기 위해 deque라이브러리 import queue = deque() # 큐(queue) 자료구조 생성 &gt; deque([]) queue.append(1) # 큐에 1 추가 &gt; deque([1]) queue.append(2) # 큐에 2 추가 &gt; deque([1, 2]) queue.popleft() # 큐에서 앞의 원소를 추출함 &gt; 선입선출 구조 &gt; deque([2]) queue . deque([2]) .",
            "url": "https://jaesu26.github.io/study-blog/data%20structure/2021/09/05/%EC%9E%90%EB%A3%8C%EA%B5%AC%EC%A1%B0-%ED%81%90.html",
            "relUrl": "/data%20structure/2021/09/05/%EC%9E%90%EB%A3%8C%EA%B5%AC%EC%A1%B0-%ED%81%90.html",
            "date": " • Sep 5, 2021"
        }
        
    
  
    
        ,"post29": {
            "title": "수리통계학",
            "content": "- 수리통계학 내용 정리 . - 참고 : 수리통계학 제5판 송성주$ cdot$전명식 지음 . &#54869;&#47456;&#51060;&#47200; . - 확률모형 &gt; 동전 던지기와 같이 가능성(chance)에 의존 . &#54364;&#48376;&#44277;&#44036;&#44284; &#49324;&#44148; . - 표본공간(sample space) : 모든 관찰 가능한 결과들의 집합 &gt; $S$ 또는 $ Omega$ . - 사건(event) : 표본공간의 일부분(부분집합) &gt; $A, B$ 등 영어 알파벳 대문자 . - 실험(experiment) 또는 시행(trial) : 어떤 현상의 관찰결과를 얻기위한 과정 . 예시 | . - 동전의 앞면을 H, 뒷면을 T라 할 때 동전을 2회 던지는 실험을 시행하자 . - 표본공간 $S = {HH, HT, TH, TT }$ . - $S$의 원소는 $HH, HT, TH, TT$이다 . - 1회 앞면이 나오는 사건 $A = {HT, TH }$ . - 2회 뒷면이 나오는 사건 $B = {TT }$ . - 참고로 집합을 나타나낼 땐 $ { }$를 사용한다 . - ex) $HT$: $S$의 원소(집합X), $ {HT }$ : $S$의 부분집합(집합O) . - 또한 $HT in S$, $ {HT } subset S$ . 정의 | . - 사건 $A$와 $B$가 동시에 속하는 사건 &gt; $A$와 $B$의 공통부분(intersection) &gt; $A cap B$ . - 사건 $A$ 또는 $B$에 속하는 사건 &gt; $A$와 $B$의 합(union) &gt; $A cup B$ . - $A cap B$ = $ phi$ &gt; 두 사건 $A$와 $B$는 상호배반(mutually exclusive) . - 사건 $A$에 포함되지 않은 모든 $S$의 원소의 집합 &gt; $A$의 여사건(complement) &gt; $A^c$ . 사건에 대한 분배법칙과 드 모르간 법칙 | . - $(A cup B)^c = A^c cap B^c$ &gt; 드 모르간(De Morgan) 법칙 . - $(A cap B)^c = A^c cup B^c$ &gt; 드 모르간 법칙 . - $A cup (B cap C) = (A cup B) cap (A cup C)$ &gt; 분배법칙 . - $A cap (B cup C) = (A cap B) cup (A cap C)$ &gt; 분배법칙 . &#54869;&#47456;&#51032; &#51221;&#51032; . - 확률은 함수임 . 고전적 정의 | . - 표본공간이 유한 개($N$)의 결과로 구성되고 모든 가능한 실험결과들이 일어날 가능성이 동일한경우 $M$개의 실험결과로 이루어진 사건 $A$의 확률 $P(A) = dfrac{M}{N}$ . 상대도수의 극한 | . - 실험을 독립적으로 n회 반복했을 때 사건 $A$의 발생횟수를 m이라 하면 실험이 무한히 반복되면 $P(A) = dfrac{m}{n}$ . &#54869;&#47456; &#44277;&#47532; . 1. 임의의 사건 $A$에 대해 $P(A) geq 0$ . 2. $P(S)=1$ . 3. 표본공간 $S$에 정의된 사건열 $A_1, A_2, cdots$가 있다고 할 때 모든 $i neq j$에 대하여 $A_i cap A_j = phi$이면 $P bigg( bigcup limits_{i=1}^{ infty} A_i bigg) = P(A_1 cup A_2 cup A_3 cup cdots) = sum limits_{i=1}^{ infty} P(A_i)$ . - 3번째 공리는 쉽게 말하자면 서로소인 두 사건 $A$와 $B$에 대해 $P(A) + P(B) = p(A cup B)$이다 + 집합열 이해 안되면 통계수학 책 참고하셈 . - 확률 &gt; 표본공간의 부분집합의 모임(특별한 성질 만족)을 정의역으로 하면서 확률공리를 만족하는 함수 . 정리 | . - 증명은 교재 참고 . 1. $P(A^c) = 1- P(A)$ . 2. $P( phi) = 0$ . 3. $A subset B$이면 $P(A) leq P(B)$ . 4. $P(A cup B)=P(A)+P(B)-P(A cap B)$ . - 정리 4번 사건 3개 버전 . - $P(A cup B cup C) = P(A) + P(B) + P(C) - P(A cap B) - P(B cap C) - P(C cap A) + P(A cap B cap C)$ &gt; 벤 다이어그램을 그려보면 간단히 알 수 있음 . &#51312;&#44148;&#48512; &#54869;&#47456; . - 사건$A$와 $B$가 표본공간 $S$상에 정의되어 있으며 $P(B) &gt; $일 때 $B$가 일어났다는 가정하에 사건 $A$가 일어날 조건부 확률은$P(A mid B) = cfrac{P(A cap B)}{P(B)}$로 정의됨 . - 조건부 확률도 확률 공리를 만족함 . &#51204;&#54869;&#47456; &#44277;&#49885;(total probability) . - 사건 $B_1, B_2, cdots,B_k$ 는 상호배반이며 $(B_1 cap B_j = phi, ;i neq j), ; bigcup limits_{i=1}^{k}B_{i}=S$라고 하자 . - 이때 임의의 사건 $A$에 대하여 $P(A) = sum limits_{i=1}^{k}P(B_i)P(A mid B_i)$가 성립함 . - $P(A) = P(A cap S) = P bigg[A cap bigg( bigcup limits_{i=1}^{k}B_i bigg) bigg] = sum limits_{i=1}^{k}P(A cap B_i)= sum limits_{i=1}^{k}P(B_i)P(A mid B_i)$ . &#48288;&#51060;&#51592; &#51221;&#47532;(Bayes&#39; theorem) . - 사건 $B_1, B_2, cdots,B_k$ 는 상호배반이며 $(B_1 cap B_j = phi, ;i neq j), ; bigcup limits_{i=1}^{k}B_{i}=S$라고 하자 . - 이때 사건 $A$가 일어났다는 조건하에서 사건 $B_j$가 일어날 확률은 $P(B_j mid A)= cfrac{P(B_j)P(A mid B_j)}{ sum limits_{i=1}^{k}P(B_i)P(A mid B_i)}$ . - $P(B_j mid A)= cfrac{P(A cap B_j)}{P(A)}= cfrac{P(B_j)P(A mid B_j)}{P(A)}= cfrac{P(B_j)P(A mid B_j)}{ sum limits_{i=1}^{k}P(B_i)P(A mid B_i)}$ . - $P(B_1), cdots,P(B_k)$는 $B$의 사전확률(prior probability) . - 사건 $A$가 일어났다는 정보가 추가됨 &gt; $P(B_1 mid A), cdots,P(B_k mid A)$는 $B$의 사후확률(posteriori probability) . &#49324;&#44148;&#51032; &#46021;&#47549; . - 두 사건 $A$와 $B$가 $P(A cap B) = P(A) cdot P(B)$를 만족시키면 서로 독립(independent)이다 . &#44221;&#50864;&#51032; &#49688; . &#49692;&#50676;(permutation) . - 서로 다른 n개의 원소 중에서 r개를 선택하여 순서 있게 놓는 것(${_n rm P_r}$) . &#51312;&#54633; . - 서로 다른 n개의 원소 중에서 순서에 관계없이 r개를 선택하는 것($_n rm C_r$) . &#51060;&#54637;&#51221;&#47532; . - $(a+b)^n = sum limits_{k=0}^{n} dbinom{n}{k}a^{k} b^{n-k}$ . &#44057;&#51008; &#44163;&#51060; &#51080;&#45716; &#49692;&#50676; . - $ dbinom{n}{ ;r_1 ; r_2 ; cdots ;r_k ;} = cfrac{n!}{r_1! ; r_2! ; cdots ; r_k!}$ . &#45796;&#54637;&#51221;&#47532; . - $(a_1+a_2+ cdots+a_k)^n= sum limits_{r_1, cdots,r_k in mathbb N}^{r_1+ cdots+r_k=n} dbinom{n}{ ;r_1 ; r_2 ; cdots ;r_k ;} ,a_1^{r_1} ,a_2^{r_2} cdots a_k^{r_k}$ . &#54869;&#47456;&#48320;&#49688; . - 확률변수(random variable) : 실험결과를 표현하는 수치적인 양 . - 확률변수의 값은 실험결과에 따라 정해지므로 비결정적(non-deterministic) . - 확률분포(probability distribution) : 확률변수의 값들이 나올 가능성 . &#54869;&#47456;&#48320;&#49688;&#51032; &#51221;&#51032; . - 확률변수 : 표본공간 $ Omega$에 정의된 실수값을 가지는 함수(real-valued function) $ to$ $X: Omega to mathbb{R}$ . - 예컨대 $X( omega)=x$, 참고로 $x$를 realization(실현)이라고 한다 . - 이산형(discrete) - 가질 수 있는 값이 유한개 (finite) 또는 셀 수 있는 무한개(countably infinite)인 확률변수 . - 연속형(continuous) - 가질 수 있는 값의 범위가 실직선상의 어떤 구간인 확률변수 . - 혼합형 - ex) $ {1, 2, (5, 10) }$ . &#54869;&#47456;&#44277;&#44036;(probability space) . - 확률 공간($ Omega, mathcal{F}, Pr)$은 전체 측도가 $1$인 측도 공간이다 . - 측도는 집합에 크기를 부여하기 위해 만든 개념으로 가산집합에 실수로 가는 함수를 부여한 것 . - 확률적인 현상에서 확률공간의 측도는 확률을 정의한다 . - 확률공간이 같다는건 $ Omega$가 동일하고 (주사위 던지기 $ Omega= {1,2,3,4,5,6 }$) . - $ mathcal{F}$가 동일하고(예컨대 짝수, 홀수에만 관심이 있어서 $ mathcal{F}= { phi, {1,3,5 }, {2,4,6 }, Omega }$) . - $Pr$이 동일하다는 것(예컨대 짝수, 홀수가 나올 가능성이 다른 주사위라 확률측도가 다음과 같다) . $$ begin{aligned} Pr( phi)&amp;=0.0 Pr( {1,3,5 })&amp;=0.4 Pr( {2,4,6 })&amp;=0.6 Pr( Omega)&amp;=1.0 end{aligned}$$ . - 참고 : https://ko.wikipedia.org/wiki/%ED%99%95%EB%A5%A0_%EA%B3%B5%EA%B0%84 . &#54364;&#48376;&#44277;&#44036; . - 확률실험에서 발생할 수 있는 모든 결과들의 집합을 표본공간(Sample Space) 이라고 한다 . - 표본공간은 $S$ 또는 $ Omega$ 기호로 나타낸다 . - $ Omega= { omega_1, omega_2, cdots, omega_n }$는 가능한 모든 결과를 포함하고 각 원소끼리는 배반이다 . - 예컨대 동전던지기 실험에서 표본공간은 다음과 같이 나타낼 수 있음 &gt; $ Omega= {H,T }$ . - 참고 : https://en.wikipedia.org/wiki/Sample_space . &#49324;&#44148;&#44277;&#44036; . - 표본공간 $ Omega$의 $ sigma$-field를 사건공간(event space) 이라 한다 . - 사건공간의 원소를 사건이라고 한다 . - 사건 : 표본공간의 부분집합 . - 사건공간($ mathcal{F}$) : 사건의 집합 $ Longleftrightarrow$ 표본공간의 $ sigma$-field . - 동전던지기의 경우 사건은 $ phi, {H }, {T }, Omega$이므로 사건공간 중 하나를 다음과 같이 나타낼 수 있음 . - $ mathcal{F}= { phi, {H }, {T }, Omega }$ &gt; $ mathcal{F}$의 원소 하나하나가 사건에 해당함 . - 사건공간 중 하나라고 표현한건 $ sigma$-field 정의에 의해 사건공간은 여러개가 될 수 있기 때문 . - 예컨대 주사위 던지기의 경우에서 주사위의 특정값이 아닌 단지 짝인지 홀인지에만 관심이 있으면 $ mathcal{F}= { phi, {1,3,5 }, {2,4,6 }, Omega }$로 설정해도 된다 . - 참고 : https://en.wikipedia.org/wiki/%CE%A3-algebra . &#54869;&#47456;&#52769;&#46020; . - 측도공간 $( Omega, mathcal{F})$에 대해서 어떤 함수 $ Pr: mathcal{F} to [0,1]$가 다음 세 조건(확률 공리)을 만족하면 $ Pr$을 확률측도라고 한다 . 1. $ Pr(A) geq 0, quad forall A in mathcal{F}$ . 2. $ Pr( Omega)=1$ . 3. Countable, pairwise disjoint set $ {A_1,A_2, cdots mid A_i in mathcal{F} }$에 대하여 $ Pr bigg( bigcap limits_{i=1}^{ infty}A_i bigg)= sum limits_{i=1}^{ infty} Pr(A_i)$ . - 예컨대 동전던지기의 사건공간이 $ mathcal{F}= { phi, {H }, {T }, Omega }$ 라면 위의 조건을 만족하는 확률측도를 아래와 같이 만들 수 있다 . $$ begin{aligned} Pr( phi)&amp;=0.0 Pr( {H })&amp;=0.5 Pr( {T })&amp;=0.5 Pr( Omega)&amp;=1.0 end{aligned}$$ . - 위의 경우 함수 $ Pr(A)$는 $ cfrac{ text{집합 $A$의 원소 개수}}{ text{표본공간 $ Omega$의 원소 개수}}$로 정의된다고 할 수 있다 . - 바로 위의 $ Pr$정의에 따르면 동전 던지기나 주사위 굴리기 같은 것은 $ Pr$이 동일하다 . - 그러나 확률측도는 위의 세 조건인 Kolmogorov axioms를 만족하기만 하면 되기에 확률측도는 하나가 아니다 . - 예컨대 아래와 같이 확률측도를 일반적이지 않게 만들 수 도 있다는 것 . $$ begin{aligned} Pr( phi)&amp;=0.0 Pr( {H })&amp;=0.4 Pr( {T })&amp;=0.6 Pr( Omega)&amp;=1.0 end{aligned}$$ . - 참고로 함수 $ Pr$의 정의역은 $ mathcal{F}$이고 치역은 $ {s in R:0 leq s leq 1 }$이다 . - 참고 : https://gem763.github.io/probability%20theory/%ED%99%95%EB%A5%A0%EC%9D%98-%EC%9D%B4%ED%95%B4.html . - 그런데 $ Pr$이랑 $P$랑 다른거야? &gt; https://stats.stackexchange.com/questions/108441/which-notation-and-why-textp-pr-textprob-or-mathbbp . &#54869;&#47456;&#44277;&#44036; &#52628;&#44032; &#51221;&#47532; . - 찾아볼수록 더 헷갈려서 추가로 정리함 . - 틀릴 수 있음 . - Q1 : 확률변수 $X_1$과 $X_2$가 동일한 확률공간에서 정의될 때 둘의 CDF는 다를 수 있는가? . - 확률공간이 같은데 둘의 CDF가 다르다라...... . - 가능하다 . - $ Omega = {T }$라고 하자 . - 즉 확률실험에서 발생할 수 있는 모든 결과가 $ {T }$ 하나다 &gt; 예컨대 앞면 뒷면 둘다 학이 그려진 동전을 던진다면 항상 학만 나올 것임 . - $ mathcal{F}= { phi, Omega }$라고 하자 . - 그러면 $ Pr( Omega)=1, ; Pr( phi)=0$ &gt; 확률공리를 만족시켜야 하니까 . - 이제 $X_1=0,X_2=2$라고 하자($X_1(T)=0,X_2(T)=2$와 동일함) . - 확률변수 $X_1$과 $X_2$는 같은 확률공간에서 정의됐으며 둘의 차이점이라곤 $ Omega$의 원소 $T$를 $0$으로 맵핑하냐 $2$로 맵핑하냐 뿐이다 . - 자 $X_1&gt;1$일 확률과 $X_2&gt;1$일 확률이 같은가? &gt; 아니다 $ Pr(X_1&gt;1)=0, ; Pr(X_2&gt;1)=1$이다 . - 그러니 CDF는 다르다 . - $ Pr(X_1&gt;1)=0, ; Pr(X_2&gt;1)=1$을 보고 둘다 $X&gt;1$일 확률인데 값이 다르니 $ Pr$도 다르다고 하면 안된다 . - $X_1&gt;1 = phi$이고 $X_2&gt;1= Omega$이다, $ Pr( phi)$와 $ Pr( Omega)$는 당연히 다르다 . - 하지만 $ Pr$은 동일하다($ Pr( phi)=0$, $ Pr( Omega)=1$) . - 다른 예시도 있음 . - 주사위던지기를 생각하자 . - $ Omega= {1,2,3,4,5,6 }$ 이고 $ mathcal{F}= { phi, {1 }, {2 }, {3 }, {4 }, {5 }, {6 }, Omega }$라 하자 . - 즉 주사위를 한번 던져서 나온 결과에만 관심이 있음 . - 그리고 $ Pr( { omega })= dfrac{1}{6}, ,1 leq omega leq 6$ . - 확률변수 $X( omega)=I( text{$ omega$ is odd})$라 하고 $Y( omega)= omega$라고 하자 . - 즉 확률변수 $X$는 주사위를 던져서 나온값이 홀수이면 $1$로 맵핑하고 짝수이면 $0$으로 맵핑한다 . - 반면 확률변수 $Y$는 주사위를 던져서 나온값으로 맵핑한다(확률변수 $Y$는 항등함수) . - 확률변수 $X$와 $Y$는 같은 확률공간을 가진다, 둘의 차이점이라곤 주사위를 던져서 나온값을 어떤 실수로 맵핑하냐 뿐이다 . - 하지만 둘의 cdf는 다르다 . $$F_X(x)= begin{cases}0, quad x&lt;0 frac{1}{2}, quad 0 leq x &lt;1 1, quad x geq 1 end{cases}$$ . $$F_Y(y)= begin{cases}0, quad y&lt;1 [5pt] dfrac{1}{6}, quad 1 leq y &lt;2 [7pt] dfrac{2}{6}, quad 2 leq y &lt;3 [7pt] dfrac{3}{6}, quad 3 leq y &lt;4 [7pt] dfrac{4}{6}, quad 4 leq y &lt;5 [7pt] dfrac{5}{6}, quad 5 leq y &lt;6 [5pt] 1, quad y geq 6 end{cases}$$- 참고로 cdf뿐만 아니라 pdf도 다르다 . - 참고 : https://math.stackexchange.com/questions/2596665/x-and-y-are-defined-on-the-same-probability-space-omega-mathcalf-ma?rq=1 . - Q2 : 확률변수 $X$가 임의의 확률분포를 따른다는건 무슨 의미일까? . - 예컨대 $X sim B(10,0.5)$ . - 내 생각 : $X$의 pdf는 $B(10,0.5)$이다 . - 또한 등호($=$)를 쓰지않고 $ sim$을 쓰는건 확률변수는 시행마다 다른 값을 가질 수 있기 때문이다 . &#54869;&#47456;(probability) . - 확률공간 $( Omega, mathcal{F}, Pr)$과 특정사건 $A in mathcal{F}$에 대하여 $Pr(A)$을 사건 $A$의 확률이라고 한다 . &#54869;&#47456;&#48128;&#46020;&#54632;&#49688;(pdf) &#48143; &#45572;&#51201;&#48516;&#54252;&#54632;&#49688;(cdf) . &#54869;&#47456;&#48128;&#46020;&#54632;&#49688;(probability density function, pdf) . - 참고하면 좋은 것: https://en.wikipedia.org/wiki/Probability_density_function . &#51060;&#49328;&#54805;&#51032; &#44221;&#50864; pdf&#51032; &#51312;&#44148; . 1. 모든 실수 $x$에 대하여 $f(x) geq 0$ . 2. 확률변수 $X$가 가질 수 있는 값 $x_1, ,x_2, , cdots$ 에 대하여 $f(x_i)&gt;0$ 이며 $ sum f(x_i)=1$ . - $f(x)$는 $P(X=x)=f(x)$ 를 만족하고 확률질량함수(probability mass function, pmf)라고도 함 . &#50672;&#49549;&#54805;&#51032; &#44221;&#50864; pdf&#51032; &#51312;&#44148; . 1. 모든 실수 $x$에 대하여 $f(x) geq 0$ . 2. $ int^{ infty}_{- infty}f(x) ,dx = 1$ . - 연속형 확률변수는 가질 수 있는 값이 셀 수 없는 무한개이므로 가능한 값 하나하나에 확률을 부여하지 않음 . - 대신에 구간에 확률을 부여함 . - $P(X=x)=0$ 이고 $- infty &lt; a &lt; b &lt; infty longrightarrow int_{a}^{b}f(x) ,dx=P(a leq X leq b)$ . pdf 헷갈려서 정리 | . - $X$를 전북대학생들의 맥박수를 실수로 맵핑하는 함수라고 하자 . - $ Omega = {x:x in A }$, 여기서 $A$는 맥박수로 가능한 실수의 집합이라고 하자 . - 맥박수에서 평균을 뺀다든가 할 수 있지만 측정한 맥박수를 그 자체로 맵핑한다고 생각하자(별다른 처리를 하지 않음) . - 그러면 $X$는 $X:A to A$인 항등함수이다 . - 맥박수의 분포가 평균이 $ mu$, 분산이 $ sigma^2$인 정규분포를 따른다고 가정하자 . - 그러면 $f_X(x; mu, sigma^2) = dfrac{1}{ sqrt{2 pi sigma^{2}}}e^{- dfrac{(x- mu)^{2}}{2 sigma^{2}}}$ 이다 . - 그러면 전북대학생들의 맥박수를 측정하는 것 부터 이에 대한 분포(pdf)를 구하는 것 까지의 과정은 아래와 같다(내 생각) . - input: $ Omega$ (전북대학생들의 맥박수로 가질 수 있는 모든 값들의 집합), function: $X$ (항등함수), output: $A(= Omega)$ . - input: $A$, function: $f_X$ (pdf), output: $f(x; mu, sigma^2) = dfrac{1}{ sqrt{2 pi sigma^{2}}}e^{- dfrac{(x- mu)^{2}}{2 sigma^{2}}}$ . - 참고로 $f_X$는 위의 pdf조건을 만족하기만 하면 되므로 무수히 많다(그런데 여기서는 정규분포로 가정한 것) . - 이를 한번에 정리하면 아래와 같다(잘 알아두자) . - $ Omega xrightarrow{~~X~~} A xrightarrow{~~f_X~~} dfrac{1}{ sqrt{2 pi sigma^{2}}}e^{- dfrac{(x- mu)^{2}}{2 sigma^{2}}}$ . - 만약, $X$대신 $X+1$의 pdf를 구하면 $f_{X+1}(x; mu, sigma^2) = dfrac{1}{ sqrt{2 pi sigma^{2}}}e^{- dfrac{(x+1- mu)^{2}}{2 sigma^{2}}}$ 이다 . - 여기서 $X$도 함수이고 $+1$도 함수인데 적용 순서는 아래와 같을 것이다 . - $ Omega xrightarrow{~~X~~} A xrightarrow{~~+1~~} B$ (맥박수를 측정하고 항등함수를 취하고 여기에 1을 더한다) . - 이제 궁금한 점(함수 적용 순서를 바꾸면 안되나?) . - $ Omega xrightarrow{~~+1~~} B xrightarrow{~~X~~} B$ (맥박수를 측정하고 1을 더하고 여기에 항등함수를 취한다) . - $X$가 항등함수니까 결과가 똑같지 만약 제곱을 취하는 함수였다면 다른 결과가 나오게 된다 . - 안되는 이유(이건 진짜 내 생각): 만약 $ Omega$의 원소가 수가 아니라면 연산이 불가능하다 . - 위의 예시처럼 real number 라면?: 먼저 적용하는 함수를 확률변수로 취급하자 . - $ Omega xrightarrow{~~+1(=f)~~} B xrightarrow{~~X~~} B$는 아래와 같이 해석할 수 있음 . - $X$가 항등함수가 아니라 표본 공간에 각 원소에 $+1$을 한 값으로 맵핑하고 $f$가 항등함수인 것 . - 아무튼 확률변수 $X$를 먼저 적용하고 후에 다른 함수를 적용한다 . 간략하게 다시 정리 | . - 확률변수 $X$에 임의의 연산을 하는 함수 $f$를 생각하자 . - 그러면 $f(X)$도 당연히 확률변수인데 이를 생각해보면 $f$는 $X$의 output에 적용한다 . - 애초에 확률변수 $X$에 연산을 하는 것이 아니라 표본공간에 연산을 한다고 생각할 수도 있는데 . - 표본공간에 연산을 취해서 실수로 맵핑하는 함수가 확률변수임(사실 이건 좀 그렇고(+1이 확률변수는 아니니까...)) . - 그냥 표본공간에 $+1$ 할 이유가 없음... . - 사실 확률변수 $X$는 $X( omega)$를 간략히 나타낸 것임 . - 따라서 $X + 1 = X( omega) + 1$이므로 당연히 아웃풋에 $1$을 더하는게 맞다 . 위치모수와 척도모수 | . - 확률변수 $X$가 분포A를 따를때 $X + b$도 분포A를 따르면 분포A는 위치모수를 가진다 . - 확률변수 $X$가 분포B를 따를때 $aX$도 분포B를 따르면 분포B는 척도모수를 가진다 . - 확률변수 $X$가 분포C를 따를때 $aX+b$도 분포C를 따르면 분포C는 위치모수와 척도모수를 가진다 . - 정규분포는 위치모수와 척도모수를 둘 다 가지는데 . - 예컨대 확률변수 $X$가 정규분포를 따른다면 $X+1$이나 $2X$도 정규분포를 따른다 . - $g(X)$의 pdf를 구하는 방식은 누적분포함수를 이용 또는 결합 확률밀도함수(자코비안) 이용 . &#45572;&#51201;&#48516;&#54252;&#54632;&#49688;(cumulative distribution function, cdf) . - 누적분포함수 $F(x) = P(X leq x)$ . - $X sim f(x)$ : 확률변수 $X$가 확률밀도함수 $f(x)$를 가진다 . - $X sim F(x)$ : 확률변수 $X$가 누적분포함수 $F(x)$를 가진다 . - $P(a&lt; X leq b) = F(b) - F(a)$ . - $f(x) = dfrac{d}{dx}F(x)$ . &#45572;&#51201;&#48516;&#54252;&#54632;&#49688;&#51032; &#51312;&#44148; . 1. $ lim limits_{x to- infty}F(x)=0$ . 2. $ lim limits_{x to infty}F(x)=1$ . 3. $ lim limits_{h to0+}F(x+h)=F(x) longrightarrow$ 우연속 함수 . 4. $a&lt;b$ 이면 $F(a) leq F(b)$ . &#44208;&#54633; &#48143; &#51312;&#44148;&#48512; &#54869;&#47456;&#48516;&#54252; . &#44208;&#54633; &#54869;&#47456;&#48516;&#54252; . - 여러 개의 확률변수들을 한번에 고려하는 경우에 사용 &gt; ex) 아빠와 아들의 키를 함께 고려 . - 확률벡터 &gt; $ boldsymbol{X} = (X_1, ,X_2, , cdots, ,X_k)$ . - 두 확률변수 $X$와 $Y$의 결합 확률밀도함수 $f_{ ,X, ,Y}(x,y)$ . - 이산형인 경우 : $f_{ ,X, ,Y}(x,y)=P(X=x, ,Y=y)$ . - 연속형인 경우 : 임의의 영역 $A$에 대하여 $P[(X, ,Y) in A]= iint_{ ,A}f_{ ,X, ,Y}(x,y) ,dxdy$ 를 만족하는 $f_{ ,X, ,Y}(x,y)$ . - 통계수학 교재의 통계학에서의 적분과 미분적분학 교재의 적분 공부하기 . &#44208;&#54633; &#45572;&#51201;&#48516;&#54252;&#54632;&#49688; . - 결합 누적분포함수 : $F(x_1, ,x_2, , cdots, ,x_k) = P(X_1 leq x_1, ,X_2 leq x_2, , cdots, ,X_k leq x_k)$ . - $f(x_1, ,x_2, , cdots, ,x_k) = cfrac{ partial^k}{ partial x_1 cdots partial x_k}F(x_1, ,x_2, , cdots, ,x_k)$ . &#51452;&#48320; &#54869;&#47456;&#48516;&#54252; . - 결합분포가 주어졌다고 하자 그런데 각 변수만의 분포가 필요할 수 있음 . - 결합 확률밀도함수 $f_{X,Y}(x,y)$가 주어졌을 때 $f_X(x), ;f_Y(y)$를 주변 확률밀도함수라고 함 . - 주변 확률밀도함수 &gt; marginal probability density function . 이산형인 경우 | . $$f_X(x) = sum limits_{ text{모든 $y$}}f_{X,Y}(x,y), quad f_Y(y) = sum limits_{ text{모든 $x$}}f_{X,Y}(x,y)$$ . 연속형인 경우 | . $$f_X(x) = int^{ infty}_{- infty}f_{X,Y}(x,y) ,dy, quad f_Y(y) = int^{ infty}_{- infty}f_{X,Y}(x,y) ,dx$$ . - 여러개의 확률변수에 대해서도 확장 가능함 . &#51312;&#44148;&#48512; &#54869;&#47456;&#48516;&#54252; . - 조건부 확률의 확률변수 버전 . - 어떤 몇 개의 확률변수 값이 주어졌을 때 다른 확률변수들의 분포 . - $X=x$가 주어졌을 때 $Y mid X=x$의 조건부 확률밀도함수는 $f_{Y mid x}(y mid x)$ 이다 . - 편의상 $Y mid X = x Longleftrightarrow Y mid x$ . - 조건부 확률밀도함수 &gt; conditional probability density function . $$f_{Y mid X=x}(y mid x)= cfrac{f_{X,Y}(x,y)}{f_X(x)} qquad text{단, } f_X(x)&gt;0$$ . - 그런데 $f(x mid theta)$와 $f(x; theta)$는 다른거야? &gt; https://stats.stackexchange.com/questions/10234/meaning-of-probability-notations-pzd-w-and-pzd-w . &#46021;&#47549;&#54869;&#47456;&#48320;&#49688; . - 두 확률변수 $X$와 $Y$는 임의의 실구간 $A$와 $B$에 대하여 $$ P(X in A, ,Y in B)=P(X in A) cdot P(Y in B)$$ 가 성립할 때 서로 독립(independent)이라고 함 . - 위의 정리를 확률밀도함수를 사용하여 나타내보자 . - 두 확률변수 $X$와 $Y$가 서로 독립일 필요충분조건은 $$f_{X,Y}(x,y)=f_X(x) cdot f_Y(y)$$ . - 두 확률변수 $X$와 $Y$의 독립여부 파악하는 방법! . 1. 결합 확률밀도함수를 통해 $X$와 $Y$의 주변 확률밀도함수를 구한다 . 2. 그리고 $f_{X,Y}(x,y)=f_X(x) cdot f_Y(y)$가 성립하는지 확인한다 . . Tip: 쉬운방법은 $f_{X,Y}(x,y)$가 $X$만의 함수와 $Y$만의 함수로 인수분해 되는지 파악하는 것 . &#44592;&#45843;&#44050; . - 확률변수 $X$의 확률밀도함수가 $f(x)$일 때 $X$의 기댓값(expectation)은 $$E(X)= begin{cases} sum limits_{ text{모든 }x_i}x_{i}f(x_i) quad text{이산형인 경우} int_{- infty}^{ infty}xf(x) ,dx quad text{연속형인 경우} end{cases}$$ . - 단 $E(|X|)&lt; infty$ . - 확률변수 $X$의 기댓값이 아닌 $2X+3$이나 $X^2$ 같은 확률변수의 기댓값이 궁금할 수 있다 . - $Y=g(X)$의 확률밀도함수를 $f_Y(y)$라고 하면 $$E_X[g(X)]=E_Y(Y)= begin{cases} sum limits_{ text{모든 }y_i}y_{i}f_{Y}(y_i) quad text{이산형인 경우} int_{- infty}^{ infty}yf_{Y}(y) ,dy quad text{연속형인 경우} end{cases}$$ . - 만약 $X$의 확률밀도함수를 알고 있으면 $Y$의 확률밀도함수를 구할 필요가 없다 . $$E_X[g(X)]=E_Y(Y)= begin{cases} sum limits_{ text{모든 }x_i}g(x_{i})f_{X}(x_i) quad text{이산형인 경우} int_{- infty}^{ infty}g(x)f_{X}(x) ,dx quad text{연속형인 경우} end{cases}$$ . - $Y=g(X)$의 기댓값을 구하는 데는 위의 두 가지 방법이 가능함 . &#44592;&#45843;&#44050;&#51032; &#49457;&#51656; . - $E(c)=c$ . - $E(aX+b)=aE(X)+b$ . - 두 확률변수 $X$와 $Y$가 서로 독립인 경우 . - $E(XY)=E(X) cdot E(Y)$ . - $E[g(X) cdot h(Y)]=E[g(X)] cdot E[h(Y)]$ . &#48516;&#49328;&#44284; &#44277;&#48516;&#49328; . $$Var(X)=E[X-E(X)]^2=E(X^2)-[E(X)]^2 sigma_{X}= sqrt{Var(X)}$$ - 두 확률변수 $X,Y$의 공분산은 다음과 같다 . $$ begin{aligned}Cov(X,Y)&amp;=E[(X-EX)(Y-EY)] &amp;=E(XY)-E(X)E(Y) end{aligned}$$ &#48516;&#49328;&#51032; &#49457;&#51656; . 1. $Var(aX+b)=a^2Var(X)$ . 2. 확률변수들이 서로 독립이면 $Var bigg( sum limits^{n}_{i=1}X_{i} bigg)= sum limits^{n}_{i=1}Var(X_i)$ . 3. $Cov(X,X)=Var(X)$ . 4. 두 확률변수가 서로 독립이면 $Cov(X,Y)=0$ . 5. $Cov(aX+b,cY+d)=acCov(X,Y)$ . 6. $Var bigg( sum limits^{n}_{i=1}X_{i} bigg)= sum limits^{n}_{i=1}Var(X_{i})+2 mathop{ sum sum} limits_{j&lt;k}Cov(X_j,X_k)$ . &#51312;&#44148;&#48512; &#44592;&#45843;&#44050; . $$E(Y mid X=x)=E_Y(Y)= begin{cases} sum limits_{ text{모든 }y_i}y_{i}f_{Y mid x}(y_i mid x) quad X,Y text{가 이산형인 경우} int_{- infty}^{ infty}yf_{Y mid x}(y mid x) ,dy quad X,Y text{가 연속형인 경우} end{cases}$$ . - (이중 기댓값 정리) 두 확률변수 $X,Y$에 대하여 $E[E(Y mid X)]=E(Y)$ 가 성립함 . - 확률변수 $X$와 $Y$가 독립이면 $E(Y mid x)=E(Y), ;E(X mid y)=E(X) to$ 사건의 독립 확률변수 버전 . - 조건부 분산 : $Var(Y mid x)=E[ {Y-E(Y mid x) }^2 mid x] = E(Y^2 mid x)-[E(Y mid x)]^2$ . - 분산 분해 : $Var(Y) = E[Var(Y mid X)]+Var[E(Y mid X)]$ . - 조건부 분산($E[Var(Y mid X)]$)이 무조건부 분산($Var(Y))$보다 평균적으로 더 작음 . - $Var(E(Y mid X)) leq Var(Y) longrightarrow$ 개별 개체의 산포보다 그룹별 평균의 산포가 작음 . &#54869;&#47456;&#48512;&#46321;&#49885; . - 마코프 확률부등식 : 실함수 $u(X) &gt; 0$라고 할 때 $P[u(X) geq c] leq dfrac{E[u(X)]}{c}$ . - $P[u(X) &lt; c] = 1-P[u(X) geq c] geq 1- dfrac{E[u(X)]}{c}$ . 마코프 확률부등식 증명 | . - $A= {x:u(x) geq c }$인 $A$에 대하여 아래가 성립한다 . $$ begin{aligned}E_X[u(X)]&amp;= int^{ infty}_{- infty}u(x)f(x)dx [10pt] &amp;= int_A u(x)f(x)dx+ int_{A^c} u(x)f(x)dx [10pt] &amp; geq int_A u(x)f(x)dx [10pt] &amp; geq int_A cf(x)dx quad( therefore u(x) geq c) [10pt] &amp;=cP(X in A) [10pt] &amp;=cP big(u(X) geq c big) quad( therefore A= {x:u(x) geq c }) end{aligned}$$- 체비셰프 부등식(확률부등식의 응용) : $P(|X- mu| &lt; k sigma) geq 1- dfrac{1}{k^2}$ . - 코시-슈바르츠 부등식 : $[E(XY)]^2 leq E(X^2) cdot E(Y^2)$ . - 젠센 부등식 : $E[ phi( boldsymbol{X})] geq phi[E( boldsymbol{X})]$ ($ therefore phi(x)$는 이차 미분가능하고 convex) . &#54364;&#48376;&#48516;&#54252; &#48143; &#44536;&#51032; &#44540;&#49324; . &#45824;&#49688;&#51032; &#48277;&#52825;&#44284; &#51473;&#49900;&#44537;&#54620;&#51221;&#47532; . &#54869;&#47456; &#49688;&#47156; . - 확률변수의 열 $X_1,X_2, cdots,X_n, cdots$과 확률변수 $X$가 같은 확률공간에 정의된다고 하자 . - 확률변수의 열을 모르면 다음을 참고하자 : https://www.probabilitycourse.com/chapter7/7_2_2_sequence_of_random_variables.php . - 확률변수의 수렴 : https://www.probabilitycourse.com/chapter7/7_2_0_convergence_of_random_variables.php . - 만약 임의의 $ epsilon&gt;0$에 대해 $ lim limits_{n to infty}P(|X_n-X| geq epsilon)=0$ 또는 $ lim limits_{n to infty}P(|X_n-X|&lt; epsilon)=1$ 이라면 . - $X_n$이 $X$로 확률적으로 수렴한다고 하고 $X_n{ xrightarrow{~~p~~}} X$로 표기한다 : 확률 수렴(convergence in probability) . - 확률 수렴이 무엇인지 뭔가 직관적으로 와닿지 않는다 . - 일단 수열의 수렴을 생각해보자 . - 예컨데 $1, frac{1}{2}, frac{1}{4}, frac{1}{8}, cdots $ 와 같은 수열이 있다고 하자 . - 위의 수열을 다음과 같이 나타낼 수 있다 &gt; $a_n= dfrac{1}{2^n}, ;n in mathbb{N}$ . - 여기서 $n to infty$ 이면 $a_n to 0$임을 알 수 있다 . - 즉 $n$이 커지면 어떠한 상수 $a$로 수렴한다는 것 . - 수열 대신 확률변수의 열인 경우도 똑같이 생각하면 된다 . - 단지 확률변수는 변동성 때문에 값이 완전히 똑같을 수는 없으니 확률을 도입한 것이다 . - 예컨대 두 확률변수가 표준정규분포를 따를 때 적당히 표본을 1억개 정도 뽑고 값을 비교한다고 해보자(kde 그려보자) . - 그러면 거의 비슷하겠지만 완전히 똑같지는 않다(random vaiable이니까 당연하다) . - 그러니 직접 값을 비교하는게 아니고 확률을 도입하여 비교하는 것이다 . - 예시에서 두 확률변수가 표준정규분포를 따른다고 표현한 것도 변동성 때문이다($X = Z$가 아니라 변동성 때문에 $X sim Z$로 표현) . 확률변수의 열 헷갈리는 점 짚고 가기 | . - $X_1,X_2, cdots,X_n longrightarrow n$에 의존한다(여기서 $n$은 표본크기 의미하는게 아님; 일련번호(또는 표본 개수)라고 생각하자) . - 그러니까 $X_n$ 자체는 그냥 어떤 확률분포를 따를 뿐 밑첨자가 $n$이라고 확률분포에서 표본 $n$개를 뽑는 것이 아님 . - 그런데 $ overline{X}_n$과 같은 경우는 $n$이 표본크기를 나타내는데 왜냐면 $ overline{X}_n = cfrac{X_1+ cdots+X_n}{n}$ 이기 때문 . 다시 본론으로 돌아와서 다음과 같은 확률변수의 열이 있다고 해보자 | . - $X_1 sim EXP(1), ; X_2 sim EXP(2), ; cdots, ;X_n sim EXP(n)$ 라고 하자 . - 즉 $X_n sim EXP(n)$, 예컨대 $n=3$이면 $X_3 sim EXP(3)$ . - 참고로 $EXP(n)$에서 $n$은 포아송분포의 모수 $ lambda$를 의미한다 . - 만약 $n to infty$ 이면 $X_n to 0$가 되고 이는 $X_n xrightarrow{~~p~~}0$ . $$ begin{aligned} lim limits_{n to infty} P(|X_n-X| geq epsilon)&amp;= lim limits_{n to infty} P(|X_n-0| geq epsilon) &amp;= lim limits_{n to infty} P(X_n geq epsilon) quad (X_n geq 0 text{ as } X_n sim EXP(n)) &amp;= lim limits_{n to infty} 1-F_{X_n}( epsilon) &amp;= lim limits_{n to infty} 1-(1-e^{-n epsilon}) &amp;= lim limits_{n to infty} e^{-n epsilon} &amp;=0, quad forall epsilon &gt; 0 end{aligned}$$- 따라서 $X_n xrightarrow{~~p~~}0$ . - 다시 말하자면 확률변수의 열 $X_1,X_2, cdots,X_n$은 zero random variable $X$로 확률 수렴한다 . - 참고 : https://www.probabilitycourse.com/chapter7/7_2_5_convergence_in_probability.php . - 근데 문득 궁금한점이 생겼다 . - $X_1,X_2, cdots,X_n$은 같은 확률공간에 존재하는건가? . - $ Omega, mathcal{F}$는 같다 . - 그런데 $ Pr$은? . - $ Pr$이 같다면 예컨대 $ Pr(1&lt;X&lt;2)$가 $X_1,X_2, cdots,X_n$에 대해서 같아야 하는거 아닌가? . - 하지만 $X_1,X_2, cdots,X_n$ 각각의 pdf는 다르기에 $ Pr(1&lt;X&lt;2)$도 다르다 . - 그럼 같은 확률공간이 아닌건가? . - 아니면 임의의 실수 $a$에 대해서 $ Pr(a)=0$이니까 똑같나? . - 그냥 내가 확률공간의 의미를 잘못알고 있는 걸수도... . 위에 대한 나의 생각 : $ Pr$은 $ mathcal{F}$를 $[0,1]$로 맵핑하는 함수다 &gt; 예컨대 동전던지기의 경우 $ Pr( {H })= dfrac{1}{2}$ | . - $ Pr(1&lt;X&lt;2)$에서 $1&lt;X&lt;2$는 $ mathcal{F}$ 중에서 하나의 사건에 해당한다(?) . - $ Pr$은 $1&lt;X&lt;2$를 $f_X(x)$ 그래프 상에서 전체면적($1$) 대비 $1&lt;x&lt;2$ 아래의 면적의 차지 비율에 맵핑한다 . - 예컨대 정규분포의 경우 $ Pr(0&lt;X&lt; infty) = 0.5$이다 . - 위의 경우 $ Pr$은 $ mathcal{F}$를 $f_X(x)$ 그래프 상에서 전체면적($1$) 대비 $ mathcal{F}$에 해당하는 아래의 면적의 차지 비율에 맵핑한다 . - 즉 $X_1,X_2, cdots,X_n$ 각각의 pdf는 다르기에 $ Pr(1&lt;X&lt;2)$도 다르지만 $ Pr$ 함수의 규칙은 같으므로 같은 확률공간에 있다고 한다(?) . - $ Pr(A)= int_A f(x)dx, quad A in mathcal{F}$ &gt; $ Pr$은 동일함! . - 다시 말하지만 $ Pr$은 함수이다 . - $y=f(x)$에서 함수는 $f$이다 &gt; 예컨대 $y=2x$이면 함수는 $ times 2$, $x$는 input, $y$는 output . - 당연히 $x$가 달라지면 $y$도 달라진다 &gt; $y=2x$에서 $x=1$이면 $y=2$, $x=2$이면 $y=4$ . - 아니 그런데 $1&lt;X&lt;2$는 다 같은거 아님? . - $1&lt;X&lt;2$는 pdf상에서 $1&lt;x&lt;2$인 영역이므로 pdf에 따라 다르다(?) &gt; 그러니 $1&lt;X&lt;2$는 다 같은것이 아니다(?) . - 같은 게 맞다. $1&lt;X&lt;2$ 영역에 존재하는 점의 밀도가 $X_1$, $X_2$에서 다르므로 $P(1 &lt; X &lt; 2)$이 다르다 . - 헷갈리면 위의 같은 확률 공간, 다른 cdf 예시를 보고 오자 . import matplotlib.pyplot as plt import numpy as np from scipy.stats import expon xx = np.linspace(0, 6, 1000) x = np.linspace(2, 4, 100) y1 = expon.pdf(x, scale = 1) y2 = expon.pdf(x, scale = 2) with plt.style.context(&#39;seaborn-darkgrid&#39;): fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (15, 5)) ax1.plot(xx, expon.pdf(x = xx, scale = 1)) ax1.set_title(&#39;$ lambda = 1$&#39;) ax1.set_xlim(0, 6) ax1.set_ylim(0, 1) ax1.fill_between(x, y1, 0) ax2.plot(xx, expon.pdf(x = xx, scale = 2)) ax2.set_title(&#39;$ lambda = 0.5$&#39;) ax2.set_xlim(0, 6) ax2.set_ylim(0, 1) ax2.fill_between(x, y2, 0) fig.suptitle(&#39;exp dist&#39;, fontsize = 16) plt.show() . . - 결론은 $ Pr$은 보통의 연속형확률변수이면 지수분포이든 정규분포이든 면적을 구하는 함수이니 동일하다는 것 . &#45824;&#49688;&#51032; &#48277;&#52825; . - 평균이 $ mu&lt; infty$인 확률밀도함수 $f(x)$로부터 랜덤표본($i.i.d$) $X_1,X_2, cdots,X_n$을 얻었다면 $ overline{X}_n xrightarrow{~~p~~} mu$가 성립 : 대수의 법칙(law of large numbers) . 증명 ($f(x)$가 분산 $ sigma^2&lt; infty$를 가진다고 가정) | . $$ begin{aligned} P left( left lvert , overline{X}_n- mu , right rvert &lt; epsilon right)&amp; = P left( left| , overline{X}_n- mu , right|^2 &lt; epsilon^2 right) &amp; leq 1 - dfrac{E left( overline{X}_n- mu right)^2}{ epsilon^2} &amp;= 1 - dfrac{ sigma^2 / n}{ epsilon^2} xrightarrow{~~n to infty~~} 1 end{aligned}$$ - 표본크기가 커질수록 표본평균은 모평균에 가까워진다 . &#48516;&#54252; &#49688;&#47156; . - 확률변수의 열 $X_1,X_2, cdots,X_n, cdots$이 누적분포함수 $F_{X_1},F_{X_2}, cdots,F_{X_n}, cdots$을 각각 갖고 $X sim F_X$라고 하자 . - 만약 함수 $F_X$가 연속인 모든 점 $x$에서 $ lim limits_{n to infty}F_{X_n}=F_X(x)$가 만족된다면 . - $X_n$이 $X$로 분포 수렴한다고 말하고 $X_n{ xrightarrow{~~d~~}} X$로 표기 : 분포 수렴(convergence in distribution) . - 여기서 $X$의 분포를 $X_n$의 극한분포(Limiting Distribution) 또는 점근적분포(Asymptotic Distribution)라고 한다 . . Note: $X_n{ xrightarrow{~~p~~}} X$ 이면 $X_n{ xrightarrow{~~d~~}} X$ 이지만 역은 항상 성립하진 않는다 . - 참고 : https://www.probabilitycourse.com/chapter7/7_2_4_convergence_in_distribution.php . . Note: $c$가 상수일 때 $X_n{ xrightarrow{~~p~~}} c$ 와 $X_n{ xrightarrow{~~d~~}} c$ 는 서로 동치이다 . &#51473;&#49900;&#44537;&#54620;&#51221;&#47532; . - 확률변수 $X_1,X_2, cdots$의 cdf가 $F_1,F_2, cdots$이고 mgf가 $M_1(t),M_2(t), cdots$라고 하자 . - 이때 어떤 $t$의 개구간 $-h&lt;t&lt;h$에 대하여 $ lim limits_{n to infty}M_n(t)=M(t)$이고 . - $M(t)$가 누적분포함수 $F(x)$를 갖는 어떤 확률분포의 mgf라고 하면 $F(x)$가 연속인 모든 점에서 $ lim limits_{n to infty}F_n(x)=F(x)$가 성립한다 . - 즉, 적률생섬함수열의 극한이 임의의 확률변수 $X$의 mgf로 수렴하면 $X_n{ xrightarrow{~~d~~}} X$가 성립한다 . - 평균과 분산이 각각 $ mu$와 $ sigma^2&lt; infty$인 $f(x)$로부터 랜덤표본 $X_1,X_2, cdots,X_n$을 얻었다면 이때 확률변량 . $$Z_n= dfrac{ sum limits_{i=1}^{n}X_i-E left( sum limits_{i=1}^{n}X_i right)}{ sqrt{Var left( sum limits_{i=1}^{n}X_i right)}}= dfrac{ sum limits_{i=1}^{n}(X_i- mu)}{ sqrt{n} sigma} = dfrac{ overline{X}_n-E left( overline{X}_n right)}{ sqrt{Var left( overline{X}_n right)}}= dfrac{ overline{X}_n- mu}{ left. sigma middle/ sqrt n right.}$$- 는 표본의 크기 $n$이 무한대에 접근함에 따라 표준정규분포 $N(0,1)$로 분포수렴한다 : 중심극한정리(central limit theorem) . 증명(적률생성함수가 존재하는 경우) | . - 랜덤표본이므로 $X_i- mu$의 mgf는 모든 $i$에 대해 동일하고 이를 $m(t)=E left[e^{t(X_i- mu)} right]$라고 하자 . - 그러면 $m&#39;(0)=E(X_i- mu)=0, ; m&#39;&#39;(0)=E(X_i- mu)^2= sigma^2$이고 테일러 전개의 의해 아래가 성립 . $$ begin{aligned}m(t)&amp;=m(0)+m&#39;(0)t+ dfrac{m&#39;&#39;( xi)t^2}{2} quad (0&lt; xi&lt;t) &amp;=1+ dfrac{m&#39;&#39;( xi)t^2}{2} &amp;=1+ dfrac{ sigma^2 t^2}{2}+ dfrac{(m&#39;&#39;( xi)- sigma^2)t^2}{2} end{aligned}$$- $Z_n = dfrac{ overline{X}_n- mu}{ left. sigma middle/ sqrt n right.}= dfrac{ sum limits_{i=1}^{n}(X_i- mu)}{ sqrt{n} sigma}$ 라고 하면 $Z_n$의 mgf는 아래와 같다 . $$ begin{aligned}M_{_{Z_{_n}}}(t)&amp;=M_{{ Sigma(X_i- mu)}} left( frac{t}{ sqrt{n} sigma} right) &amp;= prod limits_{i=1}^{n}M_{{(X_i- mu)}} left( frac{t}{ sqrt{n} sigma} right) &amp;= left[M_{{(X_i- mu)}} left( frac{t}{ sqrt{n} sigma} right) right]^n &amp;= left[m left( frac{t}{ sqrt{n} sigma} right) right]^n end{aligned}$$ . 이고, $0&lt; xi &lt; dfrac{t}{ sqrt n sigma}$인 $ xi$에 대해 $M_{_{Z_{_n}}}(t)= left[1+ dfrac{ sigma^2 t^2}{2n sigma^2}+ dfrac{ left(m&#39;&#39;( xi)- sigma^2 right)t^2}{2n sigma^2} right]^n$ . - 그런데 $n to infty$일 때 $ dfrac{t}{ sqrt n sigma} to0, , xi to 0$, 그리고 $m&#39;&#39;$의 연속성에 의해 $m&#39;&#39;( xi) to sigma$이므로 $ lim_{n to infty}M_{_{Z_{_n}}}(t)= exp left( dfrac{t^2}{2} right)$ . - 이는 표준정규분포의 mgf이므로 확률변량 $Z_n$에 대하여 $Z_n xrightarrow{~~d~~}N(0,1)$이 성립한다 . Slutsky &#51221;&#47532; . . Note: 확률변수열 $u_n$과 $u$에서 연속인 함수 $g$와 상수 $u$에 대하여 $u_n xrightarrow{~~p~~}u$이면 $g(u_n) xrightarrow{~~p~~}g(u)$가 성립한다 . - 확률변수열 $X_1,X_2, cdots,X_n$이 상수 $c$로 확률적으로 수렴($X_n xrightarrow{~~p~~}c$)하며 . - 확률변수열 $Y_1,Y_2, cdots,Y_n$은 확률변수 $Z$로 분포수렴($Y_n xrightarrow{~~d~~}Z$)한다고 하면 . - $X_n+Y_n xrightarrow{~~d~~}Z+c$와 $X_nY_n xrightarrow{~~d~~}cZ$가 성립한다 . - Slutsky 정리 응용 예시 . - 평균과 분산이 각각 $ mu$와 $ sigma^2 &lt; infty$인 모분포루터 랜덤표본 $X_1,X_2, cdots,X_n$을 얻었다고 하자 . - $ dfrac{ overline{X}_n - mu}{ left. S_n middle/ sqrt n right.} sim t(n-1)$를 스튜던트화된 표본평균이라 한다 . - 그런데 중심극한정리에 의해 $ dfrac{ overline{X}_n - mu}{ left. sigma middle/ sqrt n right.} xrightarrow{~~d~~}N(0,1)$ 이고 $S_n xrightarrow{~~p~~} sigma$ 이므로 다음이 성립한다 . - $ dfrac{ overline{X}_n - mu}{ left. S_n middle/ sqrt n right.}= dfrac{ overline{X}_n - mu}{ left. sigma middle/ sqrt n right.} times dfrac{ sigma}{S_n} xrightarrow{~~d~~}N(0,1)$ . &#45944;&#53440; &#48169;&#48277; . - 임의의 함수 $g( theta)$의 연속인 도함수 $g&#39;( theta)$가 존재하고 $0$이 아니라고 하자 . - 확률변수의 열 $X_1,X_2, cdots,X_n, cdots$에 대해서 $ sqrt{n}(X_n- theta) xrightarrow{~~d~~}N(0, sigma^2)$ 이라고 하자 . - 평균값 정리에 의하여 $X_n$과 $ theta$ 사이에 있는 $ tilde{ theta}$에 대하여 $ dfrac{g(X_n)-g( theta)}{X_n- theta}=g&#39;( tilde{ theta})$가 성립한다 . - 한편 $X_n xrightarrow{~~p~~} theta$이므로 $X_n$과 $ theta$사이에 있는 $ tilde{ theta}$에 대해서도 $ tilde{ theta} xrightarrow{~~p~~} theta$이며 $g&#39;( tilde{ theta}) xrightarrow{~~p~~}g&#39;( theta)$가 성립한다 . - 따라서 $ sqrt{n} big[(g(X_n)-g( theta) big]=g&#39;( tilde{ theta}) sqrt{n}(X_n- theta)$으로부터 슬럿츠키 정리를 사용하여 . - $ sqrt{n}(g(X_n)-g( theta)) xrightarrow{~~d~~}N(0, sigma^2[g&#39;( theta)]^2)$을 보일 수 있다 . - 델타 방법은 때로는 점근적 정규성에 대한 가정을 하지 않고 확률변수 $g(X)$의 기댓값과 분산을 확률변수 $X$를 통해 근사할 때도 사용된다 . - 테일러 전개 : $E big[g(X) big] approx E big[(g( mu)+g&#39;( mu)(X- mu) big]=g( mu)=g big(E(X) big)$ . - 테일러 전개 : $Var big(g(X) big) approx Var big((g( mu)+g&#39;( mu)(X- mu) big)=g( mu)= big {g&#39;( mu) big }^2 Var(X)$ . &#49692;&#49436;&#53685;&#44228;&#47049; . - 확률밀도함수가 $f(x)$이고 누적분포함수가 $F(x)$인 모집단으로부터 . - 크기가 $n$인 랜덤표본 $X_1,X_2, cdots,X_n$을 얻었다고 하자 . - 이때 랜덤표본을 작은 것부터 크기순으로 나열하여 다음과 같은 순서통계량(order statistic)을 구할 수 있다 . $$X_{(1)} leq X_{(2)} leq cdots leq X_{(n-1)} leq X_{(n)}$$ . - 예컨대 모집단이 표준정규분포일 때 크기가 $n$인 랜덤표본 $X_1,X_2, cdots,X_n$를 얻었다면 . - 확률변수의 순서통계량은 $1:1$ 변환이 아니다($n!:1$ 변환) . - 그렇기에 순서통계량의 결합 확률밀도함수는 $n!f(x_{(1)})f(x_{(2)}) cdots f(x_{(n)})$이다 . - 한편, $k$번째 순서통계량 $X_{(k)}$의 확률밀도함수는 다음과 같다 . $$f_{X_k}(x_{(k)})= cfrac{n!}{(k-1)!(n-k)!}(F(x_{(k)}))^{k-1}(1-F(x_{(k)}))^{n-k}f(x_{(k)})$$ .",
            "url": "https://jaesu26.github.io/study-blog/statistics/2021/09/03/%EC%88%98%EB%A6%AC%ED%86%B5%EA%B3%84%ED%95%99.html",
            "relUrl": "/statistics/2021/09/03/%EC%88%98%EB%A6%AC%ED%86%B5%EA%B3%84%ED%95%99.html",
            "date": " • Sep 3, 2021"
        }
        
    
  
    
        ,"post30": {
            "title": "이진 탐색",
            "content": "&#51060;&#51652; &#53456;&#49353; (Binary search) . - 오름차순으로 정렬된 리스트에서 특정한 값의 위치를 찾는 알고리즘 . - 처음 중간의 값을 임의의 값으로 선택하고 그 값과 찾고자 하는 값의 크고 작음을 비교하는 방식을 사용 . - 처음 선택한 중앙값이 만약 찾는 값보다 크면 그 값은 새로운 최댓값이 되며 작으면 그 값은 새로운 최솟값이 됨 . - 검색 원리상 정렬된 리스트에만 사용할 수 있다는 단점이 있지만 검색이 반복될 때마다 목표값을 찾을 확률은 두 배가 되므로 속도가 빠르다는 장점 &gt; $O(logN)$ . - 참고: 이진 탐색 . &#51060;&#51652; &#53456;&#49353; &#44396;&#54788; . - 정렬된 array에서 target의 위치를 이진 탐색으로 찾는 코드를 구현하자 . - 이 코드를 통해 1~100 숫자(arr)에서 88(target)을 찾는 과정을 살펴보자 . def binary_search(sorted_arr, target): low = 0 high = len(sorted_arr) - 1 # sorted_arr의 첫번째 인덱스(low)부터 마지막 인덱스(high)까지 탐색 while low &lt;= high: mid = (high + low) // 2 print(&quot;low: {} nhigh: {} nmid: {}&quot;.format(low, high, mid)) if sorted_arr[mid] == target: # 원하는 값을 찾으면 mid(인덱스)를 반환 return mid if sorted_arr[mid] &gt; target: # 원하는 값이 중간점보다 작은 경우 왼쪽 부분 탐색 high = mid - 1 else: low = mid + 1 # 원하는 값이 중간점보다 큰 경우 오른쪽 부분 탐색 return False # 원하는 값이 sorted_arr에 없는 경우 . arr = list(range(1, 101)) arr.sort() # 오름차순 정렬 target = 88 binary_search(arr, target) . low: 0 high: 99 mid: 49 low: 50 high: 99 mid: 74 low: 75 high: 99 mid: 87 . 87 . - 우리가 찾는 target인 88은 arr의 87번째 인덱스 값이라고 한다 . arr[87] . 88 . - 진짜임 . - 어떤 과정을 거쳐서 87번째 인덱스라는 것을 알려준 것일까? . - arr은 1부터 100까지의 값임 . 1. 1 2 3 $ cdots$ 98 99 100 &gt; low는 0이고 high는 99이므로 mid는 49임 . 2. arr[mid(49)] = 50는 target(88)보다 작으므로 arr[mid(49)+1] ~ arr[high(99)] 를 탐색하면 target(88)이 존재할 것임 . 3. 51 52 53 $ cdots$ 98 99 100 &gt; low는 50이고 high는 99이므로 mid는 74임 . 4. arr[mid(74)]는 target(88)보다 작으므로 arr[mid(74)+1] ~ arr[high(99)] 를 탐색하면 target(88)이 존재할 것임 . 5. 76 77 78 $ cdots$ 98 99 100 &gt; low는 75이고 high는 99이므로 mid는 87임 . 6. arr[mid(87)]는 target(88)과 동일하므로 mid(87)를 return한다 . &#51060;&#51652; &#53456;&#49353; &#49884;&#44036; &#48373;&#51105;&#46020; . - 시간 복잡도는 $O(logN)$이다 . - 위에서 1~100사이에서 target을 찾는 과정을 살펴봤음 . - 탐색 범위를 $N$이라고 한다면 처음에는 $N$만큼 탐색함 . - 그 다음에는 $ frac{N}{2}$만큼 탐색함 . - 또 그 다음에는 $ frac{N}{4}$만큼 탐색함 . - 이를 살펴보면 탐색 범위는 $N, frac{N}{2}, frac{N}{4}, cdots , 1$ . - 시간 복잡도는 알고리즘의 의해 수행되는 기본 연산의 개수를 보면 알 수 있음 . - 연산 횟수(탐색 반복 횟수)를 $k$라고 하면 처음 탐색($k=1$)때의 탐색 범위는 $N$, 두번째 탐색($k=2$)때의 탐색 범위는 $ frac{N}{2}$이며 이를 계속하면 탐색 범위는 $1$이 됨 . - 위의 관계식을 통해 $N times( frac{1}{2})^{k} = 1$임을 알 수 있고 이를 정리하면 $k=log_{2}N$임 . - Big O 표기법에서 로그의 밑은 영향이 없으므로 이진 탐색의 시간 복잡도는 $O(logN)$이라고 할 수 있음 &gt; 이해 안되면 통계수학 big O 표기법 다시 보기 .",
            "url": "https://jaesu26.github.io/study-blog/algorithm/2021/08/31/%EC%9D%B4%EC%A7%84%ED%83%90%EC%83%89.html",
            "relUrl": "/algorithm/2021/08/31/%EC%9D%B4%EC%A7%84%ED%83%90%EC%83%89.html",
            "date": " • Aug 31, 2021"
        }
        
    
  
    
        ,"post31": {
            "title": "자료구조 스택",
            "content": "&#49828;&#53469; (Stack) . - 자료를 넣고(push) 자료를 빼는(pop) 입구가 같은 선형 구조(LIFO - Last In First Out) . - 참고: 자료구조 스택 . &#49828;&#53469; &#49324;&#50857; . - 파이썬에서 스택은 list를 통해 구현할 수 있다 . - stack.append(x)를 통해 스택에 x를 오른쪽(뒤)에 push한다 . - stack.pop()을 통해 스택의 마지막 원소를 pop한다 . &#50696;&#51228; - &#51228;&#47196; . 문제 출처: 백준 10773번 | . - 스택의 기본적인 push와 pop을 이용하면 된다 . - 0이 입력되면 pop하고 그 외에 수가 입력되면 push한다 . def solution(): K = int(input()) stack = [] for _ in range(K): num = int(input()) if num == 0: stack.pop() else: stack.append(num) return sum(stack) print(solution()) . 0 .",
            "url": "https://jaesu26.github.io/study-blog/data%20structure/2021/08/30/%EC%9E%90%EB%A3%8C%EA%B5%AC%EC%A1%B0-%EC%8A%A4%ED%83%9D.html",
            "relUrl": "/data%20structure/2021/08/30/%EC%9E%90%EB%A3%8C%EA%B5%AC%EC%A1%B0-%EC%8A%A4%ED%83%9D.html",
            "date": " • Aug 30, 2021"
        }
        
    
  
    
        ,"post32": {
            "title": "자료구조 힙",
            "content": "&#55193; (Heap) . - 최댓값 및 최솟값을 찾아내는 연산을 빠르게 하기 위해 고안된 완전이진트리 자료구조 . - 힙 속성: A가 B의 부모노드(parent node) 이면 A의 키(key)값과 B의 키값 사이에는 대소관계가 성립 . - 최대 힙: 부모노드의 키값이 자식노드의 키값보다 항상 큰 힙 . - 최소 힙: 부모노드의 키값이 자식노드의 키값보다 항상 작은 힙 . - 키(key)값의 대소관계는 오로지 부모노드와 자식노드 간에만 성립하며 특히 형제 사이에는 대소관계가 정해지지 않음 . - 대개 자식노드 개수가 최대 2개인 이진 힙(binary heap)을 사용함 . - 데이터의 최대값(최대 힙) or 최소값(최소 힙)을 찾는데 $O(1)$이 소요됨 &gt; 루트노드에 저장되어 있으므로 . - 데이터의 삽입과 삭제는 $O( log N)$이 소요됨 . - 참고: 자료구조 힙 . &#55193; &#49324;&#50857; . - 파이썬의 heapq 모듈은 최소 힙이다 . - 힙 구조 그림으로 보기 &gt; 힙 구조 &gt; 이거 보면 무조건 이해 가능 . - 힙을 코드로 구현하기 전에 필요한 함수를 공부하자 . - heapq.heappush(heap, item) &gt; item을 heap에 추가함 . - heapq.heappop(heap) &gt; heap에서 가장 작은 원소(루트 노드)를 pop(추출)하고 비어 있으면 IndexError . - heapq.heapify(x) &gt; 리스트 x를 heap 자료 구조로 변환함 . - 참고: heapq . &#50696;&#51228;: &#52852;&#46300; &#54633;&#52404; &#45440;&#51060; . 문제 출처: 백준 15903번 | . - 카드 더미의 최소값 2개를 뽑은다음 두 숫자를 두 수의 합으로 바꿔주는 것을 반복하면 됨 . - 최소값 2개를 뽑으면 되니 Heap을 사용하자 . - 힙에서 최소값 추출은 $O(1)$ 삽입과 삭제는 $O(logN)$이므로 다른 구조보다 효율적으로 문제를 해결할 수 있음 . import heapq def solution(): n, m = map(int, input().split()) cards = list(map(int, input().split())) heapq.heapify(cards) # list인 cards를 Heap구조로 변홤함 for _ in range(m): two_card_sum = heapq.heappop(cards) + heapq.heappop(cards) # 최소값 2개(제일 작은 값과 두 번째로 작은 값)를 뽑음 heapq.heappush(cards, two_card_sum) # 두 수를 두 수의 합으로 바꿔줌 heapq.heappush(cards, two_card_sum) # 그리고 cards에 push한다 return sum(cards) print(solution()) . 19 .",
            "url": "https://jaesu26.github.io/study-blog/data%20structure/2021/08/26/%EC%9E%90%EB%A3%8C%EA%B5%AC%EC%A1%B0-%ED%9E%99.html",
            "relUrl": "/data%20structure/2021/08/26/%EC%9E%90%EB%A3%8C%EA%B5%AC%EC%A1%B0-%ED%9E%99.html",
            "date": " • Aug 26, 2021"
        }
        
    
  
    
        ,"post33": {
            "title": "R 프로그래밍",
            "content": "참고: R 프로그래밍 - 허명회 지음 . - R 프로그래밍에 대해 복습할 겸 간단히 정리 . &#48289;&#53552;(vector) . - 데이터 컨테이너의 기본형 . &#48289;&#53552; . x &lt;- 1 is.vector(x) . TRUE - x는 길이가 1인 벡터 = 스칼라 . print(pi) print(pi, 16) . [1] 3.141593 [1] 3.141592653589793 . - π는 숫자가 예약되어 있는 스칼라 . M &lt;- matrix(1:12, nrow = 4, ncol = 3, byrow = T) M . A matrix: 4 × 3 of type int 1 | 2 | 3 | . 4 | 5 | 6 | . 7 | 8 | 9 | . 10 | 11 | 12 | . - M은 행렬 &gt; 벡터의 2차원 배열 . &#51064;&#45937;&#49905; . f &lt;- c(1, 1, 2, 3, 5, 8, 13, 21) f[5] . 5 f[1:5] . &lt;ol class=list-inline&gt;1 | 1 | 2 | 3 | 5 | &lt;/ol&gt; f[-c(1,4)] ## -기호는 제외한다는 의미를 가짐 . &lt;ol class=list-inline&gt;1 | 2 | 5 | 8 | 13 | 21 | &lt;/ol&gt; f[c(1,2,4)] . &lt;ol class=list-inline&gt;1 | 1 | 3 | &lt;/ol&gt; seq&#50752; rep &#54632;&#49688; . - seq(a, b, by = c)는 a부터 b까지 c간격으로 등차수열 생성 . seq(0, 10, 2.5) . &lt;ol class=list-inline&gt;0 | 2.5 | 5 | 7.5 | 10 | &lt;/ol&gt; - seq(a, b, length = n)는 a부터 b까지 길이가 n인 일정 간격 수열을 생성 . seq(0, 10, length = 11) . &lt;ol class=list-inline&gt;0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | &lt;/ol&gt; - rep(x, times = k)는 x의 각 요소가 k의 각 요소씩 반복된 벡터 . rep(NA, 5) . &lt;ol class=list-inline&gt;&lt;NA&gt; | &lt;NA&gt; | &lt;NA&gt; | &lt;NA&gt; | &lt;NA&gt; | &lt;/ol&gt; rep(c(1, 2), 3) . &lt;ol class=list-inline&gt;1 | 2 | 1 | 2 | 1 | 2 | &lt;/ol&gt; rep(c(1, 2, 3), c(3, 2, 1)) . &lt;ol class=list-inline&gt;1 | 1 | 1 | 2 | 2 | 3 | &lt;/ol&gt; - rep(x, each = k)는 x의 각 요소가 각각 k번 반복된 벡터 . rep(c(1, 2), each = 3) . &lt;ol class=list-inline&gt;1 | 1 | 1 | 2 | 2 | 2 | &lt;/ol&gt; &#54596;&#53552;&#47553; . - 조건에 부합하는 데이터 값만 추출 . x &lt;- 1:10 x[x %% 2 == 1] . &lt;ol class=list-inline&gt;1 | 3 | 5 | 7 | 9 | &lt;/ol&gt; subset(x, x %% 2 == 0) . &lt;ol class=list-inline&gt;2 | 4 | 6 | 8 | 10 | &lt;/ol&gt; ifelse &#54632;&#49688; . - ifelse(x, yes, no)는 x가 TRUE이면 yes를 값으로 하고 FALSE이면 no를 값으로 배출 . x &lt;- 1:10 x1 &lt;- ifelse(x %% 2 == 0, x, 2*x) cbind(x, x1) . A matrix: 10 × 2 of type dbl xx1 . 1 | 2 | . 2 | 2 | . 3 | 6 | . 4 | 4 | . 5 | 10 | . 6 | 6 | . 7 | 14 | . 8 | 8 | . 9 | 18 | . 10 | 10 | . names &#54632;&#49688; . - names(x)는 벡터x의 개별 요소에 이름을 부여함 . era &lt;- c(5, 4 ,3, 4 ,5, 6) era . &lt;ol class=list-inline&gt;5 | 4 | 3 | 4 | 5 | 6 | &lt;/ol&gt; - paste()함수는 2개의 문자열 벡터를 sep인수로 붙인다 . names(era) &lt;- paste(&quot;y&quot;, 2001:2006, sep = &quot;-&quot;) era . &lt;dl class=dl-inline&gt;y-20015y-20024y-20033y-20044y-20055y-20066&lt;/dl&gt; &#54665;&#47148;(matrix) . - $p$개의 길이 $n$인 벡터를 열에 배치함 . &#54665;&#47148; . n &lt;- 100 p &lt;- 3 x &lt;- rnorm(n*p) A &lt;- matrix(x, nrow = n, ncol = p) A[1:6, ] . A matrix: 6 × 3 of type dbl 0.3985257 | 0.28159071 | 2.3264862 | . 1.4299784 | -0.60442200 | -1.1111043 | . 0.2929706 | -0.04351824 | 1.0262398 | . 0.9128263 | 0.37584395 | 1.2865189 | . -0.2134398 | 0.99927429 | 0.1097158 | . 0.3423550 | -1.62561727 | 0.8711550 | . - [행, 열] 순으로 인덱싱 . A[1:6, 1:2] . A matrix: 6 × 2 of type dbl 0.3985257 | 0.28159071 | . 1.4299784 | -0.60442200 | . 0.2929706 | -0.04351824 | . 0.9128263 | 0.37584395 | . -0.2134398 | 0.99927429 | . 0.3423550 | -1.62561727 | . - 필터링을 통해 인덱싱도 가능 . A[A[,3] &gt; 0 &amp; A[,2] &gt; 0, ] . A matrix: 31 × 3 of type dbl 0.39852571 | 0.281590708 | 2.32648623 | . 0.91282635 | 0.375843947 | 1.28651890 | . -0.21343980 | 0.999274285 | 0.10971580 | . -0.09365101 | 1.645532123 | 1.65681557 | . 0.59683032 | 1.068823401 | 1.14622308 | . -0.07694040 | 2.143518568 | 0.82898136 | . -0.25295561 | 0.525762383 | 0.48493351 | . 0.69014327 | 0.370450911 | 1.43002803 | . 0.34475001 | 2.278569946 | 0.89774452 | . -0.27996206 | 0.840513317 | 0.44426639 | . -0.80394697 | 2.537376463 | 0.28302193 | . -0.82417672 | 1.777319058 | 0.01703245 | . 0.53338332 | 1.184873169 | 0.38581004 | . -0.18553193 | 0.820022012 | 0.94885563 | . -0.18877772 | 0.128753150 | 0.27520006 | . 1.35820343 | 0.792055902 | 0.28782618 | . 1.61265986 | 0.264419791 | 0.64471494 | . 1.04088992 | 1.584494787 | 0.19616481 | . 0.11426669 | 0.790059186 | 0.94831713 | . -0.16103555 | 0.112897158 | 0.19660418 | . -0.46409134 | 0.397766551 | 1.14864829 | . -0.17503821 | 2.345658962 | 0.80798855 | . 1.14206336 | 0.064781351 | 1.88838626 | . 1.29824117 | 0.308617314 | 1.84653339 | . 0.39353885 | 0.176955322 | 1.06523621 | . -1.26937649 | 0.353061974 | 1.91192497 | . 1.02235605 | 0.936847473 | 1.47997280 | . -1.43203461 | 1.910996122 | 0.36251213 | . 0.17007790 | 1.109508033 | 0.91300794 | . 0.26444960 | 0.009549556 | 0.03743093 | . 1.70585632 | 0.595840494 | 0.27405431 | . - t(A) 함수는 행렬 $ bf A$의 전치행렬을 구해줌 . B &lt;- matrix(1:9, 3, 3) B . A matrix: 3 × 3 of type int 1 | 4 | 7 | . 2 | 5 | 8 | . 3 | 6 | 9 | . t(B) . A matrix: 3 × 3 of type int 1 | 2 | 3 | . 4 | 5 | 6 | . 7 | 8 | 9 | . - solve()함수는 역행렬을 구해줌 . C &lt;- matrix(c(16 ,4, 1, 4, 4, 1, 1, 1, 1), 3, 3) C . A matrix: 3 × 3 of type dbl 16 | 4 | 1 | . 4 | 4 | 1 | . 1 | 1 | 1 | . solve(C) . A matrix: 3 × 3 of type dbl 0.08333333 | -0.08333333 | 0.0000000 | . -0.08333333 | 0.41666667 | -0.3333333 | . 0.00000000 | -0.33333333 | 1.3333333 | . - %*%는 행렬곱 &gt; 잘 알아두자 . solve(C) %*% C . A matrix: 3 × 3 of type dbl 1.000000e+00 | -5.551115e-17 | -1.387779e-17 | . 1.665335e-16 | 1.000000e+00 | 5.551115e-17 | . 0.000000e+00 | 0.000000e+00 | 1.000000e+00 | . - 참고로 $AA^{-1} = I$ . - $I$는 단위행렬 . apply &#54632;&#49688; . - apply(A, 1 or 2, f) &gt; 행렬A의 행(1) or 열(2)에 함수 f를 적용 . - c(1, 2)는 행과 열에 적용 &gt; 각 원소 : 파이썬의 applymap 함수를 생각하자 . M &lt;- matrix(1:12, 3, 4) M . A matrix: 3 × 4 of type int 1 | 4 | 7 | 10 | . 2 | 5 | 8 | 11 | . 3 | 6 | 9 | 12 | . - apply에서 옵션을 1(행)로 하니 전치된 행렬을 반환함 . - 그래서 원래의 행렬 크기와 같게 하려면 t() 함수를 통해 전치시켜야 함 . max_ = apply(M, 2, max) apply(M, 1, &quot;-&quot;, max_) . A matrix: 4 × 3 of type int -2 | -1 | 0 | . -2 | -1 | 0 | . -2 | -1 | 0 | . -2 | -1 | 0 | . max_ = apply(M, 2, max) t(apply(M, 1, &quot;-&quot;, max_)) . A matrix: 3 × 4 of type int -2 | -2 | -2 | -2 | . -1 | -1 | -1 | -1 | . 0 | 0 | 0 | 0 | . - apply에서 옵션을 2(열)로 하니 문제 없어보임 . max_ = apply(M, 1, max) apply(M, 2, &quot;-&quot;, max_) . A matrix: 3 × 4 of type int -9 | -6 | -3 | 0 | . -9 | -6 | -3 | 0 | . -9 | -6 | -3 | 0 | . - 옵션을 c(1, 2)로 하니 각 원소에서 -1을 수행함 . apply(M, 1:2, &quot;-&quot;, 1) . A matrix: 3 × 4 of type dbl 0 | 3 | 6 | 9 | . 1 | 4 | 7 | 10 | . 2 | 5 | 8 | 11 | . - 행렬의 각 열에 대해 최소값 0과 최대값 1이 되도록 변환 . n &lt;- 5 p &lt;- 4 M &lt;- matrix(rnorm(n*p), n, p) M . A matrix: 5 × 4 of type dbl 0.03010344 | -0.7290295 | -0.93633376 | 0.8597820 | . -0.89649998 | -0.6734334 | 0.57546489 | -0.2280883 | . 0.14167091 | 0.6042198 | 0.12012976 | -1.3751352 | . 0.23300396 | -0.9783167 | 0.05895963 | -0.1561013 | . 0.97727567 | -2.1341398 | 1.52209622 | 1.1284436 | . min_ &lt;- apply(M, 2, min) max_ &lt;- apply(M, 2, max) M.1 &lt;- t(apply(M, 1, &quot;-&quot;, min_)) M.2 &lt;- t(apply(M.1, 1, &quot;/&quot;, max_-min_)) M.2 . A matrix: 5 × 4 of type dbl 0.4945114 | 0.5131212 | 0.0000000 | 0.8926890 | . 0.0000000 | 0.5334239 | 0.6149448 | 0.4581629 | . 0.5540529 | 1.0000000 | 0.4297310 | 0.0000000 | . 0.6027957 | 0.4220859 | 0.4048492 | 0.4869165 | . 1.0000000 | 0.0000000 | 1.0000000 | 1.0000000 | . rownames&#50752; colnames &#54632;&#49688; . - 행렬의 행과 열에 이름을 붙임 . n &lt;- 10 x &lt;- matrix(round(rnorm(n*4, 50, 10)), n, 4) ## 평균이 50, 표준편차가 10인 정규분포에서 난수 40개 추출 rownames(x) &lt;- paste(&quot;S&quot;, 1:n, sep = &quot;&quot;) colnames(x) &lt;- c(&quot;math&quot;, &quot;engl&quot;, &quot;science&quot;, &quot;arts&quot;) x . A matrix: 10 × 4 of type dbl mathenglsciencearts . S156 | 52 | 62 | 51 | . S243 | 50 | 35 | 45 | . S337 | 48 | 45 | 49 | . S451 | 35 | 29 | 46 | . S556 | 46 | 43 | 44 | . S656 | 56 | 46 | 51 | . S760 | 68 | 48 | 51 | . S842 | 58 | 54 | 52 | . S954 | 32 | 55 | 50 | . S1038 | 47 | 33 | 56 | . &#47532;&#49828;&#53944;(list) . - R에서 가장 일반적인 데이터 형태 . members &lt;- list(leaders = c(&quot;gang&quot;, &quot;iu&quot;), assisstants = &quot;kang&quot;) members . $leaders &lt;ol class=list-inline&gt;&#39;gang&#39; | &#39;iu&#39; | &lt;/ol&gt; $assisstants &#39;kang&#39; - class(X) 함수는 X의 type을 알려줌 . class(members) . &#39;list&#39; - names()함수로 요소의 라벨을 확인 + 변경 가능 . print(names(members)) names(members)[2] &lt;- &quot;workers&quot; print(names(members)) . [1] &#34;leaders&#34; &#34;assisstants&#34; [1] &#34;leaders&#34; &#34;workers&#34; . &#47532;&#49828;&#53944;&#50640; &#51217;&#44540;&#54616;&#44592; . - [[ ]] 사용 . members[[1]] . &lt;ol class=list-inline&gt;&#39;gang&#39; | &#39;iu&#39; | &lt;/ol&gt; - [ ]은 sublist . - [[ ]]은 벡터이고 [ ]은 리스트임 . members[1] . $leaders = &lt;ol class=list-inline&gt;&#39;gang&#39; | &#39;iu&#39; | &lt;/ol&gt; - 요소 이름 사용 . members[[&quot;leaders&quot;]] . &lt;ol class=list-inline&gt;&#39;gang&#39; | &#39;iu&#39; | &lt;/ol&gt; - $ 기호 사용 &gt; 개인적으로 제일 편함 . members$leaders . &lt;ol class=list-inline&gt;&#39;gang&#39; | &#39;iu&#39; | &lt;/ol&gt; - 리스트 내 자료 값 변경도 가능 . members$leaders[1] &lt;- &quot;park&quot; members . $leaders &lt;ol class=list-inline&gt;&#39;park&#39; | &#39;iu&#39; | &lt;/ol&gt; $workers &#39;kang&#39; lapply&#50752; sapply &#54632;&#49688; . - matrix에서 apply() 함수를 사용하듯이 list에선 lapply()와 sapply() 함수를 사용 . - lapply(list, fun)는 list 내 요소들에 함수 fun을 적용하여 결과를 리스트로 출력 &gt; sapply() 는 벡터로 출력 . salaries &lt;- list(leaders = c(250, 200), assistant = 100, members = c(300, 200, 180, 120 ,100)) salaries . $leaders &lt;ol class=list-inline&gt;250 | 200 | &lt;/ol&gt; $assistant 100 $members &lt;ol class=list-inline&gt;300 | 200 | 180 | 120 | 100 | &lt;/ol&gt; - lapply() 사용 . lapply(salaries, mean) . $leaders 225 $assistant 100 $members 180 - sapply() 사용 . - 벡터로 출력이 불가능할 때는 lapply() 처럼 list로 출력함 . sapply(salaries, mean) . &lt;dl class=dl-inline&gt;leaders225assistant100members180&lt;/dl&gt; unlist &#54632;&#49688; . - 함수 이름 그대로 list를 unlist로 만들어준다 . unlist(salaries) ## list에서 vector로 변환되었다 . &lt;dl class=dl-inline&gt;leaders1250leaders2200assistant100members1300members2200members3180members4120members5100&lt;/dl&gt; &#45936;&#51060;&#53552; &#54532;&#47112;&#51076;(data frame) . - matrix는 요소가 숫자만 가능했다면 data frame은 문자열과 같은 다른 type도 가능함 . - 데이터 프레임은 리스트의 일종 . - 리스트는 각 변수마다 길이가 달라도 되지만 데이터 프레임은 각 변수마다 길이가 같아야 함(열의 길이가 동일) . course.id &lt;- c(1, 2, 3, 4 ,5, 6 ,7, 8, 9 ,10) mid &lt;- c(8, 22, 25, 25 ,21, 12, 12, 29, 40, 25) final &lt;- c(11, 24, 31, 13 ,34 ,26, NA ,36, 34 ,38) exams &lt;- data.frame(course.id, mid, final) exams . A data.frame: 10 × 3 course.idmidfinal . &lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt; . 1 | 8 | 11 | . 2 | 22 | 24 | . 3 | 25 | 31 | . 4 | 25 | 13 | . 5 | 21 | 34 | . 6 | 12 | 26 | . 7 | 12 | NA | . 8 | 29 | 36 | . 9 | 40 | 34 | . 10 | 25 | 38 | . is.list(exams) . TRUE colnames(exams) . &lt;ol class=list-inline&gt;&#39;course.id&#39; | &#39;mid&#39; | &#39;final&#39; | &lt;/ol&gt; names(exams) . &lt;ol class=list-inline&gt;&#39;course.id&#39; | &#39;mid&#39; | &#39;final&#39; | &lt;/ol&gt; length(exams) . 3 - [row, column]으로 인덱싱 . exams[exams$mid &gt; 20, ] . A data.frame: 7 × 3 course.idmidfinal . &lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt; . 2 2 | 22 | 24 | . 3 3 | 25 | 31 | . 4 4 | 25 | 13 | . 5 5 | 21 | 34 | . 8 8 | 29 | 36 | . 9 9 | 40 | 34 | . 1010 | 25 | 38 | . exams[exams$mid &gt; 20, &#39;final&#39;] ## exams[exams$mid &gt; 20, 3] 과 동일함 . &lt;ol class=list-inline&gt;24 | 31 | 13 | 34 | 36 | 34 | 38 | &lt;/ol&gt; - 데이터 프레임의 각 열은 수치 벡터이므로 연산 가능 . mean(exams[, &quot;mid&quot;]) . 21.9 mean(exams$final) . &lt;NA&gt; - 값이 NA로 나옴 &gt; 7번 학생이 기말시험을 결시함 . - 그럼 어떻게 평균을 구하지? &gt; na.rm = T 옵션을 통해 NA를 제외한 데이터만 사용할 수 있음 . mean(exams$final, na.rm = T) . 27.4444444444444 - 만약 시험을 결시한 경우 0점 처리 한다면? &gt; is.na() 함수를 통해 NA인 경우 TRUE를 아닌 경우 FALSE를 생성하여 처리 가능 . is.na(exams$final) . &lt;ol class=list-inline&gt;FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | TRUE | FALSE | FALSE | FALSE | &lt;/ol&gt; exams$final[is.na(exams$final)] &lt;- 0 ## is.na가 True인 경우만 0으로 변경 exams . A data.frame: 10 × 3 course.idmidfinal . &lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt; . 1 | 8 | 11 | . 2 | 22 | 24 | . 3 | 25 | 31 | . 4 | 25 | 13 | . 5 | 21 | 34 | . 6 | 12 | 26 | . 7 | 12 | 0 | . 8 | 29 | 36 | . 9 | 40 | 34 | . 10 | 25 | 38 | . mean(exams$final) . 24.7 &#46160; &#45936;&#51060;&#53552; &#54532;&#47112;&#51076;&#51032; &#48337;&#54633; . - exams 변수는 중간 기말 성적이 기록되어 있음 . - 새로운 변수 book은 과제와 프로젝트 점수가 student_name의 순서로 정렬되어 있음 . - 이 둘을 합쳐보자 . student_name &lt;- c(&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;, &#39;e&#39;, &#39;f&#39;, &#39;g&#39;, &#39;h&#39;, &#39;i&#39;, &#39;j&#39;) homework &lt;- c(22, 34, 31, 24, 37, 36, 37, 28, 37, 34) project &lt;- c(NA, 7, NA, NA, 17 ,10, 8, NA ,4, NA) course.id &lt;- c(8, 10, 5, 1, 4, 2, 3 ,9 ,7 ,6) book &lt;- data.frame(student_name, homework, project, course.id) book . A data.frame: 10 × 4 student_namehomeworkprojectcourse.id . &lt;chr&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt; . a | 22 | NA | 8 | . b | 34 | 7 | 10 | . c | 31 | NA | 5 | . d | 24 | NA | 1 | . e | 37 | 17 | 4 | . f | 36 | 10 | 2 | . g | 37 | 8 | 3 | . h | 28 | NA | 9 | . i | 37 | 4 | 7 | . j | 34 | NA | 6 | . - NA는 자료의 수치 연산을 불가능하게 하므로 앞서 했던것처럼 is.na()를 통해 0점 처리하자 . book$project[is.na(book$project)] &lt;- 0 book . A data.frame: 10 × 4 student_namehomeworkprojectcourse.id . &lt;chr&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt; . a | 22 | 0 | 8 | . b | 34 | 7 | 10 | . c | 31 | 0 | 5 | . d | 24 | 0 | 1 | . e | 37 | 17 | 4 | . f | 36 | 10 | 2 | . g | 37 | 8 | 3 | . h | 28 | 0 | 9 | . i | 37 | 4 | 7 | . j | 34 | 0 | 6 | . - 2개의 데이터 프레임을 통합하고자 할 때 확인할 것은 각 데이터 프레임에서 개체들의 정렬순서 . 1. 2개의 프레임에서 순서가 같은 경우 열 묶음(cbind)를 한다 &gt; cbind(exams, book) . - 하지만 course.id의 순서가 다르므로 불가능 . 2. 2개의 프레임에서 그 순서가 다른 경우 공통 개체 식별자(key)를 찾아 정의 &gt; merge() 함수가 key 변수를 찾아줌 . class_record &lt;- merge(exams, book, by = &#39;course.id&#39;) class_record . A data.frame: 10 × 6 course.idmidfinalstudent_namehomeworkproject . &lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;chr&gt;&lt;dbl&gt;&lt;dbl&gt; . 1 | 8 | 11 | d | 24 | 0 | . 2 | 22 | 24 | f | 36 | 10 | . 3 | 25 | 31 | g | 37 | 8 | . 4 | 25 | 13 | e | 37 | 17 | . 5 | 21 | 34 | c | 31 | 0 | . 6 | 12 | 26 | j | 34 | 0 | . 7 | 12 | 0 | i | 37 | 4 | . 8 | 29 | 36 | a | 22 | 0 | . 9 | 40 | 34 | h | 28 | 0 | . 10 | 25 | 38 | b | 34 | 7 | . - 위와 같이 key 변수의 이름(위에서는 course.id)이 두 데이터 프레임에서 동일한 경우 by를 사용 &gt; 그렇지 않은 경우에는 by.x와 by.y를 사용 . - 학생들의 총 점수 합계를 구하여 데이터 프레임에 새 변수로 추가해보자 . class_record$total &lt;- apply(class_record[ ,c(2, 3, 5, 6)], 1, sum) class_record . A data.frame: 10 × 7 course.idmidfinalstudent_namehomeworkprojecttotal . &lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;chr&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt; . 1 | 8 | 11 | d | 24 | 0 | 43 | . 2 | 22 | 24 | f | 36 | 10 | 92 | . 3 | 25 | 31 | g | 37 | 8 | 101 | . 4 | 25 | 13 | e | 37 | 17 | 92 | . 5 | 21 | 34 | c | 31 | 0 | 86 | . 6 | 12 | 26 | j | 34 | 0 | 72 | . 7 | 12 | 0 | i | 37 | 4 | 53 | . 8 | 29 | 36 | a | 22 | 0 | 87 | . 9 | 40 | 34 | h | 28 | 0 | 102 | . 10 | 25 | 38 | b | 34 | 7 | 104 | . &#51064;&#51088;&#50752; &#45936;&#51060;&#53552; &#50836;&#50557;(factors and summaries) . - R에서 factor는 범주형 변수(벡터) 또는 비연속적 변수(벡터)를 지칭 . &#51064;&#51088;&#50752; &#53580;&#51060;&#48660; . set.seed(1) ## 시드 넘버 설정 alpha &lt;- sample(c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;), 25, replace = T) ## &#39;A&#39;, &#39;B&#39;, &#39;C&#39; 중에서 무작위로 25개를 중복을 허용하여 뽑는다 f &lt;- factor(alpha) ## alpha를 범주형 변수로 바꿈 . alpha . &lt;ol class=list-inline&gt;&#39;A&#39; | &#39;C&#39; | &#39;A&#39; | &#39;B&#39; | &#39;A&#39; | &#39;C&#39; | &#39;C&#39; | &#39;B&#39; | &#39;B&#39; | &#39;C&#39; | &#39;C&#39; | &#39;A&#39; | &#39;A&#39; | &#39;A&#39; | &#39;B&#39; | &#39;B&#39; | &#39;B&#39; | &#39;B&#39; | &#39;C&#39; | &#39;A&#39; | &#39;C&#39; | &#39;A&#39; | &#39;A&#39; | &#39;A&#39; | &#39;A&#39; | &lt;/ol&gt; f . &lt;ol class=list-inline&gt;A | C | A | B | A | C | C | B | B | C | C | A | A | A | B | B | B | B | C | A | C | A | A | A | A | &lt;/ol&gt; &lt;summary style=display:list-item;cursor:pointer&gt; Levels: &lt;/summary&gt; &lt;ol class=list-inline&gt;&#39;A&#39; | &#39;B&#39; | &#39;C&#39; | &lt;/ol&gt; - 문자열인 alpha와 인자 벡터인 f가 같아 보이지만 다름 . - factor는 Levels이 존재하여 데이터 분류에 용이함 . - str() 함수는 데이터를 요약하여 보여줌 . z &lt;- sample(1:5, 25, replace = T) g &lt;- factor(z) str(data.frame(f = f, g = g)) . &#39;data.frame&#39;: 25 obs. of 2 variables: $ f: Factor w/ 3 levels &#34;A&#34;,&#34;B&#34;,&#34;C&#34;: 1 3 1 2 1 3 3 2 2 3 ... $ g: Factor w/ 5 levels &#34;1&#34;,&#34;2&#34;,&#34;3&#34;,&#34;4&#34;,..: 5 5 2 2 1 4 1 4 3 2 ... . - table()은 빈도표를 만듦 . - addmargins()는 빈도표의 주변 합을 테이블에 추가함 . table(f) . f A B C 11 7 7 . table(f, g) ## f와 g의 인덱스를 보고 만듦 ex) f[x] = &#39;A&#39;이고 g[x] = 3이라면 (&#39;A&#39;, 3)위치의 값을 +1하는 식으로 만듦 . g f 1 2 3 4 5 A 2 3 1 3 2 B 2 2 1 2 0 C 1 3 0 2 1 . addmargins(table(f)) . f A B C Sum 11 7 7 25 . addmargins(table(f, g)) . A table: 4 × 6 of type dbl 12345Sum . A2 | 3 | 1 | 3 | 2 | 11 | . B2 | 2 | 1 | 2 | 0 | 7 | . C1 | 3 | 0 | 2 | 1 | 7 | . Sum5 | 8 | 2 | 7 | 3 | 25 | . tapply&#50752; aggregate&#47196; &#45936;&#51060;&#53552; &#50836;&#50557; . - tapply(x, f, fun)는 x를 f의 수준 별로 쪼개서 fun을 적용함 . - 파이썬에 존재하는 gruopby 함수와 agg 함수를 생각하면 쉽다 . set.seed(2) x &lt;- round(rnorm(25, 50, 10)) data.frame(x = x, f = f) . A data.frame: 25 × 2 xf . &lt;dbl&gt;&lt;fct&gt; . 41 | A | . 52 | C | . 66 | A | . 39 | B | . 49 | A | . 51 | C | . 57 | C | . 48 | B | . 70 | B | . 49 | C | . 54 | C | . 60 | A | . 46 | A | . 40 | A | . 68 | B | . 27 | B | . 59 | B | . 50 | B | . 60 | C | . 54 | A | . 71 | C | . 38 | A | . 66 | A | . 70 | A | . 50 | A | . tapply(x, f, mean) . &lt;dl class=dl-inline&gt;A52.7272727272727B51.5714285714286C56.2857142857143&lt;/dl&gt; tapply(x, f, function(t){max(t)-min(t)}) . &lt;dl class=dl-inline&gt;A32B43C22&lt;/dl&gt; - function()은 사용자 정의 함수임 . - 한 줄일 경우 { }생략 가능 . - 쪼갬의 대상이 벡터가 아니라 데이터 프레임인 경우에는 split()과 sapply()를 함께 이용 . split(data.frame(x = x, z = z), f) . $A A data.frame: 11 × 2 xz . &lt;dbl&gt;&lt;int&gt; . 141 | 5 | . 366 | 2 | . 549 | 1 | . 1260 | 4 | . 1346 | 4 | . 1440 | 4 | . 2054 | 1 | . 2238 | 3 | . 2366 | 2 | . 2470 | 2 | . 2550 | 5 | . $B A data.frame: 7 × 2 xz . &lt;dbl&gt;&lt;int&gt; . 439 | 2 | . 848 | 4 | . 970 | 3 | . 1568 | 2 | . 1627 | 4 | . 1759 | 1 | . 1850 | 1 | . $C A data.frame: 7 × 2 xz . &lt;dbl&gt;&lt;int&gt; . 252 | 5 | . 651 | 4 | . 757 | 1 | . 1049 | 2 | . 1154 | 2 | . 1960 | 4 | . 2171 | 2 | . s &lt;- split(data.frame(x = x, z = z), f) class(s) . &#39;list&#39; sapply(s, apply, 2, mean) . A matrix: 2 × 3 of type dbl ABC . x52.72727 | 51.571429 | 56.285714 | . z 3.00000 | 2.428571 | 2.857143 | . - aggregate(x, list(f, g), fun)은 x를 f와 g의 조합으로 쪼개서 fun을 적용함 . aggregate(data.frame(x = x, z = z)$x, list(f, g), sum) . A data.frame: 13 × 3 Group.1Group.2x . &lt;fct&gt;&lt;fct&gt;&lt;dbl&gt; . A | 1 | 103 | . B | 1 | 109 | . C | 1 | 57 | . A | 2 | 202 | . B | 2 | 107 | . C | 2 | 174 | . A | 3 | 38 | . B | 3 | 70 | . A | 4 | 146 | . B | 4 | 75 | . C | 4 | 111 | . A | 5 | 91 | . C | 5 | 52 | . - tapply()는 쪼갤 기준이 하나 . - aggregate()는 쪼갤 기준이 여러개(list) . cut &#54632;&#49688; . - cut(x, breaks)는 수치형 벡터 x를 breaks로 쪼개서 factor 변수로 만듦(구간화) . - 만약 기준 변수가 factor가 아니라면 factor로 만듦 . set.seed(21) x &lt;- runif(100, 0, 10) y &lt;- 5 + 0.5*(x-5) + rnorm(100) ## x와 y는 선형관계 chr_ &lt;- c(&#39;0&#39;, &#39;1&#39;, &#39;2&#39;, &#39;3&#39;, &#39;4&#39;, &#39;5&#39;, &#39;6&#39;, &#39;7&#39;, &#39;8&#39;, &#39;9&#39;, &#39;10&#39;) x_cut &lt;- cut(x, chr_) class(x_cut) . &#39;factor&#39; chr_ . &lt;ol class=list-inline&gt;&#39;0&#39; | &#39;1&#39; | &#39;2&#39; | &#39;3&#39; | &#39;4&#39; | &#39;5&#39; | &#39;6&#39; | &#39;7&#39; | &#39;8&#39; | &#39;9&#39; | &#39;10&#39; | &lt;/ol&gt; cbind(x, x_cut, y) . A matrix: 100 × 3 of type dbl xx_cuty . 7.8611493 | 8 | 5.8484239 | . 2.5244560 | 3 | 5.5363467 | . 6.9925230 | 7 | 5.7855895 | . 1.8446075 | 2 | 3.0701969 | . 9.5961383 | 10 | 7.8832415 | . 9.1868340 | 10 | 8.1071017 | . 1.0180455 | 2 | 2.9864533 | . 1.7219168 | 2 | 2.4578035 | . 9.8600368 | 10 | 8.3377913 | . 8.4939610 | 9 | 7.9089234 | . 6.6754012 | 7 | 5.3797472 | . 9.3521022 | 10 | 8.1040078 | . 0.5818433 | 1 | 0.6879865 | . 6.1861583 | 7 | 3.9159120 | . 1.7491846 | 2 | 5.1402481 | . 0.3767539 | 1 | 3.4828244 | . 5.2531317 | 6 | 4.6426963 | . 2.8218425 | 3 | 5.8392804 | . 4.9904520 | 5 | 4.6111098 | . 6.3382510 | 7 | 4.0824480 | . 0.1139965 | 1 | 2.7712999 | . 6.0785656 | 7 | 4.4010011 | . 7.7559853 | 8 | 6.8674062 | . 9.2397118 | 10 | 5.3672191 | . 2.9170673 | 3 | 4.4595508 | . 7.8907624 | 8 | 6.5321374 | . 5.6849721 | 6 | 5.5335596 | . 7.7843508 | 8 | 7.2240144 | . 7.1323253 | 8 | 5.3871303 | . 6.6904867 | 7 | 6.1411056 | . ⋮ | ⋮ | ⋮ | . 5.2419521 | 6 | 4.802874 | . 5.3472914 | 6 | 4.589883 | . 9.6766790 | 10 | 7.405624 | . 5.2833101 | 6 | 5.497121 | . 5.3193106 | 6 | 5.138644 | . 6.2043358 | 7 | 6.850795 | . 9.2198573 | 10 | 6.225241 | . 2.2786153 | 3 | 2.754301 | . 9.2766458 | 10 | 6.687593 | . 9.2997805 | 10 | 8.441203 | . 5.2228023 | 6 | 5.490241 | . 9.9086911 | 10 | 8.955029 | . 0.6460298 | 1 | 2.554238 | . 8.6259344 | 9 | 8.088017 | . 4.8062732 | 5 | 5.224632 | . 5.3615727 | 6 | 6.835729 | . 4.1513448 | 5 | 3.384017 | . 2.2846328 | 3 | 3.595330 | . 9.8195084 | 10 | 5.809714 | . 6.5597644 | 7 | 4.664516 | . 5.8016786 | 6 | 6.295498 | . 1.4083867 | 2 | 2.498659 | . 6.9767447 | 7 | 5.034914 | . 7.4802064 | 8 | 7.236793 | . 9.5334043 | 10 | 6.601671 | . 1.3104292 | 2 | 1.524249 | . 6.4997197 | 7 | 6.496078 | . 7.0777577 | 8 | 5.070752 | . 0.9994111 | 1 | 2.695506 | . 0.6916488 | 1 | 3.510434 | . . - $(x, y)$의 산점도에 $x$의 구간별 평균을 막대로 넣어 구간별 평균의 이동을 산출해보자 . y_local &lt;- aggregate(y, list(x_cut), mean) ## x_cut은 1~10까지 존재 &gt; 1부터 10까지 x_cut별로 따로 모아 그에 해당하는 y 데이터의 평균을 구함 y_local . A data.frame: 10 × 2 Group.1x . &lt;fct&gt;&lt;dbl&gt; . (0,1] | 2.597557 | . (1,2] | 3.252382 | . (2,3] | 4.148030 | . (3,4] | 2.849470 | . (4,5] | 4.448115 | . (5,6] | 5.436146 | . (6,7] | 5.198160 | . (7,8] | 6.197139 | . (8,9] | 6.638144 | . (9,10] | 7.384560 | . plot(x, y, ylim = c(0, 10), main = &quot;x vs y&quot; ) segments(0:9, y_local$x, 1:10, y_local$x, lwd = 2) ## segments 함수는 x좌표와 y좌표를 입력받아 line을 그려줌 abline(v = 1:9, lty = &quot;dotted&quot;) ## abline 함수는 line을 그려줌, v는 수직선의 위치 . - 참고: abline 함수 . - 참고: segments 함수 . &#51077;&#52636;&#47141;(input and output) . - read.table read.csv(&#39;파일 위치&#39;) &gt; 텍스트 파일 or csv 파일을 읽어 내부 저장소에 dataframe으로 만듦 . - getwd() &gt; 현재의 작업 디렉토리를 알려줌 . - setwd(&#39;위치&#39;) &gt; 작업 디렉토리를 입력한 위치로 변경 . - dir() &gt; 현재 작업 디렉토리에 있는 파일들의 리스트를 보여줌 . - write.table write.csv()은 특정 데이터 프레임을 작업 디렉토리에 텍스트 파일 or csv 파일로 입력함 . - 파일을 읽을 때 stringAdFactors = F 옵션을 적용하면 문자열 변수가 자동으로 factor 형이 되는 것을 막아줌 . - sink()함수를 통해 결과값을 텍스트 파일로 저장할 수 있음 &gt; sink function . scan &#54632;&#49688; . - scan() &gt; 비정형의 문자열 데이터를 읽을 때 유용 . - what 은 읽어 들일 데이터 값 형식 numeric, logical, character . - 책 따라 하는데 scan함수가 제대로 작동되지 않아 찾아보니 quote = &quot;&quot; 로 하지 않아서라고 함 &gt; 참고: https://pythonq.com/so/r/29317 . - quote = &quot;&quot; 옵션을 적용하지 않으면 Read 1 item을 반환 &gt; 빈칸을 기준으로 문자열을 쪼개지 않았다는 뜻 &gt; 그런데 sep = &quot; n&quot; 으로 하면 Read 20 item임 . - 원인을 알았는데 내가 yesterday노래 가사 텍스트 파일을 만들 때 맨 앞에 &quot; 기호를 실수로 추가했었음 &gt; &quot; 기호를 없애니 잘 동작함 . lyrics &lt;- scan(&quot;yesterday.txt&quot;, what = &quot;character&quot;) ## quote = &quot;&quot; 옵션을 적용 안해도 잘 동작함 . str(lyrics) . chr [1:126] &#34;Yesterday,&#34; &#34;all&#34; &#34;my&#34; &#34;troubles&#34; &#34;seemed&#34; &#34;so&#34; &#34;far&#34; &#34;away.&#34; ... . head(lyrics, 10) . &lt;ol class=list-inline&gt;&#39;Yesterday,&#39; | &#39;all&#39; | &#39;my&#39; | &#39;troubles&#39; | &#39;seemed&#39; | &#39;so&#39; | &#39;far&#39; | &#39;away.&#39; | &#39;Now&#39; | &#39;it&#39; | &lt;/ol&gt; - 빈칸을 구분자로 인식하여 문자열을 쪼개어 읽어옴 + 줄 단위로 읽고 싶다면 sep = &quot; n&quot; . lyrics_2 &lt;- scan(&quot;yesterday.txt&quot;, what = &quot;character&quot;, sep = &quot; n&quot;) . str(lyrics_2) . chr [1:20] &#34;Yesterday, all my troubles seemed so far away.&#34; ... . head(lyrics_2, 5) . &lt;ol class=list-inline&gt;&#39;Yesterday, all my troubles seemed so far away.&#39; | &#39;Now it looks as though they &#39;re here to stay.&#39; | &#39;oh, I believe in yesterday.&#39; | &#39;Suddenly, I &#39;m not half the man I used to be.&#39; | &#39;There &#39;s a shadow hanging over me.&#39; | &lt;/ol&gt; cat &#54632;&#49688; . - print함수와 비슷하나 여러개의 출력이 가능하고 출력이 공백 없이 이어짐 . print(&quot;a&quot;) print(&quot;b&quot;) . [1] &#34;a&#34; [1] &#34;b&#34; . cat(&quot;a&quot;) cat(&quot;b&quot;) . ab . &#47928;&#51088;&#50676; &#51089;&#50629; . grep &#54632;&#49688; . - grep(pattern, x)는 x에서 pattern이 있는 곳을 알려줌 . grep(&quot;Yesterday&quot;, lyrics) . &lt;ol class=list-inline&gt;1 | 63 | 105 | &lt;/ol&gt; grep(&quot;yesterday&quot;, lyrics) . &lt;ol class=list-inline&gt;22 | 40 | 62 | 84 | 104 | 126 | &lt;/ol&gt; - &quot;Yesterday&quot;는 1 ,63 ,105번째 요소에 있고 &quot;yesterday&quot;는 22, 40 ,62, 84, 104, 126번째 요소에 있음을 알려줌 . - 이번에는 &quot;?&quot;를 찾아보자 . - grep(&quot;?&quot;, lyrics)를 하면 될 것 같지만 아님 . grep(&quot;?&quot;, lyrics) . &lt;ol class=list-inline&gt;1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11 | 12 | 13 | 14 | 15 | 16 | 17 | 18 | 19 | 20 | 21 | 22 | 23 | 24 | 25 | 26 | 27 | 28 | 29 | 30 | 31 | 32 | 33 | 34 | 35 | 36 | 37 | 38 | 39 | 40 | 41 | 42 | 43 | 44 | 45 | 46 | 47 | 48 | 49 | 50 | 51 | 52 | 53 | 54 | 55 | 56 | 57 | 58 | 59 | 60 | 61 | 62 | 63 | 64 | 65 | 66 | 67 | 68 | 69 | 70 | 71 | 72 | 73 | 74 | 75 | 76 | 77 | 78 | 79 | 80 | 81 | 82 | 83 | 84 | 85 | 86 | 87 | 88 | 89 | 90 | 91 | 92 | 93 | 94 | 95 | 96 | 97 | 98 | 99 | 100 | 101 | 102 | 103 | 104 | 105 | 106 | 107 | 108 | 109 | 110 | 111 | 112 | 113 | 114 | 115 | 116 | 117 | 118 | 119 | 120 | 121 | 122 | 123 | 124 | 125 | 126 | &lt;/ol&gt; . - &quot;?&quot;는 정규표현식 기호로 사용되게 원래의 물음표 기호를 사용하고자 하면 &quot; &quot;을 앞에 넣어줘야함 &gt; 나중에 정규표현식 공부하자 . grep(&quot; ?&quot;, lyrics) . &lt;ol class=list-inline&gt;47 | 89 | &lt;/ol&gt; nchar &#54632;&#49688; . - nchar(x)는 문자열 x의 길이를 알려줌(빈칸 포함) . nchar(&quot;yesterday&quot;) . 9 - 참고 : length(x)의 결과는 아래와 같음 . length(&quot;yesterday&quot;) . 1 - 문자열 벡터에도 적용 가능함 . nchar(lyrics) . &lt;ol class=list-inline&gt;10 | 3 | 2 | 8 | 6 | 2 | 3 | 5 | 3 | 2 | 5 | 2 | 6 | 7 | 4 | 2 | 5 | 3 | 1 | 7 | 2 | 10 | 9 | 3 | 3 | 4 | 3 | 3 | 1 | 4 | 2 | 3 | 7 | 1 | 6 | 7 | 4 | 3 | 3 | 9 | 4 | 9 | 3 | 3 | 3 | 2 | 3 | 1 | 5 | 5 | 3 | 8 | 4 | 1 | 4 | 9 | 6 | 3 | 1 | 4 | 3 | 10 | 9 | 4 | 3 | 4 | 2 | 4 | 4 | 2 | 5 | 3 | 1 | 4 | 1 | 5 | 2 | 4 | 5 | 3 | 1 | 7 | 2 | 10 | 3 | 3 | 3 | 2 | 3 | 1 | 5 | 5 | 3 | 8 | 4 | 1 | 4 | 9 | 6 | 3 | 1 | 4 | 3 | 10 | 9 | 4 | 3 | 4 | 2 | 4 | 4 | 2 | 5 | 3 | 1 | 4 | 1 | 5 | 2 | 4 | 5 | 3 | 1 | 7 | 2 | 12 | &lt;/ol&gt; paste &#54632;&#49688; . - 다수의 문자열을 붙여 하나의 문자열을 만듦 . - 파이썬의 join 함수를 생각하면 된다 . paste(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;) . &#39;a b c&#39; paste(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, sep = &quot;-&quot;) . &#39;a-b-c&#39; - paste 함수는 디폴트로 빈칸 하나를 기준으로 문자열을 붙인다 . - paste0 함수를 사용하면 빈칸 없음을 기준으로 문자열을 붙일 수 있다 . paste0(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;) . &#39;abc&#39; substr &#54632;&#49688; . - substr(x, start, stop)은 x에서 start부터 stop까지의 문자열을 뽑아낸다 . substr(&quot;abcdefg&quot;, 2, 4) . &#39;bcd&#39; strsplit &#54632;&#49688; . - strsplit(x, split)은 x를 split을 기준으로 분리한다 . - 파이썬의 split 함수를 생각하면 쉽다 . strsplit(&quot;a-b-c-d-e&quot;, &quot;-&quot;) . &lt;ol class=list-inline&gt;&#39;a&#39; | &#39;b&#39; | &#39;c&#39; | &#39;d&#39; | &#39;e&#39; | &lt;/ol&gt; | class(strsplit(&quot;a-b-c-d-e&quot;, &quot;-&quot;)) ## 쪼갠 문자열들의 타입은 list이다 . &#39;list&#39; unlist(strsplit(&quot;a-b-c-d-e&quot;, &quot;-&quot;)) . &lt;ol class=list-inline&gt;&#39;a&#39; | &#39;b&#39; | &#39;c&#39; | &#39;d&#39; | &#39;e&#39; | &lt;/ol&gt; strsplit(c(&quot;a-b-c-d-e&quot;, &quot;qq-bb&quot;), &quot;-&quot;) ## 문자열 벡터도 가능 . &lt;ol class=list-inline&gt;&#39;a&#39; | &#39;b&#39; | &#39;c&#39; | &#39;d&#39; | &#39;e&#39; | &lt;/ol&gt; | &lt;ol class=list-inline&gt;&#39;qq&#39; | &#39;bb&#39; | &lt;/ol&gt; | gregexpr &#54632;&#49688;(global regular expression) . - gregexpr(pattern, x)은 x에서 pattern이 발견되는 모든 위치를 알려준다 . - 파이썬의 index 함수를 생각하면 쉽다 . unlist(gregexpr(&quot;-&quot;, &quot;2021-12-22&quot;)) . &lt;ol class=list-inline&gt;5 | 8 | &lt;/ol&gt; - grep 함수와의 차이점은 아래와 같음 . unlist(grep(&quot;-&quot;, &quot;2021-12-22&quot;)) . 1 - grep 함수에서는 &quot;2021-12-22&quot;를 하나 취급한다 . - 마치 length(&quot;2021-12-22&quot;)는 $1$인것처럼 . - 포함여부만 확인 가능하고 문자열의 어느 위치에 존재하는지는 확인 불가능함 . unlist(gregexpr(&quot;-&quot;, c(&quot;2021-12-22&quot;, &quot;12-22&quot;))) ## 첫 번째 문자열에선 5, 8위치에 &quot;-&quot;이 존재하고 ## 두 번째 문자열에선 3 위치에 &quot;-&quot; 존재한다 . &lt;ol class=list-inline&gt;5 | 8 | 3 | &lt;/ol&gt; unlist(grep(&quot;-&quot;, c(&quot;2021-12-22&quot;, &quot;12-22&quot;))) ## 첫 번째 문자열에 &quot;-&quot;이 존재하고 ## 두 번째 문자열에 &quot;-&quot;이 존재한다 ## 문자열 어느 위치에 &quot;-&quot;이 존재하는지는 알 수 없다 . &lt;ol class=list-inline&gt;1 | 2 | &lt;/ol&gt; - regexpr 함수(regular expression)도 있는데 이 함수는 처음 위치만 알려준다 . unlist(regexpr(&quot;-&quot;, &quot;2021-12-22&quot;)) ## 8번째 인덱스에도 &quot;-&quot;이 존재하지만 처음 &quot;-&quot;이 등장한 위치만 알려준다 . 5 gsub &#54632;&#49688; (global substitude) . - gsub(pattern, replace, x)은 x에 있는 pattern을 replace로 바꾼다 . - 파이썬의 replace 함수를 떠올리면 쉽다 . gsub(&quot;-&quot;, &quot;.&quot;, &quot;2021-12-22&quot;) . &#39;2021.12.22&#39;",
            "url": "https://jaesu26.github.io/study-blog/r/2021/08/20/R%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D.html",
            "relUrl": "/r/2021/08/20/R%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D.html",
            "date": " • Aug 20, 2021"
        }
        
    
  
    
        ,"post34": {
            "title": "파이썬 scipy.stats",
            "content": "- 확률분포를 scipy.stats를 통해 그리는데 익숙하지 않아 기본 사용에 대해 알아볼 거임 . - 참고: scipy.stats . - 참고: scipy 확률분포 . &#54869;&#47456;&#48516;&#54252; &#53364;&#47000;&#49828; . - scipy.stats를 통해 확률분포를 그려보자 . - 우선 확률분포에 대한 클래스 객체를 생성해야 함 . - 각 확률분포의 파라미터는 scipy.stats.이름을 통해 확인하자 . 종류 이름 확률분포 . 이산 | bernoulli | 베르누이 분포 | . 이산 | binom | 이항 분포 | . 이산 | poisson | 포아송 분포 | . 이산 | geom | 기하 분포 | . 이산 | nbinom | 음이항 분포 | . 이산 | hypergeom | 초기하 분포 | . 이산 | multinomial | 다항 분포 | . 연속 | norm | 정규 분포 | . 연속 | uniform | 균일 분포 | . 연속 | expon | 지수 분포 | . 연속 | gamma | 감마 분포 | . 연속 | t | t 분포 | . 연속 | chi2 | 카이제곱 분포 | . 연속 | f | f 분포 | . 연속 | beta | 베타 분포 | . &#47784;&#49688; &#51648;&#51221; . - 확률분포의 모수는 종류별로 다르므로 문서를 참고하자 . - 하지만 대부분 확률분포가 공통적으로 가지는 모수가 있음 . 모수 이름 의미 . loc | 기댓값 | . scale | 표준편차 | . &#54869;&#47456;&#48516;&#54252; methods . - 확률분포 클래스 객체가 가지는 method가 있음 . - 정규분포를 예로 들어 ppf에 대한 설명을 해보면 norm.ppf(0.5)는 정규분포에서 $50$분위수에 해당하는 $x$값으로 $0$이다 . 메서드 기능 . pmf | 확률질량함수 | . pdf | 확률밀도함수 | . cdf | 누적분포함수 | . ppf | 누적분포함수의 역함수(백분위 함수) | . sf | 생존함수 = 1 $-$ 누적분포함수 | . isf | 생존함수의 역함수 | . rvs | 무작위 표본 생성 | . &#54869;&#47456;&#48516;&#54252; plot . &#51221;&#44508; &#48516;&#54252; pdf . - 정규 분포 pdf를 그려보자 . import numpy as np import matplotlib.pyplot as plt from scipy.stats import norm xx = np.linspace(-5, 5, 1000) for scale in (0.5, 1.0, 2.0): plt.plot(xx, norm(0, scale).pdf(xx), label = &#39;μ = 0, σ = &#39; + str(scale), lw = 2, alpha = 0.8) plt.plot(xx, norm(-2, 0.5).pdf(xx), label = &#39;μ = -2, σ = 0.5&#39;, lw = 2, alpha = 0.8) plt.xticks(np.arange(-5, 6)) plt.yticks(np.arange(0.0, 1.2, 0.2)) plt.title(&quot;normal distribution pdf&quot;) plt.xlabel(&quot;$x$&quot;) plt.ylabel(&quot;$f(x)$&quot;) plt.grid() plt.legend() plt.show() . &#51221;&#44508; &#48516;&#54252; cdf . - 정규 분포 cdf를 그려보자 . - cdf에 대한 내용 정리 예정 . import numpy as np import matplotlib.pyplot as plt from scipy.stats import norm xx = np.linspace(-5, 5, 1000) for scale in (0.5, 1.0, 2.0): plt.plot(xx, norm(0, scale).cdf(xx), label = &#39;μ = 0, σ = &#39; + str(scale), lw = 2, alpha = 0.8) plt.plot(xx, norm(-2, 0.5).cdf(xx), label = &#39;μ = -2, σ = 0.5&#39;, lw = 2, alpha = 0.8) plt.xticks(np.arange(-5, 6)) plt.yticks(np.arange(0.0, 1.2, 0.2)) plt.title(&quot;normal distribution cdf&quot;) plt.xlabel(&quot;$x$&quot;) plt.ylabel(&quot;$f(x)$&quot;) plt.grid() plt.legend() plt.show() .",
            "url": "https://jaesu26.github.io/study-blog/python/statistics/2021/08/10/scipy-stats.html",
            "relUrl": "/python/statistics/2021/08/10/scipy-stats.html",
            "date": " • Aug 10, 2021"
        }
        
    
  
    
        ,"post35": {
            "title": "가설검정",
            "content": "- 대표적인 확률분포에 대한 간단한 정리를 마친 후 작성할 예정임 &gt; 시작 . - 참고: Statistics: Unlocking the power of data, Robin Lock 외 4인 . &#51473;&#49900;&#44537;&#54620;&#51221;&#47532;(central limit theorem) . - 동일한 확률분포를 가진 독립확률변수 $n$개의 평균의 분포는 충분히 크다면($n geq 30$이면) 정규분포에 가까워짐 . - 앞으로 많은 가설검정에서 사용될 예정 . - 증명 링크 : https://en.wikipedia.org/wiki/Central_limit_theorem#Proof_of_classical_CLT . &#48531;&#49828;&#53944;&#47017;&#44284; p-&#44050; . &#48531;&#49828;&#53944;&#47017;(Bootstrap) . - 뒤에서 설명할 내용들에 붓스트랩과 p-값의 개념이 쓰여서 알고가자 . - 이를 위해 간단한 예시를 들어보자 . - 전북대학교 학생들의 평균 맥박수가 모종의 이유로 궁금하다고 해보자(표본조사론 프로젝트? ㅋㅋ) . - 제일 먼저 떠오르는 생각은 전북대학교 학생들을 전부 불러모아 맥박을 측정하고 이를 평균내는 것이다 . - 확실한 방법이지만 일일이 맥박을 어느 세월에 측정할 것인가... . - 그래서 생각한 방법이 모든 학생의 맥박을 측정하는 대신에 일부 학생들의 맥박만 측정하여 평균을 내는 것이다 . - ??? : 일부 학생들의 맥박 평균과 전체 학생들의 맥박 평균이 같은지 어떻게 확신함?? . - 국이나 찌개등의 간을 볼 때 조금만 먹어보고 짠지 싱거운지 판단하는데 이는 음식에 간이 골고루 배도록 잘 섞어주었기 때문이다 . - 만약 간이 골고루 배어있지 않으면 위의 판단은 틀릴 수 있다 . - 마찬가지로 학생들을 골고루 잘 선택한다면(?) 일부 학생들의 맥박을 가지고 전체 학생들을 대표할 수 있을 것이다 . - 골고루 잘 선택하는 방법에는 학생들에게 1번부터 차례차례 번호를 부여하고 시스템을 통해 50개의 번호를 뽑는 것이 있다 . import numpy as np import matplotlib import matplotlib.pyplot as plt matplotlib.rcParams[&#39;font.family&#39;] = &#39;Malgun Gothic&#39; # 한글이 깨지지 않도록 설정 matplotlib.rcParams[&#39;axes.unicode_minus&#39;] = False # 한글이 깨지지 않도록 설정 np.random.seed(42) blood_pressure = np.random.normal(85, 15, 10000) ## 모집단 plt.hist(blood_pressure, bins=np.arange(int(np.min(blood_pressure)), int(np.max(blood_pressure)) + 1, 2)) plt.title(&#39;전북대학교 학생들의 맥박수 분포&#39;, fontsize=15) plt.show() . . - 전체 전북대학교 학생들의 맥박(모집단)을 일일이 측정하기 힘드니 임의의로 50명의 학생만 뽑아 맥박을 측정하고 평균을 내자 . - 모집단은 평균이 85, 표준편차가 15인 정규분포를 따른다고 가정하자 . sample = np.random.choice(blood_pressure, size=50, replace=False) print(f&#39;50명의 평균 맥박수는 {np.round(np.mean(sample), 1)}입니다&#39;) . 50명의 평균 맥박수는 85.9입니다 . - 50명을 무작위로 뽑아 맥박을 재고 이를 평균내보니 85.9가 나왔다 . - 그러면 이제 전북대학교 전체 학생들의 평균 맥박수가 85.9라고 할 수 있을까? . - 안타깝게도 그럴 수 없는데 무작위로 50명을 다시 뽑으면 당연하게도 다른 결과가 나오기 때문이다 . sample = np.random.choice(blood_pressure, size=50, replace=False) print(f&#39;50명의 평균 맥박수는 {np.round(np.mean(sample), 1)}입니다&#39;) . 50명의 평균 맥박수는 83.9입니다 . - 이번에는 평균이 83.9이다 . - 위의 결과로부터 2가지 문제점이 생겼다 . - 첫 번째는 평균 맥박수를 85.9로 해야될지 83.9로 해야될지 모르겠다는 것이고 . - 두 번째는 매번 50명씩 학생들의 맥박을 재는것도 쉬운일은 아니라는 것이다 . - 일단 첫 번째 문제는 전체 전북대학교 학생들의 평균 맥박수(모평균=모집단의 평균)를 점추정이 아닌 구간추정을 하면 된다 . - 즉, 모평균을 85.9, 83.9와 같이 하나의 값으로 나타내지 말고 정확히 몇인지는 모르지만 아마도 83에서 87사이인 것 같다와 같은 방식으로 나타내는 것이다 . - 그러면 구간은 어떻게 정할 것인지? &gt; 50명씩 학생들을 무작위로 뽑아 맥박을 재고 이를 평균낸다 &gt; 이를 엄청 많이 반복하자 &gt; 표본평균의 분포(표집분포) . - 그리고 최소값과 최대값을 기준으로 삼자! . - 1000번 정도 반복해보자 . np.random.seed(42) samples = [np.mean(np.random.choice(blood_pressure, size=50, replace=False)) for i in range(1000)] plt.hist(samples, bins=np.arange(int(np.min(samples)), int(np.max(samples)) + 0.5, 1)) plt.title(&#39;50명의 맥박수 평균의 분포&#39;, fontsize=15) plt.show() . . print(f&#39;구간의 최소값은 {np.round(np.min(samples), 1)}이고 최대값은 {np.round(np.max(samples), 1)}입니다&#39;) . 구간의 최소값은 78.6이고 최대값은 92.3입니다 . - 아마도 전북대학교 학생들의 평균 맥박수는 78.6에서 92.3사이인 것 같다 . - 그런데 사실 구간의 경계를 최소값과 최대값으로 할 필요는 없다 . - 예컨대 83과 87사이로 해도 된다 . - 구간의 폭이 좁으면 정확도는 떨어지지만 그만큼 쓸모가 있고 구간의 넓으면 정확도는 높아지지만 쓸모가 없다 . - 평균 맥박수가 0에서 200사이라고 한다면 정확하지만 쓸모가 없다... . - 한편, 정규분포인 경우 중심(평균)에서 표준편차의 2배 거리안에 95%의 데이터가 존재한다 . - 중심극한정리에 의해 표본크기가 30보다 큰 50이므로 표본평균의 분포(표집분포)는 정규분포를 따른다 . - 구간을 정한다는 것은 위에서 언급한 &quot;아마도(= 믿음의 크기)&quot;를 정한다는 것과 다름이 없다(구간이 넓으면 믿음의 크기가 커지고 좁으면 반대니까) . - 구간을 표집분포의 평균에서 표집분포의 표준편차(표준오차)의 2배 거리 내부로 정하면 어떨까?(95%의 데이터가 존재) . - 위에서 구한 1000개의 표본평균 중에서 95%나 구간안에 속한다!(정확도 높고 쓸모 있음) . - 그리고 이러한 구간을 신뢰구간이라고 표현한다 . - 여기서는 95% 신뢰구간! . samples_mean = np.mean(samples) samples_std = np.std(samples, ddof=1) print(f&#39;표집분포의 평균은 {np.round(samples_mean, 1)}이고 표준오차는 {np.round(samples_std, 1)}입니다&#39;) . 표집분포의 평균은 85.0이고 표준오차는 2.1입니다 . - 95% 신뢰구간은 표집분포의 평균에서 표준오차의 2배 거리 내부이므로 다음과 같다 . print(f&#39;전북대학교 학생들의 평균 맥박수에 대한 95% 신뢰구간은 ({np.round(samples_mean - 2*samples_std, 1)}, {np.round(samples_mean + 2*samples_std, 1)}) 입니다&#39;) . 전북대학교 학생들의 평균 맥박수에 대한 95% 신뢰구간은 (80.9, 89.2) 입니다 . - 전북대학교 학생들의 평균 맥박수의 95% 신뢰구간을 구했다! . - 누군가가 전북대학교 학생들의 평균 맥박수에 몇인지 물어본다면 답변할 수 있다! . - 전북대학교 학생들의 평균 맥박수가 몇이죠?? &gt; 정확히는 모르지만 80.9에서 89.2사이에 존재함을 95% 신뢰합니다! . - 신뢰한다는 표현이 현재로는 애매하게 느껴지지만 일단은 넘어가자 . - 드디어 전북대학교 학생들의 평균 맥박수가 어느정도인지 말할 수 있게 되었다 . - 그런데 심각한 문제점이 하나 있다 . - 위에서 말한 두 번째 문제점이다 . - 두 번째 문제점 : 매번 50명씩 학생들의 맥박을 재는것도 쉬운일은 아니다 . - 위에서 신뢰구간을 구하기 위해 50명의 맥박수를 재는 일을 1000번이나 반복했다 . - 총 50000명(중복 포함임)의 맥박수를 측정함... . - 우리가 처음에 전북대학교 학생들의 평균 맥박수를 구하기 위해 접근한 방식을 사용하면 . - 50000명씩 맥박수를 재지 않고 50명의 맥박수만 재는 것으로 신뢰구간을 구할 수 있다 . - 처음 접근한 방식 : 학생들을 골고루 잘 선택한다면(?) 일부 학생들의 맥박을 가지고 전체 학생들을 대표할 수 있을 것이다 . - 우리는 무작위로 50명의 학생들을 골랐다 &gt; 정말 무작위로 학생들을 골랐다면 이들이 전체를 대표할 수 있을것이다 . - 다르게 생각해보면 전체 학생들은 무작위로 고른 50명의 학생들을 복제한 것으로 판단할 수 있다! . - 즉 50명의 학생들을 무작위로 뽑고 이후부터는 50명의 학생들을 복원추출하면 된다 . - 그러면 50000명씩 맥박수를 재지 않고 단지 50명의 맥박수만 재는 것으로 위에서 구한 95% 신뢰구간을 계산할 수 있다 . np.random.seed(42) random_sample = np.random.choice(blood_pressure, size=50, replace=False) ## 학생 50명을 무작위로 뽑는다 bootstrap = [np.mean(np.random.choice(random_sample, size=50, replace=True)) for i in range(1000)] ## 무작위로 뽑은 50명의 학생들을 50명씩 복원추출한다(1000번 반복하자) plt.hist(bootstrap, bins=np.arange(int(np.min(bootstrap)), int(np.max(bootstrap)) + 0.5, 1)) plt.title(&#39;50명의 맥박수 평균의 붓스트랩 분포&#39;, fontsize=15) plt.show() . . - 95% 신뢰구간은 표집분포에서 구한것과 같은 방법으로 구한다 . - 붓스트랩 분포의 평균과 표준편차를 알면 구할 수 있음 . bootstrap_mean = np.mean(bootstrap) bootstrap_std = np.std(bootstrap, ddof=1) print(f&#39;붓스트랩 분포의 평균은 {np.round(bootstrap_mean, 1)}이고 표준오차는 {np.round(bootstrap_std, 1)}입니다&#39;) . 붓스트랩 분포의 평균은 87.1이고 표준오차는 2.1입니다 . print(f&#39;붓스트랩을 사용하여 계산한 전북대학교 학생들의 평균 맥박수에 대한 95% 신뢰구간은 ({np.round(bootstrap_mean - 2*bootstrap_std, 1)}, {np.round(bootstrap_mean + 2*bootstrap_std, 1)}) 입니다&#39;) . 붓스트랩을 사용하여 계산한 전북대학교 학생들의 평균 맥박수에 대한 95% 신뢰구간은 (83.0, 91.2) 입니다 . - 위의 붓스트랩에 기반한 95% 신뢰구간은 모평균($ mu=85$)를 포함한다 . - 표본평균의 분포를 사용했을 때와 표본평균의 붓스트랩 분포를 사용했을 때의 결과를 비교하면 한가지 차이점이 존재한다 . - 분포의 중심(평균)이 다르다 . - 그런데 표준편차는 동일하다 . - 표본평균의 분포의 중심은 모평균에 수렴하지만 표본평균의 붓스트랩 분포의 중심은 표본평균(50명 학생들의 맥박수 평균)에 수렴한다 . - 붓스트랩은 처음에 뽑은 50명 표본 하나를 가지고 확장하여 사용하기 때문에 중심은 모평균이 아닌 50명 학생들의 맥박수에 수렴할 수 밖에 없다 . - 만약 처음에 뽑은 50명이 운이 없게도 전부 극단값에 치우쳐져 있다면 이를 가지고 만든 신뢰구간은 모평균을 포함하지 못할 것이다 . - 하지만 처음에 뽑은 50명이 극단값에 치우쳐져 있는지 아니면 중심 부근에 위치한지 어떻게 알 수 있지?? . - 당연하게도 모집단에 대한 정보를 모르는 상태에서 뽑은 표본은 극단적인지 아닌지 알 방법이 없다 . - 전북대학생들의 맥박수 평균이 얼마인지도 모르고 당연히 분포의 모양도 모르는 상태에서 . - 무작위로 뽑은 학생 50명의 평균 맥박이 극단적인 값인지 아닌지 알 수 없다 . 그렇기에 이를 가지고 만든 신뢰구간을 가지고 다음과 같이 말할 수 밖에 없다 | . - 내가 붓스트랩 표본을 가지고 신뢰구간을 만들었는데 이 신뢰구간이 모평균을 포함하는지 안하는지는 모르겠어 . - 하지만 붓스트랩 표본을 가지고 신뢰구간을 만드는 행위를 반복한다면 이 중에서 95%의 신뢰구간은 모평균을 포함할 거야 . - 여기서 95%는 신뢰수준을 나타낸다 . 그런데 95% 신뢰수준이나 95% 확률이나 똑같은거 아닌가? | . &#49888;&#47280;&#49688;&#51456;&#44284; &#54869;&#47456;&#51032; &#52264;&#51060; . - 95% 신뢰수준과 95% 확률의 차이점을 간단히 알아보자 . - 예컨대 95% 확률로 아이유짤과 같은 글이 있다고 해보자 . - 글을 클릭했는데 아이유 사진이 나왔다! . - 그런데 다시 글을 클릭하더라도 계속해서 아이유 사진밖에 나오지 않는다 . - 즉, 변동성이 없다 . - 제목이 맞는 말이 되려면 글을 클릭해서 사진을 보는 행위를 반복하면 이 중에서 95%는 아이유 사진이고 나머지 5%는 다른 사진이어야 한다 . - 하지만 계속 클릭해도 아이유 사진밖에 나오지 않으므로 95% 확률로 아이유짤 이라는 말은 틀렸다 . - 글을 클릭하기 전부터 아이유 사진인지 다른 사진인지가 고정되어 있다(마찬가지로 위의 맥박 수 예시에서 모평균은 고정된 값이다) . - 그럼 95% 신뢰수준으로 아이유짤은 무엇을 의미하는 걸까? . - &quot;95% 신뢰수준으로 아이유짤&quot;과 같은 글이 여러개가 있고 이 중에서 95% 정도가 아이유 사진이라는 것을 의미한다 . p-&#44050; . - 위의 붓스트랩 매커니즘을 알고있으면 p-값은 간단하다 . - 이번에는 사람들의 평균 맥박수가 얼마인지 궁금하기 보다는 . - 기존의 알려진 평균 맥박수보다 현재의 평균 맥박수가 더 큰지가 궁금하다고 해보자 . - 예컨대 10년전 사람들의 평균 맥박수가 85라고 하자 . - 이러한 상황에서 현재 사람들의 평균 맥박수는 85보다 큰지가 궁금한 것이다 . - 이를 검정하기 위해 무작위로 50명의 사람을 뽑은 뒤 평균 맥박수를 구하자 . np.random.seed(42) blood_pressure = np.random.normal(85, 15, 10000) ## 10년전 모집단 blood_pressure2 = np.random.normal(92, 15, 10000) ## 현재 모집단 sample = np.random.choice(blood_pressure2, size=50, replace=False) print(f&#39;50명의 평균 맥박수는 {np.round(np.mean(sample), 1)}입니다&#39;) . . 50명의 평균 맥박수는 90.0입니다 . - 50의 평균 맥박수는 90이다 . - 이는 분명 85보다 크지만 표본 평균을 변동성에 의해 계산할 때마다 달라지므로 운에 의한 것일 수도 있다 . - 이를 파악하기 위해 다음의 과정을 생각하자 . 1. 평균 맥박수가 85(영가설 또는 귀무가설이라고 함)라는 가정하에 표본평균의 분포를 고려 . 2. 영가설하에 표본평균의 분포에서 90이 극단적인 값에 속한다면 이러한 상황이 발생할 확률은 매우 낮으므로 영가설은 틀렸다고 할 수 있음 . - 평균 맥박수를 85로 만들기위해 위에서 구한 50명의 맥박수에 대해 $(85-90)$만큼을 더해주자 . - 이와 같은 트릭을 통해 영가설하에서 표본평균의 분포를 고려할 수 있음 . - 표본평균의 분포는 붓스트랩을 이용하여 생성하자! . np.random.seed(42) sample = sample + (85 - 90) ## 영가설하에서의 평균인 85로 평균을 맞춰주기 위함(기존의 평균 90 -&gt; 영가설하에서의 평균 85) ## 무작위로 뽑은 50명의 학생들을 50명씩 복원추출한다(1000번 반복하자) bootstrap = np.array([np.mean(np.random.choice(sample, size=50, replace=True)) for i in range(1000)]) plt.hist(bootstrap, bins=np.arange(int(np.min(bootstrap)), int(np.max(bootstrap)) + 0.5, 1)) plt.axvline(x=90, color=&#39;red&#39;) plt.title(&#39;50명의 맥박수 평균의 붓스트랩 분포&#39;, fontsize=15) plt.show() print(f&#39;50명의 맥박수 평균이 90보다 큰 비율은 {len(bootstrap[bootstrap &gt; 90]) / 1000}입니다&#39;) . . 50명의 맥박수 평균이 90보다 큰 비율은 0.021입니다 . - 위는 50명의 맥박수 평균의 붓스트랩 분포이다 . - 위에서 구했던 맥박수 평균 90보다 큰 사건은 매우 적게 일어난다 . - 영가설이 참이라는 가정하에 얻은 결과보다 더 극단적인 결과가 관측될 확률은 2.1%이며 이를 p-value라고 한다 . - 그러므로 평균 맥박수는 85보다 크다고 할 수 있다 . - 만약 대안가설(위의 예시에선 모수가 85보다 크다)이 85보다 크다가 아니라 85와 같지 않다라면 p-value는 어떻게 될까? . - 맥박수 평균으로 85보다 5나 더 큰 90을 얻었단 것은 반대로 5가 더 작은 80도 얻을 수 있다는 의미이다 . - 따라서 이런 경우 더 극단적인 결과로 90보다 큰 경우뿐만 아니라 80보다 작은 경우도 고려해야 한다 . np.random.seed(42) #sample = sample + (85 - 90) ## 영가설하에서의 평균인 85로 평균을 맞춰주기 위함(기존의 평균 90 -&gt; 영가설하에서의 평균 85) ## 무작위로 뽑은 50명의 학생들을 50명씩 복원추출한다(1000번 반복하자) bootstrap = np.array([np.mean(np.random.choice(sample, size=50, replace=True)) for i in range(1000)]) plt.hist(bootstrap, bins=np.arange(int(np.min(bootstrap)), int(np.max(bootstrap)) + 0.5, 1)) plt.axvline(x=90, color=&#39;red&#39;) plt.axvline(x=80, color=&#39;red&#39;) plt.title(&#39;50명의 맥박수 평균의 붓스트랩 분포&#39;, fontsize=15) plt.show() print(f&#39;50명의 맥박수 평균이 90보다 크거나 80보다 작은 비율은 {len(bootstrap[(bootstrap &gt; 90) | (bootstrap &lt; 80)]) / 1000}입니다&#39;) . . 50명의 맥박수 평균이 90보다 크거나 80보다 작은 비율은 0.041입니다 . - 대안가설이 복합가설($ neq$)인 경우 붓스트랩분포에서 p-value는 대략 단측가설($&gt;$ or $&lt;$)일 때의 2배이다 . &#54217;&#44512;&#50640; &#45824;&#54620; &#52628;&#47200; . - 양적 자료에서 관심 있는 모수는 종종 모집단 평균 $ mu$이다 . - ex) 우리나라 사람들의 평균 맥박수가 어느정도 되는지 궁금함 &gt; 평균에 대한 가설검증 . &#54364;&#48376; &#54217;&#44512;&#50640; &#45824;&#54620; &#51473;&#49900;&#44537;&#54620;&#51221;&#47532; . - 평균이 $ mu$이고 표준편차가 $ alpha$인 모집단에서 표본 크기 $n$이 충분히 클 때 표본 평균의 분포는 근사적으로 평균이 $ mu$이고 표준편차는 $ cfrac{ alpha}{ sqrt{n}}$인 정규분포를 따름 . - 하지만 위의 내용을 그대로 사용할 수 없음 . 1. 모집단의 표준편차 $ alpha$를 모른다 &gt; 표본의 표준편차 $s$를 $ alpha$대신 사용 . 2. 추정된 표준오차 $ cfrac{s}{ sqrt{n}}$에 기반하여 표준화한 통계량의 분포는 표준정규분포를 따르지 않음 &gt; t 분포를 따름(t 분포 참고) . &#54364;&#48376;&#51032; &#54364;&#51456;&#54200;&#52264;&#47484; &#49324;&#50857;&#54624; &#46412; &#54364;&#48376; &#54217;&#44512;&#51032; &#48516;&#54252; . - 평균이 $ mu$인 모집단에서 표본 크기 $n$인 무작위 표본을 뽑을 때 표본 평균의 분포는 중심이 $ mu$이고 표준오차는 $ cfrac{s}{ sqrt{n}}$으로 추정 . - 표본 평균을 표준화하면 자유도 $n-1$인 t 분포를 근사적으로 따름 . - 표본 크기 $n$이 커질수록 t분포는 표준정규분포와 가까워짐 . import numpy as np import scipy as sp import scipy.stats import matplotlib.pyplot as plt x = np.linspace(-5, 5, 100) rv_norm = sp.stats.norm(loc=0, scale=1) rv_t10 = sp.stats.t(df=10) rv_t5 = sp.stats.t(df=5) rv_t1 = sp.stats.t(df=1) norm_pdf = rv_norm.pdf(x) t10_pdf = rv_t10.pdf(x) t5_pdf = rv_t5.pdf(x) t1_pdf = rv_t1.pdf(x) legend = [&#39;z-dist&#39;, &#39;t(df=1)&#39;, &#39;t(df=5)&#39;, &#39;t(df=10)&#39;] plt.figure(figsize = (10, 6)) plt.plot(x, norm_pdf) plt.plot(x, t1_pdf) plt.plot(x, t5_pdf) plt.plot(x, t10_pdf) plt.title(&quot;z-dist, t-dist(df=1, 5, 10)&quot;) plt.xlabel(&quot;$x$&quot;) plt.ylabel(&quot;$p(x)$&quot;) plt.grid() plt.legend(legend) plt.show() . . - 위의 plot을 보면 자유도가 커질수록 t분포가 표준정규분포에 가까워짐을 알 수 있음 . - 나중에 plot그리는데 사용되는 lib와 사용법 추가 예정 . t &#48516;&#54252; &#49324;&#50857; &#51312;&#44148; . - 표본 크기 $n geq 30$이면 문제 없음 . - 만약 표본 크기 $n$이 작다면? &gt; 모집단이 정규분포를 따라야 함 . - 근데 모집단이 정규분포 따르는지 모른다 &gt; 대신에 표본이 정규분포를 따르는지 확인하자 &gt; shapiro.test 실시 . - 표본에 이상점이 있거나 비대칭이면 t 분포 사용$ times$ . - 표본이 정규분포를 따르는 것 같다 &gt; $ bar{x}$의 분포는 정규분포를 따른다 &gt; t-test 실시해도 괜찮다 . &#54217;&#44512;&#50640; &#45824;&#54620; t&#44160;&#51221; . - 영가설 $H_0: mu= mu_0$를 검정하는 t-통계량은 다음과 같음 . - $t= cfrac{ bar{x}- mu_0}{ frac{s}{ sqrt{n}}}$ . - $ bar{x}$는 표본 평균, $s$는 표본에서 계산한 표준편차 . - p-값을 통해 영가설을 기각할지 기각하지 못하는지를 결정 &gt; 가설검정 용어(영가설, p-값 등등)에 대해 나중에 정리 예정 . - 검증의 p-값은 자유도가 $n-1$인 t분포에서 대안가설에 적절한 꼬리쪽의 비율을 계산 . &#54217;&#44512;&#50640; &#45824;&#54620; t&#44160;&#51221; &#50696;&#51228; . 문제 | . - 사람의 평균 체온이 $36.5^{°} mathrm{C}$인지 검정하기 위해 건강한 사람 50명의 체온을 재었다 . - 임의로 데이터를 설정하여 평균 체온 데이터는 평균이 36.3, 표준편차는 0.5인 정규분포에서 추출했음 . - 임의로 뽑은 표본을 살펴보니 $ bar{x} = 36.35, ;s=0.5$이다 . - 위의 데이터는 사람의 평균 체온이 $36.5^{°} mathrm{C}$와는 다르다는 증거인지 유의수준 $ alpha=0.05$ 에서 검정하자 . 해결 과정 | . - $H_0: mu=36.5, ;H_a: mu neq36.5$ . - 표본 크기가 충분하고 표본에 대한 히스토그램을 보면 정규분포를 따르는 것으로 보인다 . import rpy2 import os os.environ[&#39;R_HOME&#39;]=&#39;C:/anaconda3/envs/py38r40/lib/R&#39; %load_ext rpy2.ipython . The rpy2.ipython extension is already loaded. To reload it, use: %reload_ext rpy2.ipython . import matplotlib.pyplot as plt import numpy as np ## 예시 샘플 np.random.seed(2021) sample = np.random.normal(loc = 36.3, scale = 0.5, size = 50) plt.hist(sample) plt.title(&#39;body heat data&#39;) plt.show() %R -i sample . - 샤피로 윌크 검정을 통해 정규성을 정확히 확인하자 . %%R shapiro.test(sample) . Shapiro-Wilk normality test data: sample W = 0.98456, p-value = 0.7524 . - p-값이 크므로 영가설(표본은 정규분포를 따름)을 기각할 수 없으므로 표본의 정규성을 가정 . - t통계량을 직접 구해도 됨 &gt; $t= cfrac{ bar{x}- mu_0}{ frac{s}{ sqrt{n}}} = cfrac{36.35-36.5}{ frac{0.5}{ sqrt{50}}}=-2.12$ . - 하지만 매번 직접 구하기 귀찮으므로 R을 통해 구해보도록 하자 + p-값도 구해줌 . - 사실 파이썬으로도 가능하지만 내가 모르는 관계로 R로 하고 나중에 따로 공부하자 . %%R print(mean(sample)) ## 평균 print(sd(sample)) ## 분산 . [1] 36.35498 [1] 0.5006206 . %%R t.test(sample, mu = 36.5, alternative = &#39;two.sided&#39;, conf.level = 0.95) . One Sample t-test data: sample t = -2.0483, df = 49, p-value = 0.04591 alternative hypothesis: true mean is not equal to 36.5 95 percent confidence interval: 36.21271 36.49726 sample estimates: mean of x 36.35498 . - p-값을 보면 0.04591로 유의수준인 0.05보다 작음 &gt; 영가설을 기각한다 . - 따라서 표본에 따르면 사람의 평균 체온은 $36.5^{°} mathrm{C}$와 다르다고 할 수 있다 . - 임의로 만든 표본은 평균이 36.3인 정규분포에서 추출한 것이므로 올바르게 추론한 것을 알 수 있음 . &#54217;&#44512; &#52264;&#51060; &#48516;&#54252; . - 단일 평균에 대한 t검정과 차이점은 표본이 하나인가 둘인가이다 . - 평균 차이에 대한 t검정에서 관심있는 모수는 $ mu_1 - mu_2$이다 . - 평균이 $ mu_1$과 $ mu_2$인 모집단에서 표본크기가 $n_1$과 $n_2$인 무작위 표본을 얻었을 때 표본 평균 차이 $ bar{x_1}- bar{x_2}$의 분포는 중심이 모집단 평균 차이$ mu_1- mu_2$이고 표준오차는 $ sqrt{ frac{{s_1}^{2}}{n_1}+ frac{{s_2}^2}{n_2}}$이다 . - 표본 평균 차이를 표준화한 값은 t분포를 따르며 자유도는 근사적으로 $n_1+n_2-2$ . - $n_1 &lt;30$ or $n_2&lt;30$인 경우 표본 크기가 작으며 이 경우에는 모집단이 정규분포를 따라야 함 . - 평균 차이를 검정할 땐 두 집단이 서로 독립인지 아닌지가 중요함 &gt; 독립여부에 따라 검정 방법이 달라짐 . - 여기서는 독립표본에 대해 얘기할 것 임 . - 두 집단의 분산의 동질성이 중요함 &gt; 평균 차이 검정을 하기 전에 분산의 동질성 검정을 수행함 . - 분산이 같은 경우 student&#39;s t-test를 사용하고 분산이 다른 경우 Welch&#39;s t test사용함 . &#54217;&#44512; &#52264;&#51060;&#50640; &#45824;&#54620; t&#44160;&#51221; . - 영가설 $H_0: mu_1- mu_2=0$를 검정하는 t-통계량은 다음과 같음 . - $t= cfrac{( bar{x_1}- bar{x_2})-0}{ sqrt{ frac{{s_1}^2}{n_1}+ frac{{s_2}^2}{n_2}}}$ . - $ bar{x_1}$과 $ bar{x_2}$는 표본 평균, $s_1$과 $s_2$는 표본의 표준편차 . &#54217;&#44512; &#52264;&#51060;&#50640; &#45824;&#54620; t&#44160;&#51221; &#50696;&#51228; . 문제 | . - 남자의 평균 체온$( bar{x}_{_1})$과 여자의 평균 체온$( bar{x}_{_2})$이 다른지 검정하기 위해 각각 건강한 사람 50명의 체온을 재었다 . - 임의로 데이터를 설정하여 남자의 평균 체온 데이터는 평균이 36.5, 표준편차는 0.4인 정규분포에서 추출했음 . - 임의로 데이터를 설정하여 여자의 평균 체온 데이터는 평균이 36.45, 표준편차는 0.5인 정규분포에서 추출했음 . - 임의로 뽑은 표본을 보니 $ bar{x}_{_1} = 36.54, ; bar{x}_{_2} = 36.5, ; s_{_1}=0.4, ;s_{_2}=0.53$이다 . - 위의 데이터는 남자와 여자의 평균 체온이 서로 다르다는 증거인지 유의수준 $ alpha=0.05$ 에서 검정하자 . 해결 과정 | . - $H_0: mu_1- mu_2 = 0, ;H_a: mu_1 neq mu_2$ . - 표본 크기가 충분하고 표본에 대한 히스토그램을 보면 정규분포를 따르는 것으로 보인다 . - 남자 모집단과 여자 모집단에서 표본을 추출했으므로 두 표본은 서로 독립이다 . import rpy2 import os os.environ[&#39;R_HOME&#39;]=&#39;C:/anaconda3/envs/py38r40/lib/R&#39; %load_ext rpy2.ipython . C: anaconda3 envs py38r40 lib site-packages rpy2 robjects packages.py:366: UserWarning: The symbol &#39;quartz&#39; is not in this R namespace/package. warnings.warn( . import matplotlib.pyplot as plt import numpy as np ## 예시 샘플 np.random.seed(2021) man_heat = np.random.normal(loc = 36.5, scale = 0.4, size = 50) woman_heat = np.random.normal(loc = 36.45, scale = 0.5, size = 50) fig, ax = plt.subplots(1, 2, figsize = (10, 4)) ax[0].hist(man_heat) ax[1].hist(woman_heat) ax[0].set_title(&#39;man body heat data&#39;) ax[1].set_title(&#39;woman body heat data&#39;) plt.show() %R -i man_heat,woman_heat . - 두 표본이 정규성을 따르는지 정확히 확인하자 . %%R shapiro.test(man_heat) . Shapiro-Wilk normality test data: man_heat W = 0.98456, p-value = 0.7524 . %%R shapiro.test(woman_heat) . Shapiro-Wilk normality test data: woman_heat W = 0.96223, p-value = 0.1102 . - 둘다 p-값이 크므로 정규성을 가정하자 . - 평균 차이 검정을 하기전에 우선 두 표본의 분산이 동일한지 검정하자 . - var.test는 두 집단의 분산이 동일한지 비교함 ratio(두 집단 분산의 비율)이 1이 아니라면 두 집단의 분산이 다르다는 증거임 . %%R print(mean(man_heat)) print(sd(man_heat)) print(mean(woman_heat)) print(sd(woman_heat)) . [1] 36.54399 [1] 0.4004965 [1] 36.52622 [1] 0.5260057 . %%R var.test(man_heat, woman_heat, ratio = 1, alternative = &quot;two.sided&quot;, conf.level = 0.95) . F test to compare two variances data: man_heat and woman_heat F = 0.57972, num df = 49, denom df = 49, p-value = 0.05916 alternative hypothesis: true ratio of variances is not equal to 1 95 percent confidence interval: 0.3289758 1.0215715 sample estimates: ratio of variances 0.5797175 . - 두 집단의 분산이 같은지 검정하니 p-값이 0.05보다 크기 때문에 다르다고 할만한 충분한 증거가 없으므로 동일하다 가정함 . - 분산이 각각 0.4와 0.5인 집단에서 표본을 추출하여 원래는 분산이 다르지만 표본크기가 작기 때문에 0.1의 차이를 판단하지 못하였음 . - 아무튼 var.test 결과는 분산이 동일하다 나왔으므로 두 집단의 분산이 동일하다 생각하고 평균 차이를 검정하자 . %%R t.test(man_heat, woman_heat, alternative = &#39;two.sided&#39;, var.equal = T, conf.level = 0.95) . Two Sample t-test data: man_heat and woman_heat t = 0.19001, df = 98, p-value = 0.8497 alternative hypothesis: true difference in means is not equal to 0 95 percent confidence interval: -0.1677758 0.2033056 sample estimates: mean of x mean of y 36.54399 36.52622 . - 검정결과를 보면 p-값이 0.05보다 크므로 영가설을 기각하지 못함 &gt; 남자와 여자의 평균체온을 다르다고 할 수 없음 . - 실제 데이터는 평균이 36.5와 36.45로 다르지만 표본의 크기가 충분하지 않아 이를 잡아내지 못함 . - 표본 크기가 50이 아니라 더욱 커진다면 위의 차이를 알아낼 수 있음 . &#45824;&#51025;&#54364;&#48376;&#50640; &#45824;&#54620; &#54217;&#44512; &#52264;&#51060; t&#44160;&#51221; . - 위에서 두 개의 개별 표본일 때 평균 차이 검정을 했음 . - 하지만 자료가 짝으로 주어졌다면 위와 동일한 방법으로 검정을 수행하면 안됨 . - 짝 자료 &gt; 동일한 피실험체를 두 가지 다른 조건에서 측정한 데이터 ex) 개별 사람의 왼손과 오른손 악력, 약을 복용하기 전과 후의 혈압 . - 조건이 동일하다면 동일한 피실험체가 아니어도 가능함 &gt; ex) 일란성 쌍둥이의 IQ . - 짝 자료에 대한 평균 차이 검정은 우선 각 짝 자료의 차이를 계산한 후 차이에 대한 평균 $ bar{x}_{_d}$, 표준편차 $s_{_d}$, 표본 크기 $n_{_d}$를 계산 . - $t = cfrac{ bar{x}_{_d} - 0}{ frac{s_{_d}}{ sqrt{n_{_d}}}}$를 자유도가 $n_{_d}-1$인 t분포에서 검정함 . &#45824;&#51025; &#54364;&#48376;&#50640; &#45824;&#54620; &#54217;&#44512; &#52264;&#51060; t&#44160;&#51221; &#50696;&#51228; . 문제 | . - 소설을 읽을 때 스토리 스포일러를 포함한 경우와 그렇지 않은 경우에 대해 즐거움의 등급(점수)차이가 있는지 유의수준 $ alpha=0.05$ 에서 검정하자 . - 등급이 높을 수록 스토리가 더 재밌었다는 것을 의미함 . - 12개 스토리의 각 버전은 최소 30명이 읽고 1~10등급으로 등급을 매겼음 . - 스포일러 유 &gt; 4.7, 5.1, 7.9, 7.0, 7.1, 7.2, 7.1, 7.2, 4.8, 5.2, 4.6, 6.7 . - 스포일러 무 &gt; 3.8, 4.9, 7.4, 7.1, 6.2, 6.1, 6.7, 7.0, 4.3, 5.0, 4.1, 6.1 . 해결 과정 | . - 12개의 스토리를 동일한 조건(무작위 샘플링)을 지닌 사람이 두 가지 처리(스포일러 유무)를 받아 읽고 등급을 평가함 &gt; 대응 표본 . import rpy2 import os os.environ[&#39;R_HOME&#39;]=&#39;C:/anaconda3/envs/py38r40/lib/R&#39; %load_ext rpy2.ipython . C: anaconda3 envs py38r40 lib site-packages rpy2 robjects packages.py:366: UserWarning: The symbol &#39;quartz&#39; is not in this R namespace/package. warnings.warn( . %%R install.packages(&#39;ggplot2&#39;) library(ggplot2) . Please select a CRAN mirror for use in this session . R[write to console]: trying URL &#39;https://cran.seoul.go.kr/bin/windows/contrib/4.0/ggplot2_3.3.5.zip&#39; R[write to console]: Content type &#39;application/zip&#39; R[write to console]: length 4129414 bytes (3.9 MB) R[write to console]: downloaded 3.9 MB . package &#39;ggplot2&#39; successfully unpacked and MD5 sums checked The downloaded binary packages are in C: tmp Rtmp0OKRvu downloaded_packages . %%R with_spoiler &lt;- c(4.7, 5.1, 7.9, 7.0, 7.1, 7.2, 7.1, 7.2, 4.8, 5.2, 4.6, 6.7) original &lt;- c(3.8, 4.9, 7.4, 7.1, 6.2, 6.1, 6.7, 7.0, 4.3, 5.0, 4.1, 6.1) diff &lt;- with_spoiler - original diff_df &lt;- as.data.frame(diff) ggplot(diff_df, aes(x = diff)) + xlab(&#39;Difference&#39;) + geom_dotplot(binwidth = 0.1) . - 짝 자료 차이에 대한 점도표를 보면 정규분포를 부정할 만한 비대칭이나 이상점은 없어보임 . %%R shapiro.test(diff) . Shapiro-Wilk normality test data: diff W = 0.95506, p-value = 0.7116 . - 샤피로 윌크 검정도 해보니 정규분포임을 가정해도 괜찮아 보임 . %%R t.test(with_spoiler, original, paired = T, alternative = &#39;two.sided&#39;, conf.level = 0.95) . Paired t-test data: with_spoiler and original t = 4.8997, df = 11, p-value = 0.0004719 alternative hypothesis: true difference in means is not equal to 0 95 percent confidence interval: 0.2708052 0.7125281 sample estimates: mean of the differences 0.4916667 . - R에서 대응 표본에 대한 검정을 하려면 paried = T 옵션을 적용한다 . - p-값이 0.0004719로 매우 작으므로 영가설을 기각하자 &gt; 스포일러 유무에 따른 재미의 등급은 차이가 있다! . &#47784;&#48516;&#49328;&#50640; &#45824;&#54620; &#52628;&#47200; . - 모집단이 얼마나 퍼져있는지에 대해 궁금할 수 있음 . - ex) 공장에서 생산하는 과자의 무게 . - 과자의 무게 변동이 큰지 작은지에 대한 검정이 모분산에 대한 검정이다 . &#45800;&#51068; &#47784;&#48516;&#49328;&#50640; &#45824;&#54620; &#44160;&#51221; . - 우선 단일 모분산에 대한 검정에는 $ chi^2$분포가 사용됨 &gt; 왜?(나중에 증명 추가) . - 확률변수 $Q= cfrac{(n-1)s^2}{ sigma^2}$는 자유도가 $n-1$인 $ chi^2_{n-1}$를 따른다 . - $ chi^2$분포가 어떻게 생겼는지 그래프를 그려서 확인해보자 . import numpy as np import matplotlib.pyplot as plt from scipy.stats import chi2 fig, ax = plt.subplots(figsize = (14, 7)) x = np.linspace(0, 8, 1000) for df in np.arange(1, 6): ax.plot(x, chi2(df).pdf(x), label = &#39;k = &#39; + str(df)) major_xticks = np.arange(0.0, 9.0, 2.0) minor_xticks = np.arange(0.5, 8.0, 0.5) major_yticks = np.arange(0, 1.2, 0.2) minor_yticks = np.arange(0.05, 1.0, 0.05) ax.set_title(&quot;$ chi^2$ distribution(df = 1, 2, 3, 4, 5)&quot;, fontsize = 20) ax.set_ylim(0, 1) ax.set_xlim(0, 8) ax.set_xticks(major_xticks) ax.set_xticks(minor_xticks, minor = True) ax.set_yticks(major_yticks) ax.set_yticks(minor_yticks, minor = True) ax.set_xlabel(&quot;$x$&quot;, fontsize = 14) ax.set_ylabel(&quot;$f(x)$&quot;, fontsize = 14, rotation = 0, labelpad = 20) ax.tick_params(axis = &#39;both&#39;, labelsize = 15, length = 10, direction = &#39;in&#39;) ax.tick_params(axis = &#39;both&#39;, which = &#39;minor&#39;, length = 5, direction = &#39;in&#39;) ax.grid() ax.legend() plt.show() . . - 정규분포와 t분포와 다르게 오른쪽으로 꼬리가 긴 분포이다 . - $ cfrac{(n-1)s^2}{ sigma^2}$의 표본분포는 위의 그래프처럼 자유도에 따라 달라짐 . - 단일모분산을 검정하는 검정통계량은 다음과 같음 . $$ chi^2= cfrac{(n-1)s^2}{ sigma^2}$$ . - 가설 $H_0 : sigma^2 = sigma_0^2$ 에 대한 검정은 대안가설 부호에 따라 다름 . $$ begin{aligned}H_a &amp;: sigma^2&gt; sigma_0^2 longrightarrow chi^2&lt; chi^{^2}_{_{_{ alpha}}} [10pt] H_a &amp;: sigma^2&lt; sigma_0^2 longrightarrow chi^2&gt; chi^{^2}_{_{_{1- alpha}}} [10pt] H_a &amp;: sigma^2 neq sigma_0^2 longrightarrow chi^2&lt; chi^{^2}_{_{1- frac{ alpha}{2}}} ; operatorname{or} ; chi^2&gt; chi^{^2}_{_{ frac{ alpha}{2}}} end{aligned}$$ - 위에서 $ chi^{^2}_{_{_{ alpha}}}$은 자유도가 $n-1$인 $ chi^2$분포의 $100(1- alpha) %$ 백분위수이다 . - 위가 성립하면 귀무가설 $H_0$를 기각한다 . &#45800;&#51068; &#47784;&#48516;&#49328;&#50640; &#45824;&#54620; &#44160;&#51221; &#50696;&#51228; . - 임의로 샘플을 만들고 모분산에 대해 검정해보자 . import numpy as np np.random.seed(2021) data = np.random.normal(0, 2, 10) . - 평균이 0이고 분산이 4인 정규분포에서 10개의 샘플을 뽑았다 . - 샘플을 가지고 $ alpha = 0.05$에서 모분산이 3를 넘는지 검정해보자 . $$H_0 : sigma^2 = 3 H_a : sigma^2 &gt; 3$$ . var_0 = 3 n = len(data) df = n - 1 s = np.std(data, ddof = 1) chi_square = (n-1) * (s**2) / var_0 ## 검정통계량 . s ## 표분편차는 1.52 . 1.5249196358322268 . - 검정통계량(chi2)이 $ chi^2_{0.05}$ 보다 크면 영가설을 기각할 수 있다 . from scipy.stats import chi2 X_square = chi2.ppf(0.95, df) ## 카이제곱분포의 오른쪽 영역이 0.05(왼쪽 영어은 0.95)가 되게하는 x 값 ## 누적분포의 역함수(ppf)를 통해 구한다 . X_square . 16.918977604620448 . chi_square . 6.9761396872400745 . X_square &lt; chi_square . False . - 검정통계량이 기각역보다 크지 않으므로 영가설을 기각할 수 없다 . - 따라서 모분산은 3보다 크다고 말할 수 없다 . - 분산이 4인 정규분포에서 샘플을 뽑았지만 영가설을 기각하지 못했음 . - 표본크기가 10으로 작아 변동성이 커 샘플의 분산이 2.32 이기 때문임 . - 표본크기가 더 크다면 영가설을 기각할 수 있을 것이다 . &#46160; &#47784;&#51665;&#45800;&#48516;&#49328; &#52264;&#51060;&#50640; &#45824;&#54620; &#44160;&#51221; . - 두 모집단의 분산을 비교하는데에는 F분포를 사용함 &gt; 왜? .",
            "url": "https://jaesu26.github.io/study-blog/statistics/2021/07/27/%EA%B0%80%EC%84%A4%EA%B2%80%EC%A0%95.html",
            "relUrl": "/statistics/2021/07/27/%EA%B0%80%EC%84%A4%EA%B2%80%EC%A0%95.html",
            "date": " • Jul 27, 2021"
        }
        
    
  
    
        ,"post36": {
            "title": "파이썬에서 R실행",
            "content": "&#54028;&#51060;&#50028;&#50640;&#49436; R&#49892;&#54665;&#54616;&#44592; . 1. 아나콘다에 접속한 후 Anaconda Installers에서 64-Bit Graphical Installer(477MB)설치 . 2. Anaconda Prompt (anaconda3) 실행 . 3. 아래와 같이 입력 . (base) C: Users 한재수&gt; conda create -n py38r40 python=3.8 (base) C: Users 한재수&gt; conda activate py38r40 (py38r40) C: Users 한재수&gt; conda install jupyter lab (py38r40) C: Users 한재수&gt; pip install rpy2 (py38r40) C: Users 한재수&gt; R . 4. R에서 아래와 같이 입력 . &gt; install.packages(&quot;IRcernel&quot;) &gt; IRcernel::installspec() &gt; R.home() ## 나오는 경로 복사 &gt; q() ## R 종료 . 5. 다시 프롬프트로 돌아와서 주피터랩 실행 . (py38r40) C: Users 한재수&gt; jupyter lab . 6. R세팅은 끝났고 파이썬에서 R을 사용하려면 아래와 같이 입력(주피터랩 킬 때마다 한 번씩만 입력) . import os os.environ[&#39;R_HOME&#39;]=&#39;C:/anaconda3/envs/py38r40/lib/R&#39; ## R.HOME 에서 복사한 경로 import rpy2 %load_ext rpy2.ipython . 7. R사용 . 셀 마다 %R or %%R 입력하여 사용 . import os . os.environ[&#39;R_HOME&#39;]=&#39;C:/anaconda3/envs/py38r40/lib/R&#39; ## R.HOME 에서 복사한 경로 . import rpy2 . %load_ext rpy2.ipython . C: anaconda3 envs py38r40 lib site-packages rpy2 robjects packages.py:366: UserWarning: The symbol &#39;quartz&#39; is not in this R namespace/package. warnings.warn( . %R q &lt;- c(1, 2, 3) %R print(q) Q = [1, 2, 3] print(Q) . [1] 1 2 3 [1, 2, 3] . %%R x &lt;- c(1, 2, 3, 4, 5, 8, 9, 11) y &lt;- c(5, 1, 7, 12, 11, 5, 7, 21) model &lt;- lm(y ~ x) summary(model) . Call: lm(formula = y ~ x) Residuals: Min 1Q Median 3Q Max -6.3741 -4.4232 0.9096 3.2796 6.4840 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 2.9958 3.4644 0.865 0.420 x 1.0473 0.5469 1.915 0.104 Residual standard error: 5.185 on 6 degrees of freedom Multiple R-squared: 0.3793, Adjusted R-squared: 0.2759 F-statistic: 3.667 on 1 and 6 DF, p-value: 0.104 . - %R -i 을 통해 파이썬에서 정의한 변수를 R에서 사용할 수 있음 . import numpy as np data = np.random.rand(50) %R -i data . %%R hist(data) .",
            "url": "https://jaesu26.github.io/study-blog/python/r/2021/07/26/%ED%8C%8C%EC%9D%B4%EC%8D%AC%EC%97%90%EC%84%9C-R%EC%8B%A4%ED%96%89.html",
            "relUrl": "/python/r/2021/07/26/%ED%8C%8C%EC%9D%B4%EC%8D%AC%EC%97%90%EC%84%9C-R%EC%8B%A4%ED%96%89.html",
            "date": " • Jul 26, 2021"
        }
        
    
  
    
        ,"post37": {
            "title": "변수 이름",
            "content": "&#48320;&#49688; &#51460;&#51076;&#47568; . - 변수를 줄임말로 쓸 때가 있는데 뭐인지 헷갈리는 변수를 정리할 거임 . - 나중에 변수 줄임말 말고도 변수명을 어떻게 정할지에 대한 내용도 정리할 수 도 있음 . - rtn &gt; return . - tmp &gt; temporary . - num &gt; number . - lib &gt; library . - lin &gt; linear . - rv &gt; random variable . - aes &gt; aesthetic . - axes &gt; axis(축)의 복수형 . - param(s) &gt; parameter(s) . - loc &gt; location . - pch &gt; point character . - fig &gt; figure . - ax &gt; axes . - alg &gt; algebra(대수학) . - cnt &gt; count . - ec &gt; edgecolor . - fc &gt; facecolor . - h &gt; horizontal . - v &gt; vertical . - cpy &gt; copy . - tb &gt; table . - autopct &gt; autopercentage . - ptr &gt; pointer . &#48320;&#49688; &#51460;&#51076;&#47568;&#51008; &#50500;&#45768;&#51648;&#47564; &#50500;&#47924;&#53948; &#51460;&#51076;&#47568;&#51076; . - WLLN &gt; Weak Law of Large Numbers(큰 수의 약한 법칙) . - MLE &gt; maximum likelihood estimate(최대우도추정량) . &#48320;&#49688; &#51060;&#47492; &#51667;&#44592; . - 모음을 생략하여 짓기 count &gt; cnt, return &gt; rtn . - 임시 변수는 _ 붙이기 &gt; tmp_ . - 클래스 내부 객체이름 앞에 _를 붙이면 인스턴스 객체에 .을 붙이고 tab을 눌러서 확인하지 못함(dir 함수를 써야한다) .",
            "url": "https://jaesu26.github.io/study-blog/variable%20name/2021/07/26/%EB%B3%80%EC%88%98-%EC%9D%B4%EB%A6%84.html",
            "relUrl": "/variable%20name/2021/07/26/%EB%B3%80%EC%88%98-%EC%9D%B4%EB%A6%84.html",
            "date": " • Jul 26, 2021"
        }
        
    
  
    
        ,"post38": {
            "title": "적률생성함수",
            "content": "&#51201;&#47456;&#51060;&#46976; . - 확률변수의 특징을 설명 . - 확률변수 $X$의 $k$차 중심적률(central moment)을 $ mu_{k}$라 하면 $ mu_{k} = E[(X- mu)^{k}]$ . - $ mu_{1} = E(X) - mu = 0$ &gt; 확률변수 $X$의 $1$차 중심적률은 $0$ . - $ mu_{2} = E[(X- mu)^{2}]$ &gt; 확률변수 $X$의 $2$차 중심적률은 분산 . - $ mu_{3} = E[(X- mu)^{3}]$ &gt; 확률변수 $X$의 $3$차 중심적률은 왜도 . - $ mu_{4} = E[(X- mu)^{4}]$ &gt; 확률변수 $X$의 $4$차 중심적률은 첨도 . - 일반적인 확률 변수 $X$의 적률(moment)은 비중심(non-central)적률을 나타냄 $ longrightarrow$ $ mu&#39;_{k} = E[X^k]$ . - $ mu&#39;_{k} = E[X^k] = begin{cases} text{이산확률변수 : } sum limits_{x}x^{k}f(x) text{연속확률변수 : } int_{- infty}^{ infty}x^{k}f(x)dx end{cases}$ . - $ mu&#39;_{1} = mu$ . - $ sigma^{2} = mu_{2} = mu&#39;_{2} - ( mu&#39;_{1})^{2}$ . - 모평균$ mu$는 확률변수 $X$의 1차 비중심적률 . - 모분산$ sigma^{2}$은 확률변수 $X$의 2차 비중심적률에서 1차 비중심적률의 제곱을 뺀 값 . - 참고 자료: 통계수학 강의 . &#51201;&#47456;&#49373;&#49457;&#54632;&#49688;(moment generating function, mgf) . - 특정 확률 분포의 적률을 생성하는 함수 . - 적률을 계산하려면 연속확률변수의 경우 적분을 하게 되는데 어렵거나 불가능한 경우도 있음 &gt; 적률생성함수를 통해 계산 가능 . - 임의의 확률변수 $X$의 기댓값이 존재한다면 $X$의 적률생성함수 $M_{X}(t) = E(e^{tX}), ; t in mathbb{R}$ . - $M_{X}(t) = E(e^{tX}) = begin{cases} text{이산확률변수 : } sum limits_{x}e^{tx}f(x) text{연속확률변수 : } int_{- infty}^{ infty}e^{tx}f(x)dx end{cases}$ . - 확률변수 $X$의 기댓값을 구하는데 $X$가 아니라 $x$가 사용되네?? . - $X$의 기댓값은 $X$가 가질 수 있는 값인 $x$들을 통해 구한다 . - 사실 $x$말고 $k$라고 하든지 $a$라고 하든지 다른 변수를 사용해도 됨 &gt; 마치 적분할 때 $ int x ,dx = int t , dt = int a ,da$ 인 것 처럼 . - 중요한건 확률변수가 가질 수 있는 값들을 가지고 기댓값을 구한다는 것 &gt; 당연한 소리 . - 확률변수 $X$가 가질 수 있는 모든값들을 구하고 이것들의 평균을 구하면 그게 확률변수의 기댓값(당연함) . - 참고: $X$는 확률변수, $x$는 확률변수 $X$가 가지는 값 &gt; 이산확률변수는 $P(X=x)$, 연속확률변수는 $P(A leq X leq B)$ . - 적률생성함수는 항상 존재하는 것이 아님 . $e^{tX}$가 $t=0$근방에서 적분이 가능해야 함 $ ; ;$ . | $ forall , t in mathbb{R}, ; ;E(e^{tX}) &lt; infty $ . | &#51201;&#47456;&#49373;&#49457;&#54632;&#49688; &#53945;&#51669; . - 두 확률변수의 mgf가 일치하면 두 확률변수는 같은 분포를 가짐 . - 적률생성함수를 $k$번 미분하고 $t=0$을 대입하면 확률변수 $X$의 $k$차 비중심 적률이다 &gt; 왜??? . &#51201;&#47456;&#49373;&#49457;&#54632;&#49688; k&#48264; &#48120;&#48516; $ longrightarrow$ k&#52264; &#48708;&#51473;&#49900; &#51201;&#47456; . - $M_{X}(t) = E(e^{tX})$ . - $ cfrac{d^{k}M_{X}(0)}{dt^{k}} = E(X^{k})$ . - 매클로린 급수를 사용하자 . - $e^{tX} = sum limits_{k = 0}^{ infty} cfrac{X^k}{k!}(e^{tX})^{(k)}(0) = cfrac{t^{0}}{0!}X^{0}+ cfrac{t^1}{1!}X^1+ cfrac{t^2}{2!}X^2+ cfrac{t^3}{3!}X^3+ dots$ . - 양변에 기댓값을 취하면... . - $M_X(t)=E(e^{tX}) = 1 + tE(X) + cfrac{t^2}{2!}E(X^2) + cfrac{t^3}{3!}E(X^3)+ dots$ . - 이제 양변을 t에 대해 미분하자 . - $ cfrac{dM_X(t)}{dt} = 0 + E(X) + tE(X^2) + cfrac{t^2}{2}E(X^3)+ dots$ . - 이제 $t=0$을 대입하면... . - $ cfrac{dM_X(0)}{dt} = E(X)$ &gt; 1번 미분하니 1차 적률이 구해짐 . - 그럼 한 번 더 미분하면 2차 적률? &gt; ㅇㅇ . - $ cfrac{d^2M_X(t)}{dt^2} = 0 + 0 + E(X^2) + tE(X^3)+ dots$ . - 참고: $E(X)$는 $t$에 대하여 상수임 . - 이제 $t=0$을 대입하면 . - $ cfrac{d^2M_X(0)}{dt^2} = E(X^2)$ . - 정말로 2번 미분하니 2차 적률이 구해졌다.. . - 확률 분포에 대해 정리할 때 기댓값과 분산을 과정없이 결과만 적었었음 . - 적률생성함수를 통해 여러가지 확률 분포의 기댓값과 분산을 구해보자 . &#44512;&#51068; &#48516;&#54252;&#51032; &#51201;&#47456;&#49373;&#49457;&#54632;&#49688; . - 균일 분포의 확률 밀도 함수: $f(x) = cfrac{1}{b-a}$ . - 균일 분포의 적률생성함수 . $ begin{aligned}M_X(t) &amp;= E(e^{tX}) [10pt] &amp;= int_{a}^{b}e^{tx} frac{1}{b-a}dx longrightarrow text{확률변수$X$가 $a$부터 $b$까지의 값을 가진다는 뜻} [10pt] &amp;= frac{1}{b-a} left[ frac{1}{t}e^{tx} right]_{a}^{b} [10pt] &amp;= frac{e^{t}(e^{b}-e^{a})}{t(b-a)} end{aligned}$ . - 균일 분포의 기댓값 &gt; 적률생성함수를 통해 구하는 것보다 1차 적률의 정의를 통해 구하는 것이 더 쉬움 . $ begin{aligned}E(X) &amp;= int_{a}^{b} frac{1}{b-a}x ;dx [10pt] &amp;= frac{1}{b-a} left[ frac{x^2}{2} right]_{a}^{b} [10pt] &amp;= frac{b^{2}-a^{2}}{2(b-a)} [10pt] &amp;= frac{a+b}{2} end{aligned}$ . - 균일 분포의 분산 &gt; 적률의 정의를 통해 구하자 &gt; 우선 2차 비중심 적률을 구하자 . $ begin{aligned}E(X^2) &amp;= int_{a}^{b} frac{1}{b-a}x^2 ;dx [10pt] &amp;= frac{1}{b-a} left[ frac{x^3}{3} right]_{a}^{b} [10pt] &amp;= frac{b^{3}-a^{3}}{3(b-a)} [10pt] &amp;= frac{a^2+ab+b^2}{3} end{aligned}$ . $ begin{aligned}Var(X) &amp;= E(X^2) - [E(X)]^2 [10pt] &amp;= cfrac{a^2+ab+b^2}{3} - bigg( cfrac{a+b}{2} bigg)^2 [10pt] &amp;= cfrac{4(a^2+ab+b^2) ,- 3(a^2+2ab+b^2)}{12} [10pt] &amp;= frac{(b-a)^2}{12} end{aligned}$ . &#44592;&#54616; &#48516;&#54252;&#51032; &#51201;&#47456;&#49373;&#49457;&#54632;&#49688; . - 기하 분포의 확률 질량 함수: $f(x) = q^{x-1}p, ; q=1-p, ; x = 1, 2, 3, dots$ . - 첫째항이 $a$, 공비가 $r$인 무한등비수열의 합: $ frac{a}{1-r}, ; |r|&lt;1$ . - 기하 분포의 적률생성함수 . $ begin{aligned}M_X(t) &amp;= E(e^{tX}) [10pt] &amp;= sum limits_{x=1}^{ infty}e^{tx}q^{x-1}p [10pt] &amp;= frac{p}{q} sum limits_{x=1}^{ infty}(qe^{t})^{x}, quad -1 &lt; qe^t &lt; 1 [10pt] &amp;= frac{pqe^t}{q(1-qe^t)} [10pt] &amp;= frac{pe^t}{1-qe^t}, quad t&lt;-ln(1-p) end{aligned}$ . - 기하 분포의 기댓값 . - 몫의 미분: $ bigg { cfrac{f(x)}{g(x)} bigg }&#39; = cfrac{f&#39;(x)g(x)-f(x)g&#39;(x)}{(g(x))^2}$ . $ begin{aligned}E(X) &amp;= frac{dM_X(t)}{dt} [10pt] &amp;= frac{pe^{t}(1-qe^t)-pe^{t}(-qe^t)}{(1-qe^t)^2} [10pt] &amp;= frac{pe^t}{(1-qe^t)^2} , quad text{$t=0$ 대입} [10pt] &amp;= frac{p}{(1-q)^2} [10pt] &amp;= frac{1}{p} end{aligned}$ . - 기하 분포의 분산 . $ begin{aligned}E(X^2) &amp;= frac{d^2M_X(t)}{dt^2} [10pt] &amp;= frac{pe^{t}(1-qe^t)^2- 2pe^{t}(1-qe^{t})(-qe^t)}{(1-qe^t)^4} [10pt] &amp;= frac{pe^{t}(1-qe^t)((1-qe^t)+2qe^t)}{(1-qe^t)^4} [10pt] &amp;= frac{pe^{t}(1+qe^t)}{(1-qe^t)^3}, quad text{$t=0$ 대입} [10pt] &amp;= frac{p(1+q)}{(1-q)^3} [10pt] &amp;= frac{1+q}{p^2} end{aligned}$ . $ begin{aligned}Var(X) &amp;= E(X^2) - [E(X)]^2 [10pt] &amp;= frac{1+q}{p^2} - big( frac{1}{p} big)^2 [10pt] &amp;= frac{q}{p^2} end{aligned}$ . &#51060;&#54637; &#48516;&#54252;&#51032; &#51201;&#47456;&#49373;&#49457;&#54632;&#49688; . - 이항 분포의 확률 질량 함수: $f(x) ,= , _{n} rm C_{x} ,p^{x} ,(1-p)^{n-x}$ . - 이항 분포는 서로 독립이고 동일한 베르누이 분포를 따르는 확률변수들을 n개 합한 것임 . - 베르누이 분포의 확률 질량 함수 $f(x) = p^{x}(1-p)^{1-x}, ; x = 0, 1$ . - 베르누이 분포의 기댓값 . $ begin{aligned}E(X) &amp;= sum limits_{x=0}^{1}xp^{x}(1-p)^{1-x} [10pt] &amp;= 0 cdot (1-p) + 1 cdot p [10pt] &amp;= p end{aligned}$ . - 베르누이 분포의 분산 . $ begin{aligned}E(X^2) &amp;= sum limits_{x=0}^{1}x^2p^x(1-p)^{1-x} [10pt] &amp;= 0 cdot (1-p) + 1 cdot p [10pt] &amp;= p end{aligned}$ . $ begin{aligned}Var(X) &amp;= E(X^2)-[E(X)]^2 [10pt] &amp;= p - p^2 [10pt] &amp;= p(1-p) end{aligned}$ . - 확률변수 $X, Y$에 대해 $E(X + Y)= E(X) + E(Y)$ . - 확률변수 $X, Y$가 독립이면 $Var(X + Y) = Var(X) + Var(Y)$ . - 참고: 확률변수의 합 특징 . - 이항 분포의 기댓값 &gt; 이항 분포의 정의를 통해 구함: 베르누이 분포를 따르는 확률변수들의 합 . $ begin{aligned}E(X) &amp;= E bigg( sum limits_{i=1}^{n}X_i bigg) = sum limits_{i=1}^{n}E(X_i) [10pt] &amp;= E(X_1) + E(X_2) + dots+E(X_{n-1})+E(X_n) [10pt] &amp;= overbrace{p + dots + p}^{n rm times} = np end{aligned}$ . - 이항 분포의 분산 --&gt; 기댓값과 마찬가지 . $ begin{aligned}Var(X) &amp;= Var bigg( sum limits_{i=1}^{n}X_i bigg) = sum limits_{i=1}^{n}Var(X_i) [10pt] &amp;= Var(X_1)+Var(X_2)+ dots+Var(X_{n-1})+Var(X_n) [10pt] &amp;= overbrace{p(1-p)+ dots+p(1-p)}^{n rm times} = np(1-p) end{aligned}$ . - 이항 정리 . - $(x+y)^n = sum limits_{k=0}^{n} binom{n}{k}x^{n-k}y^{k}$ . - 이항 분포의 적률생성함수 . $ begin{aligned}M_{X}(t) &amp;= E(e^{tX}) [10pt] &amp;= sum limits_{x=0}^{n} binom{n}{x}e^{tx}p^{x} ,(1-p)^{n-x} [10pt] &amp;= sum limits_{x=0}^{n} binom{n}{x}(pe^{t})^{x} ,(1-p)^{n-x} [10pt] &amp;= (1-p+pe^{t})^n end{aligned}$ . - 이항 분포의 기댓값 &gt; 적률생성함수 미분해서 구하기 . - 합성함수의 미분 . - $ big {f(g(x)) big }&#39; = g&#39;(x)f&#39;(g(x))$ . $ begin{aligned}E(X) &amp;= frac{dM_X(t)}{dt} [10pt] &amp;= npe^t(1-p+pe^t)^{n-1}, quad text{$t=0$ 대입} [10pt] &amp;= np end{aligned}$ . - 곱의 미분 . - $ big {f(x)g(x) big }&#39;=f&#39;(x)g(x)+f(x)g&#39;(x)$ . - 이항 분포의 분산 &gt; 적률생성함수 미분해서 구하기 . $ begin{aligned}E(X^2) &amp;= frac{d^2M_X(t)}{dt^2} [10pt] &amp;= npe^{t} cdot(1-p+pe^t)^{n-1}+npe^{t} cdot (n-1)pe^{t}(1-p+pe^{t})^{n-2}, quad text{$t=0$ 대입} [10pt] &amp;=np+np^{2}(n-1) [10pt] &amp;= np-np^2+n^2p^2 end{aligned}$ . $ begin{aligned}Var(X) &amp;= E(X^2)-[E(X)]^2 [10pt] &amp;= np-np^2+n^2p^2-(np)^2 [10pt] &amp;= np-np^2 [10pt] &amp;=np(1-p) end{aligned}$ . &#54252;&#50500;&#49569; &#48516;&#54252;&#51032; &#51201;&#47456;&#49373;&#49457;&#54632;&#49688; . - 테일러 급수 공부해라 구더기야 + 극좌표계도(희망) 하기 싫어.......... . - 테일러 급수: 초월함수를 특정 값의 근방에서 멱함수로 근사시킴 &gt; 개사기임 . - $a$에서 $f$의 테일러 급수 . $ begin{aligned}f(x) &amp;= sum limits_{n=0}^{ infty} frac{f^{(n)}(a)}{n!}(x-a)^{n} [10pt] &amp;= f(a) + frac{f&#39;(a)}{1!}(x-a)+ frac{f&#39;&#39;(a)}{2!}(x-a)^2+ frac{f&#39;&#39;&#39;(a)}{3!}(x-a)^3+ cdots end{aligned}$ . - $a=0$인 특별한 경우 매클로린 급수라고 함 . $ begin{aligned}f(x) &amp;= sum limits_{n=0}^{ infty} frac{f^{(n)}(0)}{n!}x^n [10pt] &amp;= f(0) + frac{f&#39;(0)}{1!}x+ frac{f&#39;&#39;(0)}{2!}x^2+ frac{f&#39;&#39;&#39;(0)}{3!}x^3+ cdots end{aligned}$ . - $e^x$의 매클로린 급수 . - $e^x = sum limits^{ infty}_{n=0} cfrac{x^n}{n!}$ . - 포아송 분포의 확률 질량 함수: $f(x) = cfrac{e^{- lambda} lambda^{x}}{x!}$ . - 포아송 분포의 적률생성함수 . $ begin{aligned}M_X(t) &amp;= E(e^{tX}) [10pt] &amp;= sum limits_{x=0}^{ infty}e^{tx} frac{e^{- lambda} lambda^{x}}{x!} [10pt] &amp;=e^{- lambda} sum limits_{x=0}^{ infty} frac{( lambda e^{t})^{x}}{x!} quad text{$ therefore lambda e^t to x, quad x to n$ 으로 바꾸면 $e^x$의 매클로린 급수이다} [10pt] &amp;= e^{- lambda} cdot e^{ lambda e^{t}} [10pt] &amp;= e^{ lambda(e^{t}-1)} end{aligned}$ . - 포아송 분포의 기댓값 . - $e^{- lambda}$ 는 변수가 아니므로 $e^{ lambda e^{t}}$ 에 대해서만 미분하면 된다 . - $y =e^{t}, ; frac{d}{dy}(y) = e^{t}$ . $ begin{aligned}E(X) &amp;= frac{dM_X(t)}{dt} [10pt] &amp;=e^{- lambda} cdot(e^{ lambda y})&#39; [10pt] &amp;= e^{- lambda} cdot lambda e^{ lambda y} cdot frac{d}{dy}(y) [10pt] &amp;= e^{- lambda} cdot lambda e^{ lambda e^{t}} cdot e^{t}, quad text{$t=0$ 대입} [10pt] &amp;= lambda cdot e^{- lambda} cdot e^{ lambda} [10pt] &amp;= lambda end{aligned}$ . - 포아송 분포의 분산 . $ begin{aligned}E(X^2) &amp;= frac{d^2M_X(t)}{dt^2} [10pt] &amp;= lambda e^{- lambda} cdot big([ lambda e^{ lambda e^{t}} cdot e^{t}] cdot [e^{t}] + [e^{ lambda e^{t}}] cdot[e^{t}] big), quad text{$t=0$ 대입} [10pt] &amp;= lambda e^{- lambda}( lambda e^{ lambda}+e^{ lambda}) [10pt] &amp;= lambda^{2}+ lambda end{aligned}$ . $ begin{aligned}Var(X) &amp;= E(X^2)-[E(X)]^{2} [10pt] &amp;= lambda^{2}+ lambda - lambda^{2} [10pt] &amp;= lambda end{aligned}$ . &#51648;&#49688; &#48516;&#54252;&#51032; &#51201;&#47456;&#49373;&#49457;&#54632;&#49688; . - 지수 분포의 확률 밀도 함수: $f(x) = lambda e^{- lambda x}, ; x&gt;0$ . - $ lambda$는 포아송 분포의 모수로 단위 시간당 사건의 평균 발생 횟수 . - 지수 분포의 적률생성함수 . $ begin{aligned}M_{X}(t) &amp;= E(e^{tX}) [10pt] &amp;= int_{0}^{ infty}e^{tx} cdot lambda e^{- lambda x} ,dx [10pt] &amp;= lambda int_{0}^{ infty}e^{tx} cdot e^{- lambda x} ,dx [10pt] &amp;= lambda int_{0}^{ infty}e^{(t- lambda)x} ,dx [10pt] &amp;= frac{ lambda}{t- lambda} cdot left[e^{(t- lambda) x} right]_{0}^{ infty}, ; ; ;(t&lt; lambda) [10pt] &amp;= frac{ lambda}{ lambda - t} end{aligned}$ . - 지수 분포의 기댓값 . $ begin{aligned}E(X) &amp;= frac{dM_X(t)}{dt} [10pt] &amp;= frac{ lambda}{( lambda - t)^2}, quad text{$t=0$ 대입} [10pt] &amp;= frac{1}{ lambda} end{aligned}$ . - 지수 분포의 분산 . $ begin{aligned}E(X^2) &amp;= frac{d^2M_X(t)}{dt^2} [10pt] &amp;= - frac{-2 lambda( lambda-t) }{( lambda-t)^4} [10pt] &amp;= frac{2 lambda}{( lambda - t)^3}, quad text{$t=0$ 대입} [10pt] &amp;= frac{2}{ lambda^2} end{aligned}$ . $ begin{aligned}Var(X) &amp;= E(X^2) - [E(X)]^2 [10pt] &amp;= frac{2}{ lambda^2} - bigg( frac{1}{ lambda} bigg)^2 [10pt] &amp;= frac{1}{ lambda^2} end{aligned}$ . &#48288;&#53440; &#48516;&#54252;&#51032; &#51201;&#47456;&#49373;&#49457;&#54632;&#49688; . - 베타 분포의 확률 밀도 함수: $f(x)= cfrac{1}{B( alpha, beta)}x^{ alpha-1}(1-x)^{ beta-1}, quad 0 leq x leq1, ;( alpha , beta&gt;0)$ . - 베타 분포의 적률생성함수 . $ begin{aligned}M_t(x)&amp;=E(e^{tX}) [10pt] &amp;= int_{0}^{1} frac{1}{B( alpha, beta)}e^{tx}x^{ alpha-1}(1-x)^{ beta-1} ;dx [10pt] &amp;= int_{0}^{1} frac{1}{B( alpha, beta)} left( sum limits_{k=0}^{ infty} frac{t^k x^{k-1}}{k!} right)x^{ alpha-1}(1-x)^{ beta-1} ;dx [10pt] &amp;= sum limits_{k=0}^{ infty} int_{0}^{1} frac{1}{B( alpha, beta)} frac{t^k}{k!}x^{ alpha+k-1}(1-x)^{ beta-1} ;dx [10pt] &amp;= sum limits_{k=0}^{ infty} left[ int_{0}^{1} frac{B( alpha +k, beta)}{B( alpha, beta)} frac{1}{B( alpha+k, beta)} frac{t^k}{k!}x^{ alpha+k-1}(1-x)^{ beta-1} ;dx right] [10pt] &amp;=1+ sum limits_{k=1}^{ infty} left[ frac{B( alpha +k, beta)}{B( alpha, beta)} frac{t^k}{k!} int_{0}^{1} frac{1}{B( alpha+k, beta)}x^{ alpha+k-1}(1-x)^{ beta-1} ;dx right] [10pt] &amp;=1+ sum limits_{k=1}^{ infty} left[ frac{ Gamma( alpha +k)}{ Gamma( alpha+ beta+k)} frac{ Gamma( alpha + beta)}{ Gamma( alpha)} frac{t^k}{k!} right] [10pt] &amp;=1+ sum limits_{k=1}^{ infty} left[ prod limits_{i=0}^{k-1} frac{ Gamma( alpha +i)}{ Gamma( alpha+ beta+i)} frac{t^k}{k!} right] end{aligned}$ . - 베타 분포의 기댓값 &gt; 적률생성함수를 통해 구하는 것보다 1차 적률의 정의를 통해 구하는 것이 더 쉬움 . - 베타 분포의 $f(x)$를 적분하면 $1$이다 . - 그런데 $f(x)$가 아닌 $xf(x)$를 적분함 &gt; $x^{ alpha-1} to x^{ alpha}$ . - 원래는 성공횟수가 ${ alpha-1}$, 실패횟수가${ beta-1}$인 베타분포인데 성공횟수가 ${ alpha}$, 실패횟수가${ beta-1}$로 바뀌었음 . - 그런데 어차피 베타분포는 확률 밀도 함수이므로 정의역구간을 적분하면 $1$이므로 상관없다 &gt; 하지만 바뀐 베타분포의 상수(베타 함수)가 아닌 기존 베타분포의 상수가 곱해져있는데??? . - 어차피 상수는 적분에 영향을 주지 못하니까 상수항은 임의로 맞춰주면 된다 . $ begin{aligned}E(X) &amp;= int_{0}^{1}x frac{1}{B( alpha, beta)}x^{ alpha-1}(1-x)^{ beta-1} ;dx [10pt] &amp;= frac{1}{B( alpha, beta)} int_{0}^{1}x^{ alpha}(1-x)^{ beta-1} ;dx quad text{$ therefore frac{1}{B( alpha+1, beta)}$을 곱해주어 베타 분포를 만들자} [10pt] &amp;= frac{B( alpha+1, beta)}{B( alpha, beta)} int_{0}^{1} frac{1}{B( alpha+1, beta)}x^{ alpha}(1-x)^{ beta-1} ;dx [10pt] &amp;= frac{B( alpha+1, beta)}{B( alpha, beta)} cdot 1 &amp;= frac{ Gamma( alpha + beta)}{ Gamma( alpha) Gamma( beta)} cdot frac{ Gamma( alpha+1) Gamma( beta)}{ Gamma( alpha + beta+1)} quad text{$ therefore$ 감마함수의 성질: $ Gamma( alpha+1) = alpha Gamma( alpha)$} [10pt] &amp;= frac{ Gamma( alpha + beta)}{ Gamma( alpha) Gamma( beta)} cdot frac{ alpha Gamma( alpha) Gamma( beta)}{( alpha+ beta) Gamma( alpha + beta)} [10pt] &amp;= frac{ alpha}{ alpha+ beta} end{aligned}$ . - 베타 분포의 분산 &gt; 적률의 정의를 통해 구하자 &gt; 우선 2차 비중심 적률을 구하자 . - 베타 분포의 기댓값을 구할 때와 같은 방법을 사용하자 . $ begin{aligned}E(X^2) &amp;= int_{0}^{1}x^{2} frac{1}{B( alpha, beta)}x^{ alpha-1}(1-x)^{ beta-1} ;dx [10pt] &amp;= frac{1}{B( alpha, beta)} int_{0}^{1}x^{ alpha+1}(1-x)^{ beta-1} ;dx quad text{$ therefore frac{1}{B( alpha+2, beta)}$을 곱해주어 베타 분포를 만들자} [10pt] &amp;= frac{B( alpha+2, beta)}{B( alpha, beta)} int_{0}^{1} frac{1}{B( alpha+2, beta)}x^{ alpha+1}(1-x)^{ beta-1} ;dx [10pt] &amp;= frac{B( alpha+2, beta)}{B( alpha, beta)} cdot 1 [10pt] &amp;= frac{ Gamma( alpha + beta)}{ Gamma( alpha) Gamma( beta)} cdot frac{ Gamma( alpha+2) Gamma( beta)}{ Gamma( alpha + beta+2)} quad text{$ therefore Gamma( alpha+1) = alpha Gamma( alpha)$} [10pt] &amp;= frac{ Gamma( alpha + beta)}{ Gamma( alpha) Gamma( beta)} cdot frac{ alpha( alpha+1) Gamma( alpha) Gamma( beta)}{( alpha+ beta+1)( alpha+ beta) Gamma( alpha + beta)} [10pt] &amp;= frac{ alpha( alpha+1)}{( alpha+ beta)( alpha+ beta+1)} end{aligned}$ . $ begin{aligned}Var(X) &amp;= E(X^2) - [E(X)]^2 [10pt] &amp;= frac{ alpha( alpha+1)}{( alpha+ beta)( alpha+ beta+1)} - bigg( frac{ alpha}{ alpha+ beta} bigg)^{2} [10pt] &amp;= frac{ alpha}{ alpha+ beta} bigg( frac{ alpha+1}{ alpha+ beta+1}- frac{ alpha}{ alpha+ beta} bigg) [10pt] &amp;= frac{ alpha}{ alpha+ beta} bigg( frac{( alpha+1)( alpha+ beta)}{( alpha+ beta)( alpha+ beta+1)}- frac{ alpha( alpha+ beta+1)}{( alpha+ beta)( alpha+ beta+1)} bigg) [10pt] &amp;= frac{ alpha}{ alpha+ beta} cdot frac{ beta}{( alpha+ beta)( alpha+ beta+1)} [10pt] &amp;= frac{ alpha beta}{( alpha+ beta)^{2}( alpha+ beta+1)} end{aligned}$ . &#44048;&#47560; &#48516;&#54252;&#51032; &#51201;&#47456;&#49373;&#49457;&#54632;&#49688; . - 감마 분포의 확률 밀도 함수: $f(x) = cfrac{1}{ beta^{ alpha} Gamma( alpha)}x^{ alpha - 1}e^{- frac{x}{ beta}},(x, alpha, beta geq 0)$ . - 감마 함수: $ Gamma( alpha) = int_{0}^{ infty}x^{ alpha-1}e^{-x}dx, , alpha geq 0$ . - 감마 함수를 살짝 변형하면 $ int_{0}^{ infty} cfrac{1}{ Gamma( alpha)}x^{ alpha-1}e^{-x}dx = 1$ . - 위의 식을 감마 분포의 적률생성함수를 구하는데 사용할 것임 . - 감마 분포의 적률생성함수 &gt; $t=0$ 근방임을 잊지말자 . $ begin{aligned}M_X(t) &amp;= E(e^{tX}) [10pt] &amp;= int_{0}^{ infty} frac{1}{ beta^{ alpha} Gamma( alpha)}x^{ alpha - 1}e^{- frac{x}{ beta}}e^{tx} ;dx quad text{$ therefore$ 감마함수의 적분을 이용하기 위해 치환} [10pt] &amp;= frac{1}{ beta^ alpha} int_{0}^{ infty} frac{1}{ Gamma( alpha)}x^{ alpha - 1}e^{ Big(t- frac{1}{ beta} Big)x} ;dx quad text{$ therefore bigg(t- frac{1}{ beta} bigg)x=-y, quad dx= frac{ beta}{1- beta t}dy$} [10pt] &amp;= frac{1}{ beta^ alpha} int_{0}^{ infty} frac{1}{ Gamma( alpha)} bigg( frac{ beta}{1- beta t}y bigg)^{ alpha - 1}e^{-y} frac{ beta}{1- beta t} ;dy quad text{$ therefore x= frac{ beta}{1- beta t}y, ;x=0 to y=0, ;x= infty to y= infty, ; bigg(t&lt; frac{1}{ beta} bigg)$} [10pt] &amp;= frac{1}{ beta^ alpha} bigg( frac{ beta}{1- beta t} bigg)^{ alpha} int_{0}^{ infty} frac{1}{ Gamma( alpha)}y^{ alpha - 1}e^{-y} ;dy quad text{$ therefore int_{0}^{ infty} frac{1}{ Gamma( alpha)}y^{ alpha-1}e^{-y}dy = 1$, 위에 참고} [10pt] &amp;= bigg( frac{1}{1- beta t} bigg)^{ alpha}, quad t&lt; frac{1}{ beta} end{aligned}$ . - 감마 분포의 기댓값 . $ begin{aligned}E(X) =&amp; frac{dM_X(t)}{dt} [10pt] &amp;= alpha bigg( frac{1}{1- beta t} bigg)^{ alpha-1} cdot frac{d}{dt} bigg( frac{1}{1- beta t} bigg) [10pt] &amp;= alpha bigg( frac{1}{1- beta t} bigg)^{ alpha-1} cdot frac{ beta}{(1- beta t)^2} [10pt] &amp;= frac{ alpha beta}{(1- beta t)^{ alpha+1}}, quad text{$t=0$ 대입} [10pt] &amp;= alpha beta end{aligned}$ . . - 감마 분포의 분산 . $ begin{aligned}E(X^2) &amp;= frac{d^2M_X(t)}{dt^2} [10pt] &amp;= alpha beta frac{ beta( alpha+1)(1- beta t)^{ alpha}}{(1- beta t)^{2 alpha+2}} [10pt] &amp;= frac{ alpha beta^{2}( alpha+1)}{(1- beta t)^{ alpha+2}}, quad text{$t=0$ 대입} [10pt] &amp;= alpha beta^{2}( alpha+1) end{aligned}$ . $ begin{aligned}Var(X) &amp;= E(X^2) - [E(X)]^2 [10pt] &amp;= alpha beta^{2}( alpha+1) - ( alpha beta)^{2} [10pt] &amp;= alpha beta^{2}( alpha+1)- alpha^2 beta^2 [10pt] &amp;= alpha beta^2 end{aligned}$ . . &#52852;&#51060;&#51228;&#44273; &#48516;&#54252;&#51032; &#51201;&#47456;&#49373;&#49457;&#54632;&#49688; . - 카이제곱 분포의 확률 밀도 함수: $f(x) = dfrac{1}{2^ frac{k}{2} Gamma big( frac{k}{2} big)}x^{ frac{k}{2}-1}e^{- frac{x}{2}}$ . - $k$는 자유도 . - 감마 분포에서 $ alpha= frac{k}{2}, beta = 2$인 경우 카이제곱 분포라고 했음 . - 그렇기에 감마분포의 평균, 분산, 적률생성함수에 $ alpha= frac{k}{2}, beta = 2$를 대입하여 카이제곱 분포의 평균, 분산, 적률생섬함수를 구할 수 있음(내 생각) . - 카이제곱 분포의 적률생성함수 . $ begin{aligned}M_X(t) &amp;= bigg( frac{1}{1- beta t} bigg)^{ alpha}, quad t&lt; frac{1}{ beta}, quad text{$ alpha= frac{k}{2}, ; beta = 2$ 대입} [10pt] &amp;= bigg( frac{1}{1-2t} bigg)^ frac{k}{2} end{aligned}$ . - 카이제곱 분포의 기댓값 . - $E(X) = alpha beta= k, quad text{$ alpha= frac{k}{2}, ; beta = 2$ 대입}$ . - 카이제곱 분포의 분산 . - $Var(X) = alpha beta^2=2k, quad text{$ alpha= frac{k}{2}, ; beta = 2$ 대입}$ . &#51221;&#44508; &#48516;&#54252;&#51032; &#51201;&#47456;&#49373;&#49457;&#54632;&#49688; . - 정규 분포의 확률 밀도 함수: $f(x) = cfrac{1}{ sqrt{2 pi sigma^{2}}}e^{- dfrac{(x- mu)^{2}}{2 sigma^{2}}}$ . - 완전제곱식 생성: $x^2-ax= big(x- frac{a}{2} big)^2- frac{a^2}{4}$ . - 정규 분포의 적률생성함수 . $ begin{aligned}M_X(t) &amp;= E(e^{tX}) [10pt] &amp;= int_{- infty}^{ infty}e^{tx} frac{1}{ sqrt{2 pi sigma^{2}}}e^{- dfrac{(x- mu)^{2}}{2 sigma^{2}}} ;dx [10pt] &amp;= int_{- infty}^{ infty} frac{1}{ sqrt{2 pi sigma^{2}}}e^{- dfrac{x^2-2( mu+ sigma^{2}t)x+ mu^2}{2 sigma^{2}}} ;dx [10pt] &amp;= int_{- infty}^{ infty} frac{1}{ sqrt{2 pi sigma^{2}}}e^{- dfrac{(x- mu- sigma^{2}t)^2-( mu+ sigma^2t)^2+ mu^2}{2 sigma^{2}}} ;dx [10pt] &amp;=e^{ mu t+ frac{ sigma^2 t^2}{2}} cdot int_{- infty}^{ infty} frac{1}{ sqrt{2 pi sigma^{2}}}e^{- dfrac{(x- mu- sigma^{2}t)^2}{2 sigma^2}} ;dx [10pt] &amp;=e^{ mu t+ frac{ sigma^2 t^2}{2}} quad text{$ therefore$ 평균이 $ mu+ sigma^{2}t$이고 표준편차가 $ sigma$인 정규분포이므로 적분값은 $1$} end{aligned}$ . . - 정규 분포의 기댓값 . $ begin{aligned}E(X) &amp;= frac{dM_X(t)}{dt} [10pt] &amp;= ( mu + sigma^2 t)e^{ mu t+ frac{ sigma^2 t^2}{2}}, quad text{$t=0$ 대입} [10pt] &amp;= mu end{aligned}$ . . - 정규 분포의 분산 . $ begin{aligned}E(X^2) &amp;= frac{d^2M_X(t)}{dt^2} [10pt] &amp;= sigma^{2}e^{ mu t+ frac{ sigma^2 t^2}{2}}+( mu+ sigma^2 t)^2e^{ mu t+ frac{ sigma^2 t^2}{2}}, quad text{$t=0$ 대입} [10pt] &amp;= sigma^2+ mu^2 end{aligned}$ . $ begin{aligned}Var(X)&amp;=E(X^2)-[E(X)]^2 [10pt] &amp;= sigma^2+ mu^2-( mu)^2 [10pt] &amp;= sigma^2 end{aligned}$ . .",
            "url": "https://jaesu26.github.io/study-blog/statistics/2021/07/23/%EC%A0%81%EB%A5%A0%EC%83%9D%EC%84%B1%ED%95%A8%EC%88%98.html",
            "relUrl": "/statistics/2021/07/23/%EC%A0%81%EB%A5%A0%EC%83%9D%EC%84%B1%ED%95%A8%EC%88%98.html",
            "date": " • Jul 23, 2021"
        }
        
    
  
    
        ,"post39": {
            "title": "동적 계획법",
            "content": "&#46041;&#51201; &#44228;&#54925;&#48277; . - 다이나믹 프로그래밍 참고: 동적 계획법 . - 다이나믹 프로그래밍((Dynamic Programming)으로도 불림 . - 큰 문제를 작은 문제로 나눠서 푸는 방법 . - 분할 정복과 유사하지만... . 동적 계획법 분할 정복 . 공통점 | 큰 문제를 작은 문제로 나눠서 해결 | 큰 문제를 작은 문제로 나눠서 해결 | . 차이점 | 작은 문제가 반복됨 | 작은 문제가 반복되지 않음 | . - 나중에 분할 정복에 대해서도 다뤄보자 . &#45796;&#51060;&#45208;&#48121; &#54532;&#47196;&#44536;&#47000;&#48141; &#51312;&#44148; . 1. 작은 문제들의 반복 . 2. 같은 문제는 구할 때마다 정답이 같음 . &#45796;&#51060;&#45208;&#48121; &#54532;&#47196;&#44536;&#47000;&#48141; &#44396;&#54788; . - 모든 작은 문제는 단 한번만 풀어야 함 . - 정답을 구한 작은 문제는 어딘가에 저장 . - 큰 문제를 해결할 때 미리 구한 작은 문제의 정답을 사용 . 피보나치 수열을 다이나믹 프로그래밍으로 구현해보자 | . Top-down . - 큰 문제를 해결할 때 작은 문제가 해결되지 않았으면 작은 문제를 해결하여 큰 문제를 해결 . - 재귀 함수로 구현하는 경우가 Top-down 방법 . - 메모이제이션 기법 사용 &gt; 미리 구한 작은 문제의 정답을 어딘가에 저장 . - 단순 재귀 함수로 구현한 피보나치 함수의 시간 복잡도는 $T(n) = T(n-1) + T(n-2) + C$이다 . - 하지만 Top-down 방법을 사용한 피보나치 함수의 시간 복잡도는 $T(n) = T(n-1) + C$이다 . - 왜냐하면 메모이제이션을 통해 피보나치 함수값을 $T(n-1)$을 재귀호출 하면서 미리 구해놨기 때문에 . - $T(n-2)$에서는 재귀호출이 일어나지 않아 상수시간만 소요된다 . fibonacci = {0: 0, 1: 1} # 메모이제이션을 위한 딕셔러니 선언 def fibo_top_down(n): if n in fibonacci: return fibonacci[n] fibonacci[n] = fibo_top_down(n - 1) + fibo_top_down(n - 2) return fibonacci[n] . fibo_top_down(10) . 55 . Bottom-up . - 작은 문제부터 차근차근 해결하여 큰 문제를 해결 . - 반복문 사용 . def fibo_bottom_up1(n): if n &lt;= 1: return n fir_fibo = 0 sec_fibo = 1 for _ in range(n - 1): next_fibo = fir_fibo + sec_fibo # 2번째 피보나치 값 = 0번째 피보나치 값 + 1번째 피보나치 값 (n번째 피보나치 값 = n-2번째 피보나치 값 + n-1번째 피보나치 값) fir_fibo = sec_fibo # 0번째 피보나치 값을 1번째 피보나치 값으로 업데이트 sec_fibo = next_fibo # 1번째 피보나치 값을 2번째 피보나치 값으로 업데이트 # 다시 for문 시작으로 돌아가서 1번째 피보나치 값과 2번째 피보나치 값을 통해 3번째 피보나치 값을 구함 (이를 n-1번 반복) # for 문의 역할은 점화식을 통해 0번째와 1번째의 피보나치 값을 가지고 n번째의 피보나치 값을 구한다 return next_fibo . fibo_bottom_up1(10) . 55 . - 또 다른 방법 . - 미리 dp라는 list를 생성 . x = 100 # 문제 조건에 맞춰서 dp = [-1] * x # 리스트 초기화 def fibo_bottom_up2(n): dp[0] = 0 dp[1] = 1 for i in range(2, n + 1): dp[i] = dp[i - 1] + dp[i - 2] return dp[n] . fibo_bottom_up2(10) . 55 . - bottom-up 방식으로 구현한 위의 두개 코드의 차이점은? . - fibo(9)와 fibo(10)을 구할 때 처음 코드는 fibo_bottom_up1(9)과 fibo_bottom_up1(10) 총 함수를 2번 사용 . - 사실 fibo_bottom_up1(10)을 계산했다면 fibo_bottom_up1(9)도 당연히 알지만 각각을 따로 두 번 구했다 . - 첫 번째 코드의 경우 다이나믹 프로그래밍은 이미 구한 작은 문제 정답은 또 구하지 않기로 했지만 그렇지 않은 모습 . - 하지만 두 번째 코드는 fibo_bottom_up2(10)을 계산했다면 $ operatorname{dp}[0]$ ~ $ operatorname{dp}[10]$까지 값이 채워져 있기에 fibo_bottom_up2(9)를 계산하지 않고 $ operatorname{dp}[9]$를 통해 fibo(9)를 계산할 수 있음 . - 하지만 공간복잡도(메모리 사용) 측면으로 보면 첫 번째 코드가 두 번째 코드보다 메모리를 덜 잡아먹는다 (두 번째 코드는 충분히 큰 배열이 필요함) . - 결론: 상황에 맞게 사용하자 .",
            "url": "https://jaesu26.github.io/study-blog/algorithm/2021/07/19/%EB%8B%A4%EC%9D%B4%EB%82%98%EB%AF%B9-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D.html",
            "relUrl": "/algorithm/2021/07/19/%EB%8B%A4%EC%9D%B4%EB%82%98%EB%AF%B9-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D.html",
            "date": " • Jul 19, 2021"
        }
        
    
  
    
        ,"post40": {
            "title": "파이썬 기본 연산 시간 복잡도 (Big O)",
            "content": "&#49884;&#44036; &#48373;&#51105;&#46020; . - 컴퓨터 프로그램의 입력값과 연산 수행 시간의 함수 관계 . - 보통 Big O 표기법으로 나타냄 . Big O &#54364;&#44592;&#48277; . - 알고리즘의 시간 복잡도를 나타내는 척도 . - 두 함수 $f$와 $g ,(g&gt;0)$에 대해 상수 $k&lt; infty$가 존재해서 $x in A subset mathbb{R}$인 $x$에 대하여 $ left| frac{f(x)}{g(x)} right|&lt;K$이면 $f(x)=O(g(x))$임 . - 쉽게 말하면 $f$는 $g$로부터 일정수준 이상 벗어날 수 없다는 뜻($f$나 $g$나 비슷비슷하다) . - $f(x) = 2x, ,g(x) = x$이면 $ left| frac{f(x)}{g(x)} right| = 2&lt; infty$이므로 $f(x) = O(g(x))$임 &gt; $f$나 $g$나 비슷함 . - 만약 $h(x) = x^2$이면 $ left| frac{h(x)}{g(x)} right| = |x|$이고 $x to infty$이면 $ left| frac{h(x)}{g(x)} right| to infty$이므로 $h(x) neq O(g(x))$임 &gt; $h$와 $g$는 급이 다름 . &#50672;&#49328; &#49884;&#44036; &#48373;&#51105;&#46020; . - 자료형별 연산의 시간 복잡도를 나타내자 . &#47532;&#49828;&#53944; (List) . - l은 리스트 (list) . - k는 상수 . - 참고: 파이썬 자료형별 연산 시간 복잡도 . Operation Example Complexity Class Notes . index | l[n] | $O(1)$ | | . store | l[n] = 0 | $O(1)$ | store는 변수 저장 | . length | len(l) | $O(1)$ | | . append | l.append(5) | $O(1)$ | | . pop | l.pop() | $O(1)$ | same as l.pop(-1) | . clear | l.clear() | $O(1)$ | similar to l = [] | . slice | l[a:b] | $O(b-a)$ | $l[1:5] to O(l)$, $l[ ; ; : ; ; ] to O(len(l)-0)=O(N)$ | . extend | l.extend(...) | $O(len( dots))$ | depends only on len of extension | . construction | list(...) | $O(len( dots))$ | depends on length of ... iterable | . check ==, != | l1 == l2 | $O(N)$ | | . insert | l[a:b] = ... | $O(N)$ | | . delete | del l[n] | $O(N)$ | depends on $n$; $O(N)$ in worst case | . containment | x in/not in l | $O(N)$ | linearly searches list | . copy | l.copy() | $O(N)$ | Same as $l[ ; ;: ; ;]$ which is $O(N)$ | . remove | l.remove(...) | $O(N)$ | | . pop | l.pop(n) | $O(N)$ | $O(N-i)$: l.pop(0): $O(N)$ (see above) | . extreme value | min(l)/max(l) | $O(N)$ | linearly searches list for value | . reverse | l.reverse() | $O(N)$ | | . iteration | for v in l: | $O(N)$ | Worst: no return/break in loop | . sort | l.sort() | $O(N Log N)$ | key/reverse mostly does not change | . multiply | $k times l$ | $O(kN)$ | $5 times l$ is $O(N)$: $len(l) times l$ is $O(N^2)$ | . &#51665;&#54633; (Set) . - s는 집합 (set) . - 리스트에 비해 시간 복잡도가 작음 . Operation Example Complexity Class Notes . Length | len(s) | $O(1)$ | | . Add | s.add(5) | $O(1)$ | | . Containment | x in/not in s | $O(1)$ | compare to list/tuple - $O(N)$ | . Remove | s.remove(..) | $O(1)$ | compare to list/tuple - $O(N)$ | . Discard | s.discard(..) | $O(1)$ | | . Pop | s.pop() | $O(1)$ | popped value &quot;randomly&quot; selected | . Clear | s.clear() | $O(1)$ | similar to s = set() | . Construction | set(...) | $O(len(...))$ | depends on length of ... iterable | . check ==, != | s != t | $O(len(s))$ | same as $len(t)$; False in $O(1)$ if the lengths are different | . &lt;=/&lt; | s &lt;= t | $O(len(s))$ | issubset | . &gt;=/&gt; | s &gt;= t | $O(len(t))$ | issuperset s &lt;= t == t &gt;= s | . Union | s | t | $O(len(s)$+$len(t))$ | | . Intersection | s &amp; t | $O(len(s)$+$len(t))$ | | . Difference | s - t | $O(len(s)$+$len(t))$ | | . Symmetric Diff | s ^ t | $O(len(s)$+$len(t))$ | | . Iteration | for v in s: | $O(N)$ | Worst: no return/break in loop | . Copy | s.copy() | $O(N)$ | | . &#54644;&#49884; &#53580;&#51060;&#48660; (Dictionary) . - d는 해시 테이블 (dict) . - 시간 복잡도가 대부분 $O(1)$이다 . - 같은 함수라면 리스트 대신 딕셔너리를 사용하는 것이 시간 복잡도 면에서 우월함 . Operation Example Complexity Class Notes . Index | d[k] | $O(1)$ | | . Store | d[k] = v | $O(1)$ | | . Length | len(d) | $O(1)$ | | . Delete | del d[k] | $O(1)$ | | . get/setdefault | d.get(k) | $O(1)$ | | . Pop | d.pop(k) | $O(1)$ | | . Pop item | d.popitem() | $O(1)$ | popped item &quot;randomly&quot; selected | . Clear | d.clear() | $O(1)$ | similar to s = {} or = dict() | . View | d.keys() | $O(1)$ | same for d.values() | . Construction | dict(...) | $O(len(...))$ | depends # (key,value) 2-tuples | . Iteration | for k in d: | $O(N)$ | all forms: keys, values, items, Worst: no return/break in loop | .",
            "url": "https://jaesu26.github.io/study-blog/python/algorithm/2021/07/15/%ED%8C%8C%EC%9D%B4%EC%8D%AC-%EA%B8%B0%EB%B3%B8%EC%97%B0%EC%82%B0-%EC%8B%9C%EA%B0%84%EB%B3%B5%EC%9E%A1%EB%8F%84.html",
            "relUrl": "/python/algorithm/2021/07/15/%ED%8C%8C%EC%9D%B4%EC%8D%AC-%EA%B8%B0%EB%B3%B8%EC%97%B0%EC%82%B0-%EC%8B%9C%EA%B0%84%EB%B3%B5%EC%9E%A1%EB%8F%84.html",
            "date": " • Jul 15, 2021"
        }
        
    
  
    
        ,"post41": {
            "title": "문자열 처리",
            "content": "format &#54632;&#49688; . - 문자열을 포매팅(formatting)하는데 사용 . - 포매팅: 문자열의 원하는 위치에 특정 변수를 삽입 . - 아래 예제를 보자 . &quot;이름:{},나이:{},성별:{}&quot;.format(&quot;홍길동&quot;, &quot;21&quot;, &quot;남&quot;) . &#39;이름:홍길동,나이:21,성별:남&#39; . - 순서대로 홍길동, 21, 남이 {}에 삽입됨 . - 구구단도 쉽게 출력할 수 있음 . i = 2 for j in range(1, 10): print(&quot;{} X {} = {}&quot;.format(i, j, i * j)) . 2 X 1 = 2 2 X 2 = 4 2 X 3 = 6 2 X 4 = 8 2 X 5 = 10 2 X 6 = 12 2 X 7 = 14 2 X 8 = 16 2 X 9 = 18 . [$ star$]&#49548;&#49688;&#51216; &#51088;&#47551;&#49688; &#54364;&#54788;[$ star$] . - 알고리즘 문제를 풀다보면 특정 소수점 자릿수까지 출력을 요구할 때가 있음 . - 계산 결과를 소수점 셋째 자리 까지 표현하려면? . a = 10 b = 3 a / b . 3.3333333333333335 . - 소수점 셋째 짜리 까지 표현하고 싶음 . - format 함수 사용! . a = 10 b = 3 print(&quot;{:.3f}&quot;.format(a / b)) . 3.333 . - round 함수도 되는데? . - round(x, a) &gt; x를 소수점 a번째 까지 나타냄 . a = 10 b = 3 round(a / b, 3) . 3.333 . - 아래와 같은 경우는? . a = 10 b = 2 a / b . 5.0 . - format 함수 . a = 10 b = 2 print(&quot;{:.3f}&quot;.format(a / b)) . 5.000 . - round 함수 . a = 10 b = 2 round(a / b, 3) . 5.0 . - format 함수는 소수점 셋째 자리까지 나타낸 반면 round 함수는 첫째 자리까지 나타냄 . round 함수를 사용할 때 주의할 점 | . - 파이썬에서는 사사오입의 원칙을 따라 반올림할 자리가 5이면 반올림을 할 때 짝수면 내림, 홀수면 올림 한다 . round(2.5) . 2 . round(-1.5) . -2 . - 오사오입의 원칙으로 반올림 하려면? &gt; 함수를 따로 만들자 . def round2(number): if number &gt;= 0: if number - int(number) &gt;= 0.5: a = 1 else: a = 0 return int(number) + a else: if int(number) - number &gt; 0.5: a = -1 else: a = 0 return int(number) + a . round2(2.5) . 3 . round2(-1.5) . -1 . - 사사오입의 원칙으로 반올림을 하는 이유는 데이터의 대부분이 .5로 끝나는 자료라면 이를 반올림하면 0.5만큼의 오차가 생기기 때문 . - 결론: 원하는 자릿수 까지 나타내려면 round 함수 대신 format 함수를 쓰자 . join &#54632;&#49688; . - 문자열로 이루어진 리스트를 기준 문자열로 합쳐 문자열로 만듦 . - 구분자.join(list) . - 구분자에는 문자열, list에는 문자열을 원소로 가지는 리스트가 들어감 . a = [&quot;12&quot;, &quot;45&quot;, &quot;48&quot;] . &quot;-&quot;.join(a) . &#39;12-45-48&#39; . &quot;&quot;.join(a) . &#39;124548&#39; . replace &#54632;&#49688; . - 특정 문자를 다른 문자로 대체 . - 문자열.replace(기존 문자, 바꿀 문자) . a = &quot;hello world&quot; . a.replace(&quot;h&quot;, &quot;H&quot;) . &#39;Hello world&#39; . a.replace(&quot;&quot;, &quot;!&quot;) . &#39;!h!e!l!l!o! !w!o!r!l!d!&#39; . - 문자열에서는 빈칸도 하나의 문자로 취급 . split &#54632;&#49688; . - 문자열을 구분자를 기준으로 쪼갬 . - 문자열.split(구분자) . a = &quot;!h!e!l!l!o! !w!o!r!l!d!&quot; . a.split(&quot;!&quot;) . [&#39;&#39;, &#39;h&#39;, &#39;e&#39;, &#39;l&#39;, &#39;l&#39;, &#39;o&#39;, &#39; &#39;, &#39;w&#39;, &#39;o&#39;, &#39;r&#39;, &#39;l&#39;, &#39;d&#39;, &#39;&#39;] . upper &#54632;&#49688; . - 문자열에서 모든 소문자를 대문자로 바꿈 . - 문자열.upper(구분자) . a = &quot;hello world&quot; . a.upper() . &#39;HELLO WORLD&#39; . str.isupper() . - str이 대문자로만 이루어져 있으면 True를 아니면 False를 반환 . string = &quot;ABC&quot; string2 = &quot;AbC&quot; . string.isupper() . True . string2.isupper() . False . lower &#54632;&#49688; . - 문자열에서 모든 대문자를 소문자로 바꿈 . - 문자열.lower(구분자) . a = &quot;HELLO WORLD&quot; . a.lower() . &#39;hello world&#39; . str.islower() . - str이 소문자로만 이루어져 있으면 True를 아니면 False를 반환 . string = &quot;abc&quot; string2 = &quot;aBc&quot; . string.islower() . True . string2.islower() . False . count &#54632;&#49688; . - 문자열에서 특정 문자 또는 문자열의 개수를 반환함 . - 문자열.count(찾는 문자, 시작 인덱스, 끝 인덱스) . - 시작 인덱스 $ leq$ 문자열 $&lt;$ 끝 인덱스 . a = &quot;HELLO WORLD&quot; . a.count(&quot;L&quot;) . 3 . a.count(&quot;L&quot;, 0, 9) . 2 . a.count(&quot;L&quot;, 0, 10) . 3 . chr &#54632;&#49688; . - 아스키 코드를 문자로 변환함 . - chr(아스키코드) . - 아스키 코드 참고: https://ko.wikipedia.org/wiki/ASCII . chr(65) . &#39;A&#39; . ord &#54632;&#49688; . - 문자를 아스키 코드로 변환함 . - ord(문자) . ord(&quot;A&quot;) . 65 .",
            "url": "https://jaesu26.github.io/study-blog/python/2021/07/09/%EB%AC%B8%EC%9E%90%EC%97%B4-%ED%95%A8%EC%88%98.html",
            "relUrl": "/python/2021/07/09/%EB%AC%B8%EC%9E%90%EC%97%B4-%ED%95%A8%EC%88%98.html",
            "date": " • Jul 9, 2021"
        }
        
    
  
    
        ,"post42": {
            "title": "그리디 알고리즘",
            "content": "&#44536;&#47532;&#46356; &#50508;&#44256;&#47532;&#51608;(&#50837;&#49900;&#51137;&#51060; &#50508;&#44256;&#47532;&#51608;, Greedy Algorithm)&#51060;&#46976;? . - 다이나믹 프로그래밍이 모든 경우를 확인 한다는 점에서 고안된 알고리즘 . - 매 선택마다 가장 최적인 답을 선택하여 결론을 도출 &gt; 알파고: 자신 차례마다 가장 승률이 높은 수를 선택 . - but, 매 선택마다 최적이지만 결과가 최적이라는 보장 없음 . - 마시멜로 실험: 당장은 1개, 기다리면 2개 &gt; 최적해: 기다리고 2개 먹기 . - 하지만 그리디 알고리즘은 지금 최적의 선택인 1개를 선택 &gt; 최적해 아님 . &#44536;&#47084;&#47732; &#50612;&#46500; &#44221;&#50864;&#50640; &#51096; &#46041;&#51089;&#54616;&#45716;&#44032;? . - 탐욕 선택 속성(greedy choice property): 한번의 선택이 다음 선택과는 무관 . - 최적 부분 구조(optimal substructure): 매 순간의 최적해 &gt; 문제에 대한 최적해 . &#44536;&#47532;&#46356; &#50508;&#44256;&#47532;&#51608; &#53076;&#46300; &#44396;&#54788; . - 백준 - 설탕 배달: https://www.acmicpc.net/problem/2839 . - 설탕 $N$kg을 3kg, 5kg봉지에 담아야 하는데 봉지의 수를 최소화 . 최적 부분 구조: 매 순간 봉지의 수를 최소화하려는 행위(3kg 봉지 보다 5kg 봉지 사용)는 문제에 대한 최적해 (봉지의 수 최소화) . | 탐욕 선택 속성: 전에 5kg 봉지를 선택하든 3kg 봉지를 선택하든 상관없이 현재 남아있는 무게를 가지고만 판단하여 선택 . | - 그리디 알고리즘: 5kg 봉지로만 담는 것이 최선 . - 만약 5kg 봉지로만 담는 것이 불가능하면? . - 5kg 봉지를 하나 줄이고 3kg 봉지를 사용함 . - 이를 반복함 &gt; 만약 담는 것이 불가능하면 -1을 반환 . 설탕 배달(그리디 알고리즘) | . - 설탕의 무게는 $N$kg . 5kg 봉지 선택 (최적 판단) . | 5kg 봉지 선택 (최적 판단) . | 5kg 봉지만 계속 선택 --&gt; total: $k$ 번 선택 (최적 판단) . | 만약 남은 무게가 예컨데 4kg 이라 5kg 봉지에 담지 못한다면 3kg 선택 (최적 판단) . | 3kg 에 담고나면 1kg 이 남음 &gt; 어느 봉지에도 담지 못함 . | 5kg 봉지를 $k - 1$번 선택하고 3kg 봉지를 선택 . | 5kg 봉지를 0번 선택할 때 까지 반복 &gt; 이 경우에도 답이 없다면 해가 존재하지 않음 . | N = int(input()) def sugar(n): k = n // 5 l = n % 5 for i in range(k + 1): if l == 0: return k if l % 3 == 0: return k + (l // 3) l += 5 k -= 1 return -1 print(sugar(N)) . 21 . - 설탕 무게가 101kg 일시 5kg 19개, 3kg 2개를 선택 .",
            "url": "https://jaesu26.github.io/study-blog/algorithm/2021/07/09/%EA%B7%B8%EB%A6%AC%EB%94%94-%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98.html",
            "relUrl": "/algorithm/2021/07/09/%EA%B7%B8%EB%A6%AC%EB%94%94-%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98.html",
            "date": " • Jul 9, 2021"
        }
        
    
  
    
        ,"post43": {
            "title": "DFS와 BFS 알고리즘",
            "content": "&#44618;&#51060; &#50864;&#49440; &#53456;&#49353;(Depth First Search, DFS) . - 모든 정점을 한번만 방문 . - 시작 노드에서 다음 분기로 넘어가기 전에 해당 분기를 완벽하게 탐색 . - 방문할 노드와 방문한 노드를 기준으로 탐색 . - 특정 노드가 방문할 노드 &gt; 탐색, 방문한 노드 &gt; 지나감 . - 그래프나 트리는 dictionary로 생성 . - stack 구조 와 재귀 함수로 구현 가능 . DFS &#51109;&#51216; . - 단지 현 경로상의 노드들만을 기억하면 되므로 저장공간의 수요가 비교적 적음 . - 목표노드가 깊은 단계에 있을 경우 해를 빨리 구함 . DFS &#45800;&#51216; . - 해가 없는 경로에 깊이 빠질 가능성 존재 . - 얻어진 해가 최단 경로가 된다는 보장이 없음 &gt; 목표에 이르는 경로가 다수일 때 해에 다다르면 탐색을 끝내버림 &gt; 이때 얻어진 해는 최적이 아닐 수 있음 . DFS 참고: 깊이 우선 탐색 | . DFS &#53076;&#46300; &#44396;&#54788; . - tree 구조 . - stack 자료 구조 활용: 후입선출(한쪽면이 막힌 원통) . - 노드: [A], [B], [C], [D], [E], [F], [G], [H], [I], [J] . - 분기: [A, B, E], [A, B, F, I], [A, C, G], [A, D, H, I] . - 재귀함수를 활용한 DFS 코드가 최종 코드이다 (리스트 활용과 해시 테이블 활용 part에서 구현한 DFS는 비효율적임) . tree = {&#39;A&#39;: [&#39;B&#39;, &#39;C&#39;, &#39;D&#39;], ## A는 B, C, D와 연결됨 &#39;B&#39;: [&#39;A&#39;, &#39;E&#39;, &#39;F&#39;], ## B는 A, E, F와 연결됨 &#39;C&#39;: [&#39;A&#39;, &#39;G&#39;], ## C는 A, G와 연결됨 &#39;D&#39;: [&#39;A&#39;, &#39;H&#39;], ## D는 A, H와 연결됨 &#39;E&#39;: [&#39;B&#39;], ## E는 B와 연결됨 &#39;F&#39;: [&#39;B&#39;, &#39;I&#39;], ## F는 B, I와 연결됨 &#39;G&#39;: [&#39;C&#39;], ## G는 C와 연결됨 &#39;H&#39;: [&#39;D&#39;, &#39;J&#39;], ## H는 D, J와 연결됨 &#39;I&#39;: [&#39;F&#39;], ## I는 F와 연결됨 &#39;J&#39;: [&#39;H&#39;]} ## J는 H와 연결됨 . &#47532;&#49828;&#53944; &#54876;&#50857; . - 파이썬에서 리스트는 stack구조여서 DFS에 활용 가능 . - list.pop(i)은 성능이 떨어짐, i번째 이후 원소들을 한 칸씩 앞으로 땡겨야하기 때문 &gt; $O(N)$ . - 비고: $O(N-i) to O(N)$ 최악의 경우(0번째 인덱스) . - list.pop()은 마지막 원소만 pop하므로 $O(1)$ . - list.pop() &gt; 맨 마지막에 넣었던 노드를 가져옴: stack구조와 동일(후입선출) . def DFS_list(graph, start_node): visited = [] ## 방문한 노드 stack = [] ## 방문할 노드 stack.append(start_node) ## 방문할 노드에 시작 노드 추가 count = 0 ## 방문을 몇 번 했는지 기록 while stack: ## 방문할 노드가 있다면(리스트에 원소가 있으면 True) node = stack.pop() ## node를 방문했다!, 마지막 노드 추가(스택 구조 사용) count += 1 ## 방문 횟수 + 1 if node not in visited: ## 만약 아직 방문한 노드가 아니라면 visited.append(node) ## 이제 방문했으니까 방문한 노드에 추가 stack.extend(reversed(graph[node])) ## 방문한 노드에 연결된 노드를 탐색해보자 print(visited) print(stack) print(&#39;-&#39;) ## 방문과정 확인 return visited, count ## 방문한 노드를 반환 DFS_list(tree, &#39;A&#39;) ## 마지막은 return 값 . [&#39;A&#39;] [&#39;D&#39;, &#39;C&#39;, &#39;B&#39;] - [&#39;A&#39;, &#39;B&#39;] [&#39;D&#39;, &#39;C&#39;, &#39;F&#39;, &#39;E&#39;, &#39;A&#39;] - [&#39;A&#39;, &#39;B&#39;] [&#39;D&#39;, &#39;C&#39;, &#39;F&#39;, &#39;E&#39;] - [&#39;A&#39;, &#39;B&#39;, &#39;E&#39;] [&#39;D&#39;, &#39;C&#39;, &#39;F&#39;, &#39;B&#39;] - [&#39;A&#39;, &#39;B&#39;, &#39;E&#39;] [&#39;D&#39;, &#39;C&#39;, &#39;F&#39;] - [&#39;A&#39;, &#39;B&#39;, &#39;E&#39;, &#39;F&#39;] [&#39;D&#39;, &#39;C&#39;, &#39;I&#39;, &#39;B&#39;] - [&#39;A&#39;, &#39;B&#39;, &#39;E&#39;, &#39;F&#39;] [&#39;D&#39;, &#39;C&#39;, &#39;I&#39;] - [&#39;A&#39;, &#39;B&#39;, &#39;E&#39;, &#39;F&#39;, &#39;I&#39;] [&#39;D&#39;, &#39;C&#39;, &#39;F&#39;] - [&#39;A&#39;, &#39;B&#39;, &#39;E&#39;, &#39;F&#39;, &#39;I&#39;] [&#39;D&#39;, &#39;C&#39;] - [&#39;A&#39;, &#39;B&#39;, &#39;E&#39;, &#39;F&#39;, &#39;I&#39;, &#39;C&#39;] [&#39;D&#39;, &#39;G&#39;, &#39;A&#39;] - [&#39;A&#39;, &#39;B&#39;, &#39;E&#39;, &#39;F&#39;, &#39;I&#39;, &#39;C&#39;] [&#39;D&#39;, &#39;G&#39;] - [&#39;A&#39;, &#39;B&#39;, &#39;E&#39;, &#39;F&#39;, &#39;I&#39;, &#39;C&#39;, &#39;G&#39;] [&#39;D&#39;, &#39;C&#39;] - [&#39;A&#39;, &#39;B&#39;, &#39;E&#39;, &#39;F&#39;, &#39;I&#39;, &#39;C&#39;, &#39;G&#39;] [&#39;D&#39;] - [&#39;A&#39;, &#39;B&#39;, &#39;E&#39;, &#39;F&#39;, &#39;I&#39;, &#39;C&#39;, &#39;G&#39;, &#39;D&#39;] [&#39;H&#39;, &#39;A&#39;] - [&#39;A&#39;, &#39;B&#39;, &#39;E&#39;, &#39;F&#39;, &#39;I&#39;, &#39;C&#39;, &#39;G&#39;, &#39;D&#39;] [&#39;H&#39;] - [&#39;A&#39;, &#39;B&#39;, &#39;E&#39;, &#39;F&#39;, &#39;I&#39;, &#39;C&#39;, &#39;G&#39;, &#39;D&#39;, &#39;H&#39;] [&#39;J&#39;, &#39;D&#39;] - [&#39;A&#39;, &#39;B&#39;, &#39;E&#39;, &#39;F&#39;, &#39;I&#39;, &#39;C&#39;, &#39;G&#39;, &#39;D&#39;, &#39;H&#39;] [&#39;J&#39;] - [&#39;A&#39;, &#39;B&#39;, &#39;E&#39;, &#39;F&#39;, &#39;I&#39;, &#39;C&#39;, &#39;G&#39;, &#39;D&#39;, &#39;H&#39;, &#39;J&#39;] [&#39;H&#39;] - [&#39;A&#39;, &#39;B&#39;, &#39;E&#39;, &#39;F&#39;, &#39;I&#39;, &#39;C&#39;, &#39;G&#39;, &#39;D&#39;, &#39;H&#39;, &#39;J&#39;] [] - . ([&#39;A&#39;, &#39;B&#39;, &#39;E&#39;, &#39;F&#39;, &#39;I&#39;, &#39;C&#39;, &#39;G&#39;, &#39;D&#39;, &#39;H&#39;, &#39;J&#39;], 19) . - return 결과를 보면 DFS 방식임을 알 수 있다 . - 노드가 10개이므로 10번 방문해야 하지만 19번 방문함 . &#54644;&#49884; &#53580;&#51060;&#48660; &#54876;&#50857; . - if node not in visited: &gt; visited가 list인 경우 $O(N)$의 시간복잡도를 가짐 . - visited도 해시 테이블(key: value 관계인 자료형: 파이썬의 dictionary)로 구현하면 $O(1)$로 효율$ uparrow$ . 해시 테이블에 관한 좋은 영상 | . def DFS_Hash_Table(graph, start_node): visited = {} ## 방문한 노드 stack = [] ## 방문할 노드 stack.append(start_node) ## 방문할 노드에 시작 노드 추가 count = 0 ## 방문을 몇 번 했는지 기록 while stack: ## 방문할 노드가 있다면(리스트에 원소가 있으면 True) node = stack.pop() ## node를 방문했다!, 마지막 노드 추가(스택 구조 사용) count += 1 ## 방문 횟수 + 1 if node not in visited: ## 만약 아직 방문한 노드가 아니라면 visited[node] = True ## 이제 방문했으니까 방문한 노드에 추가 stack.extend(reversed(graph[node])) ## 방문한 노드에 연결된 노드를 탐색해보자 return list(visited.keys()), count ## 방문한 노드를 반환 DFS_Hash_Table(tree, &#39;A&#39;) ## 마지막은 return 값 . ([&#39;A&#39;, &#39;B&#39;, &#39;E&#39;, &#39;F&#39;, &#39;I&#39;, &#39;C&#39;, &#39;G&#39;, &#39;D&#39;, &#39;H&#39;, &#39;J&#39;], 19) . - list를 활용한 코드와 return 결과는 동일하다 . - 시간복잡도면에서 list를 활용한 것 보다 Hash Table을 사용한 것이 성능이 우월하다 . - return 결과를 보면 DFS 방식임을 알 수 있다 . - 노드가 10개이므로 10번 방문해야 하지만 19번 방문함 . &#51116;&#44480;&#54632;&#49688; &#54876;&#50857; . - 위에서 구현한 DFS는 방문을 한 뒤에 방문했다고 처리를 한다 . - 방문을 하고 방문 처리를 하면 하나의 노드에 대해 중복 방문하므로 비효율적이다 . - 아래와 같이 해당 노드를 방문할 때 방문 처리를 하면 중복 방문을 피할 수 있다 . - 또한 재귀함수를 활용하여 코드를 더 간략하게 할 수 있다 . count = 0 ## 방문 횟수 def DFS_recursive(graph, start_node, visited = {}): global count visited[start_node] = True ## 시작 정점 방문! (방문 처리) count += 1 ## 방문 횟수 + 1 for node in graph[start_node]: if node not in visited: ## 인접 노드를 아직 방문하지 않았다면 DFS_recursive(graph, node, visited) ## 방문하자! ## 간단히 설명 -&gt; 처음 시작 노드는 &#39;A&#39; -&gt; &#39;A&#39;를 visited에 추가 &#39;A&#39;의 node는 [&#39;B&#39;, &#39;C&#39;, &#39;D&#39;] ## -&gt; &#39;B&#39;는 아직 방문 안했음 -&gt; 재귀함수 실행 -&gt; &#39;B&#39;를 start_node로 하여 visited에 추가 -&gt;&#39;B&#39;의 node는 [&#39;A&#39;, E&#39;, &#39;F&#39;] ## -&gt; &#39;A&#39;는 이미 방문했음 -&gt; pass ## -&gt; &#39;E&#39;는 아직 방문 안했음 -&gt; 재귀함수 실행 -&gt; &#39;E&#39;를 start_node로 하여 visited에 추가 -&gt; &#39;E&#39;의 node는 [&#39;B&#39;] ## -&gt; &#39;B&#39;는 이미 방문했음 -&gt; pass ## -&gt; &#39;B&#39;의 node로 &#39;A&#39;, &#39;E&#39; 방문 했고 이제 &#39;F&#39;만 남았음 ## -&gt; &#39;F&#39;는 아직 방문 안했음 -&gt; 재귀함수 실행 -&gt; &#39;F&#39;를 start_node로 하여 visited에 추가 -&gt; &#39;F&#39;의 node는 [&#39;B&#39;, &#39;I&#39;] ## -&gt; &#39;B&#39;는 이미 방문했음 -&gt; pass ## -&gt; &#39;I&#39;는 아직 방문 안했음 -&gt; 재귀함수 실행 -&gt; &#39;I&#39;를 start_node로 하여 visited에 추가 -&gt; &#39;I&#39;의 node는 [F] ## -&gt; &#39;F&#39;는 이미 방문했음 -&gt; pass ## -&gt; &#39;A&#39;의 node인 [&#39;B&#39;, &#39;C&#39;, &#39;D&#39;]중 &#39;B&#39;를 방문 끝냈으므로 &#39;B&#39;를 탐색했던 것처럼 나머지 &#39;C&#39;와 &#39;D&#39;도 탐색하면 끝임 return list(visited.keys()), count DFS_recursive(tree, &#39;A&#39;) . ([&#39;A&#39;, &#39;B&#39;, &#39;E&#39;, &#39;F&#39;, &#39;I&#39;, &#39;C&#39;, &#39;G&#39;, &#39;D&#39;, &#39;H&#39;, &#39;J&#39;], 10) . - 재귀함수를 사용하여 방문한 노드를 visited에 추가한다 . - return 결과를 보면 DFS 방식임을 알 수 있다 . - 노드가 10개이므로 10번 방문했다 (리스트 활용과 해시 테이블 활용 part에선 쓸데없이 19번 방문했다) . &#45320;&#48708; &#50864;&#49440; &#53456;&#49353;(Breadth First Search, BFS) . - 모든 정점을 한번만 방문 . - 시작 노드에서 인접한 다음 분기로 넘어가면서 탐색 . - 넘어갈 분기가 없으면 하위 노드를 탐색 . - 방문할 노드와 방문한 노드를 기준으로 탐색 . - 특정 노드가 방문할 노드 &gt; 탐색, 방문한 노드 &gt; 지나감 . - 그래프나 트리는 dictionary로 생성 . - queue 구조로 구현 가능 . BFS &#51109;&#51216; . - 출발노드에서 목표노드까지의 최단 길이 경로를 보장 . BFS &#45800;&#51216; . - 경로가 매우 길 경우에는 탐색 가지가 급격히 증가함에 따라 보다 많은 기억 공간을 필요 . - 해가 존재하지 않는다면 유한 그래프(finite graph)의 경우에는 모든 그래프를 탐색한 후에 실패로 끝남 . - 무한 그래프(infinite graph)의 경우에는 결코 해를 찾지도 못하고, 끝내지도 못함 . BFS 참고: 너비 우선 탐색 | . BFS &#53076;&#46300; &#44396;&#54788; . - tree 구조 . - queue 자료 구조 활용: 선입선출(양쪽 면이 뚫린 원통) . - 노드: [A], [B], [C], [D], [E], [F], [G], [H], [I], [J] . - 분기: [A, B, E], [A, B, F, I], [A, C, G], [A, D, H, I] . deque &#54876;&#50857; . - 성능이 좋음 &gt; $O(1)$ . - 사용: from collections import deque . - 만약 queue = list()라면 queue.pop(0)을 해야함 &gt; $O(N)$ . - deque를 사용하여 queue.pop(0)대신 queue.popleft() 사용 &gt; $O(1)$ . - DFS와 마찬가지로 visited는 해시 테이블로 구현 . - 방문 하기 전에 방문 처리를 해야 한다 . - 만약, 방문을 하고 나서 방문 처리를 하면 중복 방문을 하게 되므로 비효율적임 . def BFS_queue(graph, start_node): from collections import deque ## deque패키지 import queue = deque() ## 방문할 노드 queue.append(start_node) ## 방문할 노드에 시작 노드 추가 visited = {} ## 방문한 노드 visited[start_node] = True ## 시작 정점을 방문! count = 0 ## 방문 횟수 while queue: ## 방문할 노드가 있다면(리스트에 원소가 있으면 True) u = queue.popleft() ## 노드 u를 방문하자! count += 1 ## 방문 횟수 + 1 print(list(visited.keys())) ## 방문한 노드 for v in graph[u]: if v not in visited: ## 만약 아직 방문한 노드가 아니라면 visited[v] = True ## 이제 방문했으니까 방문한 노드에 추가 (방문 처리) queue.append(v) ## 방문한 노드에 연결된 노드를 탐색해보자 print(queue) ## 방문할 노드 (popleft 하기 전에 방문 체크를 미리해서 실질적으로 방문할 노드와 차이가 있음) print(&#39;-&#39;) ## 방문과정 확인 return list(visited.keys()), count ## 방문한 노드를 반환 BFS_queue(tree, &#39;A&#39;) . [&#39;A&#39;] deque([&#39;B&#39;, &#39;C&#39;, &#39;D&#39;]) - [&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;] deque([&#39;C&#39;, &#39;D&#39;, &#39;E&#39;, &#39;F&#39;]) - [&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;, &#39;E&#39;, &#39;F&#39;] deque([&#39;D&#39;, &#39;E&#39;, &#39;F&#39;, &#39;G&#39;]) - [&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;, &#39;E&#39;, &#39;F&#39;, &#39;G&#39;] deque([&#39;E&#39;, &#39;F&#39;, &#39;G&#39;, &#39;H&#39;]) - [&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;, &#39;E&#39;, &#39;F&#39;, &#39;G&#39;, &#39;H&#39;] deque([&#39;F&#39;, &#39;G&#39;, &#39;H&#39;]) - [&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;, &#39;E&#39;, &#39;F&#39;, &#39;G&#39;, &#39;H&#39;] deque([&#39;G&#39;, &#39;H&#39;, &#39;I&#39;]) - [&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;, &#39;E&#39;, &#39;F&#39;, &#39;G&#39;, &#39;H&#39;, &#39;I&#39;] deque([&#39;H&#39;, &#39;I&#39;]) - [&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;, &#39;E&#39;, &#39;F&#39;, &#39;G&#39;, &#39;H&#39;, &#39;I&#39;] deque([&#39;I&#39;, &#39;J&#39;]) - [&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;, &#39;E&#39;, &#39;F&#39;, &#39;G&#39;, &#39;H&#39;, &#39;I&#39;, &#39;J&#39;] deque([&#39;J&#39;]) - [&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;, &#39;E&#39;, &#39;F&#39;, &#39;G&#39;, &#39;H&#39;, &#39;I&#39;, &#39;J&#39;] deque([]) - . ([&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;, &#39;E&#39;, &#39;F&#39;, &#39;G&#39;, &#39;H&#39;, &#39;I&#39;, &#39;J&#39;], 10) . - return 결과를 보면 BFS 방식임을 알 수 있다 . - popleft 하기 전에 방문 체크를 미리해서 출력을 보면 방문한 노드와 방문할 노드에 중복으로 들어간 원소가 있음 . - 문제가 있는 것 같지만 BFS는 정확히 원소 개수인 10번만큼 방문했다! (한 번에 하니씩 popleft 하기 때문에 시간 상에 차이가 있어서 그런 것) .",
            "url": "https://jaesu26.github.io/study-blog/algorithm/2021/07/09/DFS-BFS.html",
            "relUrl": "/algorithm/2021/07/09/DFS-BFS.html",
            "date": " • Jul 9, 2021"
        }
        
    
  
    
        ,"post44": {
            "title": "정렬 알고리즘",
            "content": "- 데이터를 오름차순으로 정렬해보자! . $O(N^2)$ &#51221;&#47148; . &#49440;&#53469; &#51221;&#47148; (Selection sort) . - 가장 작은 수를 첫 번째 인덱스로 선택 그 다음으로 작은 수를 두 번째 인덱스로 선택 . - 이런식으로 가장 큰 수까지 마지막 인덱스로 선택하면 정렬 끝 . &#49440;&#53469; &#51221;&#47148; &#50508;&#44256;&#47532;&#51608; . 1 크기가 $n$인 정렬되지 않은 리스트가 있다 . List = [5, 8, 7, 1, 2] . 2 첫 번째 인덱스와 나머지 $n - 1$개의 수를 비교하여 가장 작은 수와 위치를 바꾼다 . 3 5와 비교하여 1이 가장 작으므로 5와 1의 위치를 바꾼다 . List = [1, 8, 7, 5, 2] . 4 이제 두 번째 인덱스와 나머지$n - 2$개의 수를 비교하여 남은 수 중 가장 작은 수와 위치를 바꾼다 . 5 8과 비교하여 2가 가장 작으므로 8과 2의 위치를 바꾼다 . List = [1, 2, 7, 5, 8] . 6 이런 식으로 $n-1$번째 인덱스와 나머지 1개의 수를 비교하여 오름차순 정렬을 마친다 . List = [1, 2, 5, 7, 8] . &#49440;&#53469; &#51221;&#47148; &#50508;&#44256;&#47532;&#51608; &#53076;&#46300; &#44396;&#54788; . List = [5, 8, 7, 1, 2] n = len(List) for i in range(n - 1): min_idx = i for j in range(i + 1, n): if List[j] &lt; List[min_idx]: min_idx = j List[i], List[min_idx] = List[min_idx], List[i] print(List) . [1, 8, 7, 5, 2] [1, 2, 7, 5, 8] [1, 2, 5, 7, 8] [1, 2, 5, 7, 8] . &#48260;&#48660; &#51221;&#47148; (Bubble sort) . - 연속된 인덱스를 비교하여 더 큰 값을 오른쪽으로 보냄 . - 한 사이클을 돌면 가장 큰 값이 맨 뒤에 위치 . - 사이클마다 남은 수 중 가장 큰 값이 뒤에 위치함 . &#48260;&#48660; &#51221;&#47148; &#50508;&#44256;&#47532;&#51608; . 1 크기가 $n$인 정렬되지 않은 리스트가 있다 . List = [5, 8, 7, 1, 2] . 2 첫 번째 인덱스와 두 번째 인덱스를 비교하여 더 큰값을 오른쪽에 위치시킨다 . 3 5와 8을 비교하면 8이 더 크므로 8을 오른쪽을 보낸다 . List = [5, 8, 7, 1, 2] . 4 이제 두 번째 인덱스와 세 번째 인덱스를 비교한다 . 5 8과 7을 비교하면 8이 더 크므로 8을 오른쪽으로 보낸다 . List = [5, 7, 8, 1, 2] . 6 이런식으로 한 사이클을 돌면 8이 마지막에 위치한다 . List = [5, 7, 1, 2, 8] . 7 다시 사이클을 돌면 7이 8 왼쪽에 위치한다 . List = [5, 1, 2, 7, 8] . 8 이런식으로 $n - 1$ 번의 사이클을 돌면 자료가 오름차순으로 정렬된다 . List = [1, 2, 5, 7 ,8] . &#48260;&#48660; &#51221;&#47148; &#50508;&#44256;&#47532;&#51608; &#53076;&#46300; &#44396;&#54788; . List = [5, 8, 7, 1, 2] n = len(List) for i in range(n - 1, 0, -1): for j in range(i): if List[j + 1] &lt; List[j]: List[j + 1], List[j] = List[j], List[j + 1] print(List) . [5, 7, 1, 2, 8] [5, 1, 2, 7, 8] [1, 2, 5, 7, 8] [1, 2, 5, 7, 8] . &#49341;&#51077; &#51221;&#47148; (Insertion sort) . - 자료 배열의 모든 요소를 앞에서부터 차례대로 이미 정렬된 배열 부분과 비교함 . - 자신의 위치를 찾아 삽입함 . - 일반적으로 선택 정렬, 버블 정렬 보다 빠름 . &#49341;&#51077; &#51221;&#47148; &#50508;&#44256;&#47532;&#51608; . 1 크기가 $n$인 정렬되지 않은 리스트가 있다 . List = [5, 8, 7, 1, 2] . 2 두 번째 원소를 부분 리스트에서 적절한 위치에 삽입 . List = [5, 8, 7, 1, 2] . 3 5와 8을 비교하면 8이 더 크므로 8을 오른쪽을 보낸다 . List = [5, 8, 7, 1, 2] . 4 세 번째 원소를 부분 리스트에서 적절한 위치에 삽입 . 5 7과 8을 비교하면 8이 더 크고 5와 7을 비교하면 7이 더 크므로 5와 8사이에 위치한다 . List = [5, 7, 8, 1, 2] . 6 네 번째 원소를 부분 리스트에서 적절한 위치에 삽입 . 7 1이 부분 리스트 중 가장 작으므로 맨 앞에 삽입 . List = [1, 5, 7, 8, 2] . 8 마지막 원소를 부분 리스트에서 적절한 위치에 삽입 . 9 2는 부분 리스트 중 1 다음으로 작으므로 1 오른쪽에 삽입 . List = [1, 2, 5, 7, 8] . &#49341;&#51077; &#51221;&#47148; &#50508;&#44256;&#47532;&#51608; &#53076;&#46300; &#44396;&#54788; . List = [5, 8, 7, 1, 2] n = len(List) for i in range(1, n): j = i - 1 key = List[i] while List[j] &gt; key and j &gt;= 0: List[j + 1] = List[j] j = j - 1 List[j + 1] = key print(List) . [5, 8, 7, 1, 2] [5, 7, 8, 1, 2] [1, 5, 7, 8, 2] [1, 2, 5, 7, 8] . $O(N log N)$ &#51221;&#47148; . &#48337;&#54633; &#51221;&#47148; (Merge sort) . - 리스트 안에 있는 요소들을 왼쪽, 오른쪽 두 그룹으로 나눔 . - 각 그룹을 또 왼쪽, 오른쪽 두 그룹으로 나눔, 이를 요소가 1개 남을 때까지 반복함 . - 나누어진 두 개의 리스트를 병합함 . - 이를 정렬될 때까지 반복함 . &#48337;&#54633; &#51221;&#47148; &#50508;&#44256;&#47532;&#51608; . 1 크기가 $n$인 정렬되지 않은 리스트가 있다 . List = [5, 8, 7, 1, 2, 3, 9, 4] . 2 그룹을 두 그룹으로 나눈다 . [5, 8, 7, 1], [2, 3, 9, 4] . 3 각 그룹을 두 그룹으로 나눈다 . [5, 8], [7, 1], [2, 3], [9, 4] . 4 이를 요소가 1개 남을 때까지 반복한다 . [5], [8], [7], [1], [2], [3], [9], [4] . 5 이제 나눈 순서의 역순으로 두 그룹씩 오름차순으로 병합한다 . [5, 8], [1, 7], [2, 3], [4, 9] . 6 이를 정렬이 끝날 때까지 반복한다 . [1, 5, 7, 8], [2, 3, 4, 9] . List = [1, 2, 3, 4, 5, 7, 8, 9] . &#48337;&#54633; &#51221;&#47148; &#50508;&#44256;&#47532;&#51608; &#53076;&#46300; &#44396;&#54788; . - 위의 병합 정렬 알고리즘을 보면 두 그룹으로 나누고 병합하는 과정을 반복한다 . - 그렇기에 재귀 함수를 사용하여 구현했음 &gt; 리스트의 길이가 클 경우 많은 재귀 함수 호출이 이루어지기에 시간이 매우 오래걸림(내 생각) . - 먼저 left, right로 나눈 후 나눠진 left를 가지고 또 left, right로 나눈다 . - left를 나누는 것이 끝나면 이제서야 right를 가지고 left, right로 나눈다 . 이 코드는 아래 코드보다 느림 | . - list.pop(0)은 $O(N)$임 . List = [5, 8, 7, 1, 2, 3, 9, 4] def mergeSort(x): if len(x) &lt;= 1: return x mid = len(x) // 2 left = x[:mid] right = x[mid:] next_left = mergeSort(left) next_right = mergeSort(right) return merge(next_left, next_right) def merge(left, right): sorted_list = [] while left and right: if left[0] &lt; right[0]: sorted_list.append(left.pop(0)) else: sorted_list.append(right.pop(0)) while left: sorted_list.append(left.pop(0)) while right: sorted_list.append(right.pop(0)) return sorted_list mergeSort(List) . - 그래서 pop(0) 함수를 사용하지 않음 . - 아래의 코드가 이해가 잘 안될 수 있다 . - 그래서 어떻게 split하고 merge가 되는지 알아보기로 하자 . - 밑의 출력을 보니 처음으로 merge()에 대입된 left와 right는 [5]와 [8]임을 알 수 있다 . - 처음으로 넣은 값은 [5, 8, 7, 1, 2, 3, 9, 4]인데 신기하다 . - 자세히 살펴보자 . List = [5, 8, 7, 1, 2, 3, 9, 4] k = 0 def merge_sort(x): ## 나누기 n = len(x) if n &lt;= 1: return x mid = n // 2 left = x[:mid] ## mid를 기준으로 왼쪽 right = x[mid:] ## mid를 기준으로 오른쪽 next_left = merge_sort(left) ## 재귀적으로 나누기 next_right = merge_sort(right) ## 재귀적으로 나누기 global k k += 1 print(&#39;return 횟수 %s&#39; %k) return merge(next_left, next_right) def merge(left, right): ## 병합하기 i = 0 j = 0 sorted_list = list() print(left) print(right) while i &lt; len(left) and j &lt; len(right): ## left와 right중 더 작은 값 넣기 if left[i] &lt;= right[j]: sorted_list.append(left[i]) i += 1 else: sorted_list.append(right[j]) j += 1 ## left와 right 중 남은 값을 넣어주기 while i &lt; len(left): sorted_list.append(left[i]) i += 1 while j &lt; len(right): sorted_list.append(right[j]) j += 1 return sorted_list print(&#39; n정렬된 배열:&#39;, merge_sort(List)) . return 횟수 1 [5] [8] return 횟수 2 [7] [1] return 횟수 3 [5, 8] [1, 7] return 횟수 4 [2] [3] return 횟수 5 [9] [4] return 횟수 6 [2, 3] [4, 9] return 횟수 7 [1, 5, 7, 8] [2, 3, 4, 9] 정렬된 배열: [1, 2, 3, 4, 5, 7, 8, 9] . - 우선 mergeSort 함수에서 return은 총 7번 일어남을 알 수 있다 . - 각 상황에서 어떤일이 일어나는지 알아보자 . 1. 우리는 print(mergeSort(List))를 통해 mergeSort 함수에 List라는 input을 넣었다 . 2. mergeSort에는 [5, 8, 7, 1, 2, 3, 9, 4]이 대입됐다 . 3. left는 [5, 8, 7, 1], right는 [2, 3, 9, 4]이다 . 4. next_left는 mergeSort([5, 8, 7, 1]), next_right는 mergeSort([2, 3, 9, 4])이다 . 5. merge(next_left, next_right)값을 return한다 . 6. 근데 merge(next_left, next_right)를 return하려고 보니까 next_left, next_right 값을 알아야한다 . 7. 4번으로 돌아가서 보면 mergeSort([5, 8, 7, 1])와 mergeSort([2, 3, 9, 4])를 구해야 한다 &gt; 그럼 구하면 되지 . 8. mergeSort에 [5, 8, 7, 1]이 대입된다 . 9. 그러면 mergeSort([5, 8, 7, 1])는 merge(mergeSort([5, 8]), mergeSort([7, 1]))를 return한다 . 10. 근데 mergeSort([5, 8]), mergeSort([7, 1])값은 뭐지?? &gt; 이것도 구해야 한다 . 11. mergeSort([5, 8])을 구하면 next_left = [5], next_right = [8]이다 . 12. merge(next_left, next_right)는 merge([5], [8])이 되고 드디어 merge함수에 left와 right가 대입된다 &gt; 그래서 처음 left와 right로 출력된 값이 [5]와 [8]이었던 것: return1 . 13. merge([5], [8])은 [5,8]인 sorted_list를 return한다 &gt; mergeSort([5, 8])은 [5, 8]을 return한다 즉, mergeSort([5, 8]) = [5, 8] . 14. 이제 mergeSort([5, 8])를 구했으니 mergeSort([7, 1])값을 구할 차례이다 . 15. mergeSort([7, 1])은 merge([7], [1])이고 [1, 7]을 return한다 &gt; mergeSort([7, 1]) = [1, 7]: return2 . 16. 이제 8번을 보자. 8번은 merge([5, 8, 7, 1])이고 merge(mergeSort([5, 8]), mergeSort([7, 1]))를 return한다 . 17. 이때는 mergeSort([5, 8])와 mergeSort([7, 1])를 모르는 상태였지만 이제는 구해서 알고 있다 . 18. merge([5, 8], [1, 7])을 구해보면 sorted_list로 [1, 5, 7, 8]을 return한다: return3 . 19. 이제 mergeSort([2, 3, 9, 4])을 구할 차례이다. 이는 위에서 한 방식대로 따라하면 된다 . 20. 결과적으로 print(mergeSort(List))는 [1, 2, 3, 4, 5, 7, 8, 9]을 출력하게 된다 . - 메모리 아끼는 병합 정렬 참고: https://www.daleseo.com/sort-merge/ . &#53301; &#51221;&#47148; (Quick sort) . - 피벗을 하나 정하고 피벗을 기준으로 왼쪽에는 피벗보다 작거나 같은 원소가 오른쪽에는 피벗보다 큰 원소가 위치하도록 배열을 변경한다 . - 위에서 나눠진 왼쪽 배열과 오른쪽 배열에 대해서도 위의 연산을 재귀적으로 반복한다 . &#53301; &#51221;&#47148; &#50508;&#44256;&#47532;&#51608; . 1 크기가 $n$인 정렬되지 않은 리스트가 있다 . List = [5, 8, 7, 1, 3, 2, 9, 4] . 2 피벗을 하나 정한다 (마지막 원소를 피벗으로 정하겠다) . 3 피벗을 기준으로 왼쪽에는 피벗보다 작은 값만 오른쪽에는 피벗보다 큰 값만 있도록 배열을 변경한다 . [{1, 3, 2}, {4}, {8, 7, 9, 5}] ## { }는 이해를 돕기 위해 표시한 것 . 4 이를 왼쪽 배열과 오른쪽 배열에도 원소가 하나 남을 때까지 재귀적으로 반복한다 . [1, 2, 3, 4, 5, 7, 8, 9] . &#53301; &#51221;&#47148; &#50508;&#44256;&#47532;&#51608; &#53076;&#46300; &#44396;&#54788; . def partition(arr, left, right): ## left는 입력된 배열의 가장 왼쪽 인덱스. right는 가장 오른쪽 인덱스 pivot = arr[right] ## 피벗은 주어진 배열(arr[left:right+1], 끝 값 포함 X)에서 마지막 위치(right)의 원소이다 i = left - 1 ## 피벗보다 작은 값을 넣을 배열의 위치(인덱스) for j in range(left, right): ## 피벗을 제외한 배열의 인덱스(left~right-1) if arr[j] &lt;= pivot: ## 피벗보다 작거나 같은 경우 i += 1 ## 값을 하나 넣을 거니까 배열의 위치에 +1 arr[i], arr[j] = arr[j], arr[i] ## 피벗보다 작은 값을 i 인덱스의 값과 swap 한다(메모리 절약을 위해 새로운 list를 안 만듦 &gt; in-place algorithm) print(f&#39;현재 배열의 상태: {arr}&#39;) ## 배열이 정렬되는 과정을 확인하자 ## for문이 끝나면 입력된 배열이 다음과 같다 &gt; [pivot보다 작거나 같은 값, (p) pivot보다 큰 값, pivot] ## 이제 pivot을 (p) 위치에 있는 값과 swap 하면 된다 ## 여기서 (p)의 인덱스는 i + 1이다 arr[i + 1], arr[right] = arr[right], arr[i + 1] return i + 1 ## 피벗의 인덱스를 리턴한다 def quick_sort(arr, left, right): if left &lt; right: pivot_idx = partition(arr, left, right) ## 피벗을 기준으로 왼쪽에는 작거나 같은 값을 오른쪽에는 큰 값이 위치하도록 한다 quick_sort(arr, left, pivot_idx - 1) ## 다시 왼쪽 배열에 대해서 partition quick_sort(arr, pivot_idx + 1, right) ## 다시 오른쪽 배열에 대해서 partition . List = [5, 8, 7, 1, 3, 2, 9, 4] quick_sort(List, 0, len(List) - 1) print(f&#39;정렬된 배열: {List}&#39;) . 현재 배열의 상태: [1, 8, 7, 5, 3, 2, 9, 4] 현재 배열의 상태: [1, 3, 7, 5, 8, 2, 9, 4] 현재 배열의 상태: [1, 3, 2, 5, 8, 7, 9, 4] 현재 배열의 상태: [1, 3, 2, 4, 8, 7, 9, 5] 현재 배열의 상태: [1, 2, 3, 4, 5, 7, 9, 8] 정렬된 배열: [1, 2, 3, 4, 5, 7, 8, 9] . - 참고: in-place algorithm 이란? . - 주어진 배열 외에 사용하는 메모리 양을 나타내는 공간복잡도가 $O(1)$임을 의미한다 . - 위의 퀵 정렬을 응용하면 배열에서 $k$번째로 작은 값을 select하는 알고리즘을 만들 수 있다 . - Quickselect: https://en.wikipedia.org/wiki/Quickselect . $O(N)$ &#51221;&#47148; . &#44228;&#49688; &#51221;&#47148; . - 카운팅 정렬이라고도 한다 . - 양수만 가능, 값의 범위가 크면 안됨(메모리 크기를 넘기면 안됨) . - 수의 범위가 작다면(입력으로 주어지는 값들의 개수: 0 ~ 1이라고 수의 범위가 작은 것이 아님... 0 ~ 1사이의 수는 무한개이다) 카운팅 정렬을 통해 빠르게 정렬할 수 있음 . - 비교 정렬이 아님 &gt; 위의 코드들은 다른 요소값과 비교하는데 카운팅 정렬은 비교없이 데이터를 정렬함 . - 입력으로 주어지는 input의 개수는 큰데 주어지는 값의 개수가 적다면 메모리 관점에서 효율적이다 . - 예로 input이 최대1억개인데 값이 1 ~ 10까지라면 위에서 다룬 정렬은 1억크기의 배열이 필요하지만 카운팅 정렬에 경우는 크기가 10인 배열을 만들면 된다 . - 하지만, 최대 수를 기준으로 배열을 만든다(최대값이 100인 경우 크기가 100인 리스트 생성) . - 그렇기에 [0, 1, 1, 1, 100]인 리스트를 정렬한다고 보면 숫자는 3개 뿐이지만 최대값이 100이므로 크기가 100인 리스트를 만들어야 한다 &gt; 심한 메모리 낭비 . &#44228;&#49688; &#51221;&#47148; &#50508;&#44256;&#47532;&#51608; . 1 최대 값이 k인 크기가 $n$인 정렬되지 않은 리스트가 있다 . List = [5, 8, 7, 1, 1, 3, 9] . 2 k = 10 이라고 가정하자. [0] * (k+1) 리스트를 만든다 --&gt; 파이썬에서 인덱스는 0부터 시작하기 때문 . count = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] . 3 List 요소의 값을 x라 하면 count[x]의 값을 +1 해준다 . count = [0, 2, 0, 1, 0, 1, 0, 1, 1, 1, 0] . 4 count 리스트에서 자기(x) 앞에 몇개의 숫자가 있는지를 바탕으로 x의 위치를 결정하여 정렬한다. 예로 3의 경우 자기 앞에 숫자 2개가 있으므로 3번째이다 . List = [1, 1, 3, 5, 7, 8, 9] . &#44228;&#49688; &#51221;&#47148; &#50508;&#44256;&#47532;&#51608; &#53076;&#46300; &#44396;&#54788; . List = [5, 8, 7, 1, 1, 3, 9] def counting_sort(arr): count = [0] * (max(arr) + 1) sorted_list = [0] * len(arr) for i in arr: count[i] += 1 ## arr에 있는 수를 몇개인지 카운팅함 for j in range(1, max(arr) + 1): count[j] += count[j - 1] ## count[j] 앞에 몇 개의 숫자가 있는지 저장 ## count[5] = 10이라면 5가 x번 등장했다고 할 때 5앞에 10-x개의 숫자가 있다는 의미이므로 sorted_list[10-x : x]에 5가 위치한다. (x 번째 포함 no, x-1번째 까지) for k in range(len(arr)): sorted_list[count[arr[k]] - 1] = arr[k] ## 인덱스는 0부터 시작하므로 -1을 해줌 count[arr[k]] -= 1 return sorted_list print(counting_sort(List)) . [1, 1, 3, 5, 7, 8, 9] . &#49884;&#44036; &#48373;&#51105;&#46020; &#51221;&#47532; . Name $T_{ operatorname{comp}}(n)$ $T_{ operatorname{swap}}(n)$ Time(worst case) : $T(n)$ Space In-place(Extra) Stable Adaptive . Selection | $ Theta(n^2)$ | $ Theta(n)$ | $ Theta(n^2)$ | $ Theta(n)$ | Yes : $ Theta(1)$ | No | No | . Bubble | $ Theta(n^2)$ | $ Theta(n^2)$ | $ Theta(n^2)$ | $ Theta(n)$ | Yes : $ Theta(1)$ | Yes | No | . Bubble+ | $ Theta(n^2)$ | $ Theta(n^2)$ | $ Theta(n^2)$ | $ Theta(n)$ | Yes : $ Theta(1)$ | Yes | Yes | . Insertion | $ Theta(n^2)$ | $ Theta(n^2)$ | $ Theta(n^2)$ | $ Theta(n)$ | Yes : $ Theta(1)$ | Yes | Yes | . Merge | $ Theta(n log n)$ | $ Theta(n log n)$ | $ Theta(n log n)$ | $ Theta(n)$ | No : $ Theta(n)$ | Yes | No | . Quick | $ Theta(n^2)$ | $ Theta(n^2)$ | $ Theta(n^2)$ | $ Theta(n)$ | Yes : $ Theta( log n)$ | No | No | . Heap | $ Theta(n log n)$ | $ Theta(n log n)$ | $ Theta(n log n)$ | $ Theta(n)$ | Yes : $ Theta(1)$ | No | No | . Counting | No comparison | No swap | $ Theta(n+k)$ | $ Theta(n+k)$ | No : $ Theta(n+k)$ | Yes | No | . Radix | No comparison | No swap | $ Theta(w(n+k))$ | $ Theta(n+k)$ | No : $ Theta(n+k)$ | Yes | No | . &#51116;&#44480; &#54632;&#49688; &#49884;&#44036;&#48373;&#51105;&#46020; &#45803;&#55180; &#54644; . - 시간복잡도의 형태가 재귀 함수꼴로 되어 있어 해를 구할 줄 알아야 된다(ex: 병합 정렬) . - 아래는 이를 구하는 방법들이다 . &#48152;&#48373; &#45824;&#52824; (Repeated Substitution) . - $T(n)=T(n-1)+C$ 라고 하자 . - $T(n) = T(n-1)+C = (T(n-2)+C) + C = cdots = T(1) + (n-1)C$ . - 그러므로 $T(n)=O(n)$ . &#49688;&#54617;&#51201; &#44480;&#45225;&#48277; (Mathematical induction) . - $T(n) leq 2T left( dfrac{n}{2}+10 right)+n$ 라고 하자 . - $T(n) leq cn log n$ 이라고 추정한다(어떤 함수로 추정할지 잘 생각해야 됨) $ to$ $T(n)=O(n log n)$ . - $T(i) leq ci log i , ;n_0 leq i&lt; k$ 라고 가정한다 . - 이제 $T(k) leq ck log k$ 일 때도 성립하는지 증명한다 . $$ begin{aligned} T(k) &amp; leq 2T left( dfrac{k}{2}+10 right)+k [10pt] &amp; leq 2c left( dfrac{k}{2}+10 right) log left( dfrac{k}{2}+10 right)+k [10pt] &amp;=ck log left( dfrac{k}{2}+10 right) + 20c log left( dfrac{k}{2}+10 right)+k [10pt] &amp; leq ck log dfrac{2k}{3} + 20c log dfrac{2k}{3}+k [10pt] &amp;=ck log k +c( log 2 - log 3)k + 20c log dfrac{2k}{3}+k , , (1) [10pt] &amp; leq ck log k , , (2) end{aligned}$$ - 위에 $(1)$번 식에서 $(2)$번 식으로 어떻게 전개되는지 간단히 설명 . - 일단 $ text{(1)번 식} leq text{(2)번 식}$ 이라는 것은 $c( log 3 - log 2)k geq 20c log dfrac{2k}{3}+k $을 뜻한다 . - $c( log 3 - log 2)k geq 20c log dfrac{2k}{3}$ $ to$ $k$를 매우 크게 하면 된다($k$를 무한히 크게 하면 무한히 큰 차이가 생김) . - $c( log 3 - log 2)k geq k$ $ to$ $c$를 매우 크게 하면 된다($c$를 무한히 크게 하면 무한히 큰 차이가 생김) . 결론 | . - $ dfrac{k}{2}+10 leq k, , dfrac{k}{2}+10 leq dfrac{2k}{3}$을 만족하면서 충분히 큰 $k$와 충분히 큰 $c$를 고르면 $ text{(1)번 식} leq text{(2)번 식}$ 이 성립한다 . &#47560;&#49828;&#53552; &#51221;&#47532; (Master theorem) . - $T(n)=aT left( dfrac{n}{b} right)+f(n)$ 일 때 적용 가능하다 . - $a geq 1, ,b&gt; 1$이며 $f(n)$은 다항식 형태 . - $h(n)=n^{ log_b a}$ $ to$ $n=1$인 sub-problems 개수 . - case 1) $ lim limits_{n to infty} dfrac{f(n)}{h(n)}=0 Longrightarrow T(n)= Theta left(h(n) right)$ . - case 2) $ lim limits_{n to infty} dfrac{f(n)}{h(n)}= infty$ and $af left( dfrac{n}{b} right) &lt; f(n) Longrightarrow T(n)= Theta left(f(n) right)$ . - case 3) $ lim limits_{n to infty} dfrac{f(n)}{h(n)}= Theta(1) Longrightarrow T(n)= Theta left(h(n) log_2 n right)$ . - exception $ dfrac{f(n)}{h(n)}= Theta left( log^k n right) Longrightarrow T(n)= Theta left(h(n) log^{k+1} n right)$ . 변수를 치환해서 마스터 정리를 적합시키기 | . - $T(n)=2T left( sqrt{n} right)+ log_2 n$ . - 위의 식에는 마스터 정리를 적용시키지 못한다($ sqrt{n}=n^{0.5}$과 $f(n)= log_2 n$이 문제임, $n^1$ 이고 $f(n)$은 다항식이어야 한다) . - $m = log_2 n Longleftrightarrow 2^m=n$ . - $T(2^m)=2T left(2^{0.5m} right)+m$ . - $P(m) = T(2^m)$ 이라고 하자 . - $P(m)=2P left( dfrac{1}{2}m right)+m$ $ to$ 마스터 정리를 적용시킬 수 있다! . - 마스터 정리를 적용시키면 $P(m)= Theta(m log m)$이 되고 $m$을 다시 $ log_2 n$로 치환시키면 아래와 같다 . - $T(n)= Theta left( log n log( log n) right)$ .",
            "url": "https://jaesu26.github.io/study-blog/algorithm/2021/07/04/%EC%A0%95%EB%A0%AC-%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98.html",
            "relUrl": "/algorithm/2021/07/04/%EC%A0%95%EB%A0%AC-%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98.html",
            "date": " • Jul 4, 2021"
        }
        
    
  
    
        ,"post45": {
            "title": "확률 분포",
            "content": "- 2학기에 수리통계학 배움 . - 내용 추가 + 확률 밀도 함수 유도 과정 추가 + 증명 안하고 넘어갔던 부분 추가 예정 . - 만약 수리통계학에 없는 내용이라면? . . . . . . . &#54869;&#47456; &#48516;&#54252;&#46976;? . - 확률 분포(probability distribution)는 확률 변수가 특정한 값을 가질 확률을 나타내는 함수를 의미한다 &gt; 참고: 확률 분포 . &#54869;&#47456; &#48320;&#49688;&#46976;? . - 확률변수(Random Variable)란 무작위 실험을 했을 때 특정 확률로 발생하는 각각의 결과를 수치로 맵핑하는 함수 . - 무작위 실험 &gt; 동전 던지기 . - 특정 확률 &gt; 앞면이 나올 확률 $ dfrac{1}{2}$, 뒷면이 나올 확률 $ dfrac{1}{2}$ . - 각각의 결과 &gt; 앞면(H)과 뒷면(T) . - 수치로 맵핑 &gt; 앞면(H) : $1$, 뒷면(T) : $2$ . &#50672;&#49549; &#54869;&#47456; &#48516;&#54252; . - 연속 확률 변수가 가지는 확률 분포 . - 이산 확률 변수는 확률을 $P(X=x)$와 같이 표현 가능, 연속 확률 변수는 이런 표현이 무의미 (어차피 $0$) . - 연속 확률 변수는 확률을 $P(A leq X leq B)$로 표현 가능 . &#51221;&#44508; &#48516;&#54252; . - 정규 분포는 수집된 자료의 분포를 근사하는 데에 자주 사용됨 . - 중심극한정리에 의하여 독립적인 확률변수들의 평균은 정규 분포에 가까워지는 성질이 있기 때문임 . - 신뢰구간이나 가설검정 등의 모델에서 사용 . - 어떤 확률 변수 $X$가 정규분포를 따를 때 기호로 $X sim N( mu, sigma^{2})$과 같이 표기 . - 정규 분포의 기댓값, 중앙값, 최빈값은 $ mu$, 분산은 $ sigma^{2}$ . - 표준정규분포는 평균이 $0$, 표준편차가 $1$인 경우임 &gt; $N(0, 1)$ . - 정규 분포에서 $( mu-2 sigma, mu+2 sigma)$에 전체 데이터 중 $95 %$가 존재 . &#54364;&#51456;&#54868; . - 정규 분포 밀도 함수에서 $Z = cfrac{X - mu}{ sigma}$ 를 통해 $X$(원점수)를 $Z$($z$점수) 표준화하여 표준정규분포(z-분포)를 얻을 수 있다 . &#51221;&#44508; &#48516;&#54252;&#51032; &#54869;&#47456; &#48128;&#46020; &#54632;&#49688;(PDF) . $f(x) = dfrac{1}{ sqrt{2 pi sigma^{2}}}e^{- dfrac{(x- mu)^{2}}{2 sigma^{2}}}$ . &#51221;&#44508; &#48516;&#54252; plot . import numpy as np np.random.normal(loc, scale, size) . - loc는 평균, scale은 표준편차, size는 표본의 수 . np.random.normal(loc=0, scale=1, size=1000) . - np.random.normal(loc=0, scale=1, size=1000)을 히스토그램으로 나타내면? . import matplotlib.pyplot as plt import numpy as np np.random.seed(1) sample = np.random.normal(loc=0, scale=1, size=1000) plt.hist(sample, bins=30) plt.title(&quot;np.random.normal(loc=0, scale=1, size=1000)&quot;) plt.show() . &#44512;&#51068; &#48516;&#54252; . - 모든 확률 변수에 대하여 구간 내에서 균일한 확률을 가짐 . - 임의의 구간 내에서 균일한 확률을 가지기에 난수 생성기로 쓰임 . - 이산 확률 변수에서도 가능 . &#44512;&#51068; &#48516;&#54252;&#51032; &#54869;&#47456; &#48128;&#46020; &#54632;&#49688; . $f(x) = begin{cases} cfrac{1}{b-a} &amp; text{for $x in [a,b]$} 0 &amp; text{otherwise} end{cases} $ . - $f(x)$는 구간 $[a,b]$에서 균등한 확률을 가짐 . &#44512;&#51068; &#48516;&#54252;&#51032; &#44592;&#45843;&#44050;&#44284; &#48516;&#49328; . - $E(X) = cfrac{a+b}{2}$ . - $Var(X) = cfrac{(b-a)^{2}}{12}$ . &#44512;&#51068; &#48516;&#54252; plot . import numpy as np np.random.uniform(low, high, size) . - low는 출력값의 최소 경계, high은 출력값의 최대 경계, size는 표본의 수 . np.random.uniform(low=0, high=1, size=1000) . - np.random.uniform(low=0, high=1, size=1000)을 히스토그램으로 나타내면? . import numpy as np import matplotlib.pyplot as plt np.random.seed(1) sample = np.random.uniform(low=0, high=1, size=1000) plt.hist(sample, bins=30) plt.title(&quot;np.random.normal(loc=0, scale=1, size=1000)&quot;) plt.show() . &#50672;&#49549;&#54805; &#54869;&#47456;&#48320;&#49688;&#51032; cdf&#45716; $U(0, 1)$&#51012; &#46384;&#47480;&#45796; . 증명 | . $U=F(x)=P(X leq x) F_{U}(u)=P(U leq u)=P(F(X) leq u)=P(X leq F^{-1}(u))=F(F^{-1}(u))=u f_{U}(u)=1, ;0&lt;u&lt;1 therefore F(X) sim U(0,1)$ . - 역함수가 없는 경우는... 몰라 . - 정규분포를 예로 들자 . - 정규분포에서 샘플을 뽑고 샘플을 누적분포함수에 input하자 . - 그러면 output이 나오고 이를 가지고 확률밀도함수를 그리면 $U(0, 1)$이 된다 . - 일단 연속형 확률변수의 cdf 값은 $0$과 $1$ 사이에 있다 . - 정규분포에서 $x$를 뽑았는데 $0$이 나왔다고 하자 . - 이에 대한 누적분포함수값은 $0.5$이다 . - 이를 반복하면 누적분포함수값이 많이 나올것이다 . - 이를 가지고 확률밀도함수를 그리면 $U(0, 1)$이라는 것이다 . - 즉 누적분포함수값이 $0$과 $1$사이인데 나올 가능성이 모두 같다는 것이다(?) . - 근데 하나의 누적분포함수값에는 하나의 $x$가 대응되는것 아닌가? . - 누적분포함수값이 $0.5$라면 그에 대한 $x$값은 $0$이다 . - $0$과 $1$ 사이의 값을 가지는 누적분포함수값이 나올 가능성이 모두 같다면 $x$도 뽑힐 가능성이 같다(?) . - 히스토그램을 그려보면 $x$값이 $0$근처에 몰려있고 $3$이 넘어가면 거의 없는데 뭐가 같지??? . - 하지만 이는 잘못됐는데 일단 실수는 무한히 많기에 정규분포에서 특정값이 나올 확률은 $0$이다 . - 그러니 특정값에 대한 확률은 같다 . - 그렇기에 범위로 비교하는것이 올바르다 . - 그러면 $x$값이 $0$과 $1$사이에서 나올 확률이랑 $1$과 $2$사이에서 나올 확률이 같음? . - no 다름 . - ??? 위에서 누적분포함수값이 나올 가능성이 모두 같다면 $x$도 뽑힐 가능성이 같다고 했잖음... . - 동일한 누적분포함수값의 범위에 대해서는 같다 . - 일단 하나의 실수를 뽑았다고 치자 &gt; $x$는 $0$이 나왔고 이에 대한 cdf값은 $0.5$임 . - cdf값은 $0$부터 $1$사이에 존재하고 $0$부터 $1$사이의 실수는 무한개이기에 cdf값이 $0.5$일 확률은 $0$이다 . - 또한 $x$가 $3$ 이 나왔다고 치고 이에대한 cdf값은 대충 $0.99$라 치자 &gt; 이 역시 확률은 $0$이다 . - 그럼 범위로 따지면? . - 누적분포함수값이 $0$부터 $0.5$사이일 확률과 $0.5$부터 $1$사이일 확률은 서로 동일하다 . - 바꿔말하자면 확률밀도함수 아래의 면적으로 따졌을 때 $- infty$부터 $0$사이 면적과 $0$부터 $ infty$사이 면적은 동일하다 . - 즉 정규분포에서 표본을 뽑았을 때 $x$값이 $- infty$부터 $0$사이일 확률과 $0$부터 $ infty$사이일 확률은 같다 . - 확률밀도함수에 확률은 $y$값이 아니라 면적이다 . - $x$값이 $0$과 $1$사이에서 나올 확률이랑 $1$과 $2$사이에서 나올 확률은 다른데 그래프 아래의 면적이 다르다 . - 그렇기에 당연히 누적분포함수값의 범위도 다르다 . - 정규분포에서 cdf값이 $0.1$과 $0.3$사이일 확률과 $0.5$와 $0.7$사이일 확률은 같음 . - 이는 정규분포에서 $x$값을 뽑았을 때 $-1.28 sim -0.52$일 확률과 $0 sim 0.52$일 확률이 같다는 의미 . - 즉 $X$를 정규분포에서 생성하고 $X$에 정규분포 cdf를 취하면 이것은 $U(0,1)$을 따른다는 소리 . - 직접 구현하여 맞는지 확인해보자 . import numpy as np import matplotlib.pyplot as plt from scipy.stats import norm # 연속형 확률변수는 정규분포로 하자 . np.random.seed(2021) x = np.random.normal(loc=0, scale=1, size=10000) ## 표준정규분포 plt.hist(x, bins=30) plt.title(&quot;Standard Normal Distribution&quot;, fontsize=20) plt.show() . - $x$는 정규분포에서 뽑은 거니까 이를 가지고 히스토그램을 그리면 당연히 정규분포이다 . - $x$축은 정규확률변수가 가질 수 있는 값, $y$축은 빈도수 . - 히스토그램의 면적을 $1$로 만들면 $y$축은 $f(x)$(정규분포의 pdf)가 된다 . - $f(x) = dfrac{1}{ sqrt{2 pi sigma^{2}}}e^{- dfrac{(x- mu)^{2}}{2 sigma^{2}}}$ . - ex) $f(0) = 0.3989422804014327$ . - 정규확률변수가 가질 수 있는 값($x$)의 $99 %$는 $ mu pm 2 sigma$안에 있고 $ mu$에 가까울 수 록 뽑힐 가능성이 높다 . norm.pdf(0) . 0.3989422804014327 . F_x = norm.cdf(x) plt.hist(F_x) plt.show() . - $x$축은 $F(X)$, $y$축은 빈도수, $X$는 정규분포를 따름 . - 정말 $U(0, 1)$를 따른다 . - 즉 연속형 확률분포(예컨대 정규분포) $f(x)$에서 $x$를 뽑고 이를 동일한 연속형 확률분포의 cdf $F(x)$에 input하여 나온 값으로 히스토그램을 그리면 위와 같이 $U(0,1)$ 된다 . 뭔가 한번에 와닿지 않는 이유(내 기준) | . - 위에 있는 정규분포 히스토그램을 보면 좁은 구간($-1$에서 $1$)에 데이터가 몰려있다 . - 그래서 이를 가지고 cdf를 그리면 마찬가지로 cdf도 특정 구간에 값이 몰려있을 것 같은 생각이 든다 . - 하지만 그렇지 않은데 아래처럼 생각하면 편하다 . - 예컨대 물감통($-1 sim 1$과 $-3 sim -1$)에 동일한 양의 물감이 있음 . - 좁고 깊은 물감통에 붓을 푹 담근다((좁은 구간: $-1 sim 1$)에 값이 많이 몰림) &gt; 많이 묻힌 만큼 넓은 범위에 칠한다 . - 넓고 얕은 물감통에 북을 찍는다((넓은 구간: $-3 sim -1$)에 값이 조금 몰림) &gt; 조금 묻힌 만큼 좁은 범위에 칠한다 . - 그렇기에 전체적으로 보면 비슷한 수준으로 칠해져있다(균일 분포를 따른다) . - 그럼 특정 연속형 확률분포에서 $x$를 뽑지 않고 그냥 균일분포에서 뽑으면? . X = np.random.uniform(low=-3, high=3, size=10000) plt.hist(norm.cdf(X)) plt.show() . - 균일분포를 따르지 않는다... . - 위와 다른 그림이 나온 이유 $ longrightarrow$ $-1 sim 1$에는 예상보다 적은 데이터가 있고 $-3 sim -1$에는 예상보다 많은 데이터가 있음 . - 그런데 문득 궁금한점이 있다 . x = np.random.normal(loc=0, scale=1, size=10000) . - 위의 코드를 사용하여 정규분포에서 랜덤표본을 뽑았다 . - 그런데 랜덤표본은 어떻게 뽑지?(난수 생성기: https://en.wikipedia.org/wiki/Random_number_generation) . - $x$의 pdf를 아는것과 $x$에 대한 샘플링이 가능한것은 다른 문제 . - 예컨대 정규분포에서 특정$x$가 뽑힐 확률은 $0$인데 어떻게 뽑을거? . - $U(0,1)$은 생성할 수 있다고 했을 때 랜덤표본을 추출하는 방법을 알아보자 . - 위에서 $F(x) = U$라고 했다 &gt; 연속형 확률변수의 cdf는 균일분포를 따른다 . - 그런데 이를 바꿔 말하자면 $x = F^{-1}(U)$ . - 즉 임의의 확률변수에서 $x$를 뽑는것은 $x$의 cdf의 역함수에 $U(0,1)$에서 뽑은 난수를 input하여 구하는것과 동일하다는 것 . - 즉 $x$의 cdf의 역함수를 알고 균일분포에서 랜덤표본을 뽑을 수 있으면 임의의 확률변수에서 $x$를 뽑는것과 같은 효과를 얻을 수 있다는 것 . - 이를 역변환기법(Inverse CDF Method)이라고 한다 . - 단점은 cdf의 역함수를 알아야 한다는 것.... . from scipy.stats import uniform n = 10000 U = uniform.rvs(size=n) X1 = norm.ppf(U) X2 = norm.rvs(size=n) fig, (ax1, ax2) = plt.subplots(1, 2) ax1.hist(X1, bins=30) ax2.hist(X2, bins=30) plt.show() . - 정말 둘 다 표준정규분포이다! . &#52852;&#51060;&#51228;&#44273; &#48516;&#54252;($ chi^2$&#48516;&#54252;) . - $k$개의 서로 독립인 표준 정규 확률변수를 각각 제곱하여 합해 얻어진 분포 . - 이때 $k$는 자유도이며 카이제곱 분포의 매개변수 . - 분산의 퍼진 정도를 분포로 보여줌 . - 모분산을 구하거나 적합도 검정, 독립성/동질성 검정 등의 모델에서 사용 . - $k$개의 독립적이고 표준정규분포를 따르는 확률변수 $Z_1, dots,Z_k$가 있을 때 자유도 $k$의 카이제곱 분포는 . - 확률변수 $Q = sum limits^{k}_{i=1}Z{_i}{^2}$의 분포임 . - 따라서 $Q sim chi{^2}(k)$ . - 참고: 카이제곱 분포 . &#52852;&#51060;&#51228;&#44273; &#48516;&#54252;&#51032; &#54869;&#47456; &#48128;&#46020; &#54632;&#49688; . $f(x; k) = dfrac{1}{2^ frac{k}{2} Gamma big( frac{k}{2} big)}x^{ frac{k}{2}-1}e^{- frac{x}{2}}$ . - $ Gamma big( frac{k}{2} big)$는 감마함수이다 . &#52852;&#51060;&#51228;&#44273; &#48516;&#54252;&#51032; &#44592;&#45843;&#44050;&#44284; &#48516;&#49328; . - $E(X) = k$ . - $Var(X) = 2k$ . &#52852;&#51060;&#51228;&#44273; &#48516;&#54252; plot . import numpy as np np.random.chisquare(df, size) . - df는 자유도, size는 표본의 수 . np.random.chisquare(df=10, size=1000) . - np.random.chisquare(df=10, size=1000)를 히스토그램으로 나타내면? . import numpy as np import matplotlib.pyplot as plt np.random.seed(1) sample = np.random.chisquare(df=10, size=1000) plt.hist(sample, bins=30) plt.title(&quot;np.random.chisquare(df=10, size=1000)&quot;) plt.show() . - 자유도(df)를 바꿔볼까? . - df = 5 . np.random.seed(1) sample = np.random.chisquare(df=5, size=1000) plt.hist(sample, bins=30) plt.title(&quot;np.random.chisquare(df=5 , size=1000)&quot;) plt.show() . - df = 1 . - 표준정규분포의 제곱은 자유도가 1인 카이제곱 분포를 따름 . - $V = bigg( dfrac{X- mu}{ sigma} bigg)^{2} sim chi^{2}(1)$ . - 표본을 10000개 뽑아 둘을 비교해보자! . np.random.seed(2) sample = np.random.chisquare(df=1, size=10000) plt.hist(sample, bins=30) plt.title(&quot;np.random.chisquare(df=1 , size=10000)&quot;) plt.show() . np.random.seed(2) sample = np.random.normal(loc=0, scale=1, size=10000) sample = sample**2 plt.hist(sample, bins=30) plt.title(&quot;square of a standard normal distribution&quot;) plt.show() . - 두 분포가 거의 동일하다 . - 표준정규분포의 제곱은 자유도가 1인 카이제곱 분포를 따른다는 것을 확인할 수 있다 . &#51648;&#49688; &#48516;&#54252; . - 사건이 서로 독립적일 때, 일정 시간동안 발생하는 사건의 횟수가 포아송 분포를 따른다면, 다음 사건이 일어날 때까지 대기 시간은 지수분포를 따른다(지수 분포) . - 기하 분포에서 베르누이 시행 횟수$n$이 많아지고 성공 확률 $p$가 작아지면 지수 분포로 수렴 . - 감마 분포에서 $ alpha = 1$일 때의 특수한 경우임(감마 분포 참고) . &#51648;&#49688; &#48516;&#54252;&#51032; &#47924;&#44592;&#50613;&#49457; . - 기하 분포의 무기억성과 같은 내용임 . - $P(A mid B)$ &gt; 사건 B가 발생한 상황에서 사건 A가 발생할 확률 . - $P(X&gt;s+t mid X&gt;t) = P(X&gt;s)$ . - 핸드폰의 고장률이 지수 분포를 따른다면 내가 핸드폰을 처음 구매하고 1년안에 고장날 확률 = 핸드폰을 5년 사용한 시점에서 1년 안에 고장날 확률 . - 물론 현실은 핸드폰을 5년 사용한 후에 고장날 확률이 더 크다 . &#51648;&#49688; &#48516;&#54252;&#51032; &#54869;&#47456; &#48128;&#46020; &#54632;&#49688; . $f(x; beta) = frac{1}{ beta}e^{- frac{x}{ beta}}, ; x &gt; 0$ . - 위의 확률 밀도 함수는 감마 분포의 확률 밀도 함수에서 $ alpha = 1$을 대입한 결과이다 . - 여기서 $ beta$는 사건 사이의 평균 시간인데 포아송 분포의 모수인 $ lambda$는 단위 시간당 사건의 평균 발생 횟수이다 . - 위의 지수 분포 설명에서 사건의 횟수가 포아송 분포를 따를 때를 전제로 대기 시간은 지수 분포를 따른다고 했다 . - 그렇기에 여기서는 위의 확률 밀도 함수 대신 포아송 분포의 모수인 $ lambda = frac{1}{ beta}$ 를 통해 지수 분포의 확률 밀도 함수를 나타내기로 함 . - 위아래 확률 밀도 함수 둘 다 맞는 표현임, 그런데 numpy.random.exponential이 위의 확률 밀도 함수를 사용하므로 위의 확률 밀도 함수를 기억하는 것이 좋을 것 같음 . $f(x; lambda) = lambda e^{- lambda x}, ; x&gt;0$ . &#51648;&#49688; &#48516;&#54252;&#51032; &#44592;&#45843;&#44050;&#44284; &#48516;&#49328; . - $E(X) = cfrac{1}{ lambda}$ . - $Var(X) = cfrac{1}{ lambda^{2}}$ . - 기댓값은 어찌보면 당연한데 단위 시간 동안 사건이 $ lambda$번 발생한다면 대기 시간은 $ cfrac{1}{ lambda}$여야 $ lambda times cfrac{1}{ lambda} = 1$(단위 시간)이 성립한다 . &#51648;&#49688; &#48516;&#54252; plot . - 사건이 발생하고 다음 사건이 발생하기 까지의 대기 시간에 대한 확률 분포 . - numpy.random.exponential의 확률 밀도 함수는 $f(x; beta) = frac{1}{ beta}e^{- frac{x}{ beta}}, ; x &gt; 0$임 (numpy 지수 함수) . import numpy as np np.random.exponential(scale, size) . - scale은 $ beta$ = 대기 시간, size는 표본의 수 . np.random.exponential(scale=2, size=1000) . - 우리 집 앞에서 1시간당 평균 0.5명이 넘어진다 &gt; $ lambda$(사건의 빈도) $= 0.5$ 이므로 대기 시간 $ beta$(대기 시간) $= 2$ . - 다시말하면 우리 집 앞에서 한 명이 넘어지고 다음 사람이 넘어지기 까지 2시간이 걸린다 . - 이때 한 사람이 넘어지고 다음 사람이 넘어지기 까지 걸리는 대기 시간에 대한 분포를 그려보자 . - np.random.exponential(scale=2, size=1000)를 히스토그램으로 나타내보면? . import numpy as np import matplotlib.pyplot as plt np.random.seed(1) sample = np.random.exponential(scale=2, size=1000) plt.hist(sample, bins=30) plt.title(&quot;np.random.exponential(scale=2, size=1000)&quot;) plt.show() . &#44048;&#47560; &#48516;&#54252; . - 감마 분포는 지수 분포나 푸아송 분포 등의 매개변수에 대한 켤레 사전 확률 분포 . - 이에 따라 베이즈 확률론에서 사전 확률 분포로 사용 . - $ alpha$개의 사건이 일어날 때까지 걸리는 대기 시간에 대한 분포 . - 지수 분포를 한 번의 사건이 아닌 여러 개의 사건으로 확장 . - 지수 분포의 모수가 $ beta$ &gt; $ beta$ = 사건 사이의 평균 시간 . - 모수가 $ beta$인 지수 분포를 따르는 확률 변수 X가 $ alpha$개가 있고 각 확률 변수 X는 i.i.d를 따름 &gt; 이 확률 변수의 합은 모수가 $ alpha, beta$인 감마 분포를 따름 . - 참고: 감마 분포 . &#44048;&#47560;&#54632;&#49688;(Gamma Function) . - 복소수 범위까지 일반화 된 팩토리얼(!) . $ Gamma( alpha) = int_{0}^{ infty}x^{ alpha-1}e^{-x}dx, , alpha geq 0$ . &#44048;&#47560;&#54632;&#49688; &#49457;&#51656; . - $ Gamma( alpha+1) = alpha Gamma( alpha)$ . - $ Gamma(n) = (n-1)!, , n in mathbb{N}$ . - $ Gamma big( frac{1}{2} big) = sqrt{ pi}$ . &#44048;&#47560; &#48516;&#54252;&#51032; &#54869;&#47456; &#48128;&#46020; &#54632;&#49688; . $f(x; alpha, beta) = cfrac{1}{ beta^{ alpha} Gamma( alpha)}x^{ alpha - 1}e^{- frac{x}{ beta}},(x, alpha, beta geq 0)$ . - 확률 변수 $X$가 감마 분포를 따른 다면 $X sim Gamma( alpha, beta)$ . - 발생하기 까지의 평균$ beta = cfrac{1}{ lambda}$의 시간이 소요되는 어떤 사건이 $ alpha$번 발생하는데 걸리는 시간 $X$에 대한 확률 분포 . - $ lambda$는 포아송 분포의 모수로 단위 시간당 사건의 평균 발생 횟수 . - $ alpha = 1$일 때 $ lambda = cfrac{1}{ beta}$인 지수 분포를 따름 . - $X sim Gamma(1, beta) Longleftrightarrow exp big( frac{1}{ beta} big)$ . &#44048;&#47560; &#48516;&#54252;&#51032; &#44592;&#45843;&#44050;&#44284; &#48516;&#49328; . - $E(X) = alpha beta$ . - $Var(X) = alpha beta^{2}$ . &#44048;&#47560; &#48516;&#54252; plot . - $ alpha$는 형태 모수(shape parameter), $ beta$는 척도 모수(scale parameter) . - 사건이 발생하고 다음 사건이 발생하기 까지의 평균 대기 시간이 $ beta$일 때 $ alpha$번의 사건이 발생하는데 걸리는 시간에 대한 확률 분포 . import numpy as np np.random.gamma(shape, scale, size) . - shape는 $ alpha$, scale은$ beta$, size는 표본의 수 . np.random.gamma(shape=2, scale=2, size=1000) . - 우리 집 앞에서 1시간당 평균 0.5명이 넘어진다 &gt; $ lambda = 0.5$이므로 $ beta = 2$ . - 다시말하면 우리 집 앞에서 한 명이 넘어지고 다음 사람이 넘어지기 까지 평균 2시간이 걸린다 . - 이때 2명의 사람이 넘어지기 까지 걸리는 시간에 대한 분포를 그려보자 . - np.random.gamma(shape=2, scale=2, size=1000)를 히스토그램으로 나타내보면? . import numpy as np import matplotlib.pyplot as plt np.random.seed(1) sample = np.random.gamma(shape=2, scale=2, size=1000) plt.hist(sample, bins=30) plt.title(&quot;np.random.gamma(shape=2, scale=2, size=1000)&quot;) plt.show() . - 위에서 지수 분포는 감마 분포에서 $ alpha = 1$인 특수한 경우라고 했음 . - 진짜로 동일한지 $ beta = 4$인 지수 분포와 $ alpha = 1, beta = 4$인 감마 분포를 히스토그램을 그려 비교하자 . np.random.seed(1) sample1 = np.random.gamma(shape=1, scale=4, size=1000) sample2 = np.random.exponential(scale=4, size=1000) fig, ax = plt.subplots(1, 2, figsize = (14, 4)) ax[0].hist(sample1, bins=30) ax[1].hist(sample2, bins=30) ax[0].set_title(&quot;np.random.gamma(shape=2, scale=4, size=1000)&quot;) ax[1].set_title(&quot;np.random.exponential(scale=4, size=1000)&quot;) plt.show() . - 히스토그램을 통해 비교하니 $ alpha = 1$인 감마 분포는 지수 분포와 동일함을 알 수 있다 . $ alpha$&#50752;$ beta$&#50640; &#46384;&#47480; &#44048;&#47560; &#48516;&#54252; &#47784;&#50577; . - $ alpha$는 형태 모수로 $ alpha$가 커질수록 그래프의 모양이 종모양에 가까워짐 . - $ beta$는 척도 모수로 $ beta$가 커질수록 그래프가 퍼짐 . - shape는 $ alpha$, scale은 $ beta$, loc은 위치 매개변수 . - scipy.stats.gamma 참고 . $ alpha$ &#48320;&#54868; $ beta$ &#44256;&#51221; . - $ alpha$(사건 발생 횟수)가 커질수록 그래프가 종모양에 가까워짐 . import numpy as np import matplotlib.pyplot as plt from scipy.stats import gamma loc = 0 scale = 0.5 x = np.linspace(0, 12, 1000) plt.figure(figsize = (14, 7)) for shape in np.arange(2, 11, 2): plt.plot(x, gamma(shape, loc, scale).pdf(x), label = &quot;α = &quot; + str(shape)) plt.title(&quot;Gamma distribution(α = 2, 4, 6, 8, 10, β = 0.5)&quot;) plt.xlabel(&quot;$x$&quot;) plt.ylabel(&quot;$f(x)$&quot;) plt.grid() plt.legend() plt.show() . $ alpha$ &#44256;&#51221; $ beta$ &#48320;&#54868; . - $ beta$(대기 시간)가 커질수록 그래프가 넓게 퍼짐 . loc = 0 shape = 3 x = np.linspace(0, 16, 1000) plt.figure(figsize = (14, 7)) for scale in np.arange(0.4, 2.1, 0.4): plt.plot(x, gamma(shape, loc, scale).pdf(x), label = &quot;β = &quot; + str(round(scale, 1))) plt.title(&quot;Gamma distribution(α = 3, β = 0.4, 0.8, 1.2, 1.6, 2.0)&quot;) plt.xlabel(&quot;$x$&quot;) plt.ylabel(&quot;$f(x)$&quot;) plt.grid() plt.legend() plt.show() . t &#48516;&#54252; . - 표본평균$ bar{X}$을 이용해 정규분포의 평균을 해석 &gt; 모집단이 정규분포를 따를 때 . - 표준화한 표본평균의 분포: 모표준편차를 알고 있음$ bigg( frac{x- mu}{ sqrt{ frac{ sigma}{n}}} bigg)$ --&gt; 정규분포, 모표준편차를 모르고 표본표준편차를 알고 있음$ bigg( frac{x- bar{x}}{ sqrt{ frac{s}{n}}} bigg)$ &gt; t분포 . - 다음의 확률 분포로 정의 &gt; $ cfrac{Z}{ sqrt{ frac{V}{ nu}}}$ . - $Z$는 표준정규분포, $V$는 자유도$ nu$인 카이제곱 분포 . - 자유도가 커질수록 t분포는 표준정규분포에 가까워짐 (중심극한정리와 무관) &gt; 보통 표본 크기 $n geq30$이면 표준정규분포와 가깝다고 한다 . - [$ star$]표본크기가 커지면 표준정규분포에 가까워짐[$ star$] &gt; 표본 크기가 커진다는 것은 모집단에 가까워진다는 의미이므로 표본표준편차도 모표준편차에 가까워짐 . - t 분포의 적률생성함수는 정의되지 않음 . - 참고: t분포 . t &#48516;&#54252;&#51032; &#54869;&#47456; &#48128;&#46020; &#54632;&#49688; . $f(x) = cfrac{ Gamma big( frac{ nu + 1}{2} big)}{ sqrt{ nu pi} Gamma big( frac{ nu}{2} big)} big(1+ frac{x^2}{ nu} big)^{- big( frac{ nu+1}{2} big)}$ . t &#48516;&#54252;&#51032; &#44592;&#45843;&#44050;&#44284; &#48516;&#49328; . - $E(X) = 0, ; nu &gt; 1$ . - $Var(X) = cfrac{ nu}{ nu-2} ,( nu&gt;2), ; infty ,(1&lt;v leq2)$ . t &#48516;&#54252; plot . import numpy as np np.random.standard_t(df, size) . - df는 자유도, size는 표본의 수 . np.random.standard_t(df=5, size=1000) . - np.random.standard_t(df=5, size=1000)를 히스토그램으로 나타내보면? . import numpy as np import matplotlib.pyplot as plt np.random.seed(1) sample = np.random.standard_t(df=5, size=1000) plt.hist(sample, bins=30) plt.title(&quot;np.random.standard_t(df=5, size=1000)&quot;) plt.show() . - $x = 0$을 기준으로 대칭임 . - 자유도가 5이므로 표본 크기는 6 . - 모표준편차 대신 표본표준편차를 알고 표본 크기가 6일 때 표준화한 표본 평균$ bigg( frac{x- bar{x}}{ sqrt{ frac{s}{n}}} bigg)$에 대한 분포 . - t분포는 표준정규분포보다 꼬리 부근에 밀도가 높음 &gt; 모표준편차 대신 표본표준편차를 사용하기 때문 &gt; 표본의 특성상 추출할 때마다 다르므로 변동성이 있음 . t&#48516;&#54252;&#50752; &#54364;&#51456;&#51221;&#44508;&#48516;&#54252; &#48708;&#44368; . import numpy as np import scipy as sp import scipy.stats import matplotlib.pyplot as plt . x = np.linspace(-5, 5, 100) rv_norm = sp.stats.norm(loc=0, scale=1) rv_t10 = sp.stats.t(df=10) rv_t5 = sp.stats.t(df=5) rv_t1 = sp.stats.t(df=1) norm_pdf = rv_norm.pdf(x) t10_pdf = rv_t10.pdf(x) t5_pdf = rv_t5.pdf(x) t1_pdf = rv_t1.pdf(x) legend = [&quot;z-dist&quot;, &quot;t(df=1)&quot;, &quot;t(df=5)&quot;, &quot;t(df=10)&quot;] plt.figure(figsize = (10, 6)) plt.plot(x, norm_pdf) plt.plot(x, t1_pdf) plt.plot(x, t5_pdf) plt.plot(x, t10_pdf) plt.title(&quot;z-dist, t-dist(df=1, 5, 10)&quot;) plt.xlabel(&quot;$x$&quot;) plt.ylabel(&quot;$p(x)$&quot;) plt.grid() plt.legend(legend) plt.show() . - 위에서 말한대로 t분포가 표준정규분포보다 꼬리가 두껍다 . - 하지만 자유도가 커지면 표준정규분포와 비슷해진다 . F &#48516;&#54252; . - F 검정과 분산분석(ANOVA)등에서 주로 사용됨 . - 카이제곱 분포가 한 집단의 분산에 대해 다뤘다면 F 분포는 두 집단의 분산에 대해 다룸 . - 두 확률변수 $V_1, V_2$가 각각 자유도가 $ nu_1, nu_2$이고 서로 독립인 카이제곱 분포를 따를 때 다음의 확률변수 F는 자유도가 ($ nu_1, nu_2$)인 F-분포를 따름 . - 적률생성함수가 존재하지 않음 . - $F = cfrac{ frac{V_1}{ nu_1}}{ frac{V_2}{ nu_2}} sim F( nu_1, nu_2)$ . - 참고: F 분포 . F &#48516;&#54252; &#49457;&#51656; . - 분자와 분모의 자유도가 뒤바뀐 F 분포 성질: $F_{ nu_1, nu_2, alpha} = cfrac{1}{F_{ nu_2, nu_1, alpha}}$ . - t 분포를 제곱하면 분자와 분모의 자유도가 각각 1, $ nu$인 F분포가 된다 . - $t = cfrac{Z}{ sqrt{ frac{U}{ nu}}} sim t_{ nu}$ . F &#48516;&#54252;&#51032; &#54869;&#47456; &#48128;&#46020; &#54632;&#49688; . $f(x) = cfrac{ Gamma big( frac{ nu_1+ nu_2}{2} big) big( frac{ nu_1}{ nu_2} big)^{ frac{ nu_1}{2}}x^{ frac{ nu_1}{2}-1}}{ Gamma big( frac{ nu_1}{2} big) Gamma big( frac{ nu_2}{2} big) big(1+ frac{ nu_1}{ nu_2}x big)^{ frac{ nu_1+ nu_2}{2}}}$ . F &#48516;&#54252;&#51032; &#44592;&#45843;&#44050;&#44284; &#48516;&#49328; . - $E(X)= cfrac{ nu_2}{ nu_2-2}, ; nu_2&gt;2$ . - $Var(X)= cfrac{2{ nu_{2}}^{2}( nu_1+ nu_2-2)}{ nu_1( nu_2-2)^{2}( nu_2-4)}, ; nu_2&gt;4$ . F &#48516;&#54252; plot . import numpy as np np.random.f(dfnum, dfden, size) . - dfnum은 분자의 자유도, dfden은 분모의 자유도, size는 표본의 수 . np.random.f(dfnum=1, dfden=10, size=1000) . - np.random.f(dfnum=1, dfden=5, size=1000)를 히스토그램으로 나타내보면? . import numpy as np import matplotlib.pyplot as plt np.random.seed(1) sample = np.random.f(dfnum=1, dfden=10, size=1000) plt.hist(sample, bins=30) plt.title(&quot;np.random.f(dfnum=1, dfden=10, size=1000)&quot;) plt.show() . &#48288;&#53440; &#48516;&#54252; . - 제한된 범위$[0, 1]$에서 확률적인 모델링에 적합함(ex: 비율) . - 두개의 매개변수 $ alpha, beta$에 따라 그래프의 모양이 다양함 . - 베타 분포는 확률에 대한 확률분포 &gt; 베이즈안 통계학에서 이항 분포의 켤레 사전 분포로 사용됨 . - 베이지안 방법 &gt; 모수를 확률변수로 생각하여 사전 정보를 활용해 모수를 추정함 . - 이항 분포에서는 성공 확률 $p$가 고정이고 성공 횟수($n-x=$ 실패횟수)가 확률변수인데 베타 분포에서는 성공 횟수($ alpha-1$)와 실패 횟수($ beta-1$)이 고정이고 성공 확률이 확률변수임 . - 베타 분포에서 $ alpha =1, beta=1$이면 균일분포와 동일함 &gt; $ alpha=1, beta=1$이면 성공 횟수와 실패 횟수 둘다$0$이므로 성공확률을 특정할 수 없어서 균일분포 모양을 띄움 . - 참고: 베타 분포 . &#48288;&#53440; &#54632;&#49688; . - 베타 분포의 확률 밀도 함수의 적분값을 1로 만드는 상수 . - 이항 계수를 실수범위까지 확장한 것 . $B( alpha, beta)= int_{0}^{1}x^{ alpha -1}(1-x)^{ beta - 1}dx = cfrac{ Gamma( alpha) Gamma( beta)}{ Gamma( alpha + beta)}$ . &#48288;&#53440; &#48516;&#54252;&#51032; &#54869;&#47456; &#48128;&#46020; &#54632;&#49688; . $f(x)= cfrac{1}{B( alpha, beta)}x^{ alpha-1}(1-x)^{ beta-1}, quad 0 leq x leq1, ;( alpha , beta&gt;0)$ . &#48288;&#53440; &#48516;&#54252;&#51032; &#44592;&#45843;&#44050;&#44284; &#48516;&#49328; . - $E(X)= cfrac{ alpha}{ alpha + beta}$ . - $Var(X)= cfrac{ alpha beta}{( alpha+ beta)^{2}( alpha+ beta+1)}$ . - $ underset{x}{ mathrm{argmax}} , f(x)= cfrac{ alpha-1}{ alpha + beta - 2}, ; ( alpha, beta &gt; 1)$ . - 최빈값은 성공횟수($ alpha-1$)와 실패횟수($ beta-1$)에 대한 성공률(= 성공횟수($ alpha-1$) / 성공횟수($ alpha-1$) + 실패횟수($ beta-1$)) . &#48288;&#53440; &#48516;&#54252;&#50752; &#51060;&#54637; &#48516;&#54252; . - 베타 분포는 확률에 대한 확률분포라고 했음 . - 예시를 들어서 설명하자 . - 게임을 하는 중임 &gt; 동전이 있는데 앞면이 나오면 이김 &gt; 그런데 앞면과 뒷면이 나올 확률을 알지 못함 . - 연습으로 동전을 10번 던져봤더니 앞면이 3번 뒷면이 7번 나왔음 &gt; 앞면이 나와야 이기므로 앞면이 나올 확률이 뒷면이 나올 확률 보다 높으면 좋겠음 . - 위에 상황에서 앞면이 나올 확률이 0.5보다 클 확률은 얼마일까? &gt; 확률에 대한 확률분포 . $$ begin{aligned}P(X&gt;0.5) &amp;= 1-P(X&lt;0.5) [10pt] &amp;=1- int_{0}^{0.5} cfrac{ Gamma(12)}{ Gamma(4) Gamma(8)}x^{4-1}(1-x)^{8-1}dx [10pt] &amp;=1- int_{0}^{0.5} binom{12}{4}x^{4-1}(1-x)^{8-1}dx [12pt] &amp;= ,??? end{aligned}$$ - 적분하기가 힘들다 . - R의 pbeta() 함수로 구해보자 . import rpy2 import os os.environ[&quot;R_HOME&quot;] = &quot;C:/anaconda3/envs/py38r40/lib/R&quot; %load_ext rpy2.ipython . C: anaconda3 envs py38r40 lib site-packages rpy2 robjects packages.py:366: UserWarning: The symbol &#39;quartz&#39; is not in this R namespace/package. warnings.warn( . %%R 1 - pbeta(0.5, shape1=4, shape2=8) . [1] 0.1132812 . - 앞면이 3번 뒷면이 7번 나왔을 때 앞면이 나올 확률이 0.5보다 클 확률은 0.1132812이다 &gt; 약 11% . - 아무래도 게임에서 이기기는 힘들어 보인다 . - 그런데 위의 식에서 3번째 줄을 보면 이항 분포가 보인다 . - 성공확률의 거듭제곱과 실패확률의 거듭제곱은 이항분포의 확률 질량 함수에서도 존재함 . - 베타 분포에서는 확률변수 $X$가 성공 확률인 반면 이항 분포에서는 확률변수 $X$가 성공 횟수임 . - 베타 분포: $ cfrac{1}{B( alpha, beta)}x^{ alpha-1}(1-x)^{ beta-1}, ;$ $x$는 성공 확률 . - 이항 분포: $ binom{n}{x} ,p^{k} ,(1-p)^{n-x}, ;$ $x$는 성공 횟수 . - 이렇기에 이항 분포의 모수를 추정하는데 베타 분포가 사전 분포로 사용된다 . &#48288;&#53440; &#48516;&#54252; plot . - scipy.stats.beta()를 통해 다양한 베타 분포를 그려보자 . import numpy as np import matplotlib.pyplot as plt from scipy.stats import beta x = np.linspace(0, 1, 1000) beta_pdf1 = beta(a=0.5, b=0.5).pdf(x) beta_pdf2 = beta(a=5, b=1).pdf(x) beta_pdf3 = beta(a=1, b=3).pdf(x) beta_pdf4 = beta(a=2, b=2).pdf(x) beta_pdf5 = beta(a=2, b=5).pdf(x) plt.figure(figsize = (7, 5)) plt.plot(x, beta_pdf1, label = &quot;α = 0.5, β = 0.5&quot;) plt.plot(x, beta_pdf2, label = &quot;α = 5, β = 1&quot;) plt.plot(x, beta_pdf3, label = &quot;α = 1, β = 3&quot;) plt.plot(x, beta_pdf4, label = &quot;α = 2, β = 2&quot;) plt.plot(x, beta_pdf5, label = &quot;α = 2, β = 5&quot;) plt.xlabel(&quot;rate of success(x)&quot;) plt.ylabel(&quot;Beta pdf&quot;) plt.title(&quot;Beta distribution&quot;) plt.grid() plt.legend() plt.show() . - $x$축은 성공확률이어서 0과 1사이임 . - $y$축 자체가 확률이 아니라 $ int_{a}^{b}f(x)dx$가 확률이고 $y$축은 $f(x)$임 . - $ alpha = 1, beta geq 1$이면 성공횟수는 0인데 실패횟수는 존재하므로 성공확률 $x$가 낮을 수록 함수값이 큼 . - $ alpha geq 1, beta = 1$이면 성공횟수는 존재하는데 실패횟수는 0이므로 성공확률 $x$가 높을 수록 함수값이 큼 . - $ alpha &gt; 1, beta &gt; 1$이면 기댓값 부근에서 함수값이 크다 + $ alpha+ beta$가 커지고 $ alpha$와 $ beta$가 비슷하면 정규분포에 근사 가능 . - $ alpha &lt; 1, beta &lt; 1$이면 $x$가 0 과 1에 극단적으로 치우침 . &#51060;&#49328; &#54869;&#47456; &#48516;&#54252; . - 이산 확률 변수가 가지는 확률 분포 . &#48288;&#47476;&#45572;&#51060; &#48516;&#54252; . - 성공 확률이 $p$인 베르누이 시행 결과가 성공이면 $1$, 실패면 $0$의 값을 가지는 확률변수의 분포 . &#48288;&#47476;&#45572;&#51060; &#49884;&#54665; . - 임의의 결과가 성공 또는 실패와 같이 가능한 결과가 2 가지 . &#48288;&#47476;&#45572;&#51060; &#49884;&#54665; &#51312;&#44148; . - 각 시행의 결과는 상호 배타적인 두 사건(성공 or 실패)으로 구분 . - 성공 확률 $p$, 실패 확률 $q$일 때, $p+q=1$ . - 각 시행은 독립적 . &#48288;&#47476;&#45572;&#51060; &#48516;&#54252;&#51032; &#54869;&#47456; &#51656;&#47049; &#54632;&#49688;(PMF) . $f(x)=p^x(1-p)^{1-x}, quad x=0,1$ . &#48288;&#47476;&#45572;&#51060; &#48516;&#54252;&#51032; &#44592;&#45843;&#44050;&#44284; &#48516;&#49328; . - $E(X) = p$ . - $Var(X) = p(1-p)$ . &#51060;&#54637; &#48516;&#54252; . - 서로 독립이고 동일한 베르누이 분포를 따르는 확률변수$X_1, dots,X_n$을 모두 합한 것 &gt; $X = sum limits_{i=1}^{n}X_i$ . - 성공 확률이 $p$인 베르누이 시행을 독립적으로 $n$번 반복했을 때 성공 횟수 $X$는 이항 분포를 따름 . - 기호로는 $X sim B(n,p)$ . - 독립적 시행 &gt; 각 시행은 서로 영향을 주지 않음 . &#51060;&#54637; &#48516;&#54252;&#51032; &#54869;&#47456; &#51656;&#47049; &#54632;&#49688; . $f(x) ,= , _{n} rm C_{x} ,p^{x} ,(1-p)^{n-x} ,= , binom{n}{x} ,p^{k} ,(1-p)^{n-x}$ . - 성공 확률 $p$인 베르누이 시행을 $n$번 시행하여 그 중 $x$번을 성공할 확률 질량 함수 . - 베르누이 분포는 이항 분포에서 $n=1$일 때이다 . &#51060;&#54637;&#48516;&#54252;&#51032; &#44592;&#45843;&#44050;&#44284; &#48516;&#49328; . - $E(X) = np$ . - $Var(X) = np(1-p)$ . &#51060;&#54637; &#48516;&#54252; plot . import numpy as np np.random.binomial(n, p, size) . - $n$은 표본 크기, $p$는 성공 확률, size는 표본의 수 . np.random.binomial(n=50, p=0.5, size=1000) . - 성공 확률이 p = 0.5인 베르누이 시행을 n = 50번 반복하는 것을 표본 하나로 두고 표본을 size = 1000번 추출한다 . - 동전 던지기($p=0.5$)를 $n$ = $50$번 시행하여 앞면이 나온 횟수($X=0,1,2, dots,49,50$)를 하나의 표본이라 할 때 표본을 $size = 1000$번 추출한다 . - np.random.binomial(n=10, p=0.5, size=1000)을 히스토그램으로 나타내면? . - $np geq 5$ 이면 이항분포를 정규분포로 근사할 수 있다 . import numpy as np import matplotlib.pyplot as plt np.random.seed(1) sample = np.random.binomial(n=10, p=0.5, size=1000) plt.hist(sample) plt.title(&quot;np.random.binomial(n=10, p=0.5, size=1000)&quot;) plt.show() . &#54252;&#50500;&#49569; &#48516;&#54252; . - 단위 시간, 단위 공간 안에 어떤 사건이 몇 번 발생할 것인지를 표현하는 이산 확률 분포 . - 이항 분포에서 시행횟수$n$이 매우 크고 성공 확률$p$가 매우 작은 경우 성공횟수는 포아송 분포로 근사 가능 &gt; 나중에 증명 . - 음이항 분포에서 성공횟수$x$가 매우 크고 실패 확률$p$가 매우 작은 경우 실패횟수는 포아송 분포로 근사 가능 &gt; 나중에 증명 . - 포아송 분포의 모수($ lambda$)는 단위 시간에서 사건의 평균 발생 횟수 . &#54252;&#50500;&#49569; &#48516;&#54252; &#51204;&#51228; &#51312;&#44148; . - 독립성: 1시간 동안 우리 집 앞에서 넘어진 사람 수와 친구 집앞에서 넘어진 사람 수는 독립이다 . - 일정성: 1시간 동안 평균 3명이 넘어졌다면 2시간 동안에는 평균 6명이 넘어진다 . - 비집락성: 우리 집 앞에서 같은 시간에 두 명 이상이 넘어질 확률은 0이다 . &#54252;&#50500;&#49569; &#48516;&#54252;&#51032; &#54869;&#47456; &#51656;&#47049; &#54632;&#49688; . $f(x) = cfrac{e^{- lambda} lambda^{x}}{x!}$ . - $x$는 단위 시간에서 사건의 발생 횟수, $ lambda$는 단위 시간에서 사건의 평균 발생 횟수 . - $ lambda = 10$, $x = 7$ &gt; 단위 시간에서 사건의 평균 10번 발생할 때 7번 발생할 확률은? . - 우리 집 앞에서 1시간에 사람이 평균적으로 10명이 넘어진다고 한다. 이 때 1시간에 사람이 5명 넘어질 확률은? . - $ lambda = 10, , x = 5 longrightarrow f(5) = cfrac{e^{-10} ,10^5}{5!} = 0.03783327480207071$ . &#54252;&#50500;&#49569; &#48516;&#54252;&#51032; &#44592;&#45843;&#44050;&#44284; &#48516;&#49328; . - $E(X) = lambda$ . - $Var(X) = lambda$ . - 평균과 분산이 같으므로 평균이 클수록 그래프가 더 넓게 퍼진다 . &#54252;&#50500;&#49569; &#48516;&#54252; plot . import numpy np.random.poisson(lam, size) . - $ lambda$는 모수, size는 표본의 수 . np.random.poisson(lam=10, size=1000) . - 단위 시간에서 사건이 평균 10번 발생할 때 (lam = 10) 단위 시간에서 사건이 몇 번 발생하는지를 하나의 표본이라 할 때 size = 1000번 표본을 추출한다 . - 우리 집 앞에서 1시간당 평균 10명이 넘어질 때($ lambda=10$) 1시간당 몇 명 넘어지는지($x = 0,1,2, dots,10,11, dots$)를 $size = 1000$번 기록한다 . - np.random.poisson(lam=10, size=1000)을 히스토그램으로 나타내면? . import numpy as np import matplotlib.pyplot as plt np.random.seed(1) sample = np.random.poisson(lam=10, size=1000) plt.hist(sample, bins=24) plt.title(&quot;np.random.poisson(lam=10, size=1000)&quot;) plt.show() . - $ lambda$를 바꿔볼까? &gt; 우리 집 앞에서 1시간당 평균 4명이 넘어진다면?? . np.random.seed(1) sample = np.random.poisson(lam=4, size=1000) plt.hist(sample) plt.title(&quot;np.random.poisson(lam=4, size=1000)&quot;) plt.show() . &#44592;&#54616; &#48516;&#54252; . - 어떤 확률변수 $X$가 성공 확률이 $p$인 베르누이 시행에서 처음 성공까지 시도한 횟수라고 할 때 $X$는 성공 확률 $p$인 기하분포를 따른다 . - 처음 성공할 때까지 걸린 시도 횟수 X가 확률 변수이다 . &#44592;&#54616; &#48516;&#54252;&#51032; &#47924;&#44592;&#50613;&#49457; . - $P(X=x+k mid X&gt;k)=P(X=x)$ . - 성공 확률 p인 베르누이 시행을 현재 k번 시도 했다 . - 하지만 아직 까지 성공하지 못했다 . - 내가 여태까지 k번 실패했으니까 성공확률이 올라갈까?? &gt; 답은 No . - 내가 이제껏 시도한 횟수와 관계없이 성공할 확률은 p로 동일하다 . - 쉽게 말하자면 내가 순백의 주문서10%를 바르고 있는 중이다 . - 여태까지 50장을 발랐는데도 성공하지 못했다 . - 하지만 확률은 그대로 10%이고 기댓값도 10번으로 동일하다 . - 즉, 처음에 순백의 주문서를 성공시키기 위한 기대되는 시도 횟수는 10번이다 . - 50번을 실패했지만 여전히 순백의 주문서를 성공시키기 위한 기대되는 시도 횟수는 10번이다...... . &#44592;&#54616; &#48516;&#54252;&#51032; &#54869;&#47456; &#51656;&#47049; &#54632;&#49688; . $f(x) = (1-p)^{x-1}p, ; x = 1, 2, 3, dots$ . - 성공 확률이 $p$일 때 $x-1$번 째 시도까지는 모두 실패하고 $x$번 째 시도에 성공할 확률 질량 함수 . &#44592;&#54616; &#48516;&#54252;&#51032; &#44592;&#45843;&#44050;&#44284; &#48516;&#49328; . - $E(X) = cfrac{1}{p}$ . - $Var(X) = cfrac{1-p}{p^2}$ . &#44592;&#54616; &#48516;&#54252; plot . import numpy np.random.geometric(p, size) . - $p$는 베르누이 시행에서 성공 확률, size는 표본의 수 . np.random.geometric(p=0.1, size=1000) . - 성공 확률이 p = 0.1인 베르누이 시행을 성공할 때까지 시도하는 것을 size = 1000번 반복한다 . - 순백의 주문서($p=0.1$)를 성공할 때까지 시도하여 순백의 주문서가 적용될 때까지 걸린 시도 횟수($X=1,2, dots$)를 $size = 1000$번 기록한다 . - np.random.geometric(p=0.1, size=1000)을 히스토그램으로 나타내면? . import numpy as np import matplotlib.pyplot as plt np.random.seed(1) sample = np.random.geometric(p=0.1, size=1000) plt.hist(sample, bins=30) plt.title(&quot;np.random.geometric(p=0.1, size=1000)&quot;) plt.show() . &#51020;&#51060;&#54637; &#48516;&#54252; . - 확률변수 $X$를 성공 확률이 $p$인 베르누이 시행을 반복하여 $k$번째 성공이 나올 때 까지 시행횟수라 하면 확률변수 $X$는 음이항 분포를 따름 . - 기하분포는 $k=1$인 음이항 분포 . &#51020;&#51060;&#54637; &#48516;&#54252;&#51032; &#54869;&#47456; &#51656;&#47049; &#54632;&#49688; . $f(x) ,= , _{x-1} rm C_{k-1} ,p^{k} ,(1-p)^{x-k} ,= , binom{x-1}{k-1} ,p^{k} ,(1-p)^{x-k}$ . - $x-1$번째 시도까지 성공횟수 $k-1$번였다가 $x$번째 시도에서 성공하여 성공횟수는 $k$가 되었음 . &#51020;&#51060;&#54637; &#48516;&#54252;&#51032; &#44592;&#45843;&#44050;&#44284; &#48516;&#49328; . - $E(X) = cfrac{k}{p}$ . - $Var(X) = cfrac{k(1-p)}{p^2}$ . &#51020;&#51060;&#54637; &#48516;&#54252; plot . import numpy np.random.negative_binomial(n, p, size) . - $n$은 성공횟수, $p$는 베르누이 시행에서 성공 확률, size는 표본의 수 . np.random.negative_binomial(n=5, p=0.1, size=1000) . - 성공 확률이 p = 0.1인 베르누이 시행을 5번 성공할 때까지 시도하는 것을 size = 1000번 반복한다 . - 순백의 주문서($p=0.1$)를 5번 성공할 때까지 시도하여 순백의 주문서가 5번 적용될 때까지 걸린 시도 횟수($X=5,6, dots$)를 $size = 1000$번 기록한다 . - np.random.negative_binomial(n=5, p=0.1, size=1000)을 히스토그램으로 나타내면? . import numpy as np import matplotlib.pyplot as plt np.random.seed(1) sample = np.random.negative_binomial(n=5, p=0.1, size=1000) plt.hist(sample, bins=30) plt.title(&quot;np.random.negative_binomial(n=5, p=0.1, size=1000)&quot;) plt.show() . - 위에서 기하 분포는 음이항 분포에서 $k = 1$인 특수한 경우라고 했음 . - 진짜로 동일한지 $p = 0.4$인 기하 분포와 $p = 0.4, k = 1$인 음이항 분포를 히스토그램을 그려 비교하자 . np.random.seed(1) sample1 = np.random.geometric(p=0.4, size=1000) sample2 = np.random.negative_binomial(n = 1, p=0.4, size=1000) fig, ax = plt.subplots(1, 2, figsize = (14, 4)) ax[0].hist(sample1, bins=12) ax[1].hist(sample2, bins=12) ax[0].set_title(&quot;np.random.geomaric(p=0.3, size=1000)&quot;) ax[1].set_title(&quot;np.random.negative_binomial(n=1, p=0.3, size=1000)&quot;) plt.show() . - 히스토그램을 통해 비교하니 $k= 1$인 음이항 분포는 기하 분포와 동일함을 알 수 있다 . &#52488;&#44592;&#54616; &#48516;&#54252; . - $k$개의 성공과 $N-k$개의 실패로 이루어진 크기가 $N$인 유한모집단에서 크기가 $n$인 표본을 뽑고 이 중 성공의 개수를 $X$라 할 때 확률변수$X$는 초기하 분포를 따름 . - $N, k to infty$이고 $ cfrac{k}{N} to p$이면 초기하 분포를 이항 분포로 근사 가능 . - 비복원추출을 하기에 각각의 시행이 서로 영향을 미치므로 독립적 시행이 아님 &gt; 베르누이 시행과의 차이점 . - 샘플링 검사 시에 복원추출을 하지 않고 비복원 추출을 하기 때문에 초기하 분포를 주로 사용함 . &#52488;&#44592;&#54616; &#48516;&#54252;&#51032; &#54869;&#47456; &#51656;&#47049; &#54632;&#49688; . $f(x) = cfrac{_{k} , rm C ,_{x} ; times ; _{N-k} ; rm C ,_{n-x}}{_{N} , rm C ,_{n}} $ . - $N$개 중 $n$개를 뽑는 방법 중에서 성공 $k$개에서 $x$개의 성공을 뽑고 실패 $N-k$개에서 $n-x$개의 실패를 뽑을 확률 . &#52488;&#44592;&#54616; &#48516;&#54252;&#51032; &#44592;&#45843;&#44050;&#44284; &#48516;&#49328; . - $E(X)=n cdot cfrac{k}{N}$ . - $Var(X)= n cdot cfrac{k}{N} cdot cfrac{N-k}{N} cdot cfrac{N-n}{N-1}$ . - 이항분포의 기댓값과 분산과 유사함 . - n은 표본크기, $ cfrac{k}{N}$은 성공확률, $ cfrac{N-k}{N}$은 실패확률 . - $ cfrac{N-n}{N-1}$은 유한모집단수정항으로 $n$는 대체로 1보다 크므로 유한모집단수정항도 1보다 작음 &gt; 이항분포보다 분산이 더 작음 . &#52488;&#44592;&#54616; &#48516;&#54252; plot . import numpy np.random.hypergeometric(ngood, nbad, nsample, size) . - $ngood(=k)$은 유한모집단중 성공횟수, $nbad(=N-k)$는 유한모집단중 실패횟수, $nsample(=n)$은 표본크기, size는 표본의 수 . np.random.hypergeometric(ngood=700, nbad=300, nsample=100, size=1000) . - 성공횟수 ngood = 700개와 실패횟수 nbad = 300개로 구성된 크기가 1000인 유한모집단($N$)에서 샘플 nsample = 100개를 비복원추출하여 나온 성공횟수 $x$를 size = 1000번 반복한다 . - 당첨용지 700개($ngood = 700$)와 꽝용지 300개($nbad = 300$)로 구성된 로또용지 1000개(유한모집단의 크기$N$)중에서 100개($nsample = 100$)를 비복원추출하여 나온 성공횟수를 $size = 1000$번 기록한다 . - np.random.hypergeometric(ngood=700, nbad=300, nsample=100, size=1000)을 히스토그램으로 나타내면? . import numpy as np import matplotlib.pyplot as plt np.random.seed(1) sample = np.random.hypergeometric(ngood=700, nbad=300, nsample=100, size=1000) plt.hist(sample, bins=30) plt.title(&quot;np.random.hypergeometric(ngood=700, nbad=300, nsample=100, size=1000)&quot;) plt.show() . - 이항분포와 유사해 보임 .",
            "url": "https://jaesu26.github.io/study-blog/statistics/2021/06/30/%ED%99%95%EB%A5%A0%EB%B6%84%ED%8F%AC.html",
            "relUrl": "/statistics/2021/06/30/%ED%99%95%EB%A5%A0%EB%B6%84%ED%8F%AC.html",
            "date": " • Jun 30, 2021"
        }
        
    
  
    
        ,"post46": {
            "title": "깃허브 데스크탑",
            "content": "&#44611;&#54728;&#48652; &#45936;&#49828;&#53356;&#53457; &#51060;&#50857;&#54644;&#49436; &#52964;&#48139;&#54616;&#44592; . 1. 처음에 레포지토리 선택할 때 정보를 저장할 폴더 경로를 선택한다 . 2. 나의 경우에는 &quot;C:/Users/HANJAESU/github_desktop/study-blog&quot; 이다 . 3. study-blog 폴더에 가보면 _notebooks 폴더가 있는데 거기서 작업한 주피터 노트북 파일은 깃허브 데스크탑 changes에 표시된다 . 4. 커밋할 파일 하나를 클릭하고 하단에 메시지를 같이 남긴다 . 5. 변동 내역 메시지를 작성하고 커밋을 했으면 마지막으로 푸쉬를 한다 . 6. 깃허브에 변동 내역이 저장된다 . - 아무 것도 변경하지 않고 save만 해도 깃허브 데스크탑 changes에서 감지된다 . - 아무 것도 변경하지 않았는데 커밋이 된다는 의미 &gt; 아무짝에도 쓸모 없다 &gt; 이런 경우에는 커밋을 하지 말고 냅두자 . - 파일이 제대로 푸쉬가 안됐다면? &gt; 깃허브 _notebook 파일에 있는 history를 보자 . - 만약 빨간색으로 $ times$표시가 되어있다면 클릭 &gt; error메시지를 볼 수 있음 &gt; 이를 보고 오류 수정 하면 됨 . &#51089;&#50629; &#44277;&#44036; . - 이제부터 작업은 나의 깃허브 레포지토리(study-blog) 저장 폴더인 study-blog에 있는 _notebooks에서 해야 한다 . - 만약 &quot;C:/Users/HANJAESU/github_desktop/study-blog/_notebooks&quot; 에서 작업하지 않으면 깃허브 데스크탑 changes에 기록되지 않는다 . Liquid Exception: Liquid syntax error . - Jekyll에서 사용되는 liquid는 {{ 와 }}를 escape 문자로 사용 &gt; 마크다운에 {{ 과 }}이 있으면 커밋이 error가 나고 {{ 과 }} 사이에 있는 내용은 무시됨 . - 해결 방법 &gt; 여는 중괄호 앞에 {% raw %}를 닫는 중괄호 뒤에 {% endraw %}를 추가함 . - 참고: Liquid syntax error 해결 . - 참고: How to escape liquid template tags . Latex math alignment not working . - Liquid syntax error를 예상하고 {% raw %}와 {% endraw %}를 사용했는데 오류가 발생했음 . - Liquid Exception: Liquid syntax error (line 732): Unknown tag &#39;endraw&#39; . - 뭐가 문제인지 삽질하다가 {% raw %}와 {% endraw %}를 모두 없앴는데 오류가 해결됨 . - 교훈 : 미리 사용하지 말고 오류가 발생하면 사용하자 . - 그런데 또 다른 문제가 생겼다 &gt; 블로그에 수식이 랜더링되지 않음 . - 수식을 등호를 기준으로 정렬하려고 begin{align} ~ end{align} 을 사용했는데 이게 문제를 일으킴 . - 찾아보니 align 대신 aligned를 사용하면 된다고 한다 . - ref : https://github.com/fastai/fastpages/issues/439 . YAML Exception: found character that cannot start any token . - YAML에서 @와 같은 특정 문자를 사용할 때 에러가 발생할 수 있음 . - 나의 경우 데코레이터를 설명하고자 title에 @를 사용했는데 에러가 발생했다 . - @이 포함된 문장을 따옴표로 감싸주니 에러가 사라졌다 . &#44611;&#54728;&#48652; &#49436;&#48260; &#50724;&#47448; &#54869;&#51064; . - 깃허브 데스크탑으로 커밋을 하려는데 오류가 발생했음 . - 왜 그런가 찾아보니 내 문제가 아니라 서버 문제였다 . - 갑자기 오류가 생겼는데 내 문제가 아닌 것 같으면 서버 상태를 확인해보자 . - site: 깃허브 서버 오류 확인 .",
            "url": "https://jaesu26.github.io/study-blog/github/2021/06/26/%EA%B9%83%ED%97%88%EB%B8%8C-%EB%8D%B0%EC%8A%A4%ED%81%AC%ED%83%91.html",
            "relUrl": "/github/2021/06/26/%EA%B9%83%ED%97%88%EB%B8%8C-%EB%8D%B0%EC%8A%A4%ED%81%AC%ED%83%91.html",
            "date": " • Jun 26, 2021"
        }
        
    
  
    
        ,"post47": {
            "title": "리스트 처리",
            "content": "&#47532;&#49828;&#53944; &#51221;&#47148; . sort &#54632;&#49688;&#50752; sorted&#54632;&#49688; . - ?.sort 함수는 list타입인 ? 의 요소를 오름차순으로 정렬한다 . - ?.sort(reverse = True)함수는 내림차순으로 정렬한다 . - sort함수와 sorted함수는 거의 같다 . - ?.sort() 함수는 ?의 속성을 바꾸지만 sorted() 함수는 ?의 속성을 바꾸지 않는다 (a.append()와 + 연산의 차이) . a = [1, 5, 2, 3, 7, 4] print(a) . [1, 5, 2, 3, 7, 4] . a.sort() print(a) . [1, 2, 3, 4, 5, 7] . a.sort(reverse = True) print(a) . [7, 5, 4, 3, 2, 1] . - sort, sorted의 key 옵션에 지정된 함수의 결과에따라 정렬한다 . - lambda함수(익명 함수) 사용 &gt; lambda 매개변수: 결과 . b = [(1, 2), (0, 2), (1, 3), (1, 5), (0, 1), (2, 8)] c = sorted(b, key = lambda x: (x[0], -x[1])) ## x[1]앞에 있는 &#39;-&#39;기호는 현재정렬순서와 반대로이다 print(c) ##첫 번째 원소는 오름차순, 두 번째 원소는 내림차순으로 정렬 . [(0, 2), (0, 1), (1, 5), (1, 3), (1, 2), (2, 8)] . reverse &#54632;&#49688; . - ?.reverse 함수는 list형태인 ? 의 요소를 역순으로 정렬한다 . d = [1, 5, 2, 3, 7, 4] d.reverse() print(d) . [4, 7, 3, 2, 5, 1] . reversed &#54632;&#49688; . - reversed 함수는 요소를 역순으로 정렬해 반환한다 . - 반환값을 그대로 사용하지 않고 list()나 tuple()함수를 통해 사용한다 . d = [1, 5, 2, 3, 7, 4] reversed(d) . &lt;list_reverseiterator at 0x179d8c11f10&gt; . d = [1, 5, 2, 3, 7, 4] print(tuple(reversed(d))) . (4, 7, 3, 2, 5, 1) . &#47532;&#49828;&#53944; &#52488;&#44592;&#54868; . 1&#52264;&#50896; &#47532;&#49828;&#53944; . a = [] ## 빈 리스트로 초기화 print(a) . [] . A = [x] * n . - $A = [x, x, x, cdots, x, x] longrightarrow$ $x$가 $n$개인 $1$차원 리스트 . a = [0]*10 ## 0리스트로 초기화 print(a) . [0, 0, 0, 0, 0, 0, 0, 0, 0, 0] . 2&#52264;&#50896; &#47532;&#49828;&#53944; . n = 5 list_ = [[0] * n for _ in range(n)] ## 0으로 채원진 2차원 리스트 . list_ . [[0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0]] . list_[0][0] = 123 . list_ . [[123, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0]] . List = [[0] * 5 for _ in range(5) . - 그런데 _ 는 뭐지? . - 사실 _ 자리에 다른 것이 들어가도 된다 이를 테면 i . x = [0*i for i in range(5)] print(x) . [0, 0, 0, 0, 0] . - 위에 List에서 _ 대신에 i를 넣는다고 생각하자 . List = [[0] * 5 for i in range(5) . - 위에 리스트인 x 에서는 i가 리스트 안에 0을 몇 개 생성할 지 정하는 변수였다 . - 위에 리스트인 List 에서는 i가 무슨 역할을 하지?? . - 아무역할도 하지 않는다 . - 0을 5개 생성하고 이를 5번 반복한다 . - List를 정의할 때 부터 정해졌다 . - i는 그저 for문을 쓰기 위해 필요함 &gt; range(5)의 값을 받아낼 변수가 필요하다 . - 그래서 i 자리에 오는 변수는 아무짝에도 쓸모가 없다 . - 아무 의미가 없어서 그냥 아무 의미 없어보이는 기호인 _를 쓴다(내 생각) . &#47532;&#49828;&#53944; &#52628;&#44032; . ?.append() . - ? &gt; 리스트 . - 마지막(?[-1]) 위치에 하나의 원소 추가 . a = [] a.append(1) print(a) . [1] . ?.insert(i, v) . - i 위치에 v 원소 추가 . b = [1, 2, 3, 5, 6, 7] b.insert(3,4) print(b) . [1, 2, 3, 4, 5, 6, 7] . ?.extend() . - 마지막(?[-1]) 위치에 리스트 추가 . c = [1, 2, 3, 4, 5] c.extend([6, 7, 8]) print(c) . [1, 2, 3, 4, 5, 6, 7, 8] . ?.pop() . - pop(i)는 리스트의 i번째 요소를 돌려주고 그 요소는 삭제, pop() = pop(-1) . d = [1, 2, 3, 4 ,5] x = d.pop() print(x) print(d) . 5 [1, 2, 3, 4] . arr[::] &#50857;&#48277; . - 슬라이싱 방법임 . - arr[A:B:C] &gt; index A부터 index B(포함X)까지 C간격으로 arr 생성 . - A가 none이면 처음부터 B가 none이면 끝까지 C가 none이면 1만큼 . - 참고: https://docs.python.org/release/2.3.5/whatsnew/section-slices.html . arr = list(range(10)) print(arr) . [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] . arr[1:9:2] . [1, 3, 5, 7] . arr[:10:3] . [0, 3, 6, 9] . arr[1::2] ## arr[1:2]와 결과가 동일함 . [1, 3, 5, 7, 9] . arr[1:5:] . [1, 2, 3, 4] . arr[5::] ## arr[5:]과 결과가 동일함 . [5, 6, 7, 8, 9] . arr[5:] . [5, 6, 7, 8, 9] . arr[:3:] . [0, 1, 2] . arr[::4] ## arr[:4]와 결과가 동일함 . [0, 4, 8] . arr[:4] . [0, 1, 2, 3] . arr[::] ## arr[:]과 결과가 동일함 . [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] . arr[:] . [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] . &#45796;&#52264;&#50896;&#50640;&#49436;&#51032; &#49324;&#50857; . - 다차원 matrix에서의 사용도 동일함 . - 리스트에서 [ ]를 영역마다 사용하여 슬라이싱 &gt; ex) list[0:2][0:2][0:2] . - 참고: https://docs.scipy.org/doc/numpy-1.13.0/reference/arrays.indexing.html . arr1 = [[1, 2, 3], [2, 3, 4], [3, 4, 5]] ## arr1은 (3, 3)차원 ## arr1(a, b) &gt; a는 1차원 b는 2차원 &gt; a는 x축 b는 y축이라 생각해도 됨 arr1[0:2][0:2] ## x축에서 0~1까지, y축에서 0~1까지 리스트를 슬라이싱함 . [[1, 2, 3], [2, 3, 4]] . arr2 = [[[1, 2, 3], [2, 3, 4]], [[3, 4, 5], [4, 5, 6]], [[5, 6, 7], [6, 7, 8]]] arr2[0:2][0:2][0:2] ## x축에서 0~1까지, y축에서 0~1까지, z축에서 0~1까지 리스트를 슬라이싱함 . [[[1, 2, 3], [2, 3, 4]], [[3, 4, 5], [4, 5, 6]]] . arr2[:][1][0:2] ## x축에서 처음부터 끝까지, y축에서 1, z축에서 0~1까지 리스트를 슬라이싱함 . [[3, 4, 5], [4, 5, 6]] . numpy&#50640;&#49436;&#51032; &#49324;&#50857; . import numpy as np arr3 = np.array(arr2) print(arr3) . [[[1 2 3] [2 3 4]] [[3 4 5] [4 5 6]] [[5 6 7] [6 7 8]]] . arr3.shape ## arr3는 (3, 2, 3)차원의 matrix임 . (3, 2, 3) . - list에서는 [ ]를 영역마다 사용했지만 numpy array에서는 하나의 [ ] 안에서 표현 가능 . - numpy array에서는 콤마(,)로 영역을 구분하고 :를 통해 슬라이싱을 함 &gt; ex) numpy_array[0:2, 0:2, 0:2] . - list[0:2][0:2][0:2] &gt; 리스트에서 슬라이싱 . - arr[0:2, 0:2, 0:2] &gt; numpy array에서 슬라이싱 . - 둘다 의미는 x축에서 0~1까지, y축에서 0~1까지, z축에서 0~1까지 array를 슬라이싱하라는 뜻 . arr3[1, 1 ,1] ## 기본적인 인덱싱 방법 . 5 . arr3[0:2, 0:2, 0:2] ## x축에서 0~1까지, y축에서 0~1까지, z축에서 0~1까지 array를 슬라이싱함 . array([[[1, 2], [2, 3]], [[3, 4], [4, 5]]]) . arr3[:2, :1, :] ## x축에서 처음부터 1까지 y축에서 처음부터 0까지, z축에서 처음부터 끝까지 array를 슬라이싱함 . array([[[1, 2, 3]], [[3, 4, 5]]]) . - 어떤 array가 있는데 마지막 차원에서 인덱스가 마지막 번호인 array만 슬라이싱하고 싶다고 하자 . - 아래와 같이 해도 됨 . arr3[:, :, -1] ## 1차원의 모든 원소, 2차원의 모든 원소, 3차원은 마지막 원소만 가지는 array를 슬라이싱함 . array([[3, 4], [5, 6], [7, 8]]) . - numpy array에서는 ,를 통해 차원의 구분을 하고 :를 통해 슬라이싱을 함 . - 근데 차원이 매우 크다면? . - 예컨데 차원이 100차원이라면 일일이 :와 ,를 입력할 것인가? &gt; 궁금한건 마지막 차원에 대한 조건임, 더 작은 차원은 무관심 . - 어떻게 함?? &gt; ...(ellipsis)를 사용 . - ...은 우리가 일일이 입력해야할 앞의 차원에서의 :와 ,을 의미함 + ...을 뒤에 입력하면 뒤의 차원을 커버함 &gt; 하나의 [ ]안에서 한 개만 사용 가능 . arr3[..., -1] ## ...은 앞의 차원들의 원소를 모두 포함한다는 의미 . array([[3, 4], [5, 6], [7, 8]]) . arr3[..., 0:2] . array([[[1, 2], [2, 3]], [[3, 4], [4, 5]], [[5, 6], [6, 7]]]) . arr3[1, ...] ## 1차원에서 인덱스가 1인 array를 추출, 뒤에 차원들의 원소는 ...을 사용하여 모두 포함했음 . array([[3, 4, 5], [4, 5, 6]]) . &#49836;&#46972;&#51060;&#49905;&#51012; &#49324;&#50857;&#54644; &#51060;&#48120;&#51648;&#51032; RGB&#44050; &#44144;&#44984;&#47196;&#54616;&#44592; . - 이 문제 때문에 ellipsis에 대해 알아봄 . - OpenCV를 통해 이미지를 불러온다고 해보자 . - OpenCV에서는 컬러 이미지를 BGR 순서로 저장함 . - plt.imshow()로 이미지를 확인할 것임 . - 그런데 matplotlib에서는 RGB 순서로 저장함 &gt; RGB순서가 바뀜(흑백 사진은 괜찮음) . - 즉 OpenCV로 읽어온 이미지를 RGB순서로 바꿔야 함 . import matplotlib.pyplot as plt import cv2 as cv img = cv.imread(&#39;squirrel.jpg&#39;) plt.imshow(img) . &lt;matplotlib.image.AxesImage at 0x2737ecd7880&gt; . - cv.imread()를 통해 이미지를 읽어오는데 이 함수가 RGB순서가 아닌 BGR순서로 이미지를 읽어서 원본과 다르게 보이는 것임 . - 이미지도 숫자 matrix임 &gt; BGR순서만 RGB로 할 수 있을까? . - 만약 어떤 array가 있는데 나머지는 그대로 두고 마지막 차원의 원소의 순서만 반대로 하고 싶다면?? &gt; ...을 활용하자 . - img[..., ?]과 같이 하면 일단 마지막 차원의 원소를 제외하고 모두 그대로임 . - 이제 제어할 차원이 하나 남음 &gt; 벡터와 마찬가지 . - 1차원 array의 순서를 거꾸로 하려면??? &gt; array[ : : -1] &gt; 처음부터 끝까지 음의 방향으로 리스트 슬라이싱 . img2 = img[..., ::-1] plt.imshow(img2) ## 원본 이미지가 보임 . &lt;matplotlib.image.AxesImage at 0x2737ee0c340&gt; . - 원본 이미지가 제대로 보임 . - ref: https://stackoverflow.com/questions/50963283/python-opencv-imshow-doesnt-need-convert-from-bgr-to-rgb . - ref: https://ko.wikipedia.org/wiki/%EB%8B%A4%EB%9E%8C%EC%A5%90 . &#47532;&#49828;&#53944; &#49325;&#51228; . ?.remove(x) . - 리스트에서 x원소를 삭제 . - 삭제할 원소가 없을 시 error . a = [1, 2, 3, 4, 5, 6] a.remove(1) print(a) . [2, 3, 4, 5, 6] . a.remove(10) . ValueError Traceback (most recent call last) &lt;ipython-input-2-72b3315abecc&gt; in &lt;module&gt; -&gt; 1 a.remove(10) ValueError: list.remove(x): x not in list . &#47928;&#51088;&#50676; &#54252;&#54632;&#50668;&#48512; . ?.find(&#39;&#47928;&#51088;&#50676;&#39;) . - ?에 문자열이 존재하면 가장 앞에 원소의 시작 인덱스 값을 반환하며 존재하지 않으면 -1값을 반환 . day = &#39;2021-07-03&#39; . day.find(&#39;2021&#39;) . 0 . day.find(&#39;-&#39;) . 4 . day.find(&#39;2222&#39;) . -1 . &#39;&#47928;&#51088;&#50676;&#39; in ? , &#39;&#47928;&#51088;&#50676;&#39; not in ? . - ?에 문자열이 존재하면 True 반환, 존재하지 않으면 False 반환, not in에 경우는 반대로 . day = &#39;2021-07-03&#39; . &#39;2021&#39; in day . True . &#39;-&#39; not in day . False . &#39;2222&#39; in day . False . list = [&#39;1011&#39;, &#39;2022&#39;, &#39;day&#39;, &#39;model&#39;] . &#39;2022&#39; in list . True . &#39;day&#39; not in list . False . &#39;month&#39; in list . False . enumerate &#54632;&#49688; . - for문을 사용할 때 인덱스를 같이 출력할 수 있음 . - 참고: 파이썬 for문 . cards = [&#39;A&#39;, &#39;B&#39;, &#39;C&#39;] for i in range(len(cards)): print(i, cards[i]) . 0 A 1 B 2 C . for value in enumerate(cards): print(value) . (0, &#39;A&#39;) (1, &#39;B&#39;) (2, &#39;C&#39;) . - enumerate 함수는 인덱스와 원소로 이루어진 tuple을 생성함 . - 만약 인덱스와 원소를 다른 변수로 만들고 싶다면 tuple unpacking을 사용하면 됨 . for idx, card in enumerate(cards): print(idx, card) . 0 A 1 B 2 C . zip &#54632;&#49688; . - zip 함수는 iterable한 객체들을 인자로 받아 각각의 원소를 tuple로 접근가능한 iterator를 만듦 . - 참고: python zip function . a = (&#39;John&#39;, &#39;Charles&#39;, &#39;Mike&#39;) b = (&#39;Jenny&#39;, &#39;Christy&#39;, &#39;Monica&#39;) zip(a, b) . &lt;zip at 0x179d8b6d100&gt; . list(zip(a, b)) . [(&#39;John&#39;, &#39;Jenny&#39;), (&#39;Charles&#39;, &#39;Christy&#39;), (&#39;Mike&#39;, &#39;Monica&#39;)] . tuple(zip(a, b)) . ((&#39;John&#39;, &#39;Jenny&#39;), (&#39;Charles&#39;, &#39;Christy&#39;), (&#39;Mike&#39;, &#39;Monica&#39;)) .",
            "url": "https://jaesu26.github.io/study-blog/python/2021/06/24/%EB%A6%AC%EC%8A%A4%ED%8A%B8-%ED%95%A8%EC%88%98.html",
            "relUrl": "/python/2021/06/24/%EB%A6%AC%EC%8A%A4%ED%8A%B8-%ED%95%A8%EC%88%98.html",
            "date": " • Jun 24, 2021"
        }
        
    
  
    
        ,"post48": {
            "title": "마크다운 용법",
            "content": "fastpages &#52852;&#53580;&#44256;&#47532; . - _notebook 폴더안에 파일을 만드는데 아래와 같은 형식을 준수하자 . 제목 &quot;부제목&quot; -toc: true -branch: master -badges: true -comments: true -author: 한재수 -categories: [Python] . - 위에 내용을 아무곳에나 붙여 넣는다, 부제목은 (&gt; &quot;부제목&quot;), 제목은 (# 제목) . - categories에 해당하는 부분이 깃허브 홈페이지에서 tag에 보이는 부분이다 . - categories에서 [ ] 안에 여러개를 추가 할 수 있다 ex) [Python, R, CSS] . &#48660;&#47196;&#44536; &#44288;&#47532; . 1. 깃허브 가입하기 . 2. fastai/fastpages 사용 . 3. 깃허브 데스크탑 이용 . (1) 주피터노트북으로 공부한다 . (2) 깃허브와 연결된 어떤 폴더(드랍박스 안의 green)에 공부한 내용을 넣는다 . (3) 깃허브 데스크탑이라는 프로그램을 이용하여 local(내 윈도우 컴퓨터)에서 remote (github)로 변경사항을 반영한다 . (4) 2~3분 뒤에 블로그 홈페이지에 반영된다 . (5) 공부한 내용을 편집없이 주피터 노트북 파일을 올리기만 하면 블로그에 올라가서 편하다 필요에 따라 숨기기, 비밀 포스트도 만들 수 있다 . - 수식을 제대로 입력했는데 블로그에서는 raw 수식 내용이 그대로 보인다면 text{ ... }안에 내용이 수식과 일반 텍스트로 심하게 혼용이 되어 있는지 보자 . - 일반 텍스트는 text{ }안에 적고 수식은 밖에 적으면 해결됨 &gt; 삽질해서 확인함 . &#44611;, &#44611;&#54728;&#48652; . - 버전 관리 시스템 . - 서로 코드를 공유 . - 혼자 쓰면 개인 저장소... . &#51452;&#54588;&#53552; &#45432;&#53944;&#48513; . &#50976;&#50857;&#54620; &#53412; . - 삭제한 셀 복원 &gt; Edit - Undo cell operation or Esc 후 z키 입력 . - 삭제한 코드 복원 &gt; Ctrl + z . - 주석처리 단축키 &gt; Ctrl + / (여러줄을 동시에 처리할려면 마우스로 스크롤하기) . &#51452;&#54588;&#53552; &#45432;&#53944;&#48513; &gt; remote &gt; page (&#50504; &#50732;&#46972;&#44040; &#49688; &#46020; &#51080;&#45796;) . - 깃허브 데스크탑 history에서 이제껏 했던 커밋을 볼 수 있다, 게다가 삭제된 파일을 복구할 수 도 있다 . - 화면 캡쳐 프로그램으로 캡쳐를 함 &gt; 마크다운에서 캡쳐한 이미지를 ctrl+v하면 캡쳐한 이미지가 삽입된다 . - 이미지 파일을 넣은 주피터 노트북 파일을 올리면 깃허브 notebook에는 올라가지만 블로그에는 올라가지 않는다 . &#47553;&#53356; &#49341;&#51077; . - 보통 링크 삽입은 [label](link)의 형식임 . - 그런데link에 )기호가 있으면 링크 연결에 문제가 있을 수 도 있음 . - [label][key] . - [key]: link . - 위와 같이 해도 링크 연결에 문제가 없고 위의 문제도 해결 가능함 . - 참고: 링크 연결 . &#49688;&#49885; &#44592;&#54840; &#54364;&#54788; . - 3.141592를 변수에 저장하고 싶음 . - pi = 3.141592 . - 그런데 pi 대신에 $ pi$를 사용하고 싶다면?? . - code셀에서 pi를 입력한 후 Tab을 누르면 됨 . pi = 3.141592 π = 3.141592 . pi . 3.141592 . π . 3.141592 . &#49472;&#51032; &#50577;&#45149;&#51004;&#47196; &#51060;&#46041; . - 키보드 위 키를 누르면 셀의 오른쪽 끝으로 이동함 . - 키보드 아래 키를 누르면 셀의 왼쪽 끝으로 이동함 . &#49688;&#49885;&#51012; &#47691;&#51080;&#44172; &#54364;&#54788;&#54616;&#44256; &#49910;&#45796;&#47732;?? . - $수식$ 꼴로 나타낸다. . - y = x^2 + 1 . - $y = x^2 +1$ . &#48145; &#52392;&#51088; &#54364;&#54788; . - $수식_밑첨자$ . - x_1 + x_2 = x_3 . - $x_1 + x_2 = x_3$ . $ sum$ &#54364;&#54788; . - limits 옵션을 통해 $ sum$의 시작과 끝의 위치를 $ sum$의 바로 위와 아래로 지정가능 . - $ sum_{n=1}^{ infty} frac{1}{n^2}$ . - $ sum limits_{n=1}^{ infty} frac{1}{n^2}$ . - mathop로 여러개의 sum을 { }로 감싸주면 글씨를 가운데에 표현 가능 . - $2 mathop{ sum sum} limits_{j&lt;k}Cov(X_j,X_k)$ &gt; mathop{ sum sum} limits_{j&lt;k} . &#48177;&#53552; &#54364;&#54788; . - 벡터 표현하기: 화살표, 볼드체 . - $X$는 변수 . - $ boldsymbol{X}, ; mathbf{X}, ; vec{~X~}$는 벡터 . &#50948;&#50500;&#47000;&#47196; &#51473;&#44292;&#54840; &#54364;&#54788; . - overbrace를 통해 위로 중괄호를 표현함 . - $x+x+x+ dots+x+x, ;x$를 $n$번 더함 . - underbrace를 통해 아래로 중괄호를 표현함 . - $x times x times x times dots times x times x, ;x$를 $n$번 곱함 . - $ overbrace{x + cdots + x}^{n rm times}$ . - $ underbrace{x times cdots times x}_{n rm times}$ . &#51216;&#52237;&#44592; . - s 제외하면 점 하나만 찍힘, s 포함하면 점 세개 찍힌다 . - dots &gt; $ dots$ . - cdots &gt; $ cdots$ . - ddots &gt; $ ddots$ . - vdots &gt; $ vdots$ . &#44292;&#54840; &#53356;&#44172; &#47564;&#46308;&#44592; . - big Big bigg Bigg 을 통해 괄호를 크게 만들 수 있음 . - $ big( Big( bigg( Bigg($ . - $ big[ Big[ bigg[ Bigg[$ . - $ big { Big { bigg { Bigg { $ . - 참고로 수식안에 들어가는 기호로서 중괄호 표현은 { 이다 . &#44544;&#50472; &#53356;&#44592; &#51312;&#51208; . - link : https://ko.overleaf.com/learn/latex/Font_sizes,_families,_and_styles . &#44060;&#54665; &#44036;&#44201; &#51312;&#51208; . - link : https://tex.stackexchange.com/questions/494582/spacing-of-newline-and . - 참고로 주피터노트북에서 보이는 간격이랑 블로그에서 보이는 간격이 다름 . &#49688;&#49885; &#49353;&#44628; &#48148;&#44984;&#44592; . - $x^2+1$ , $(x+1)^2$ . - ref : https://stackoverflow.com/questions/35465557/how-to-apply-color-in-markdown . &#47928;&#51088; &#50948;&#50640; &#47928;&#51088; &#54364;&#49884; . - ${H_0}^{ sim}$ &gt; {H_0}^{ sim} . - $ overset{ sim}{H_0}$ &gt; overset{ sim}{H_0} . - ref : https://tex.stackexchange.com/questions/43335/how-to-write-is-distributed-as-under-a-certain-hypothesis . &#49688;&#49885;&#51032; &#49884;&#51089; &#50948;&#52824;&#47484; &#46041;&#51068;&#54616;&#44172; &#54616;&#44256; &#49910;&#45796;&#47732;? . $$ frac{ partial boldsymbol L}{ partial beta_0} = - frac{1}{ sigma^2} sum limits^{n}_{i=1}(y_i- beta_0- beta_1 x_i)=0 frac{ partial boldsymbol L}{ partial beta_1} = frac{1}{ sigma^2} sum limits^{n}_{i=1}x_i(y_i- beta_0- beta_1 x_i)=0 frac{ partial boldsymbol L}{ partial beta_1} = - frac{n}{2 sigma^2}+ frac{1}{2 sigma^4} sum limits^{n}_{i=1}x_i(y_i- beta_0- beta_1 x_i)=0$$- begin{aligned} 와 end{aligned}를 사용하면 된다 . $$ begin{aligned} frac{ partial boldsymbol L}{ partial beta_0} &amp; = - frac{1}{ sigma^2} sum limits^{n}_{i=1}(y_i- beta_0- beta_1 x_i)=0 frac{ partial boldsymbol L}{ partial beta_1} &amp; = frac{1}{ sigma^2} sum limits^{n}_{i=1}x_i(y_i- beta_0- beta_1 x_i)=0 frac{ partial boldsymbol L}{ partial beta_1} &amp; = - frac{n}{2 sigma^2}+ frac{1}{2 sigma^4} sum limits^{n}_{i=1}x_i(y_i- beta_0- beta_1 x_i)=0 end{aligned}$$- ref: https://stackoverflow.com/questions/28353127/how-to-change-alignment-of-displayed-equations-in-ipython-notebook . - 방정식 끝에 라벨 매기기(R markdown): Hyperlink . &#50976;&#50857;&#54620; latex . boldsymbol . - applies to nearly all symbols, not just letters and numbers . - ex) $ boldsymbol{A} ,A$ . bf . - Used to turn on boldface; affects uppercase and lowercase letters, and digits . - ex) ${ bf 123} ,{123}$ . - ex) ${ bf A} ,{A}$ . therefore . - therefore를 통해 삼각형 모양 점3개를 만듦 . - $ therefore 1+1= text{힘든 삶}$ . bigcup . - 집합열을 포현할 때 합집합 기호의 밑과 위에 시작과 끝을 표시하고 싶다면 bigcup과 limits를 사용하자 . - $ cup_{i=1}^{ infty} A_i$ &gt; cup_{i=1}^{ infty} A_i . - $ bigcup_{i=1}^{ infty} A_i$ &gt; bigcup_{i=1}^{ infty} A_i . - $ bigcup limits_{i=1}^{ infty} A_i$ &gt; bigcup limits_{i=1}^{ infty} A_i . cfrac . - 일반적인 frac과의 차이점은 글씨의 크기임 . - $P(A|B) = frac{P(A cap B)}{P(B)}$ &gt; frac . - $P(A|B) = cfrac{P(A cap B)}{P(B)}$ &gt; cfrac . mid . - 수직선을 그려줌 &gt; 조건부 확률 표현할 때 사용 . - $P(A|B) = cfrac{P(A cap B)}{P(B)}$ &gt; | . - $P(A mid B) = cfrac{P(A cap B)}{P(B)}$ &gt; mid . xrightarrow . - 오른쪽방향의 화살표를 그려주는데 화살표위에 글씨를 적을 수 있다! . - 확률변수의 수렴을 표현할 때 사용할 수 있음 . - $X_n{ xrightarrow{p}} X$ &gt; X_n{ xrightarrow{p}} X : 확률수렴 . - 그런데 화살표길이가 더 길었으면 좋겠다 . - 그럴땐 ~ 기호를 이용하면 된다 . - $X_n{ xrightarrow{~~p~~}} X$ &gt; X_n{ xrightarrow{~~p~~}} X . - 아래처럼 할 수 도 있음 . - $X_n overset{p}{ longrightarrow}X$ &gt; X_n overset{p}{ longrightarrow}X . operatorname . - 이탤릭체인 글씨체를 변경 . - $ underset{x}{argmin}f(x)$ &gt; underset{x}{argmin}f(x) . - $ underset{x}{ operatorname{argmin}}f(x)$ &gt; underset{x}{ operatorname{argmin}}f(x) . &#47588;&#50864; &#50976;&#50857;&#54620; &#49324;&#51060;&#53944; . - &lt;Jupyter 노트북에서 Markdown 및 LaTeX을 작성하는 방법 알아보기 &gt; https://ichi.pro/ko/jupyter-noteubug-eseo-markdown-mich-latexleul-jagseonghaneun-bangbeob-al-abogi-18246612521469 . - latex command 총 정리 &gt; https://www.tutorialspoint.com/tex_commands/percentage.htm . - Table 편하게 생성하기 &gt; https://www.tablesgenerator.com/markdown_tables .",
            "url": "https://jaesu26.github.io/study-blog/github/markdown/jupyter/latex/2021/06/24/markdown-in-latex.html",
            "relUrl": "/github/markdown/jupyter/latex/2021/06/24/markdown-in-latex.html",
            "date": " • Jun 24, 2021"
        }
        
    
  
    
        ,"post49": {
            "title": "map 함수",
            "content": "map &#54632;&#49688; &#53945;&#51669; . - 여러 개의 데이터를 한 번에 다른 형태로 변화하기 위해 사용한다. . - map 함수는 원본 리스트를 변경하지 않고 새 리스트를 생성한다. . - map 함수는 map 타입으로 결과를 리턴하기 때문에 리스트나 튜플 등으로 변환해야 한다. . - map 함수는 리스트의 요소를 지정된 함수로 처리한다. . x = list(range(5)) x . [0, 1, 2, 3, 4] . def two_times(x): return x * 2 . y = two_times(x) y . [0, 1, 2, 3, 4, 0, 1, 2, 3, 4] . z = list(map(two_times, x)) z . [0, 2, 4, 6, 8] . map &#54632;&#49688; &#49324;&#50857;&#48277; . - map(함수, 반복가능한 객체) . x = [1.1, 2.1, 3.1, 4.1] y = map(int, x) print(y) . &lt;map object at 0x0000023B6D93D040&gt; . - map 함수는 map 타입으로 결과를 리턴하기 때문에 리스트나 튜플 등으로 변환한다. $ rightarrow [ star$] 변환하지 않으면 위와 같은 결과를 출력한다. [$ star$] . - print(y)하지 않고 그냥 y만 입력해도 된다. . x = [1.1, 2.1, 3.1, 4.1] y = list(map(int, x)) y . [1, 2, 3, 4] . def minus(a): return a - 0.1 . list(map(minus, x)) . [1.0, 2.0, 3.0, 3.9999999999999996] . - minus 함수는 map 함수를 위해 한 번 쓰고 버려질 운명이다. 만드는게 귀찮음... . map &#54632;&#49688;&#50640; &#46988;&#45796; &#49885; &#49324;&#50857; . x = [1.1, 2.1, 3.1, 4.1] list(map(lambda a: a - 0.1, x)) . [1.0, 2.0, 3.0, 3.9999999999999996] . input().split()&#44284; map . - input()함수는 c언어의 scanf()함수와 비슷하다. . z = input() . z . &#39;hello&#39; . - input()으로 입력받은 값은 문자열이다. . n = input() . type(n) . str . - input()함수에서 안내문구를 추가할 수 도 있다. . Q = input(&#39;숫자 하나를 입력하세요:&#39;) . Q . &#39;26&#39; . - input()함수의 출력값을 문자열이 아닌 다른 자료형으로 바꾸고 싶다면? . w = int(input(&#39;숫자 하나를 입력하세요:&#39;)) . type(w) . int . - input().split(&quot;기준문자열&quot;)을 사용하면 입력값을 변수 여러 개에 저장할 수 있다. . - split()에서 &quot;기준문자열&quot;이 없는 즉 default는 공백이다. . a, b = input().split() # 입력받은 값을 공백(스페이스, 탭, 엔터 등)을 기준으로 분리 . a, b . (&#39;10&#39;, &#39;20&#39;) . c = a, b type(c) . tuple . - a와b가 문자열이다. . - int형으로 바꾸고 싶다면? . a, b = int(input().split()) . TypeError Traceback (most recent call last) &lt;ipython-input-17-0de5d52cb787&gt; in &lt;module&gt; -&gt; 1 a, b = int(input().split()) TypeError: int() argument must be a string, a bytes-like object or a number, not &#39;list&#39; . - int()함수를 쓰면 될 것 같았는데 오류가 나온다 . - error메시지를 읽어보니 int()함수는 무조건 a string, a bytes-like object or a number 여야 한다.(not &#39;list&#39;) . - a, b는 tuple인 것 같다. . - 그러면 어떻게 하지? $ longrightarrow$ map()함수를 쓰면 된다. . a, b = map(int, input().split()) # 입력받은 값을 정수로 변환 . a, b . (10, 20) . type(a) . int . type(b) . int . - a, b = map(int, input().split())을 풀어서 쓰면 다음과 같은 코드이다. . x = input().split() # input().split()의 결과는 문자열 리스트 m = map(int, x) # 리스트의 요소를 int형으로 변환, 결과는 맵 객체 a, b = m # 맵 객체는 변수 여러 개에 저장 가능 . map()&#54632;&#49688; &#51060;&#50857;&#54644; &#54620; &#51460;&#50640; &#50668;&#47084; &#44050; &#51077;&#47141; &#48155;&#44592; . L = list(map(int, input().split())) L . [10, 8, 7, 1, 0, 3, 5, 2] . map()&#54632;&#49688; &#51060;&#50857;&#54644; &#50668;&#47084; &#51460;&#50640; &#50668;&#47084; &#44050; &#51077;&#47141; &#48155;&#44592; . data = [] N = int(input()) for i in range(N): data.append(list(map(int, input().split()))) . data . [[1, 4, 0, 2], [17, 8, 1, 0, 4, 6], [1, 0], [0, 4, 5], [0, 0, 10]] .",
            "url": "https://jaesu26.github.io/study-blog/python/2021/06/21/map%ED%95%A8%EC%88%98.html",
            "relUrl": "/python/2021/06/21/map%ED%95%A8%EC%88%98.html",
            "date": " • Jun 21, 2021"
        }
        
    
  
    
        ,"post50": {
            "title": "파이썬 기말시험",
            "content": "- 문제 : 시험 문제 . import pandas as pd import numpy as np . 1&#48264; &#47928;&#51228; . class execution_sword(): def __init__(self): self.upgradestate = pd.DataFrame({&quot;day0&quot;: [0] * 100}) self.prob = 0.3 self.day = 0 def add_day(self): self.day = self.day + 1 def attempt(self): self.attemptresult = np.random.binomial(n=1, p=self.prob, size=100) def update(self): self.upgradestate[&quot;day%s&quot; % self.day] = np.minimum(self.upgradestate[&quot;day%s&quot; % (self.day - 1)] + self.attemptresult, 5) # +5이후로는 증가하지 않는다 self.ratio = sum(self.upgradestate.loc[:, &quot;day%s&quot; % self.day] == 5) / 100 def return_ratio(self): return self.ratio # ratio(성공한 사람 수 / 전체 사람 수)를 리턴한다 . # 1-(1) test1 = execution_sword() for test1.day in range(1, 63): test1.attempt() test1.update() 100 * test1.ratio # 62일후 100명중 몇명이 +5강화 상태인가? # 시뮬레이션 결과 100명이였다 . 100.0 . - 위에처럼 test.day를 함수 외부에서 조작하는 것은 좋지 않다 . - 마찬가지로 test1 클래스의 멤버변수(ratio)에 직접 접근하는 것도 좋지 않다 . - 이를 조작할 수 있는 함수를 새로 만들고 코드를 다시 구현하자 . test_1 = execution_sword() for k in range(1, 63): test_1.add_day() test_1.attempt() test_1.update() 100 * test_1.return_ratio() . 100.0 . 2&#48264; &#47928;&#51228; . class execution_sword2(execution_sword): def __init__(self): super().__init__() self.prob = 0.7 self.failstate = pd.DataFrame({&quot;day0&quot;: [0] * 100}) def update(self): super().update() self.failstate[&quot;day%s&quot; % self.day] = self.failstate[&quot;day%s&quot; % (self.day - 1)] + (self.attemptresult == 0) * 1 for j in range(100): if self.upgradestate.iloc[j, self.day] == 0: self.failstate.iloc[j, self.day] = self.failstate.iloc[j, self.day] - 1 # i-1번째 + 강화시도(0 or 1) = i번째 # i, i-1번째 강화상태가 0이라는 의미는 i-1째에 시도한 강화가 실패했다는 의미 # upgradestate가 0이라는 의미는 실패했다는 것이므로 실패횟수가 하나 쌓인다 # +0에서는 실패횟수가 쌓이지 않으므로 failstate값을 하나 뺀다 if (self.upgradestate.iloc[j, self.day] == 5) and (self.attemptresult[j] == 0): self.failstate.iloc[j, self.day] = self.failstate.iloc[j, self.day] - 1 # i-1번째 + 강화시도(0 or 1) = i번째 # i번째가 +5강화이면서 i-1번째 시도한 강화가 실패라는 의미는 # i-1번째가 +5강화였다는 의미이다. 그러므로 i번째 실패횟수가 +1 됐을것이다 # +5강화에서는 강화를 도전하지 않을 것이다 # 그러므로 i번째 실패횟수를 1을 감소시킨다 # +5에서는 강화를 시도하지 않을것이므로 # 만약 실패했다면 failstate값을 하나 뺀다 def reset(self): for j in range(100): if (self.upgradestate.iloc[j, self.day] &gt; 0) and (self.upgradestate.iloc[j, self.day] &lt; 5): if self.failstate.iloc[j, self.day] == 2: self.failstate.iloc[j, self.day] = 0 self.upgradestate.iloc[j, self.day] = 0 # 실패스택이 2라면 실패스택을 0으로 바꾸고 강화상태를 +0으로 바꾼다 def arrangeprobt(self): if self.ratio &gt;= 0.5: self.prob = 0.9 # +5강 비율이 50%이상이라면 전체유저의 강화 성공확률을 90%로 바꾼다 @property def return_ratio(self): return self.ratio . - 위에서 멤버변수 ratio를 반환하는 return_ratio라는 함수를 만들었다 . - 그런데 전에는 인스턴스.ratio를 사용했는데 이제는 인스턴스.return_ratio()를 써야한다 . - 전에 사용하던 것처럼 값으로 쓰고싶다(괄호를 생략하여 메소드를 값처럼 사용하고 싶다) . - @property를 사용! . # 2-(1) test2 = execution_sword2() for k in range(1, 63): test2.add_day() test2.attempt() test2.update() test2.reset() 100 * test2.return_ratio # 괄호 생략 가능, 그런데 메소드 이름이 return_ratio라 괄호가 있는 것이 자연스러운 것 같음 # 시뮬레이션 결과 100명이였다 . 100.0 . # 2-(2) test3 = execution_sword2() for k in range(1, 32): test3.add_day() test3.attempt() test3.update() test3.reset() 100 * test3.return_ratio # 31일후 100명중 몇명이 +5강화 상태인가? # 시뮬레이션 결과 99명이였다 . 99.0 . # 2-(3) test4 = execution_sword2() for k in range(1, 63): test4.add_day() test4.attempt() test4.update() test4.reset() test4.arrangeprobt() 100 * test4.return_ratio # 과반수가 +5강화 일때 성공확률을 0.9로 바꾼다, 62일후 100명중 몇명이 +5강화 상태인가? # 시뮬레이션 결과 100명이였다 . 100.0 . 3&#48264; &#47928;&#51228; . - 다음문장을 잘 읽고 참 거짓을 판단하여라 (10점) . 1. tuple은 원소의 값을 임의로 바꿀 수 있다 &gt; 거짓 . 2. class 에 정의된 함수(=메서드)는 self 만을 인자로 받을수 있다 &gt; 거짓 .",
            "url": "https://jaesu26.github.io/study-blog/python/2021/06/18/%ED%8C%8C%EC%9D%B4%EC%8D%AC%EC%9E%85%EB%AC%B8-%EA%B8%B0%EB%A7%90%EC%8B%9C%ED%97%98.html",
            "relUrl": "/python/2021/06/18/%ED%8C%8C%EC%9D%B4%EC%8D%AC%EC%9E%85%EB%AC%B8-%EA%B8%B0%EB%A7%90%EC%8B%9C%ED%97%98.html",
            "date": " • Jun 18, 2021"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "학력 . - 전북대학교 통계학과 4-1 (7학기 이수), 현재 휴학 중 . 학부 성적 . - 전체 평점: 4.43 . - 전공 평점: 4.47 . 수상 내역 . - 2022 월간 데이콘 숫자 3D 이미지 분류 AI 경진대회 수상 . - 2022 제2회 K-water AI 경진대회 수돗물 수요예측 AI 알고리즘 개발 장려상 . - 2023년 전북대학교 SW중심대학사업 인공지능 경진대회 금상 . - 총장상 (성적우수상) . 프로젝트 . - 데이콘 Basic 대회 . - 국민건강보험공단 건강검진정보 공공데이터를 활용한 통계 분석 . - 사람로 명언 텍스트 마이닝 . - 데이콘 신용카드 사기 거래 탐지 AI 경진대회 . - 데이콘 2022 관광데이터 AI 경진대회 . - 2022 국립국어원 인공 지능 언어 능력 평가 . - 데이콘 유전체 정보 품종 분류 AI 경진대회 . 오픈 소스 . - https://github.com/Jaesu26/textmentations . - https://github.com/Jaesu26/vime . 프로그래밍 언어 . - Python ($ star star star$) . 자격증 . - 컴퓨터활용능력 1급 .",
          "url": "https://jaesu26.github.io/study-blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://jaesu26.github.io/study-blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}